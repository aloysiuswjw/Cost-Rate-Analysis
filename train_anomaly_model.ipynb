{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "df = pd.read_csv('CR_COST_FC.csv', converters={'PARTY_ID': str, 'COM_ID': str, 'CNTR_SIZE': str})\n",
    "df['POD'] = pd.to_datetime(df['POD'])\n",
    "df['ENCODED_TYPE'] = df['ENCODED_TYPE'].fillna(-1).astype(int)\n",
    "df = df.dropna(subset=['ENCODED_TYPE'])\n",
    "df['RATE'] = df['RATE'].fillna(-1).astype(int)\n",
    "df = df.dropna(subset=['RATE'])\n",
    "df['ENCODED_TYPE'] = df['ENCODED_TYPE'].astype(int)\n",
    "\n",
    "# Remove NAN values\n",
    "df_clean= df.dropna().reset_index(drop=True)\n",
    "\n",
    "df_clean.head()\n",
    "df_clean.info()\n",
    "print(f'Dataset size: {df_clean.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['CNTR_SIZE'] = df_clean['CNTR_SIZE'].astype(np.int32)\n",
    "df_clean['RATE'] = df_clean['RATE'].astype(np.int32)\n",
    "df_clean['PARTY_ID_EN'] = df_clean['PARTY_ID_EN'].astype(np.int32)\n",
    "df_clean['POD_ID_EN'] = df_clean['POD_ID_EN'].astype(np.int64)\n",
    "df_clean['ETA_ETD_NO'] = df_clean['ETA_ETD_NO'].astype(np.int32)\n",
    "df_clean.info()\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_col = ['COM_ID','CSL_ID', 'CNTR_ID','ENCODED_TERM','COST_TERM','POD_ID','ETD_POL_D','PARTY_ID',\n",
    "           'PARTY_ID_EN', 'PARTY_NAME','POD_ID_EN','ETA_ETD_NO','POD',\n",
    "           'CNTR_SIZE','ENCODED_TYPE','CNTR_TYPE','RATE']\n",
    "\n",
    "df_fc = df_clean[sel_col]\n",
    "df_fc.head()\n",
    "df_fc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out rows where the year is 2002\n",
    "df_filtered = df_fc[df_fc['POD'].dt.year != 2002]\n",
    "df_filtered.head()\n",
    "df_filtered.info()\n",
    "\n",
    "# Checking if year 2002 is removed\n",
    "df_filtered['POD'].dt.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.sort_values(by='POD').reset_index(drop=True)\n",
    "df_filtered.head()\n",
    "df_filtered['POD'].dt.year.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>FIltering and getting a list stored as a dictionary</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe(df):\n",
    "    filtered_dataframes = {}\n",
    "\n",
    "    for (port, size, ctype, party_id), group in df.groupby(['POD_ID', 'CNTR_SIZE', 'CNTR_TYPE', 'PARTY_ID']):\n",
    "        group = group.reset_index().sort_values(by='POD')\n",
    "        df_id = f\"Port_{port}_Size_{size}_Type_{ctype}_PartyID_{party_id}\"\n",
    "        filtered_dataframes[df_id] = group\n",
    "\n",
    "    return filtered_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataframes = filter_dataframe(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ids = list(filtered_dataframes.keys())\n",
    "print(list(df_ids))\n",
    "print(len(list(df_ids)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_df = filtered_dataframes['Port_AUCKLAND_Size_40_Type_HC_PartyID_01005136']\n",
    "# grouped_df.head()\n",
    "# grouped_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Training Isolation Forest with all historical data for anomaly</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(filtered_dataframes):\n",
    "    # Initialize a dictionary to store the trained models and their evaluation scores\n",
    "    trained_models = {}\n",
    "    scores = {}\n",
    "\n",
    "    # Train an IsolationForest model on each dataframe and evaluate its performance using cross-validation\n",
    "    for key, group in filtered_dataframes.items():\n",
    "        # Create an IsolationForest model\n",
    "        model = IsolationForest(n_estimators=100, contamination='auto', random_state=42)\n",
    "\n",
    "        # Evaluate the model using cross-validation\n",
    "        scores[key] = cross_val_score(model, group[['RATE']], cv=5, scoring='f1_macro')\n",
    "\n",
    "        # Fit the model to the dataframe\n",
    "        model.fit(group[['RATE']])\n",
    "\n",
    "        # Store the trained model\n",
    "        trained_models[key] = model\n",
    "\n",
    "    # Select the model with the highest evaluation score\n",
    "    best_model_key = max(scores, key=scores.get)\n",
    "    best_model = trained_models[best_model_key]\n",
    "\n",
    "    # Return the best model\n",
    "    return best_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation can be used for evaluating the performance of an Isolation Forest algorithm for anomaly detection, but it's not always the best option.\n",
    "\n",
    "Isolation Forest is an unsupervised learning algorithm, which means that there are no labels available to evaluate its performance in a traditional supervised learning sense. In this case, cross-validation can be used to evaluate the stability of the algorithm and its ability to detect anomalies in new, unseen data.\n",
    "\n",
    "However, cross-validation assumes that the data is independently and identically distributed (i.i.d.), which may not always be the case in practice, especially when dealing with time series data. In such cases, a more appropriate evaluation method may be to use a sliding window approach, where the model is trained on a fixed window of past data and evaluated on a sliding window of future data.\n",
    "\n",
    "Another evaluation metric that can be used for Isolation Forest is the area under the Receiver Operating Characteristic (ROC) curve (AUC-ROC). AUC-ROC is a measure of how well the model can distinguish between normal and anomalous data points, and can be useful when evaluating the performance of anomaly detection algorithms.\n",
    "\n",
    "In summary, while cross-validation can be useful for evaluating the performance of an Isolation Forest algorithm, it's not always the best option, and other evaluation metrics and methods should also be considered depending on the specific use case and data characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = train_isolation_forest(filtered_dataframes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
