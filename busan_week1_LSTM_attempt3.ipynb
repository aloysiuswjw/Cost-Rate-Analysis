{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dropout, LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.optimizers import Adam\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Importing Datasets</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset and clean, ready as a dataframe for creating keys\n",
    "def createDF(datasets):\n",
    "    df = pd.read_csv(datasets, converters={'PARTY_ID': str, 'COM_ID': str, 'CNTR_SIZE': str})\n",
    "\n",
    "    # Formating to type and remove NaN values\n",
    "    df['POD'] = pd.to_datetime(df['POD'])\n",
    "    df['ENCODED_TYPE'] = df['ENCODED_TYPE'].fillna(-1).astype(int)\n",
    "    df = df.dropna(subset=['ENCODED_TYPE'])\n",
    "    df['RATE'] = df['RATE'].fillna(-1).astype(float)\n",
    "    df = df.dropna(subset=['RATE'])\n",
    "    df['ENCODED_TYPE'] = df['ENCODED_TYPE'].astype(int)\n",
    "    df_clean= df.dropna().reset_index(drop=True)\n",
    "\n",
    "    # Selecting and rearranging columns\n",
    "    sel_col = ['CSL_ID', 'CNTR_ID','POD_ID','ETD_POL_D','PARTY_ID',\n",
    "            'PARTY_NAME','POD','CNTR_SIZE','CNTR_TYPE','RATE']\n",
    "    df_fc = df_clean[sel_col]\n",
    "\n",
    "    # Removing years we do not want to process in our models\n",
    "    df_filtered = df_fc[df_fc['POD'].dt.year != 2002]\n",
    "\n",
    "    # Sorting the dates\n",
    "    df_filtered = df_filtered.sort_values(by='POD').reset_index(drop=True)\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CSL_ID</th>\n",
       "      <th>CNTR_ID</th>\n",
       "      <th>POD_ID</th>\n",
       "      <th>ETD_POL_D</th>\n",
       "      <th>PARTY_ID</th>\n",
       "      <th>PARTY_NAME</th>\n",
       "      <th>POD</th>\n",
       "      <th>CNTR_SIZE</th>\n",
       "      <th>CNTR_TYPE</th>\n",
       "      <th>RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECS01050600224</td>\n",
       "      <td>CTNR010050700354</td>\n",
       "      <td>ROTTERDAM</td>\n",
       "      <td>NLRTM</td>\n",
       "      <td>01008827</td>\n",
       "      <td>YANG MING (SINGAPORE) PTE. LTD.</td>\n",
       "      <td>2005-07-15</td>\n",
       "      <td>40</td>\n",
       "      <td>HC NOR</td>\n",
       "      <td>1620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECS01050600610</td>\n",
       "      <td>CTNR010050700353</td>\n",
       "      <td>FELIXSTOWE</td>\n",
       "      <td>GBFXT</td>\n",
       "      <td>01002303</td>\n",
       "      <td>GLOBELINK FALLOW LIMITED</td>\n",
       "      <td>2005-07-15</td>\n",
       "      <td>40</td>\n",
       "      <td>GP</td>\n",
       "      <td>1800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECS01050600041</td>\n",
       "      <td>CTNR010050700351</td>\n",
       "      <td>AUCKLAND</td>\n",
       "      <td>NZAKL</td>\n",
       "      <td>01005136</td>\n",
       "      <td>MONDIALE FREIGHT SERVICES LIMITED-AUCKLAND</td>\n",
       "      <td>2005-07-15</td>\n",
       "      <td>40</td>\n",
       "      <td>HC NOR</td>\n",
       "      <td>2170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ECS01050600163</td>\n",
       "      <td>CTNR010050700370</td>\n",
       "      <td>PASIR GUDANG</td>\n",
       "      <td>MYPGU</td>\n",
       "      <td>01002767</td>\n",
       "      <td>GLOBELINK CONTAINER LINES (JB) S/B</td>\n",
       "      <td>2005-07-15</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ECS01050600456</td>\n",
       "      <td>CTNR010050700450</td>\n",
       "      <td>KARACHI (KICT)</td>\n",
       "      <td>PKKHI</td>\n",
       "      <td>01002783</td>\n",
       "      <td>GLOBELINK PAKISTAN (PVT) LTD</td>\n",
       "      <td>2005-07-16</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>1625.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CSL_ID           CNTR_ID          POD_ID ETD_POL_D  PARTY_ID  \\\n",
       "0  ECS01050600224  CTNR010050700354       ROTTERDAM     NLRTM  01008827   \n",
       "1  ECS01050600610  CTNR010050700353      FELIXSTOWE     GBFXT  01002303   \n",
       "2  ECS01050600041  CTNR010050700351        AUCKLAND     NZAKL  01005136   \n",
       "3  ECS01050600163  CTNR010050700370    PASIR GUDANG     MYPGU  01002767   \n",
       "4  ECS01050600456  CTNR010050700450  KARACHI (KICT)     PKKHI  01002783   \n",
       "\n",
       "                                   PARTY_NAME        POD CNTR_SIZE CNTR_TYPE  \\\n",
       "0             YANG MING (SINGAPORE) PTE. LTD. 2005-07-15        40    HC NOR   \n",
       "1                    GLOBELINK FALLOW LIMITED 2005-07-15        40        GP   \n",
       "2  MONDIALE FREIGHT SERVICES LIMITED-AUCKLAND 2005-07-15        40    HC NOR   \n",
       "3          GLOBELINK CONTAINER LINES (JB) S/B 2005-07-15        40        HC   \n",
       "4                GLOBELINK PAKISTAN (PVT) LTD 2005-07-16        40        HC   \n",
       "\n",
       "     RATE  \n",
       "0  1620.0  \n",
       "1  1800.0  \n",
       "2  2170.0  \n",
       "3   280.0  \n",
       "4  1625.0  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CSL_ID</th>\n",
       "      <th>CNTR_ID</th>\n",
       "      <th>POD_ID</th>\n",
       "      <th>ETD_POL_D</th>\n",
       "      <th>PARTY_ID</th>\n",
       "      <th>PARTY_NAME</th>\n",
       "      <th>POD</th>\n",
       "      <th>CNTR_SIZE</th>\n",
       "      <th>CNTR_TYPE</th>\n",
       "      <th>RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECS01050600224</td>\n",
       "      <td>CTNR010050700354</td>\n",
       "      <td>ROTTERDAM</td>\n",
       "      <td>NLRTM</td>\n",
       "      <td>01008827</td>\n",
       "      <td>YANG MING (SINGAPORE) PTE. LTD.</td>\n",
       "      <td>2005-07-15</td>\n",
       "      <td>40</td>\n",
       "      <td>HC NOR</td>\n",
       "      <td>1620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECS01050600610</td>\n",
       "      <td>CTNR010050700353</td>\n",
       "      <td>FELIXSTOWE</td>\n",
       "      <td>GBFXT</td>\n",
       "      <td>01002303</td>\n",
       "      <td>GLOBELINK FALLOW LIMITED</td>\n",
       "      <td>2005-07-15</td>\n",
       "      <td>40</td>\n",
       "      <td>GP</td>\n",
       "      <td>1800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECS01050600041</td>\n",
       "      <td>CTNR010050700351</td>\n",
       "      <td>AUCKLAND</td>\n",
       "      <td>NZAKL</td>\n",
       "      <td>01005136</td>\n",
       "      <td>MONDIALE FREIGHT SERVICES LIMITED-AUCKLAND</td>\n",
       "      <td>2005-07-15</td>\n",
       "      <td>40</td>\n",
       "      <td>HC NOR</td>\n",
       "      <td>2170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ECS01050600163</td>\n",
       "      <td>CTNR010050700370</td>\n",
       "      <td>PASIR GUDANG</td>\n",
       "      <td>MYPGU</td>\n",
       "      <td>01002767</td>\n",
       "      <td>GLOBELINK CONTAINER LINES (JB) S/B</td>\n",
       "      <td>2005-07-15</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ECS01050600456</td>\n",
       "      <td>CTNR010050700450</td>\n",
       "      <td>KARACHI (KICT)</td>\n",
       "      <td>PKKHI</td>\n",
       "      <td>01002783</td>\n",
       "      <td>GLOBELINK PAKISTAN (PVT) LTD</td>\n",
       "      <td>2005-07-16</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>1625.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CSL_ID           CNTR_ID          POD_ID ETD_POL_D  PARTY_ID  \\\n",
       "0  ECS01050600224  CTNR010050700354       ROTTERDAM     NLRTM  01008827   \n",
       "1  ECS01050600610  CTNR010050700353      FELIXSTOWE     GBFXT  01002303   \n",
       "2  ECS01050600041  CTNR010050700351        AUCKLAND     NZAKL  01005136   \n",
       "3  ECS01050600163  CTNR010050700370    PASIR GUDANG     MYPGU  01002767   \n",
       "4  ECS01050600456  CTNR010050700450  KARACHI (KICT)     PKKHI  01002783   \n",
       "\n",
       "                                   PARTY_NAME        POD CNTR_SIZE CNTR_TYPE  \\\n",
       "0             YANG MING (SINGAPORE) PTE. LTD. 2005-07-15        40    HC NOR   \n",
       "1                    GLOBELINK FALLOW LIMITED 2005-07-15        40        GP   \n",
       "2  MONDIALE FREIGHT SERVICES LIMITED-AUCKLAND 2005-07-15        40    HC NOR   \n",
       "3          GLOBELINK CONTAINER LINES (JB) S/B 2005-07-15        40        HC   \n",
       "4                GLOBELINK PAKISTAN (PVT) LTD 2005-07-16        40        HC   \n",
       "\n",
       "     RATE  \n",
       "0  1620.0  \n",
       "1  1800.0  \n",
       "2  2170.0  \n",
       "3   280.0  \n",
       "4  1625.0  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframes for old and new\n",
    "old_data = '.\\Datasets\\CR_COST_FC.csv'\n",
    "df1 = createDF(old_data)\n",
    "df1.head()\n",
    "\n",
    "new_data = '.\\Datasets\\CR_COST_FC_new.csv'\n",
    "df2 = createDF(new_data)\n",
    "df2.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Creating Dictionary Keys</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe(df):\n",
    "    filtered_dataframes = {}\n",
    "\n",
    "    for (port, size, ctype, party_id), group in df.groupby(['POD_ID', 'CNTR_SIZE', 'CNTR_TYPE', 'PARTY_ID']):\n",
    "        group = group.reset_index(drop=True).sort_values(by='POD')\n",
    "        df_id = f\"Port_{port}_Size_{size}_Type_{ctype}_PartyID_{party_id}\"\n",
    "        filtered_dataframes[df_id] = group\n",
    "\n",
    "    return filtered_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Data keys:\n",
      "['Port_(CONSTANZA)_Size_40_Type_GP_PartyID_010007816', 'Port_(CONSTANZA)_Size_40_Type_HC_PartyID_010007816', 'Port_AARHUS_Size_20_Type_GP_PartyID_01000043', 'Port_AARHUS_Size_20_Type_GP_PartyID_0100027830', 'Port_AARHUS_Size_20_Type_GP_PartyID_010006666', 'Port_AARHUS_Size_40_Type_GP_PartyID_01000043', 'Port_AARHUS_Size_40_Type_HC_PartyID_01000043', 'Port_AARHUS_Size_40_Type_HC_PartyID_0100027830', 'Port_AARHUS_Size_40_Type_HC_PartyID_0100028193', 'Port_AARHUS_Size_40_Type_HC_PartyID_010006666', 'Port_ABIDJAN_Size_20_Type_GP_PartyID_0100027878', 'Port_ABIDJAN_Size_40_Type_HC_PartyID_010021097', 'Port_ADELAIDE_Size_20_Type_GP_PartyID_01002775', 'Port_ADELAIDE_Size_40_Type_GP_PartyID_01002775', 'Port_ADELAIDE_Size_40_Type_HC_PartyID_01002775', 'Port_ADELAIDE_Size_40_Type_HC_PartyID_01005078', 'Port_ADELAIDE_Size_40_Type_HC NOR_PartyID_01002775', 'Port_ADELAIDE(AU)_Size_20_Type_GP_PartyID_01002775', 'Port_ADELAIDE(AU)_Size_40_Type_HC_PartyID_01002775', 'Port_ADELAIDE(AU)_Size_40_Type_HC NOR_PartyID_01002775', 'Port_ALEXANDRIA (EL DEKHELA PORT)_Size_40_Type_HC_PartyID_010004995', 'Port_ALEXANDRIA (OLD PORT)_Size_20_Type_GP_PartyID_010004995', 'Port_ALEXANDRIA (OLD PORT)_Size_40_Type_HC_PartyID_010004995', 'Port_ALEXANDRIA(OLD PORT)_Size_20_Type_GP_PartyID_010004995', 'Port_ALEXANDRIA(OLD PORT)_Size_40_Type_HC_PartyID_010004995', 'Port_ALEXANDRIA(OLD PORT)_Size_40_Type_HC NOR_PartyID_010004995', 'Port_ALGECIRAS_Size_20_Type_GP_PartyID_01008306', 'Port_ALGECIRAS_Size_40_Type_GP_PartyID_01008306', 'Port_ALGECIRAS_Size_40_Type_HC_PartyID_01008306', 'Port_ALGECIRAS_Size_40_Type_HC NOR_PartyID_01008306', 'Port_ALIAGA_Size_20_Type_GP_PartyID_01008316', 'Port_ALIAGA_Size_40_Type_HC_PartyID_01008316', 'Port_ALIAGA PORT (IZMIR)_Size_40_Type_HC_PartyID_01008316', 'Port_ANTWERP_Size_20_Type_GP_PartyID_01001449', 'Port_ANTWERP_Size_40_Type_GP_PartyID_01001449', 'Port_ANTWERP_Size_40_Type_HC_PartyID_01001449', 'Port_ANTWERP_Size_40_Type_HC NOR_PartyID_01001449', 'Port_AQABA_Size_20_Type_GP_PartyID_010006618', 'Port_AQABA_Size_20_Type_GP_PartyID_010021081', 'Port_AQABA_Size_40_Type_HC_PartyID_010006618', 'Port_AQABA_Size_40_Type_HC_PartyID_010021081', 'Port_ASHDOD_Size_20_Type_GP_PartyID_010008035', 'Port_ASHDOD_Size_40_Type_GP_PartyID_010008035', 'Port_ASHDOD_Size_40_Type_GP_PartyID_01008417', 'Port_ASHDOD_Size_40_Type_HC_PartyID_010008035', 'Port_ASHDOD_Size_40_Type_HC_PartyID_01008417', 'Port_AUCKLAND_Size_20_Type_GP_PartyID_01005136', 'Port_AUCKLAND_Size_20_Type_GP (DG)_PartyID_01005136', 'Port_AUCKLAND_Size_40_Type_GP_PartyID_01005136', 'Port_AUCKLAND_Size_40_Type_HC_PartyID_01005136', 'Port_AUCKLAND_Size_40_Type_HC (DG)_PartyID_01005136', 'Port_AUCKLAND_Size_40_Type_HC NOR_PartyID_01005136', 'Port_BANGKOK_Size_20_Type_GP_PartyID_010021593', 'Port_BANGKOK_Size_20_Type_GP_PartyID_01002799', 'Port_BANGKOK_Size_20_Type_GP (DG)_PartyID_01002799', 'Port_BANGKOK_Size_40_Type_GP_PartyID_01002799', 'Port_BANGKOK_Size_40_Type_HC_PartyID_010021593', 'Port_BANGKOK_Size_40_Type_HC_PartyID_01002799', 'Port_BANGKOK_Size_40_Type_HC (DG)_PartyID_010021593', 'Port_BANGKOK_Size_40_Type_HC (DG)_PartyID_01002799', 'Port_BANGKOK_Size_40_Type_HC (SOC)_PartyID_01002799', 'Port_BANGKOK ( TPT )_Size_20_Type_GP_PartyID_010021593', 'Port_BANGKOK ( TPT )_Size_20_Type_GP_PartyID_01002799', 'Port_BANGKOK ( TPT )_Size_40_Type_HC_PartyID_010021593', 'Port_BANGKOK ( TPT )_Size_40_Type_HC_PartyID_01002799', 'Port_BANGKOK (TST)_Size_20_Type_GP_PartyID_010021593', 'Port_BANGKOK (TST)_Size_40_Type_HC_PartyID_010021593', 'Port_BARCELONA_Size_20_Type_GP_PartyID_01008305', 'Port_BARCELONA_Size_40_Type_GP_PartyID_01008305', 'Port_BARCELONA_Size_40_Type_HC_PartyID_01008305', 'Port_BARCELONA_Size_40_Type_HC NOR_PartyID_01008305', 'Port_BEIRUT_Size_20_Type_GP_PartyID_010003651', 'Port_BEIRUT_Size_40_Type_GP_PartyID_010003651', 'Port_BEIRUT_Size_40_Type_HC_PartyID_010003651', 'Port_BEIRUT FREE ZONE_Size_20_Type_GP_PartyID_010003651', 'Port_BEIRUT FREE ZONE_Size_40_Type_HC_PartyID_010003651', 'Port_BEIRUT FREE ZONE_Size_45_Type_HC_PartyID_010003651', 'Port_BELAWAN_Size_20_Type_GP_PartyID_010008921', 'Port_BELAWAN_Size_20_Type_GP_PartyID_01006254', 'Port_BELAWAN_Size_40_Type_GP_PartyID_01006254', 'Port_BELAWAN_Size_40_Type_HC_PartyID_010008921', 'Port_BELAWAN_Size_40_Type_HC_PartyID_01006254', 'Port_BRATISLAVA_Size_20_Type_GP_PartyID_010007864', 'Port_BRATISLAVA_Size_20_Type_GP_PartyID_01003062', 'Port_BRATISLAVA_Size_40_Type_GP_PartyID_01000054', 'Port_BRATISLAVA_Size_40_Type_GP_PartyID_010005269', 'Port_BRATISLAVA_Size_40_Type_GP_PartyID_01003062', 'Port_BRATISLAVA_Size_40_Type_HC_PartyID_01000054', 'Port_BRATISLAVA_Size_40_Type_HC_PartyID_010005269', 'Port_BRATISLAVA_Size_40_Type_HC_PartyID_01003062', 'Port_BRISBANE_Size_20_Type_GP_PartyID_01002776', 'Port_BRISBANE_Size_20_Type_GP_PartyID_01002778', 'Port_BRISBANE_Size_20_Type_GP_PartyID_01002779', 'Port_BRISBANE_Size_20_Type_GP NOR_PartyID_01002776', 'Port_BRISBANE_Size_40_Type_GP_PartyID_01002776', 'Port_BRISBANE_Size_40_Type_HC_PartyID_01002776', 'Port_BRISBANE_Size_40_Type_HC_PartyID_01002778', 'Port_BRISBANE_Size_40_Type_HC NOR_PartyID_01002776', 'Port_BRISBANE_Size_40_Type_HC NOR_PartyID_01002779', 'Port_BUDAPEST_Size_20_Type_GP_PartyID_010007829', 'Port_BUDAPEST_Size_40_Type_GP_PartyID_010007829', 'Port_BUDAPEST_Size_40_Type_HC_PartyID_010007829', 'Port_BUENAVENTURA ,SPR_Size_20_Type_GP_PartyID_010006728', 'Port_BUENAVENTURA ,SPR_Size_40_Type_HC NOR_PartyID_010006728', 'Port_BUENAVENTURA ,SPR_Size_40_Type_HC NOR_PartyID_01001485', 'Port_BUENAVENTURA(COLOMBIA)_Size_20_Type_GP_PartyID_010006728', 'Port_BUENAVENTURA(COLOMBIA)_Size_20_Type_GP_PartyID_01001485', 'Port_BUENAVENTURA(COLOMBIA)_Size_40_Type_GP_PartyID_010006728', 'Port_BUENAVENTURA(COLOMBIA)_Size_40_Type_GP_PartyID_01001485', 'Port_BUENAVENTURA(COLOMBIA)_Size_40_Type_HC_PartyID_010006728', 'Port_BUENAVENTURA(COLOMBIA)_Size_40_Type_HC_PartyID_01001485', 'Port_BUENAVENTURA(COLOMBIA)_Size_40_Type_HC NOR_PartyID_01001485', 'Port_BUENOS AIRES_Size_20_Type_GP_PartyID_01006063', 'Port_BUENOS AIRES_Size_40_Type_HC_PartyID_010006300', 'Port_BUENOS AIRES_Size_40_Type_HC_PartyID_010021498', 'Port_BUENOS AIRES_Size_40_Type_HC_PartyID_01006063', 'Port_BUENOS AIRES_Size_40_Type_HC NOR_PartyID_010006300', 'Port_BUENOS AIRES_Size_40_Type_HC NOR_PartyID_010021498', 'Port_BUENOS AIRES_Size_40_Type_HC NOR_PartyID_01006063', 'Port_BUSAN_Size_20_Type_GP_PartyID_010004286', 'Port_BUSAN_Size_20_Type_GP_PartyID_01001867', 'Port_BUSAN_Size_40_Type_HC_PartyID_010004286', 'Port_BUSAN_Size_40_Type_HC_PartyID_01001867', 'Port_BUSAN_Size_40_Type_HC (SOC)_PartyID_010004286', 'Port_BUSAN_Size_40_Type_HC NOR_PartyID_010017867', 'Port_CALCUTTA_Size_20_Type_GP_PartyID_010006978', 'Port_CALCUTTA_Size_40_Type_HC_PartyID_010006978', 'Port_CALLAO_Size_20_Type_GP_PartyID_01002621', 'Port_CALLAO_Size_20_Type_GP_PartyID_010026711', 'Port_CALLAO_Size_40_Type_GP_PartyID_01002621', 'Port_CALLAO_Size_40_Type_HC_PartyID_01002621', 'Port_CALLAO_Size_40_Type_HC_PartyID_010026711', 'Port_CALLAO_Size_40_Type_HC NOR_PartyID_01002621', 'Port_CALLAO_Size_40_Type_HC NOR_PartyID_010026711', 'Port_CAPE TOWN_Size_20_Type_GP_PartyID_010007917', 'Port_CAPE TOWN_Size_40_Type_HC_PartyID_010007917', 'Port_CAPE TOWN_Size_40_Type_HC NOR_PartyID_010007917', 'Port_CAPETOWN_Size_20_Type_GP_PartyID_010007917', 'Port_CAPETOWN_Size_20_Type_GP_PartyID_01007272', 'Port_CAPETOWN_Size_40_Type_GP_PartyID_010007917', 'Port_CAPETOWN_Size_40_Type_GP_PartyID_01007272', 'Port_CAPETOWN_Size_40_Type_HC_PartyID_010007917', 'Port_CAPETOWN_Size_40_Type_HC_PartyID_01007272', 'Port_CASABLANCA_Size_20_Type_GP_PartyID_010006336', 'Port_CASABLANCA_Size_40_Type_GP_PartyID_010006336', 'Port_CASABLANCA_Size_40_Type_HC_PartyID_010006336', 'Port_CAT LAI (HO CHI MINH)_Size_20_Type_GP_PartyID_010005256', 'Port_CAT LAI (HO CHI MINH)_Size_20_Type_GP_PartyID_01004649', 'Port_CAT LAI (HO CHI MINH)_Size_40_Type_GP_PartyID_010005256', 'Port_CAT LAI (HO CHI MINH)_Size_40_Type_HC_PartyID_010005256', 'Port_CAT LAI (HO CHI MINH)_Size_40_Type_HC_PartyID_01004649', 'Port_CAT LAI (HO CHI MINH)_Size_40_Type_HC_PartyID_01005854', 'Port_CAT LAI (HO CHI MINH)_Size_40_Type_HC NOR_PartyID_010005256', 'Port_CAT LAI (HO CHI MINH)_Size_45_Type_HC_PartyID_010005256', 'Port_CAT LAI (HOCHIMINH)_Size_20_Type_GP_PartyID_010005256', 'Port_CAT LAI (HOCHIMINH)_Size_20_Type_GP (DG)_PartyID_010005256', 'Port_CAT LAI (HOCHIMINH)_Size_40_Type_HC_PartyID_010005256', 'Port_CAT LAI PORT_Size_20_Type_GP_PartyID_010005256', 'Port_CAT LAI PORT_Size_20_Type_GP (DG)_PartyID_010005256', 'Port_CAT LAI PORT_Size_40_Type_HC_PartyID_010005256', 'Port_CAT LAI PORT_Size_40_Type_HC (DG)_PartyID_010005256', 'Port_CEBU_Size_20_Type_GP_PartyID_010020487', 'Port_CEBU_Size_20_Type_GP_PartyID_010021735', 'Port_CEBU_Size_20_Type_GP_PartyID_01004970', 'Port_CEBU_Size_40_Type_HC_PartyID_010020487', 'Port_CEBU_Size_40_Type_HC_PartyID_010021735', 'Port_CEBU_Size_40_Type_HC_PartyID_01004970', 'Port_CHATTOGRAM (CHITTAGONG)_Size_20_Type_GP_PartyID_010021463', 'Port_CHATTOGRAM (CHITTAGONG)_Size_40_Type_HC_PartyID_010021463', 'Port_CHENNAI_Size_20_Type_GP_PartyID_010006979', 'Port_CHENNAI_Size_40_Type_HC_PartyID_010006979', 'Port_CHITTAGONG_Size_20_Type_GP_PartyID_010007693', 'Port_COCHIN_Size_20_Type_GP_PartyID_010006980', 'Port_COCHIN_Size_20_Type_GP_PartyID_01008782', 'Port_COCHIN_Size_40_Type_HC_PartyID_010006980', 'Port_COCHIN_Size_40_Type_HC_PartyID_01008782', 'Port_COLOMBO_Size_20_Type_GP_PartyID_01001668', 'Port_COLOMBO_Size_40_Type_GP_PartyID_01001668', 'Port_COLOMBO_Size_40_Type_HC_PartyID_01001668', 'Port_COLOMBO_Size_40_Type_HC_PartyID_01004906', 'Port_COLOMBO_Size_45_Type_HC_PartyID_01001668', 'Port_COLON FREE ZONE_Size_20_Type_GP_PartyID_010006741', 'Port_COLON FREE ZONE_Size_40_Type_HC_PartyID_010006741', 'Port_COLON FREE ZONE_Size_40_Type_HC_PartyID_010019558', 'Port_COLON FREE ZONE_Size_40_Type_HC NOR_PartyID_010006741', 'Port_CONSTANTA_Size_20_Type_GP_PartyID_010007816', 'Port_CONSTANTA_Size_20_Type_GP_PartyID_010009323', 'Port_CONSTANTA_Size_40_Type_GP_PartyID_010007816', 'Port_CONSTANTA_Size_40_Type_HC_PartyID_010007816', 'Port_CONSTANTA_Size_40_Type_HC_PartyID_010009323', 'Port_CONSTANTA CFS_Size_20_Type_GP_PartyID_010009323', 'Port_CONSTANTA CFS_Size_40_Type_GP_PartyID_010009323', 'Port_CONSTANTA CFS_Size_40_Type_HC_PartyID_010009323', 'Port_CONSTANZA_Size_20_Type_GP_PartyID_010007816', 'Port_CONSTANZA_Size_40_Type_GP_PartyID_010007816', 'Port_CONSTANZA_Size_40_Type_HC_PartyID_010007816', 'Port_COPENHAGEN_Size_20_Type_GP_PartyID_01000043', 'Port_COPENHAGEN_Size_20_Type_GP_PartyID_0100027830', 'Port_COPENHAGEN_Size_20_Type_GP_PartyID_010006666', 'Port_COPENHAGEN_Size_20_Type_GP_PartyID_010006669', 'Port_COPENHAGEN_Size_40_Type_GP_PartyID_01000043', 'Port_COPENHAGEN_Size_40_Type_HC_PartyID_01000043', 'Port_COPENHAGEN_Size_40_Type_HC_PartyID_0100027830', 'Port_COPENHAGEN_Size_40_Type_HC_PartyID_010006669', 'Port_COPENHAGEN_Size_40_Type_HC NOR_PartyID_010006669', 'Port_DALIAN_Size_20_Type_GP_PartyID_010007376', 'Port_DALIAN_Size_40_Type_HC_PartyID_010007376', 'Port_DANANG_Size_20_Type_GP_PartyID_010005257', 'Port_DANANG_Size_40_Type_HC_PartyID_010005257', 'Port_DAR ES SALAAM(TANZANIA)_Size_20_Type_GP_PartyID_010020396', 'Port_DAR ES SALAAM(TANZANIA)_Size_20_Type_GP_PartyID_010020400', 'Port_DAR ES SALAAM(TANZANIA)_Size_20_Type_GP_PartyID_01003047', 'Port_DAR ES SALAAM(TANZANIA)_Size_40_Type_HC_PartyID_010020396', 'Port_DAR ES SALAAM(TANZANIA)_Size_40_Type_HC_PartyID_010020400', 'Port_DUBAI (JEBEL ALI)_Size_20_Type_GP_PartyID_01002788', 'Port_DUBAI (JEBEL ALI)_Size_40_Type_GP (SOC)_PartyID_01002788', 'Port_DUBAI (JEBEL ALI)_Size_40_Type_HC_PartyID_01002788', 'Port_DUBLIN_Size_20_Type_GP_PartyID_010009104', 'Port_DUBLIN_Size_20_Type_GP_PartyID_010027322', 'Port_DUBLIN_Size_20_Type_GP_PartyID_01003442', 'Port_DUBLIN_Size_40_Type_GP_PartyID_010009104', 'Port_DUBLIN_Size_40_Type_GP_PartyID_01003442', 'Port_DUBLIN_Size_40_Type_HC_PartyID_010009104', 'Port_DUBLIN_Size_40_Type_HC_PartyID_010027322', 'Port_DUBLIN_Size_40_Type_HC_PartyID_01003442', 'Port_DUBLIN_Size_40_Type_HC NOR_PartyID_010009104', 'Port_DUBLIN_Size_40_Type_HC NOR_PartyID_010027322', 'Port_DURBAN_Size_20_Type_GP_PartyID_010007911', 'Port_DURBAN_Size_20_Type_GP_PartyID_01007273', 'Port_DURBAN_Size_40_Type_GP_PartyID_010007911', 'Port_DURBAN_Size_40_Type_GP_PartyID_01007273', 'Port_DURBAN_Size_40_Type_GP (SOC)_PartyID_01007273', 'Port_DURBAN_Size_40_Type_HC_PartyID_010007911', 'Port_DURBAN_Size_40_Type_HC_PartyID_01007273', 'Port_DURBAN_Size_40_Type_HC (SOC)_PartyID_01007273', 'Port_DURBAN_Size_40_Type_HC NOR_PartyID_010007911', 'Port_DURBAN_Size_40_Type_HC NOR (SOC)_PartyID_010007911', 'Port_EVYAP TERMINAL IZMIT_Size_20_Type_GP_PartyID_01008316', 'Port_FELIXSTOWE_Size_20_Type_GP_PartyID_01002303', 'Port_FELIXSTOWE_Size_40_Type_GP_PartyID_01002303', 'Port_FELIXSTOWE_Size_40_Type_HC_PartyID_01002303', 'Port_FELIXSTOWE_Size_40_Type_HC NOR_PartyID_01002303', 'Port_FOS SUR MER_Size_20_Type_GP_PartyID_010019364', 'Port_FOS SUR MER_Size_40_Type_GP_PartyID_010019364', 'Port_FOS SUR MER_Size_40_Type_HC_PartyID_010019364', 'Port_FOS SUR MER_Size_40_Type_HC NOR_PartyID_010019364', 'Port_FOS SUR MER-MARSEILLE_Size_20_Type_GP_PartyID_010019364', 'Port_FOS SUR MER-MARSEILLE_Size_40_Type_GP_PartyID_010019364', 'Port_FOS SUR MER-MARSEILLE_Size_40_Type_HC_PartyID_010019364', 'Port_FREDERICIA / AARHUS_Size_20_Type_GP_PartyID_010006666', 'Port_FREDERICIA / AARHUS_Size_40_Type_HC_PartyID_010006666', 'Port_FREDERICIA / AARHUS_Size_40_Type_HC NOR_PartyID_010006666', 'Port_FREMANTLE_Size_20_Type_GP_PartyID_01002777', 'Port_FREMANTLE_Size_40_Type_GP_PartyID_01002777', 'Port_FREMANTLE_Size_40_Type_HC_PartyID_01002777', 'Port_FREMANTLE_Size_40_Type_HC NOR_PartyID_01002777', 'Port_FREMANTLE (PERTH)_Size_20_Type_GP_PartyID_01002777', 'Port_FREMANTLE (PERTH)_Size_40_Type_HC_PartyID_01002777', 'Port_FREMANTLE (PERTH)_Size_40_Type_HC NOR_PartyID_01002777', 'Port_GDANSK_Size_20_Type_GP_PartyID_010008275', 'Port_GDANSK_Size_40_Type_HC_PartyID_010008275', 'Port_GDYNIA_Size_20_Type_GP_PartyID_010008275', 'Port_GDYNIA_Size_40_Type_GP_PartyID_010008275', 'Port_GDYNIA_Size_40_Type_HC_PartyID_010008275', 'Port_GDYNIA_Size_40_Type_HC NOR_PartyID_010008275', 'Port_GENOA_Size_20_Type_GP_PartyID_01001496', 'Port_GENOA_Size_40_Type_GP_PartyID_01001496', 'Port_GENOA_Size_40_Type_HC_PartyID_01001496', 'Port_GENOA_Size_40_Type_HC NOR_PartyID_01001496', 'Port_GENOVA_Size_40_Type_HC_PartyID_01001496', 'Port_GOTHENBURG_Size_20_Type_GP_PartyID_0100027831', 'Port_GOTHENBURG_Size_20_Type_GP_PartyID_010006668', 'Port_GOTHENBURG_Size_20_Type_GP_PartyID_01002876', 'Port_GOTHENBURG_Size_40_Type_HC_PartyID_0100027831', 'Port_GOTHENBURG_Size_40_Type_HC_PartyID_010006668', 'Port_GOTHENBURG_Size_40_Type_HC NOR_PartyID_010006668', 'Port_HAIPHONG_Size_20_Type_GP_PartyID_010005255', 'Port_HAIPHONG_Size_40_Type_GP_PartyID_010005255', 'Port_HAIPHONG_Size_40_Type_HC_PartyID_010005255', 'Port_HAMAD PORT_Size_20_Type_GP_PartyID_010020089', 'Port_HAMAD PORT_Size_40_Type_HC_PartyID_010020089', 'Port_HAMAD PORT (QATAR)_Size_40_Type_HC_PartyID_010020089', 'Port_HAMBURG_Size_20_Type_GP_PartyID_01002294', 'Port_HAMBURG_Size_40_Type_GP_PartyID_01002294', 'Port_HAMBURG_Size_40_Type_HC_PartyID_01002294', 'Port_HAMBURG_Size_40_Type_HC NOR_PartyID_01002294', 'Port_HAYDARPASA_Size_40_Type_HC_PartyID_01008316', 'Port_HELSINKI_Size_20_Type_GP_PartyID_0100027832', 'Port_HELSINKI_Size_20_Type_GP_PartyID_010003678', 'Port_HELSINKI_Size_20_Type_GP_PartyID_010006667', 'Port_HELSINKI_Size_40_Type_GP_PartyID_010003678', 'Port_HELSINKI_Size_40_Type_GP_PartyID_010006667', 'Port_HELSINKI_Size_40_Type_HC_PartyID_0100027832', 'Port_HELSINKI_Size_40_Type_HC_PartyID_0100028191', 'Port_HELSINKI_Size_40_Type_HC_PartyID_010003678', 'Port_HELSINKI_Size_40_Type_HC_PartyID_010006667', 'Port_HO CHI MINH_Size_20_Type_GP_PartyID_010005256', 'Port_HO CHI MINH_Size_40_Type_HC_PartyID_010005256', 'Port_HO CHI MINH_Size_40_Type_HC (SOC)_PartyID_010005256', 'Port_HOCHIMINH ( CAT LAI )_Size_20_Type_GP_PartyID_010005256', 'Port_HOCHIMINH ( CAT LAI )_Size_40_Type_HC_PartyID_010005256', 'Port_HOCHIMINH CAT LAI,VIETNAM_Size_20_Type_GP_PartyID_010005256', 'Port_HOCHIMINH CAT LAI,VIETNAM_Size_40_Type_GP_PartyID_010005256', 'Port_HOCHIMINH CAT LAI,VIETNAM_Size_40_Type_HC_PartyID_010005256', 'Port_HOCHIMINH CAT LAI,VIETNAM_Size_40_Type_HC (DG)_PartyID_010005256', 'Port_HOCHIMINH CITY ( TAN CANG )_Size_40_Type_HC_PartyID_01004649', 'Port_HONG KONG_Size_20_Type_GP_PartyID_01004594', 'Port_HONG KONG_Size_40_Type_GP_PartyID_01004594', 'Port_HONG KONG_Size_40_Type_HC_PartyID_010009070', 'Port_HONG KONG_Size_40_Type_HC_PartyID_01004594', 'Port_ICD BANGALORE_Size_20_Type_GP_PartyID_010007237', 'Port_ICD BANGALORE_Size_40_Type_HC_PartyID_010007237', 'Port_ICD PATPARGANJ_Size_20_Type_GP_PartyID_01002787', 'Port_ICD PATPARGANJ_Size_40_Type_GP_PartyID_01002787', 'Port_ICD PATPARGANJ_Size_40_Type_HC_PartyID_01002787', 'Port_ICD PATPARGANJ_Size_40_Type_HC_PartyID_01008782', 'Port_ICD PHUOC LONG 3_Size_40_Type_HC_PartyID_010005256', 'Port_ILYCHEVSK_Size_20_Type_GP_PartyID_010019008', 'Port_ILYCHEVSK_Size_20_Type_GP_PartyID_010019966', 'Port_ILYCHEVSK_Size_40_Type_HC_PartyID_010019008', 'Port_ISTANBUL (HAYDARPASA)_Size_20_Type_GP_PartyID_01008316', 'Port_ISTANBUL (HAYDARPASA)_Size_40_Type_HC_PartyID_01008316', 'Port_ISTANBUL (MARPORT)_Size_40_Type_HC_PartyID_01008316', 'Port_ISTANBUL(AMBARLI)_Size_40_Type_GP_PartyID_01008316', 'Port_ISTANBUL(AMBARLI)_Size_40_Type_HC_PartyID_01008316', 'Port_ISTANBUL(AMBARLI)_Size_40_Type_HC NOR_PartyID_01008316', 'Port_ISTANBUL(AMBARLI)-KUMPORT_Size_20_Type_GP_PartyID_01008316', 'Port_ISTANBUL(AMBARLI)-KUMPORT_Size_40_Type_HC_PartyID_01008316', 'Port_ISTANBUL(AMBARLI)-MARPORT_Size_20_Type_GP_PartyID_01008316', 'Port_ISTANBUL(AMBARLI)-MARPORT_Size_40_Type_HC_PartyID_01008316', 'Port_ISTANBUL(HAYDARPASA)_Size_20_Type_GP_PartyID_01008316', 'Port_ISTANBUL(HAYDARPASA)_Size_40_Type_GP_PartyID_01008316', 'Port_ISTANBUL(HAYDARPASA)_Size_40_Type_GP_PartyID_01008827', 'Port_ISTANBUL(HAYDARPASA)_Size_40_Type_HC_PartyID_01008316', 'Port_ISTANBUL/KUMPORT (AMBARLI)_Size_20_Type_GP_PartyID_01008316', 'Port_ISTANBUL/KUMPORT (AMBARLI)_Size_40_Type_HC_PartyID_01008316', 'Port_ISTANBUL/MARPORT (AMBARLI)_Size_20_Type_GP_PartyID_01008316', 'Port_ISTANBUL/MARPORT (AMBARLI)_Size_40_Type_HC_PartyID_01008316', 'Port_ITAJAI_Size_20_Type_GP_PartyID_010006079', 'Port_IZMIR_Size_20_Type_GP_PartyID_01008316', 'Port_IZMIR_Size_40_Type_GP_PartyID_01008316', 'Port_IZMIR_Size_40_Type_HC_PartyID_01008316', 'Port_JAKARTA_Size_20_Type_GP_PartyID_010008969', 'Port_JAKARTA_Size_20_Type_GP_PartyID_01006255', 'Port_JAKARTA_Size_20_Type_GP (DG)_PartyID_010008969', 'Port_JAKARTA_Size_40_Type_GP_PartyID_010008969', 'Port_JAKARTA_Size_40_Type_GP_PartyID_01006255', 'Port_JAKARTA_Size_40_Type_HC_PartyID_010008969', 'Port_JAKARTA_Size_40_Type_HC_PartyID_01006255', 'Port_JOHANNESBURG_Size_20_Type_GP_PartyID_010007918', 'Port_JOHANNESBURG_Size_20_Type_GP_PartyID_01007274', 'Port_JOHANNESBURG_Size_40_Type_GP_PartyID_01007274', 'Port_JOHANNESBURG_Size_40_Type_GP (SOC)_PartyID_010007918', 'Port_JOHANNESBURG_Size_40_Type_GP (SOC)_PartyID_01007274', 'Port_JOHANNESBURG_Size_40_Type_HC_PartyID_010007918', 'Port_JOHANNESBURG_Size_40_Type_HC_PartyID_01007274', 'Port_JOHANNESBURG_Size_40_Type_HC NOR_PartyID_010007918', 'Port_KARACHI_Size_20_Type_GP_PartyID_01002783', 'Port_KARACHI_Size_40_Type_HC_PartyID_01002783', 'Port_KARACHI (KICT)_Size_20_Type_GP_PartyID_01002783', 'Port_KARACHI (KICT)_Size_40_Type_HC_PartyID_01002783', 'Port_KEELUNG_Size_20_Type_GP_PartyID_01005822', 'Port_KEELUNG_Size_40_Type_HC_PartyID_010020534', 'Port_KLAIPEDA_Size_20_Type_GP_PartyID_010017977', 'Port_KLAIPEDA_Size_40_Type_GP_PartyID_010017977', 'Port_KLAIPEDA_Size_40_Type_HC_PartyID_010017977', 'Port_KOBE_Size_20_Type_GP_PartyID_01005564', 'Port_KOBE_Size_20_Type_GP_PartyID_01008573', 'Port_KOBE_Size_40_Type_HC_PartyID_01005564', 'Port_KOLKATA_Size_20_Type_GP_PartyID_010006978', 'Port_KOLKATA_Size_40_Type_HC_PartyID_010006978', 'Port_KOPER_Size_20_Type_GP_PartyID_01000055', 'Port_KOPER_Size_20_Type_GP_PartyID_010008166', 'Port_KOPER_Size_20_Type_GP_PartyID_010009052', 'Port_KOPER_Size_40_Type_GP_PartyID_01000055', 'Port_KOPER_Size_40_Type_GP_PartyID_010008166', 'Port_KOPER_Size_40_Type_GP_PartyID_010009052', 'Port_KOPER_Size_40_Type_HC_PartyID_01000055', 'Port_KOPER_Size_40_Type_HC_PartyID_010008166', 'Port_KOPER_Size_40_Type_HC_PartyID_010009052', 'Port_KOPER_Size_40_Type_HC NOR_PartyID_010009052', 'Port_KOTA KINABALU_Size_20_Type_GP_PartyID_01004179', 'Port_KUMPORT_Size_40_Type_GP_PartyID_01008316', 'Port_KUMPORT_Size_40_Type_HC_PartyID_01008316', 'Port_LAEM CHABANG_Size_20_Type_GP_PartyID_010021593', 'Port_LAEM CHABANG_Size_20_Type_GP_PartyID_01002799', 'Port_LAEM CHABANG_Size_20_Type_GP (DG)_PartyID_01002799', 'Port_LAEM CHABANG_Size_40_Type_GP_PartyID_01002799', 'Port_LAEM CHABANG_Size_40_Type_HC_PartyID_010021593', 'Port_LAEM CHABANG_Size_40_Type_HC_PartyID_01002799', 'Port_LAGOS_Size_20_Type_GP_PartyID_010008774', 'Port_LAGOS_Size_40_Type_HC_PartyID_010008774', 'Port_LAT KRABANG_Size_40_Type_HC_PartyID_010021593', 'Port_LATKRABANG_Size_20_Type_GP_PartyID_010021593', 'Port_LATKRABANG_Size_20_Type_GP_PartyID_01002799', 'Port_LATKRABANG_Size_40_Type_GP_PartyID_01002799', 'Port_LATKRABANG_Size_40_Type_HC_PartyID_010021593', 'Port_LATKRABANG_Size_40_Type_HC_PartyID_01002799', 'Port_LAUTOKA_Size_20_Type_GP_PartyID_010008152', 'Port_LAUTOKA_Size_40_Type_HC_PartyID_010008152', 'Port_LE HAVRE_Size_20_Type_GP_PartyID_01001088', 'Port_LE HAVRE_Size_20_Type_GP_PartyID_010019363', 'Port_LE HAVRE_Size_40_Type_GP_PartyID_01001088', 'Port_LE HAVRE_Size_40_Type_GP_PartyID_010019363', 'Port_LE HAVRE_Size_40_Type_HC_PartyID_01001088', 'Port_LE HAVRE_Size_40_Type_HC_PartyID_010019363', 'Port_LE HAVRE_Size_40_Type_HC NOR_PartyID_01001088', 'Port_LE HAVRE_Size_40_Type_HC NOR_PartyID_010019363', 'Port_LEIXOES_Size_20_Type_GP_PartyID_010008857', 'Port_LEIXOES_Size_20_Type_GP_PartyID_01008132', 'Port_LEIXOES_Size_20_Type_GP_PartyID_01008133', 'Port_LEIXOES_Size_40_Type_GP_PartyID_010008857', 'Port_LEIXOES_Size_40_Type_GP_PartyID_010019569', 'Port_LEIXOES_Size_40_Type_GP_PartyID_01008132', 'Port_LEIXOES_Size_40_Type_GP_PartyID_01008133', 'Port_LEIXOES_Size_40_Type_HC_PartyID_010008857', 'Port_LEIXOES_Size_40_Type_HC_PartyID_01008132', 'Port_LIMASSOL_Size_20_Type_GP_PartyID_010007769', 'Port_LIMASSOL_Size_20_Type_GP_PartyID_01001096', 'Port_LIMASSOL_Size_20_Type_GP_PartyID_01002518', 'Port_LIMASSOL_Size_40_Type_GP_PartyID_010007769', 'Port_LIMASSOL_Size_40_Type_GP_PartyID_01001096', 'Port_LIMASSOL_Size_40_Type_GP_PartyID_01002518', 'Port_LIMASSOL_Size_40_Type_HC_PartyID_010007769', 'Port_LIMASSOL_Size_40_Type_HC_PartyID_01001096', 'Port_LIMASSOL_Size_40_Type_HC_PartyID_01002518', 'Port_LISBOA_Size_20_Type_GP_PartyID_010008857', 'Port_LISBOA_Size_20_Type_GP_PartyID_010019569', 'Port_LISBOA_Size_20_Type_GP_PartyID_01008133', 'Port_LISBOA_Size_40_Type_GP_PartyID_010019569', 'Port_LISBOA_Size_40_Type_GP_PartyID_01008133', 'Port_LISBOA_Size_40_Type_HC_PartyID_010008857', 'Port_LISBOA_Size_40_Type_HC_PartyID_010019569', 'Port_LISBOA_Size_40_Type_HC_PartyID_01008133', 'Port_LISBOA_Size_40_Type_HC NOR_PartyID_010019569', 'Port_LOS ANGELES_Size_20_Type_GP_PartyID_01005857', 'Port_LOS ANGELES_Size_40_Type_GP_PartyID_01005857', 'Port_LOS ANGELES_Size_40_Type_HC_PartyID_01005857', 'Port_LOS ANGELES_Size_40_Type_HC NOR_PartyID_01005857', 'Port_LOS ANGELES_Size_45_Type_HC_PartyID_01005857', 'Port_LOS ANGELES (US)_Size_20_Type_GP_PartyID_01005857', 'Port_LOS ANGELES (US)_Size_40_Type_GP_PartyID_01005857', 'Port_LOS ANGELES (US)_Size_40_Type_HC_PartyID_01005857', 'Port_LOS ANGELES (US)_Size_40_Type_HC NOR_PartyID_01005857', 'Port_LOS ANGELES (US)_Size_45_Type_HC_PartyID_01005857', 'Port_LYTTELTON_Size_20_Type_GP_PartyID_01005136', 'Port_LYTTELTON_Size_40_Type_GP_PartyID_01005136', 'Port_LYTTELTON_Size_40_Type_HC_PartyID_01005136', 'Port_LYTTELTON_Size_40_Type_HC NOR_PartyID_01005136', 'Port_MADRAS_Size_20_Type_GP_PartyID_010006979', 'Port_MADRAS_Size_20_Type_GP_PartyID_01008779', 'Port_MADRAS_Size_40_Type_HC_PartyID_010006979', 'Port_MADRAS_Size_40_Type_HC_PartyID_01008779', 'Port_MADRAS/CHENNAI_Size_20_Type_GP_PartyID_010006979', 'Port_MADRAS/CHENNAI_Size_20_Type_GP (DG)_PartyID_010006979', 'Port_MADRAS/CHENNAI_Size_40_Type_GP_PartyID_010006979', 'Port_MADRAS/CHENNAI_Size_40_Type_HC_PartyID_010006979', 'Port_MALTA (FREE PORT)_Size_20_Type_GP_PartyID_010007469', 'Port_MALTA (FREE PORT)_Size_20_Type_GP_PartyID_010008325', 'Port_MALTA (FREE PORT)_Size_20_Type_GP_PartyID_010018998', 'Port_MALTA (FREE PORT)_Size_40_Type_HC_PartyID_010007469', 'Port_MALTA (FREE PORT)_Size_40_Type_HC_PartyID_010008325', 'Port_MALTA (FREE PORT)_Size_40_Type_HC_PartyID_010018998', 'Port_MANILA (NORTH HARBOUR)_Size_20_Type_GP_PartyID_010020486', 'Port_MANILA (NORTH HARBOUR)_Size_20_Type_GP_PartyID_010021727', 'Port_MANILA (NORTH HARBOUR)_Size_20_Type_GP_PartyID_01004969', 'Port_MANILA (NORTH HARBOUR)_Size_20_Type_GP (DG)_PartyID_01004969', 'Port_MANILA (NORTH HARBOUR)_Size_40_Type_GP_PartyID_01004969', 'Port_MANILA (NORTH HARBOUR)_Size_40_Type_HC_PartyID_010020486', 'Port_MANILA (NORTH HARBOUR)_Size_40_Type_HC_PartyID_010021727', 'Port_MANILA (NORTH HARBOUR)_Size_40_Type_HC_PartyID_01004969', 'Port_MANILA (NORTH HARBOUR)_Size_40_Type_HC (DG)_PartyID_010020486', 'Port_MANILA (SOUTH HARBOUR)_Size_20_Type_GP_PartyID_010020486', 'Port_MANILA (SOUTH HARBOUR)_Size_20_Type_GP_PartyID_010021727', 'Port_MANILA (SOUTH HARBOUR)_Size_20_Type_GP_PartyID_01004969', 'Port_MANILA (SOUTH HARBOUR)_Size_40_Type_HC_PartyID_010020486', 'Port_MANILA (SOUTH HARBOUR)_Size_40_Type_HC_PartyID_010021727', 'Port_MANILA (SOUTH HARBOUR)_Size_40_Type_HC_PartyID_01004969', 'Port_MANILA(SOUTH HARBOUR)_Size_20_Type_GP_PartyID_01004969', 'Port_MANILA(SOUTH HARBOUR)_Size_20_Type_GP_PartyID_01005114', 'Port_MANILA(SOUTH HARBOUR)_Size_40_Type_HC_PartyID_01004969', 'Port_MANZANILLO , MEXICO_Size_20_Type_GP_PartyID_010004319', 'Port_MANZANILLO , MEXICO_Size_20_Type_GP_PartyID_010017866', 'Port_MANZANILLO , MEXICO_Size_20_Type_GP_PartyID_01008144', 'Port_MANZANILLO , MEXICO_Size_40_Type_GP_PartyID_010004319', 'Port_MANZANILLO , MEXICO_Size_40_Type_GP_PartyID_010006338', 'Port_MANZANILLO , MEXICO_Size_40_Type_GP_PartyID_010017866', 'Port_MANZANILLO , MEXICO_Size_40_Type_GP_PartyID_01008144', 'Port_MANZANILLO , MEXICO_Size_40_Type_HC_PartyID_010004319', 'Port_MANZANILLO , MEXICO_Size_40_Type_HC_PartyID_010006338', 'Port_MANZANILLO , MEXICO_Size_40_Type_HC_PartyID_010017866', 'Port_MANZANILLO , MEXICO_Size_40_Type_HC_PartyID_01008144', 'Port_MANZANILLO , MEXICO_Size_40_Type_HC NOR_PartyID_010004319', 'Port_MANZANILLO , MEXICO_Size_40_Type_HC NOR_PartyID_010017866', 'Port_MANZANILLO, MEXICO_Size_20_Type_GP_PartyID_010017866', 'Port_MANZANILLO, MEXICO_Size_20_Type_GP_PartyID_010017867', 'Port_MANZANILLO, MEXICO_Size_40_Type_GP_PartyID_010017866', 'Port_MANZANILLO, MEXICO_Size_40_Type_HC_PartyID_010017866', 'Port_MANZANILLO, MEXICO_Size_40_Type_HC_PartyID_010017867', 'Port_MANZANILLO, MEXICO_Size_40_Type_HC NOR_PartyID_010017866', 'Port_MANZANILLO, MEXICO_Size_40_Type_HC NOR_PartyID_010017867', 'Port_MARSAXLOKK( MALTA )_Size_20_Type_GP_PartyID_010008325', 'Port_MARSAXLOKK( MALTA )_Size_20_Type_GP_PartyID_010018998', 'Port_MARSAXLOKK( MALTA )_Size_40_Type_GP_PartyID_010008325', 'Port_MARSAXLOKK( MALTA )_Size_40_Type_GP_PartyID_010018998', 'Port_MARSAXLOKK( MALTA )_Size_40_Type_HC_PartyID_010008325', 'Port_MARSAXLOKK( MALTA )_Size_40_Type_HC_PartyID_010018998', 'Port_MARSAXLOKK( MALTA )_Size_40_Type_HC NOR_PartyID_010018998', 'Port_MARSEILLE_Size_20_Type_GP_PartyID_01001088', 'Port_MARSEILLE_Size_20_Type_GP_PartyID_010019364', 'Port_MARSEILLE_Size_40_Type_GP_PartyID_01001088', 'Port_MARSEILLE_Size_40_Type_HC_PartyID_01001088', 'Port_MARSEILLE_Size_40_Type_HC_PartyID_010019364', 'Port_MARSEILLE_Size_40_Type_HC NOR_PartyID_01001088', 'Port_MARSEILLE_Size_40_Type_HC NOR_PartyID_010019364', 'Port_MELBOURNE_Size_20_Type_GP_PartyID_01002778', 'Port_MELBOURNE_Size_20_Type_GP_PartyID_01005078', 'Port_MELBOURNE_Size_40_Type_GP_PartyID_01002778', 'Port_MELBOURNE_Size_40_Type_HC_PartyID_01002778', 'Port_MELBOURNE_Size_40_Type_HC_PartyID_01002779', 'Port_MELBOURNE_Size_40_Type_HC NOR_PartyID_01002778', 'Port_MERSIN_Size_20_Type_GP_PartyID_01008316', 'Port_MERSIN_Size_40_Type_GP_PartyID_01008316', 'Port_MERSIN_Size_40_Type_HC_PartyID_01008316', 'Port_MIAMI_Size_20_Type_GP_PartyID_010008022', 'Port_MIAMI_Size_40_Type_GP_PartyID_010008022', 'Port_MIAMI_Size_40_Type_GP_PartyID_01001993', 'Port_MIAMI_Size_40_Type_HC_PartyID_010008022', 'Port_MIAMI_Size_40_Type_HC_PartyID_01001993', 'Port_MIAMI_Size_40_Type_HC NOR_PartyID_010008022', 'Port_MIAMI_Size_40_Type_HC NOR_PartyID_01001993', 'Port_MIAMI_Size_45_Type_GP_PartyID_01001993', 'Port_MOMBASA_Size_20_Type_GP_PartyID_01001963', 'Port_MOMBASA_Size_20_Type_GP_PartyID_010020691', 'Port_MOMBASA_Size_40_Type_GP_PartyID_01001963', 'Port_MOMBASA_Size_40_Type_HC_PartyID_01001963', 'Port_MOMBASA_Size_40_Type_HC_PartyID_010020691', 'Port_MOMBASA_Size_40_Type_HC NOR_PartyID_01001963', 'Port_MONTEVIDEO_Size_20_Type_GP_PartyID_01006065', 'Port_MONTEVIDEO_Size_40_Type_HC_PartyID_010021385', 'Port_MONTEVIDEO_Size_40_Type_HC_PartyID_01006065', 'Port_MONTEVIDEO_Size_40_Type_HC NOR_PartyID_010021385', 'Port_MONTEVIDEO_Size_40_Type_HC NOR_PartyID_010021505', 'Port_MONTEVIDEO_Size_40_Type_HC NOR_PartyID_01006065', 'Port_MUMBAI_Size_20_Type_GP_PartyID_01002787', 'Port_MUMBAI_Size_40_Type_GP_PartyID_01002787', 'Port_MUMBAI_Size_40_Type_HC_PartyID_01002787', 'Port_NAGOYA_Size_20_Type_GP_PartyID_010008038', 'Port_NAGOYA_Size_20_Type_GP_PartyID_01005565', 'Port_NAGOYA_Size_20_Type_GP_PartyID_01008573', 'Port_NAGOYA_Size_40_Type_HC_PartyID_010008038', 'Port_NEW DELHI_Size_20_Type_GP_PartyID_010003632', 'Port_NEW DELHI_Size_40_Type_HC_PartyID_010003632', 'Port_NEW DELHI (VIA NHAVA SHEVA)_Size_20_Type_GP_PartyID_010003632', 'Port_NEW DELHI (VIA NHAVA SHEVA)_Size_40_Type_HC_PartyID_010003632', 'Port_NEW YORK_Size_20_Type_GP_PartyID_01005886', 'Port_NEW YORK_Size_40_Type_GP_PartyID_01005886', 'Port_NEW YORK_Size_40_Type_HC_PartyID_01005857', 'Port_NEW YORK_Size_40_Type_HC_PartyID_01005886', 'Port_NEW YORK_Size_40_Type_HC NOR_PartyID_01005886', 'Port_NEW YORK_Size_45_Type_HC_PartyID_01005886', 'Port_NHAVA SHEVA_Size_20_Type_GP_PartyID_01002787', 'Port_NHAVA SHEVA_Size_40_Type_HC_PartyID_01002787', 'Port_NHAVA SHEVA_Size_40_Type_HC (DG)_PartyID_01002787', 'Port_NHAVA SHEVA ( JNPT )_Size_20_Type_GP_PartyID_01002787', 'Port_NHAVA SHEVA ( JNPT )_Size_40_Type_GP_PartyID_01002787', 'Port_NHAVA SHEVA ( JNPT )_Size_40_Type_HC_PartyID_01002787', 'Port_NHAVA SHEVA, INDIA_Size_40_Type_HC_PartyID_01002787', 'Port_NHAVA SHEVA/NEW DELHI_Size_20_Type_GP_PartyID_010003632', 'Port_NHAVA SHEVA/NEW DELHI_Size_40_Type_HC_PartyID_010003632', 'Port_NINGBO_Size_20_Type_GP_PartyID_01001667', 'Port_NINGBO_Size_40_Type_HC_PartyID_01001667', 'Port_ODESSA_Size_20_Type_GP_PartyID_010019008', 'Port_ODESSA_Size_20_Type_GP_PartyID_010019966', 'Port_ODESSA_Size_40_Type_GP_PartyID_010019966', 'Port_ODESSA_Size_40_Type_HC_PartyID_010019008', 'Port_ODESSA_Size_40_Type_HC_PartyID_010019966', 'Port_OSAKA_Size_20_Type_GP_PartyID_01005564', 'Port_OSAKA_Size_40_Type_HC_PartyID_01005564', 'Port_OSAKA_Size_40_Type_HC_PartyID_01008573', 'Port_OSLO_Size_20_Type_GP_PartyID_0100027829', 'Port_OSLO_Size_20_Type_GP_PartyID_010006665', 'Port_OSLO_Size_40_Type_HC_PartyID_0100027829', 'Port_OSLO_Size_40_Type_HC_PartyID_010006665', 'Port_OSLO_Size_40_Type_HC NOR_PartyID_0100027829', 'Port_OSLO_Size_40_Type_HC NOR_PartyID_010006665', 'Port_PASIR GUDANG_Size_20_Type_GP_PartyID_010016702', 'Port_PASIR GUDANG_Size_20_Type_GP_PartyID_01002767', 'Port_PASIR GUDANG_Size_20_Type_GP (SOC)_PartyID_010016702', 'Port_PASIR GUDANG_Size_20_Type_GP (SOC)_PartyID_01002767', 'Port_PASIR GUDANG_Size_40_Type_GP_PartyID_01002767', 'Port_PASIR GUDANG_Size_40_Type_HC_PartyID_010016702', 'Port_PASIR GUDANG_Size_40_Type_HC_PartyID_01002767', 'Port_PASIR GUDANG_Size_40_Type_HC (SOC)_PartyID_01002767', 'Port_PENANG_Size_20_Type_GP_PartyID_010007888', 'Port_PENANG_Size_20_Type_GP_PartyID_01002765', 'Port_PENANG_Size_40_Type_HC_PartyID_010007888', 'Port_PENANG_Size_40_Type_HC_PartyID_01002765', 'Port_PHNOM PENH_Size_40_Type_HC_PartyID_010021748', 'Port_PIRAEUS_Size_20_Type_GP_PartyID_010006369', 'Port_PIRAEUS_Size_40_Type_GP_PartyID_010006369', 'Port_PIRAEUS_Size_40_Type_HC_PartyID_010006369', 'Port_POINTE DES GALETS_Size_20_Type_GP_PartyID_010007778', 'Port_POINTE DES GALETS_Size_40_Type_HC_PartyID_010007778', 'Port_POINTE DES GALETS/REUNION_Size_20_Type_GP_PartyID_010007778', 'Port_POINTE DES GALETS/REUNION_Size_20_Type_GP_PartyID_010026749', 'Port_POINTE DES GALETS/REUNION_Size_40_Type_GP_PartyID_010007778', 'Port_POINTE DES GALETS/REUNION_Size_40_Type_HC_PartyID_010007778', 'Port_POINTE DES GALETS/REUNION_Size_40_Type_HC_PartyID_010026749', 'Port_PORT ELIZABETH_Size_20_Type_GP_PartyID_010007919', 'Port_PORT ELIZABETH_Size_40_Type_GP_PartyID_010007919', 'Port_PORT ELIZABETH_Size_40_Type_HC_PartyID_010007919', 'Port_PORT ELIZABETH_Size_40_Type_HC NOR_PartyID_010007919', 'Port_PORT KELANG_Size_20_Type_GP_PartyID_01002769', 'Port_PORT KELANG_Size_40_Type_HC_PartyID_01002769', 'Port_PORT KLANG_Size_20_Type_GP_PartyID_01002769', 'Port_PORT KLANG_Size_20_Type_GP (DG)_PartyID_01002769', 'Port_PORT KLANG_Size_40_Type_HC_PartyID_01002769', 'Port_PORT KLANG (NORTH PORT)_Size_20_Type_GP_PartyID_01002769', 'Port_PORT KLANG (NORTH PORT)_Size_40_Type_HC_PartyID_01002769', 'Port_PORT KLANG (WEST PORT)_Size_20_Type_GP_PartyID_01002769', 'Port_PORT LOUIS_Size_20_Type_GP_PartyID_01000083', 'Port_PORT LOUIS_Size_20_Type_GP_PartyID_010007778', 'Port_PORT LOUIS_Size_20_Type_GP_PartyID_010009137', 'Port_PORT LOUIS_Size_20_Type_GP_PartyID_010026749', 'Port_PORT LOUIS_Size_40_Type_GP_PartyID_01000083', 'Port_PORT LOUIS_Size_40_Type_GP_PartyID_010007778', 'Port_PORT LOUIS_Size_40_Type_GP_PartyID_010009137', 'Port_PORT LOUIS_Size_40_Type_GP_PartyID_010026749', 'Port_PORT LOUIS_Size_40_Type_HC_PartyID_01000083', 'Port_PORT LOUIS_Size_40_Type_HC_PartyID_010007778', 'Port_PORT LOUIS_Size_40_Type_HC_PartyID_010007877', 'Port_PORT LOUIS_Size_40_Type_HC_PartyID_010009137', 'Port_PORT LOUIS_Size_40_Type_HC_PartyID_010026749', 'Port_PORT LOUIS_Size_40_Type_HC NOR_PartyID_010026749', 'Port_PORT MORESBY_Size_40_Type_GP_PartyID_01007594', 'Port_PORT SAID_Size_20_Type_GP_PartyID_010004995', 'Port_PORT SAID_Size_40_Type_GP_PartyID_010004995', 'Port_PORT SAID_Size_40_Type_HC_PartyID_010004995', 'Port_PORT SAID (WEST)_Size_20_Type_GP_PartyID_010004995', 'Port_PORT SAID (WEST)_Size_40_Type_HC_PartyID_010004995', 'Port_PORT TANGIER MEDITERRANEE (TANGIER PORT)_Size_20_Type_GP_PartyID_010006336', 'Port_PORT TANGIER MEDITERRANEE (TANGIER PORT)_Size_40_Type_HC_PartyID_010006336', 'Port_PORTO (LEIXOES)_Size_20_Type_GP_PartyID_010008857', 'Port_PORTO (LEIXOES)_Size_20_Type_GP NOR_PartyID_010008857', 'Port_PORTO (LEIXOES)_Size_40_Type_GP_PartyID_010008857', 'Port_PORTO (LEIXOES)_Size_40_Type_HC_PartyID_010008857', 'Port_PORTO (LEIXOES)_Size_40_Type_HC NOR_PartyID_010008857', 'Port_POTI_Size_20_Type_GP_PartyID_010020790', 'Port_POTI_Size_20_Type_GP_PartyID_010021426', 'Port_POTI_Size_20_Type_GP_PartyID_010021486', 'Port_POTI_Size_40_Type_HC_PartyID_010020790', 'Port_POTI_Size_40_Type_HC_PartyID_010021426', 'Port_PRAGUE_Size_20_Type_GP_PartyID_010007758', 'Port_PRAGUE_Size_40_Type_GP_PartyID_010007758', 'Port_PRAGUE_Size_40_Type_HC_PartyID_010007758', 'Port_PRAGUE_Size_40_Type_HC (SOC)_PartyID_010007758', 'Port_PRAGUE / PRAHA_Size_20_Type_GP_PartyID_010007758', 'Port_PRAGUE / PRAHA_Size_40_Type_GP_PartyID_010007758', 'Port_PRAGUE / PRAHA_Size_40_Type_HC_PartyID_010007758', 'Port_PRAGUE / PRAHA_Size_40_Type_HC (SOC)_PartyID_010007758', 'Port_QINGDAO_Size_20_Type_GP_PartyID_010007376', 'Port_QINGDAO_Size_40_Type_HC_PartyID_010007376', 'Port_QINGDAO_Size_40_Type_HC_PartyID_01001118', 'Port_QINGDAO_Size_40_Type_HC (SOC)_PartyID_01005854', 'Port_RIJEKA_Size_20_Type_GP_PartyID_010005276', 'Port_RIJEKA_Size_20_Type_GP_PartyID_010008166', 'Port_RIJEKA_Size_40_Type_GP_PartyID_010008166', 'Port_RIJEKA_Size_40_Type_HC_PartyID_010005276', 'Port_RIJEKA_Size_40_Type_HC_PartyID_010008166', 'Port_RIO DE JANEIRO_Size_40_Type_HC NOR_PartyID_01001602', 'Port_RIO GRANDE (BRAZIL)_Size_40_Type_HC NOR_PartyID_01001602', 'Port_ROSARIO_Size_20_Type_GP_PartyID_010006613', 'Port_ROSARIO_Size_40_Type_HC_PartyID_010006613', 'Port_ROTTERDAM_Size_20_Type_GP_PartyID_01001448', 'Port_ROTTERDAM_Size_40_Type_HC_PartyID_01001448', 'Port_ROTTERDAM_Size_40_Type_HC NOR_PartyID_01001448', 'Port_ROTTERDAM_Size_40_Type_HC NOR_PartyID_01008827', 'Port_SAN JOSE_Size_20_Type_GP_PartyID_010017587', 'Port_SAN JOSE_Size_40_Type_HC_PartyID_010017587', 'Port_SAN JOSE_Size_40_Type_HC NOR_PartyID_010017587', 'Port_SEMARANG_Size_20_Type_GP_PartyID_010007418', 'Port_SEMARANG_Size_20_Type_GP_PartyID_010008923', 'Port_SEMARANG_Size_20_Type_GP_PartyID_01006256', 'Port_SEMARANG_Size_40_Type_GP_PartyID_01006256', 'Port_SEMARANG_Size_40_Type_HC_PartyID_010007418', 'Port_SEMARANG_Size_40_Type_HC_PartyID_010008923', 'Port_SEMARANG_Size_40_Type_HC_PartyID_01006256', 'Port_SHANGHAI_Size_40_Type_HC_PartyID_010007376', 'Port_SHANGHAI_Size_40_Type_HC_PartyID_01005130', 'Port_SIHANOUKVILLE_Size_20_Type_GP_PartyID_010021748', 'Port_SIHANOUKVILLE_Size_20_Type_GP_PartyID_010027696', 'Port_SIHANOUKVILLE_Size_40_Type_HC_PartyID_010021748', 'Port_SIHANOUKVILLE_Size_40_Type_HC_PartyID_010027696', 'Port_SINES_Size_20_Type_GP_PartyID_010008857', 'Port_SINES_Size_40_Type_GP_PartyID_010008857', 'Port_SINES_Size_40_Type_HC_PartyID_010008857', 'Port_SINES (PORTUGAL)_Size_40_Type_HC_PartyID_010008857', 'Port_SOUTHAMPTON_Size_20_Type_GP_PartyID_01002303', 'Port_SURABAYA_Size_20_Type_GP_PartyID_010008922', 'Port_SURABAYA_Size_20_Type_GP_PartyID_01006257', 'Port_SURABAYA_Size_20_Type_GP (DG)_PartyID_010008922', 'Port_SURABAYA_Size_40_Type_GP_PartyID_01006257', 'Port_SURABAYA_Size_40_Type_HC_PartyID_010008922', 'Port_SURABAYA_Size_40_Type_HC_PartyID_01005114', 'Port_SURABAYA_Size_40_Type_HC_PartyID_01006257', 'Port_SUVA_Size_20_Type_GP_PartyID_01008681', 'Port_SUVA_Size_40_Type_GP_PartyID_01008681', 'Port_SUVA_Size_40_Type_HC_PartyID_01008681', 'Port_SYDNEY_Size_20_Type_GP_PartyID_01002779', 'Port_SYDNEY_Size_40_Type_GP_PartyID_01002779', 'Port_SYDNEY_Size_40_Type_HC_PartyID_01002779', 'Port_SYDNEY_Size_40_Type_HC_PartyID_01005078', 'Port_SYDNEY_Size_40_Type_HC NOR_PartyID_01002779', 'Port_SYDNEY(AU)_Size_20_Type_GP_PartyID_01002779', 'Port_SYDNEY(AU)_Size_40_Type_HC_PartyID_01002779', 'Port_SYDNEY(AU)_Size_40_Type_HC NOR_PartyID_01002779', 'Port_TALLINN_Size_20_Type_GP_PartyID_010018747', 'Port_TALLINN_Size_40_Type_GP_PartyID_010018747', 'Port_TALLINN_Size_40_Type_HC_PartyID_010018747', 'Port_TAMATAVE (TOAMASINA)_Size_20_Type_GP_PartyID_010007778', 'Port_TAMATAVE (TOAMASINA)_Size_20_Type_GP_PartyID_010026749', 'Port_TAMATAVE (TOAMASINA)_Size_40_Type_HC_PartyID_010007778', 'Port_TAMATAVE (TOAMASINA)_Size_40_Type_HC_PartyID_010026749', 'Port_TAMATAVE (TOMASINA)_Size_20_Type_GP_PartyID_010007778', 'Port_TAMATAVE (TOMASINA)_Size_20_Type_GP_PartyID_010008880', 'Port_TAMATAVE (TOMASINA)_Size_40_Type_GP_PartyID_010008880', 'Port_TAMATAVE (TOMASINA)_Size_40_Type_HC_PartyID_010007778', 'Port_TAMATAVE (TOMASINA)_Size_40_Type_HC_PartyID_010008880', 'Port_TAN CANG (NEW PORT)_Size_20_Type_GP_PartyID_010005256', 'Port_TAN CANG (NEW PORT)_Size_40_Type_HC_PartyID_010005256', 'Port_TANGIER PORT_Size_40_Type_HC_PartyID_010006336', 'Port_TEMA_Size_40_Type_HC_PartyID_010008832', 'Port_THESSALONIKI_Size_20_Type_GP_PartyID_010006487', 'Port_THESSALONIKI_Size_40_Type_GP_PartyID_010006487', 'Port_THESSALONIKI_Size_40_Type_HC_PartyID_010006487', 'Port_TOKYO_Size_20_Type_GP_PartyID_01005565', 'Port_TOKYO_Size_40_Type_HC_PartyID_01005552', 'Port_TOKYO_Size_40_Type_HC_PartyID_01005565', 'Port_TORONTO_Size_40_Type_HC NOR_PartyID_01002807', 'Port_TRIPOLI_Size_20_Type_GP_PartyID_010003651', 'Port_TRIPOLI_Size_40_Type_HC_PartyID_010003651', 'Port_TRIPOLI (LEBANON)_Size_20_Type_GP_PartyID_010003651', 'Port_VALENCIA_Size_20_Type_GP_PartyID_01008306', 'Port_VALENCIA_Size_40_Type_GP_PartyID_01008306', 'Port_VALENCIA_Size_40_Type_HC_PartyID_01008306', 'Port_VALENCIA_Size_40_Type_HC NOR_PartyID_01008306', 'Port_VALPARAISO_Size_20_Type_GP_PartyID_010006350', 'Port_VALPARAISO_Size_20_Type_GP_PartyID_01008304', 'Port_VALPARAISO_Size_40_Type_GP_PartyID_010006350', 'Port_VALPARAISO_Size_40_Type_GP_PartyID_01008304', 'Port_VALPARAISO_Size_40_Type_HC_PartyID_010006350', 'Port_VALPARAISO_Size_40_Type_HC_PartyID_01008304', 'Port_VALPARAISO_Size_40_Type_HC NOR_PartyID_010006350', 'Port_VALPARAISO_Size_40_Type_HC NOR_PartyID_01008304', 'Port_VANCOUVER_Size_40_Type_GP_PartyID_01002807', 'Port_VANCOUVER_Size_40_Type_HC_PartyID_010007790', 'Port_VANCOUVER_Size_40_Type_HC_PartyID_01002807', 'Port_VANCOUVER_Size_40_Type_HC NOR_PartyID_010007790', 'Port_VANCOUVER_Size_40_Type_HC NOR_PartyID_01002807', 'Port_VANCOUVER_Size_45_Type_GP_PartyID_01002807', 'Port_VANCOUVER_Size_45_Type_HC_PartyID_010007790', 'Port_VANCOUVER_Size_45_Type_HC_PartyID_01002807', 'Port_VARNA ( BULGARIA )_Size_20_Type_GP_PartyID_010007870', 'Port_VARNA ( BULGARIA )_Size_20_Type_GP_PartyID_010019070', 'Port_VARNA ( BULGARIA )_Size_40_Type_GP_PartyID_010007870', 'Port_VARNA ( BULGARIA )_Size_40_Type_HC_PartyID_010007870', 'Port_VARNA ( BULGARIA )_Size_40_Type_HC_PartyID_010019070', 'Port_VIENNA_Size_20_Type_GP_PartyID_010005265', 'Port_XIAMEN_Size_20_Type_GP_PartyID_01001667', 'Port_XIAMEN_Size_40_Type_HC_PartyID_01000498', 'Port_XIAMEN_Size_40_Type_HC_PartyID_01001667', 'Port_XINGANG_Size_20_Type_GP_PartyID_010007376', 'Port_XINGANG_Size_20_Type_GP (SOC)_PartyID_010007376', 'Port_XINGANG_Size_40_Type_GP_PartyID_01001118', 'Port_XINGANG_Size_40_Type_HC (SOC)_PartyID_010007376', 'Port_YANGON_Size_40_Type_HC_PartyID_010003639', 'Port_YANGON (AWPT)_Size_20_Type_GP_PartyID_010003639', 'Port_YANGON (AWPT)_Size_40_Type_GP_PartyID_010003639', 'Port_YANGON (AWPT)_Size_40_Type_HC_PartyID_010003639', 'Port_YANGON (AWT)_Size_20_Type_GP_PartyID_010003639', 'Port_YANGON (AWT)_Size_20_Type_GP NOR_PartyID_010003639', 'Port_YANGON (AWT)_Size_40_Type_HC_PartyID_010003639', 'Port_YANGON (AWT)_Size_40_Type_HC NOR_PartyID_010003639', 'Port_YANGON (BSW)_Size_40_Type_HC NOR_PartyID_010003639', 'Port_YANGON (MIP)_Size_20_Type_GP_PartyID_010003639', 'Port_YANGON (MIP)_Size_40_Type_HC_PartyID_010003639', 'Port_YOKOHAMA_Size_20_Type_GP_PartyID_01005565', 'Port_YOKOHAMA_Size_40_Type_HC_PartyID_01005565']\n",
      "789\n",
      "\n",
      "New Data keys:\n",
      "['Port_(CONSTANZA)_Size_40_Type_GP_PartyID_010007816', 'Port_(CONSTANZA)_Size_40_Type_HC_PartyID_010007816', 'Port_AARHUS_Size_20_Type_GP_PartyID_01000043', 'Port_AARHUS_Size_20_Type_GP_PartyID_0100027830', 'Port_AARHUS_Size_20_Type_GP_PartyID_0100028193', 'Port_AARHUS_Size_20_Type_GP_PartyID_010006666', 'Port_AARHUS_Size_40_Type_GP_PartyID_01000043', 'Port_AARHUS_Size_40_Type_HC_PartyID_01000043', 'Port_AARHUS_Size_40_Type_HC_PartyID_0100027830', 'Port_AARHUS_Size_40_Type_HC_PartyID_0100028193', 'Port_AARHUS_Size_40_Type_HC_PartyID_010006666', 'Port_ABIDJAN_Size_20_Type_GP_PartyID_0100027878', 'Port_ABIDJAN_Size_40_Type_HC_PartyID_010021097', 'Port_ADELAIDE_Size_20_Type_GP_PartyID_01002775', 'Port_ADELAIDE_Size_40_Type_GP_PartyID_01002775', 'Port_ADELAIDE_Size_40_Type_HC_PartyID_01002775', 'Port_ADELAIDE_Size_40_Type_HC_PartyID_01005078', 'Port_ADELAIDE_Size_40_Type_HC NOR_PartyID_01002775', 'Port_ADELAIDE(AU)_Size_20_Type_GP_PartyID_01002775', 'Port_ADELAIDE(AU)_Size_40_Type_HC_PartyID_01002775', 'Port_ADELAIDE(AU)_Size_40_Type_HC NOR_PartyID_01002775', 'Port_ALEXANDRIA (EL DEKHELA PORT)_Size_40_Type_HC_PartyID_010004995', 'Port_ALEXANDRIA (OLD PORT)_Size_20_Type_GP_PartyID_010004995', 'Port_ALEXANDRIA (OLD PORT)_Size_40_Type_HC_PartyID_010004995', 'Port_ALEXANDRIA(OLD PORT)_Size_20_Type_GP_PartyID_010004995', 'Port_ALEXANDRIA(OLD PORT)_Size_40_Type_HC_PartyID_010004995', 'Port_ALEXANDRIA(OLD PORT)_Size_40_Type_HC NOR_PartyID_010004995', 'Port_ALGECIRAS_Size_20_Type_GP_PartyID_01008306', 'Port_ALGECIRAS_Size_40_Type_GP_PartyID_01008306', 'Port_ALGECIRAS_Size_40_Type_HC_PartyID_01008306', 'Port_ALGECIRAS_Size_40_Type_HC NOR_PartyID_01008306', 'Port_ALIAGA_Size_20_Type_GP_PartyID_01008316', 'Port_ALIAGA_Size_40_Type_HC_PartyID_01008316', 'Port_ALIAGA PORT (IZMIR)_Size_40_Type_HC_PartyID_01008316', 'Port_ANTWERP_Size_20_Type_GP_PartyID_01001449', 'Port_ANTWERP_Size_40_Type_GP_PartyID_01001449', 'Port_ANTWERP_Size_40_Type_HC_PartyID_01001449', 'Port_ANTWERP_Size_40_Type_HC NOR_PartyID_01001449', 'Port_AQABA_Size_20_Type_GP_PartyID_010006618', 'Port_AQABA_Size_20_Type_GP_PartyID_010021081', 'Port_AQABA_Size_40_Type_HC_PartyID_010006618', 'Port_AQABA_Size_40_Type_HC_PartyID_010021081', 'Port_ASHDOD_Size_20_Type_GP_PartyID_010008035', 'Port_ASHDOD_Size_40_Type_GP_PartyID_010008035', 'Port_ASHDOD_Size_40_Type_GP_PartyID_01008417', 'Port_ASHDOD_Size_40_Type_HC_PartyID_010008035', 'Port_ASHDOD_Size_40_Type_HC_PartyID_01008417', 'Port_AUCKLAND_Size_20_Type_GP_PartyID_01005136', 'Port_AUCKLAND_Size_20_Type_GP (DG)_PartyID_01005136', 'Port_AUCKLAND_Size_40_Type_GP_PartyID_01005136', 'Port_AUCKLAND_Size_40_Type_HC_PartyID_01005136', 'Port_AUCKLAND_Size_40_Type_HC (DG)_PartyID_01005136', 'Port_AUCKLAND_Size_40_Type_HC NOR_PartyID_01005136', 'Port_BANGKOK_Size_20_Type_GP_PartyID_010021593', 'Port_BANGKOK_Size_20_Type_GP_PartyID_01002799', 'Port_BANGKOK_Size_20_Type_GP (DG)_PartyID_01002799', 'Port_BANGKOK_Size_40_Type_GP_PartyID_01002799', 'Port_BANGKOK_Size_40_Type_HC_PartyID_010021593', 'Port_BANGKOK_Size_40_Type_HC_PartyID_01002799', 'Port_BANGKOK_Size_40_Type_HC (DG)_PartyID_010021593', 'Port_BANGKOK_Size_40_Type_HC (DG)_PartyID_01002799', 'Port_BANGKOK_Size_40_Type_HC (SOC)_PartyID_01002799', 'Port_BANGKOK ( TPT )_Size_20_Type_GP_PartyID_010021593', 'Port_BANGKOK ( TPT )_Size_20_Type_GP_PartyID_01002799', 'Port_BANGKOK ( TPT )_Size_40_Type_HC_PartyID_010021593', 'Port_BANGKOK ( TPT )_Size_40_Type_HC_PartyID_01002799', 'Port_BANGKOK (TST)_Size_20_Type_GP_PartyID_010021593', 'Port_BANGKOK (TST)_Size_40_Type_HC_PartyID_010021593', 'Port_BARCELONA_Size_20_Type_GP_PartyID_01008305', 'Port_BARCELONA_Size_40_Type_GP_PartyID_01008305', 'Port_BARCELONA_Size_40_Type_HC_PartyID_01008305', 'Port_BARCELONA_Size_40_Type_HC NOR_PartyID_01008305', 'Port_BEIRUT_Size_20_Type_GP_PartyID_010003651', 'Port_BEIRUT_Size_40_Type_GP_PartyID_010003651', 'Port_BEIRUT_Size_40_Type_HC_PartyID_010003651', 'Port_BEIRUT FREE ZONE_Size_20_Type_GP_PartyID_010003651', 'Port_BEIRUT FREE ZONE_Size_40_Type_HC_PartyID_010003651', 'Port_BEIRUT FREE ZONE_Size_45_Type_HC_PartyID_010003651', 'Port_BELAWAN_Size_20_Type_GP_PartyID_010008921', 'Port_BELAWAN_Size_20_Type_GP_PartyID_01006254', 'Port_BELAWAN_Size_40_Type_GP_PartyID_01006254', 'Port_BELAWAN_Size_40_Type_HC_PartyID_010008921', 'Port_BELAWAN_Size_40_Type_HC_PartyID_01006254', 'Port_BRATISLAVA_Size_20_Type_GP_PartyID_010007864', 'Port_BRATISLAVA_Size_20_Type_GP_PartyID_01003062', 'Port_BRATISLAVA_Size_40_Type_GP_PartyID_01000054', 'Port_BRATISLAVA_Size_40_Type_GP_PartyID_010005269', 'Port_BRATISLAVA_Size_40_Type_GP_PartyID_01003062', 'Port_BRATISLAVA_Size_40_Type_HC_PartyID_01000054', 'Port_BRATISLAVA_Size_40_Type_HC_PartyID_010005269', 'Port_BRATISLAVA_Size_40_Type_HC_PartyID_01003062', 'Port_BRISBANE_Size_20_Type_GP_PartyID_01002776', 'Port_BRISBANE_Size_20_Type_GP_PartyID_01002778', 'Port_BRISBANE_Size_20_Type_GP_PartyID_01002779', 'Port_BRISBANE_Size_20_Type_GP NOR_PartyID_01002776', 'Port_BRISBANE_Size_40_Type_GP_PartyID_01002776', 'Port_BRISBANE_Size_40_Type_HC_PartyID_01002776', 'Port_BRISBANE_Size_40_Type_HC_PartyID_01002778', 'Port_BRISBANE_Size_40_Type_HC NOR_PartyID_01002776', 'Port_BRISBANE_Size_40_Type_HC NOR_PartyID_01002779', 'Port_BUDAPEST_Size_20_Type_GP_PartyID_010007829', 'Port_BUDAPEST_Size_40_Type_GP_PartyID_010007829', 'Port_BUDAPEST_Size_40_Type_HC_PartyID_010007829', 'Port_BUENAVENTURA ,SPR_Size_20_Type_GP_PartyID_010006728', 'Port_BUENAVENTURA ,SPR_Size_40_Type_HC NOR_PartyID_010006728', 'Port_BUENAVENTURA ,SPR_Size_40_Type_HC NOR_PartyID_01001485', 'Port_BUENAVENTURA(COLOMBIA)_Size_20_Type_GP_PartyID_010006728', 'Port_BUENAVENTURA(COLOMBIA)_Size_20_Type_GP_PartyID_01001485', 'Port_BUENAVENTURA(COLOMBIA)_Size_40_Type_GP_PartyID_010006728', 'Port_BUENAVENTURA(COLOMBIA)_Size_40_Type_GP_PartyID_01001485', 'Port_BUENAVENTURA(COLOMBIA)_Size_40_Type_HC_PartyID_010006728', 'Port_BUENAVENTURA(COLOMBIA)_Size_40_Type_HC_PartyID_01001485', 'Port_BUENAVENTURA(COLOMBIA)_Size_40_Type_HC NOR_PartyID_01001485', 'Port_BUENOS AIRES_Size_20_Type_GP_PartyID_01006063', 'Port_BUENOS AIRES_Size_40_Type_HC_PartyID_010006300', 'Port_BUENOS AIRES_Size_40_Type_HC_PartyID_010021498', 'Port_BUENOS AIRES_Size_40_Type_HC_PartyID_01006063', 'Port_BUENOS AIRES_Size_40_Type_HC NOR_PartyID_010006300', 'Port_BUENOS AIRES_Size_40_Type_HC NOR_PartyID_010021498', 'Port_BUENOS AIRES_Size_40_Type_HC NOR_PartyID_01006063', 'Port_BUSAN_Size_20_Type_GP_PartyID_010004286', 'Port_BUSAN_Size_20_Type_GP_PartyID_01001867', 'Port_BUSAN_Size_40_Type_HC_PartyID_010004286', 'Port_BUSAN_Size_40_Type_HC_PartyID_01001867', 'Port_BUSAN_Size_40_Type_HC (SOC)_PartyID_010004286', 'Port_BUSAN_Size_40_Type_HC NOR_PartyID_010017867', 'Port_CALCUTTA_Size_20_Type_GP_PartyID_010006978', 'Port_CALCUTTA_Size_40_Type_HC_PartyID_010006978', 'Port_CALLAO_Size_20_Type_GP_PartyID_01002621', 'Port_CALLAO_Size_20_Type_GP_PartyID_010026711', 'Port_CALLAO_Size_40_Type_GP_PartyID_01002621', 'Port_CALLAO_Size_40_Type_HC_PartyID_01002621', 'Port_CALLAO_Size_40_Type_HC_PartyID_010026711', 'Port_CALLAO_Size_40_Type_HC NOR_PartyID_01002621', 'Port_CALLAO_Size_40_Type_HC NOR_PartyID_010026711', 'Port_CAPE TOWN_Size_20_Type_GP_PartyID_010007917', 'Port_CAPE TOWN_Size_40_Type_HC_PartyID_010007917', 'Port_CAPE TOWN_Size_40_Type_HC NOR_PartyID_010007917', 'Port_CAPETOWN_Size_20_Type_GP_PartyID_010007917', 'Port_CAPETOWN_Size_20_Type_GP_PartyID_01007272', 'Port_CAPETOWN_Size_40_Type_GP_PartyID_010007917', 'Port_CAPETOWN_Size_40_Type_GP_PartyID_01007272', 'Port_CAPETOWN_Size_40_Type_HC_PartyID_010007917', 'Port_CAPETOWN_Size_40_Type_HC_PartyID_01007272', 'Port_CASABLANCA_Size_20_Type_GP_PartyID_010006336', 'Port_CASABLANCA_Size_40_Type_GP_PartyID_010006336', 'Port_CASABLANCA_Size_40_Type_HC_PartyID_010006336', 'Port_CAT LAI (HO CHI MINH)_Size_20_Type_GP_PartyID_010005256', 'Port_CAT LAI (HO CHI MINH)_Size_20_Type_GP_PartyID_01004649', 'Port_CAT LAI (HO CHI MINH)_Size_40_Type_GP_PartyID_010005256', 'Port_CAT LAI (HO CHI MINH)_Size_40_Type_HC_PartyID_010005256', 'Port_CAT LAI (HO CHI MINH)_Size_40_Type_HC_PartyID_01004649', 'Port_CAT LAI (HO CHI MINH)_Size_40_Type_HC_PartyID_01005854', 'Port_CAT LAI (HO CHI MINH)_Size_40_Type_HC NOR_PartyID_010005256', 'Port_CAT LAI (HO CHI MINH)_Size_45_Type_HC_PartyID_010005256', 'Port_CAT LAI (HOCHIMINH)_Size_20_Type_GP_PartyID_010005256', 'Port_CAT LAI (HOCHIMINH)_Size_20_Type_GP (DG)_PartyID_010005256', 'Port_CAT LAI (HOCHIMINH)_Size_40_Type_HC_PartyID_010005256', 'Port_CAT LAI PORT_Size_20_Type_GP_PartyID_010005256', 'Port_CAT LAI PORT_Size_20_Type_GP (DG)_PartyID_010005256', 'Port_CAT LAI PORT_Size_40_Type_HC_PartyID_010005256', 'Port_CAT LAI PORT_Size_40_Type_HC (DG)_PartyID_010005256', 'Port_CEBU_Size_20_Type_GP_PartyID_010020487', 'Port_CEBU_Size_20_Type_GP_PartyID_010021735', 'Port_CEBU_Size_20_Type_GP_PartyID_01004970', 'Port_CEBU_Size_40_Type_HC_PartyID_010020487', 'Port_CEBU_Size_40_Type_HC_PartyID_010021735', 'Port_CEBU_Size_40_Type_HC_PartyID_01004970', 'Port_CHATTOGRAM (CHITTAGONG)_Size_20_Type_GP_PartyID_010021463', 'Port_CHATTOGRAM (CHITTAGONG)_Size_40_Type_HC_PartyID_010021463', 'Port_CHENNAI_Size_20_Type_GP_PartyID_010006979', 'Port_CHENNAI_Size_40_Type_HC_PartyID_010006979', 'Port_CHITTAGONG_Size_20_Type_GP_PartyID_010007693', 'Port_COCHIN_Size_20_Type_GP_PartyID_010006980', 'Port_COCHIN_Size_20_Type_GP_PartyID_01008782', 'Port_COCHIN_Size_40_Type_HC_PartyID_010006980', 'Port_COCHIN_Size_40_Type_HC_PartyID_01008782', 'Port_COLOMBO_Size_20_Type_GP_PartyID_01001668', 'Port_COLOMBO_Size_40_Type_GP_PartyID_01001668', 'Port_COLOMBO_Size_40_Type_HC_PartyID_01001668', 'Port_COLOMBO_Size_40_Type_HC_PartyID_01004906', 'Port_COLOMBO_Size_45_Type_HC_PartyID_01001668', 'Port_COLON FREE ZONE_Size_20_Type_GP_PartyID_010006741', 'Port_COLON FREE ZONE_Size_40_Type_HC_PartyID_010006741', 'Port_COLON FREE ZONE_Size_40_Type_HC_PartyID_010019558', 'Port_COLON FREE ZONE_Size_40_Type_HC NOR_PartyID_010006741', 'Port_CONSTANTA_Size_20_Type_GP_PartyID_010007816', 'Port_CONSTANTA_Size_20_Type_GP_PartyID_010009323', 'Port_CONSTANTA_Size_40_Type_GP_PartyID_010007816', 'Port_CONSTANTA_Size_40_Type_HC_PartyID_010007816', 'Port_CONSTANTA_Size_40_Type_HC_PartyID_010009323', 'Port_CONSTANTA CFS_Size_20_Type_GP_PartyID_010009323', 'Port_CONSTANTA CFS_Size_40_Type_GP_PartyID_010009323', 'Port_CONSTANTA CFS_Size_40_Type_HC_PartyID_010009323', 'Port_CONSTANZA_Size_20_Type_GP_PartyID_010007816', 'Port_CONSTANZA_Size_40_Type_GP_PartyID_010007816', 'Port_CONSTANZA_Size_40_Type_HC_PartyID_010007816', 'Port_COPENHAGEN_Size_20_Type_GP_PartyID_01000043', 'Port_COPENHAGEN_Size_20_Type_GP_PartyID_0100027830', 'Port_COPENHAGEN_Size_20_Type_GP_PartyID_010006666', 'Port_COPENHAGEN_Size_20_Type_GP_PartyID_010006669', 'Port_COPENHAGEN_Size_40_Type_GP_PartyID_01000043', 'Port_COPENHAGEN_Size_40_Type_HC_PartyID_01000043', 'Port_COPENHAGEN_Size_40_Type_HC_PartyID_0100027830', 'Port_COPENHAGEN_Size_40_Type_HC_PartyID_010006669', 'Port_COPENHAGEN_Size_40_Type_HC NOR_PartyID_010006669', 'Port_DALIAN_Size_20_Type_GP_PartyID_010007376', 'Port_DALIAN_Size_40_Type_HC_PartyID_010007376', 'Port_DANANG_Size_20_Type_GP_PartyID_010005257', 'Port_DANANG_Size_40_Type_HC_PartyID_010005257', 'Port_DAR ES SALAAM(TANZANIA)_Size_20_Type_GP_PartyID_010020396', 'Port_DAR ES SALAAM(TANZANIA)_Size_20_Type_GP_PartyID_010020400', 'Port_DAR ES SALAAM(TANZANIA)_Size_20_Type_GP_PartyID_01003047', 'Port_DAR ES SALAAM(TANZANIA)_Size_40_Type_HC_PartyID_010020396', 'Port_DAR ES SALAAM(TANZANIA)_Size_40_Type_HC_PartyID_010020400', 'Port_DUBAI (JEBEL ALI)_Size_20_Type_GP_PartyID_01002788', 'Port_DUBAI (JEBEL ALI)_Size_40_Type_GP (SOC)_PartyID_01002788', 'Port_DUBAI (JEBEL ALI)_Size_40_Type_HC_PartyID_01002788', 'Port_DUBLIN_Size_20_Type_GP_PartyID_010009104', 'Port_DUBLIN_Size_20_Type_GP_PartyID_010027322', 'Port_DUBLIN_Size_20_Type_GP_PartyID_01003442', 'Port_DUBLIN_Size_40_Type_GP_PartyID_010009104', 'Port_DUBLIN_Size_40_Type_GP_PartyID_01003442', 'Port_DUBLIN_Size_40_Type_HC_PartyID_010009104', 'Port_DUBLIN_Size_40_Type_HC_PartyID_010027322', 'Port_DUBLIN_Size_40_Type_HC_PartyID_01003442', 'Port_DUBLIN_Size_40_Type_HC NOR_PartyID_010009104', 'Port_DUBLIN_Size_40_Type_HC NOR_PartyID_010027322', 'Port_DURBAN_Size_20_Type_GP_PartyID_010007911', 'Port_DURBAN_Size_20_Type_GP_PartyID_01007273', 'Port_DURBAN_Size_40_Type_GP_PartyID_010007911', 'Port_DURBAN_Size_40_Type_GP_PartyID_01007273', 'Port_DURBAN_Size_40_Type_GP (SOC)_PartyID_01007273', 'Port_DURBAN_Size_40_Type_HC_PartyID_010007911', 'Port_DURBAN_Size_40_Type_HC_PartyID_01007273', 'Port_DURBAN_Size_40_Type_HC (SOC)_PartyID_01007273', 'Port_DURBAN_Size_40_Type_HC NOR_PartyID_010007911', 'Port_DURBAN_Size_40_Type_HC NOR (SOC)_PartyID_010007911', 'Port_EVYAP TERMINAL IZMIT_Size_20_Type_GP_PartyID_01008316', 'Port_FELIXSTOWE_Size_20_Type_GP_PartyID_01002303', 'Port_FELIXSTOWE_Size_40_Type_GP_PartyID_01002303', 'Port_FELIXSTOWE_Size_40_Type_HC_PartyID_01002303', 'Port_FELIXSTOWE_Size_40_Type_HC NOR_PartyID_01002303', 'Port_FOS SUR MER_Size_20_Type_GP_PartyID_010019364', 'Port_FOS SUR MER_Size_40_Type_GP_PartyID_010019364', 'Port_FOS SUR MER_Size_40_Type_HC_PartyID_010019364', 'Port_FOS SUR MER_Size_40_Type_HC NOR_PartyID_010019364', 'Port_FOS SUR MER-MARSEILLE_Size_20_Type_GP_PartyID_010019364', 'Port_FOS SUR MER-MARSEILLE_Size_40_Type_GP_PartyID_010019364', 'Port_FOS SUR MER-MARSEILLE_Size_40_Type_HC_PartyID_010019364', 'Port_FREDERICIA / AARHUS_Size_20_Type_GP_PartyID_010006666', 'Port_FREDERICIA / AARHUS_Size_40_Type_HC_PartyID_010006666', 'Port_FREDERICIA / AARHUS_Size_40_Type_HC NOR_PartyID_010006666', 'Port_FREMANTLE_Size_20_Type_GP_PartyID_01002777', 'Port_FREMANTLE_Size_40_Type_GP_PartyID_01002777', 'Port_FREMANTLE_Size_40_Type_HC_PartyID_01002777', 'Port_FREMANTLE_Size_40_Type_HC NOR_PartyID_01002777', 'Port_FREMANTLE (PERTH)_Size_20_Type_GP_PartyID_01002777', 'Port_FREMANTLE (PERTH)_Size_40_Type_HC_PartyID_01002777', 'Port_FREMANTLE (PERTH)_Size_40_Type_HC NOR_PartyID_01002777', 'Port_GDANSK_Size_20_Type_GP_PartyID_010008275', 'Port_GDANSK_Size_40_Type_HC_PartyID_010008275', 'Port_GDYNIA_Size_20_Type_GP_PartyID_010008275', 'Port_GDYNIA_Size_40_Type_GP_PartyID_010008275', 'Port_GDYNIA_Size_40_Type_HC_PartyID_010008275', 'Port_GDYNIA_Size_40_Type_HC NOR_PartyID_010008275', 'Port_GENOA_Size_20_Type_GP_PartyID_01001496', 'Port_GENOA_Size_40_Type_GP_PartyID_01001496', 'Port_GENOA_Size_40_Type_HC_PartyID_01001496', 'Port_GENOA_Size_40_Type_HC NOR_PartyID_01001496', 'Port_GENOVA_Size_40_Type_HC_PartyID_01001496', 'Port_GOTHENBURG_Size_20_Type_GP_PartyID_0100027831', 'Port_GOTHENBURG_Size_20_Type_GP_PartyID_0100028190', 'Port_GOTHENBURG_Size_20_Type_GP_PartyID_010006668', 'Port_GOTHENBURG_Size_20_Type_GP_PartyID_01002876', 'Port_GOTHENBURG_Size_40_Type_HC_PartyID_0100027831', 'Port_GOTHENBURG_Size_40_Type_HC_PartyID_0100028190', 'Port_GOTHENBURG_Size_40_Type_HC_PartyID_010006668', 'Port_GOTHENBURG_Size_40_Type_HC NOR_PartyID_010006668', 'Port_HAIPHONG_Size_20_Type_GP_PartyID_010005255', 'Port_HAIPHONG_Size_40_Type_GP_PartyID_010005255', 'Port_HAIPHONG_Size_40_Type_HC_PartyID_010005255', 'Port_HAMAD PORT_Size_20_Type_GP_PartyID_010020089', 'Port_HAMAD PORT_Size_40_Type_HC_PartyID_010020089', 'Port_HAMAD PORT (QATAR)_Size_40_Type_HC_PartyID_010020089', 'Port_HAMBURG_Size_20_Type_GP_PartyID_01002294', 'Port_HAMBURG_Size_40_Type_GP_PartyID_01002294', 'Port_HAMBURG_Size_40_Type_HC_PartyID_01002294', 'Port_HAMBURG_Size_40_Type_HC NOR_PartyID_01002294', 'Port_HAYDARPASA_Size_20_Type_GP_PartyID_01008316', 'Port_HAYDARPASA_Size_40_Type_HC_PartyID_01008316', 'Port_HELSINKI_Size_20_Type_GP_PartyID_0100027832', 'Port_HELSINKI_Size_20_Type_GP_PartyID_0100028191', 'Port_HELSINKI_Size_20_Type_GP_PartyID_010003678', 'Port_HELSINKI_Size_20_Type_GP_PartyID_010006667', 'Port_HELSINKI_Size_40_Type_GP_PartyID_010003678', 'Port_HELSINKI_Size_40_Type_GP_PartyID_010006667', 'Port_HELSINKI_Size_40_Type_HC_PartyID_0100027832', 'Port_HELSINKI_Size_40_Type_HC_PartyID_0100028191', 'Port_HELSINKI_Size_40_Type_HC_PartyID_010003678', 'Port_HELSINKI_Size_40_Type_HC_PartyID_010006667', 'Port_HO CHI MINH_Size_20_Type_GP_PartyID_010005256', 'Port_HO CHI MINH_Size_40_Type_HC_PartyID_010005256', 'Port_HO CHI MINH_Size_40_Type_HC (SOC)_PartyID_010005256', 'Port_HOCHIMINH ( CAT LAI )_Size_20_Type_GP_PartyID_010005256', 'Port_HOCHIMINH ( CAT LAI )_Size_40_Type_HC_PartyID_010005256', 'Port_HOCHIMINH CAT LAI,VIETNAM_Size_20_Type_GP_PartyID_010005256', 'Port_HOCHIMINH CAT LAI,VIETNAM_Size_40_Type_GP_PartyID_010005256', 'Port_HOCHIMINH CAT LAI,VIETNAM_Size_40_Type_HC_PartyID_010005256', 'Port_HOCHIMINH CAT LAI,VIETNAM_Size_40_Type_HC (DG)_PartyID_010005256', 'Port_HOCHIMINH CITY ( TAN CANG )_Size_40_Type_HC_PartyID_01004649', 'Port_HONG KONG_Size_20_Type_GP_PartyID_01004594', 'Port_HONG KONG_Size_40_Type_GP_PartyID_01004594', 'Port_HONG KONG_Size_40_Type_HC_PartyID_010009070', 'Port_HONG KONG_Size_40_Type_HC_PartyID_01004594', 'Port_ICD BANGALORE_Size_20_Type_GP_PartyID_010007237', 'Port_ICD BANGALORE_Size_40_Type_HC_PartyID_010007237', 'Port_ICD PATPARGANJ_Size_20_Type_GP_PartyID_01002787', 'Port_ICD PATPARGANJ_Size_40_Type_GP_PartyID_01002787', 'Port_ICD PATPARGANJ_Size_40_Type_HC_PartyID_01002787', 'Port_ICD PATPARGANJ_Size_40_Type_HC_PartyID_01008782', 'Port_ICD PHUOC LONG 3_Size_40_Type_HC_PartyID_010005256', 'Port_ILYCHEVSK_Size_20_Type_GP_PartyID_010019008', 'Port_ILYCHEVSK_Size_20_Type_GP_PartyID_010019966', 'Port_ILYCHEVSK_Size_40_Type_HC_PartyID_010019008', 'Port_ISTANBUL (HAYDARPASA)_Size_20_Type_GP_PartyID_01008316', 'Port_ISTANBUL (HAYDARPASA)_Size_40_Type_HC_PartyID_01008316', 'Port_ISTANBUL (MARPORT)_Size_40_Type_HC_PartyID_01008316', 'Port_ISTANBUL(AMBARLI)_Size_40_Type_GP_PartyID_01008316', 'Port_ISTANBUL(AMBARLI)_Size_40_Type_HC_PartyID_01008316', 'Port_ISTANBUL(AMBARLI)_Size_40_Type_HC NOR_PartyID_01008316', 'Port_ISTANBUL(AMBARLI)-KUMPORT_Size_20_Type_GP_PartyID_01008316', 'Port_ISTANBUL(AMBARLI)-KUMPORT_Size_40_Type_HC_PartyID_01008316', 'Port_ISTANBUL(AMBARLI)-MARPORT_Size_20_Type_GP_PartyID_01008316', 'Port_ISTANBUL(AMBARLI)-MARPORT_Size_40_Type_HC_PartyID_01008316', 'Port_ISTANBUL(HAYDARPASA)_Size_20_Type_GP_PartyID_01008316', 'Port_ISTANBUL(HAYDARPASA)_Size_40_Type_GP_PartyID_01008316', 'Port_ISTANBUL(HAYDARPASA)_Size_40_Type_GP_PartyID_01008827', 'Port_ISTANBUL(HAYDARPASA)_Size_40_Type_HC_PartyID_01008316', 'Port_ISTANBUL/KUMPORT (AMBARLI)_Size_20_Type_GP_PartyID_01008316', 'Port_ISTANBUL/KUMPORT (AMBARLI)_Size_40_Type_HC_PartyID_01008316', 'Port_ISTANBUL/MARPORT (AMBARLI)_Size_20_Type_GP_PartyID_01008316', 'Port_ISTANBUL/MARPORT (AMBARLI)_Size_40_Type_HC_PartyID_01008316', 'Port_ITAJAI_Size_20_Type_GP_PartyID_010006079', 'Port_IZMIR_Size_20_Type_GP_PartyID_01008316', 'Port_IZMIR_Size_40_Type_GP_PartyID_01008316', 'Port_IZMIR_Size_40_Type_HC_PartyID_01008316', 'Port_JAKARTA_Size_20_Type_GP_PartyID_010008969', 'Port_JAKARTA_Size_20_Type_GP_PartyID_01006255', 'Port_JAKARTA_Size_20_Type_GP (DG)_PartyID_010008969', 'Port_JAKARTA_Size_40_Type_GP_PartyID_010008969', 'Port_JAKARTA_Size_40_Type_GP_PartyID_01006255', 'Port_JAKARTA_Size_40_Type_HC_PartyID_010008969', 'Port_JAKARTA_Size_40_Type_HC_PartyID_01006255', 'Port_JOHANNESBURG_Size_20_Type_GP_PartyID_010007918', 'Port_JOHANNESBURG_Size_20_Type_GP_PartyID_01007274', 'Port_JOHANNESBURG_Size_40_Type_GP_PartyID_01007274', 'Port_JOHANNESBURG_Size_40_Type_GP (SOC)_PartyID_010007918', 'Port_JOHANNESBURG_Size_40_Type_GP (SOC)_PartyID_01007274', 'Port_JOHANNESBURG_Size_40_Type_HC_PartyID_010007918', 'Port_JOHANNESBURG_Size_40_Type_HC_PartyID_01007274', 'Port_JOHANNESBURG_Size_40_Type_HC NOR_PartyID_010007918', 'Port_KARACHI_Size_20_Type_GP_PartyID_01002783', 'Port_KARACHI_Size_40_Type_HC_PartyID_01002783', 'Port_KARACHI (KICT)_Size_20_Type_GP_PartyID_01002783', 'Port_KARACHI (KICT)_Size_40_Type_HC_PartyID_01002783', 'Port_KEELUNG_Size_20_Type_GP_PartyID_01005822', 'Port_KEELUNG_Size_40_Type_HC_PartyID_010020534', 'Port_KLAIPEDA_Size_20_Type_GP_PartyID_010017977', 'Port_KLAIPEDA_Size_40_Type_GP_PartyID_010017977', 'Port_KLAIPEDA_Size_40_Type_HC_PartyID_010017977', 'Port_KOBE_Size_20_Type_GP_PartyID_01005564', 'Port_KOBE_Size_20_Type_GP_PartyID_01008573', 'Port_KOBE_Size_40_Type_HC_PartyID_01005564', 'Port_KOLKATA_Size_20_Type_GP_PartyID_010006978', 'Port_KOLKATA_Size_40_Type_HC_PartyID_010006978', 'Port_KOPER_Size_20_Type_GP_PartyID_01000055', 'Port_KOPER_Size_20_Type_GP_PartyID_010008166', 'Port_KOPER_Size_20_Type_GP_PartyID_010009052', 'Port_KOPER_Size_40_Type_GP_PartyID_01000055', 'Port_KOPER_Size_40_Type_GP_PartyID_010008166', 'Port_KOPER_Size_40_Type_GP_PartyID_010009052', 'Port_KOPER_Size_40_Type_HC_PartyID_01000055', 'Port_KOPER_Size_40_Type_HC_PartyID_010008166', 'Port_KOPER_Size_40_Type_HC_PartyID_010009052', 'Port_KOPER_Size_40_Type_HC NOR_PartyID_010009052', 'Port_KOTA KINABALU_Size_20_Type_GP_PartyID_01004179', 'Port_KUMPORT_Size_40_Type_GP_PartyID_01008316', 'Port_KUMPORT_Size_40_Type_HC_PartyID_01008316', 'Port_LAEM CHABANG_Size_20_Type_GP_PartyID_010021593', 'Port_LAEM CHABANG_Size_20_Type_GP_PartyID_01002799', 'Port_LAEM CHABANG_Size_20_Type_GP (DG)_PartyID_01002799', 'Port_LAEM CHABANG_Size_40_Type_GP_PartyID_01002799', 'Port_LAEM CHABANG_Size_40_Type_HC_PartyID_010021593', 'Port_LAEM CHABANG_Size_40_Type_HC_PartyID_01002799', 'Port_LAGOS_Size_20_Type_GP_PartyID_010008774', 'Port_LAGOS_Size_40_Type_HC_PartyID_010008774', 'Port_LAT KRABANG_Size_40_Type_HC_PartyID_010021593', 'Port_LATKRABANG_Size_20_Type_GP_PartyID_010021593', 'Port_LATKRABANG_Size_20_Type_GP_PartyID_01002799', 'Port_LATKRABANG_Size_40_Type_GP_PartyID_01002799', 'Port_LATKRABANG_Size_40_Type_HC_PartyID_010021593', 'Port_LATKRABANG_Size_40_Type_HC_PartyID_01002799', 'Port_LAUTOKA_Size_20_Type_GP_PartyID_010008152', 'Port_LAUTOKA_Size_40_Type_HC_PartyID_010008152', 'Port_LE HAVRE_Size_20_Type_GP_PartyID_01001088', 'Port_LE HAVRE_Size_20_Type_GP_PartyID_010019363', 'Port_LE HAVRE_Size_40_Type_GP_PartyID_01001088', 'Port_LE HAVRE_Size_40_Type_GP_PartyID_010019363', 'Port_LE HAVRE_Size_40_Type_HC_PartyID_01001088', 'Port_LE HAVRE_Size_40_Type_HC_PartyID_010019363', 'Port_LE HAVRE_Size_40_Type_HC NOR_PartyID_01001088', 'Port_LE HAVRE_Size_40_Type_HC NOR_PartyID_010019363', 'Port_LEIXOES_Size_20_Type_GP_PartyID_010008857', 'Port_LEIXOES_Size_20_Type_GP_PartyID_01008132', 'Port_LEIXOES_Size_20_Type_GP_PartyID_01008133', 'Port_LEIXOES_Size_40_Type_GP_PartyID_010008857', 'Port_LEIXOES_Size_40_Type_GP_PartyID_010019569', 'Port_LEIXOES_Size_40_Type_GP_PartyID_01008132', 'Port_LEIXOES_Size_40_Type_GP_PartyID_01008133', 'Port_LEIXOES_Size_40_Type_HC_PartyID_010008857', 'Port_LEIXOES_Size_40_Type_HC_PartyID_01008132', 'Port_LIMASSOL_Size_20_Type_GP_PartyID_010007769', 'Port_LIMASSOL_Size_20_Type_GP_PartyID_01001096', 'Port_LIMASSOL_Size_20_Type_GP_PartyID_01002518', 'Port_LIMASSOL_Size_40_Type_GP_PartyID_010007769', 'Port_LIMASSOL_Size_40_Type_GP_PartyID_01001096', 'Port_LIMASSOL_Size_40_Type_GP_PartyID_01002518', 'Port_LIMASSOL_Size_40_Type_HC_PartyID_010007769', 'Port_LIMASSOL_Size_40_Type_HC_PartyID_01001096', 'Port_LIMASSOL_Size_40_Type_HC_PartyID_01002518', 'Port_LISBOA_Size_20_Type_GP_PartyID_010008857', 'Port_LISBOA_Size_20_Type_GP_PartyID_010019569', 'Port_LISBOA_Size_20_Type_GP_PartyID_01008133', 'Port_LISBOA_Size_40_Type_GP_PartyID_010019569', 'Port_LISBOA_Size_40_Type_GP_PartyID_01008133', 'Port_LISBOA_Size_40_Type_HC_PartyID_010008857', 'Port_LISBOA_Size_40_Type_HC_PartyID_010019569', 'Port_LISBOA_Size_40_Type_HC_PartyID_01008133', 'Port_LISBOA_Size_40_Type_HC NOR_PartyID_010019569', 'Port_LOS ANGELES_Size_20_Type_GP_PartyID_01005857', 'Port_LOS ANGELES_Size_40_Type_GP_PartyID_01005857', 'Port_LOS ANGELES_Size_40_Type_HC_PartyID_01005857', 'Port_LOS ANGELES_Size_40_Type_HC NOR_PartyID_01005857', 'Port_LOS ANGELES_Size_45_Type_HC_PartyID_01005857', 'Port_LOS ANGELES (US)_Size_20_Type_GP_PartyID_01005857', 'Port_LOS ANGELES (US)_Size_40_Type_GP_PartyID_01005857', 'Port_LOS ANGELES (US)_Size_40_Type_HC_PartyID_01005857', 'Port_LOS ANGELES (US)_Size_40_Type_HC_PartyID_01008827', 'Port_LOS ANGELES (US)_Size_40_Type_HC NOR_PartyID_01005857', 'Port_LOS ANGELES (US)_Size_45_Type_HC_PartyID_01005857', 'Port_LYTTELTON_Size_20_Type_GP_PartyID_01005136', 'Port_LYTTELTON_Size_40_Type_GP_PartyID_01005136', 'Port_LYTTELTON_Size_40_Type_HC_PartyID_01005136', 'Port_LYTTELTON_Size_40_Type_HC NOR_PartyID_01005136', 'Port_MADRAS_Size_20_Type_GP_PartyID_010006979', 'Port_MADRAS_Size_20_Type_GP_PartyID_01008779', 'Port_MADRAS_Size_40_Type_HC_PartyID_010006979', 'Port_MADRAS_Size_40_Type_HC_PartyID_01008779', 'Port_MADRAS/CHENNAI_Size_20_Type_GP_PartyID_010006979', 'Port_MADRAS/CHENNAI_Size_20_Type_GP (DG)_PartyID_010006979', 'Port_MADRAS/CHENNAI_Size_40_Type_GP_PartyID_010006979', 'Port_MADRAS/CHENNAI_Size_40_Type_HC_PartyID_010006979', 'Port_MALTA (FREE PORT)_Size_20_Type_GP_PartyID_010007469', 'Port_MALTA (FREE PORT)_Size_20_Type_GP_PartyID_010008325', 'Port_MALTA (FREE PORT)_Size_20_Type_GP_PartyID_010018998', 'Port_MALTA (FREE PORT)_Size_40_Type_HC_PartyID_010007469', 'Port_MALTA (FREE PORT)_Size_40_Type_HC_PartyID_010008325', 'Port_MALTA (FREE PORT)_Size_40_Type_HC_PartyID_010018998', 'Port_MANILA (NORTH HARBOUR)_Size_20_Type_GP_PartyID_010020486', 'Port_MANILA (NORTH HARBOUR)_Size_20_Type_GP_PartyID_010021727', 'Port_MANILA (NORTH HARBOUR)_Size_20_Type_GP_PartyID_01004969', 'Port_MANILA (NORTH HARBOUR)_Size_20_Type_GP (DG)_PartyID_01004969', 'Port_MANILA (NORTH HARBOUR)_Size_40_Type_GP_PartyID_01004969', 'Port_MANILA (NORTH HARBOUR)_Size_40_Type_HC_PartyID_010020486', 'Port_MANILA (NORTH HARBOUR)_Size_40_Type_HC_PartyID_010021727', 'Port_MANILA (NORTH HARBOUR)_Size_40_Type_HC_PartyID_01004969', 'Port_MANILA (NORTH HARBOUR)_Size_40_Type_HC (DG)_PartyID_010020486', 'Port_MANILA (SOUTH HARBOUR)_Size_20_Type_GP_PartyID_010020486', 'Port_MANILA (SOUTH HARBOUR)_Size_20_Type_GP_PartyID_010021727', 'Port_MANILA (SOUTH HARBOUR)_Size_20_Type_GP_PartyID_01004969', 'Port_MANILA (SOUTH HARBOUR)_Size_40_Type_HC_PartyID_010020486', 'Port_MANILA (SOUTH HARBOUR)_Size_40_Type_HC_PartyID_010021727', 'Port_MANILA (SOUTH HARBOUR)_Size_40_Type_HC_PartyID_01004969', 'Port_MANILA(SOUTH HARBOUR)_Size_20_Type_GP_PartyID_01004969', 'Port_MANILA(SOUTH HARBOUR)_Size_20_Type_GP_PartyID_01005114', 'Port_MANILA(SOUTH HARBOUR)_Size_40_Type_HC_PartyID_01004969', 'Port_MANZANILLO , MEXICO_Size_20_Type_GP_PartyID_010004319', 'Port_MANZANILLO , MEXICO_Size_20_Type_GP_PartyID_010017866', 'Port_MANZANILLO , MEXICO_Size_20_Type_GP_PartyID_01008144', 'Port_MANZANILLO , MEXICO_Size_40_Type_GP_PartyID_010004319', 'Port_MANZANILLO , MEXICO_Size_40_Type_GP_PartyID_010006338', 'Port_MANZANILLO , MEXICO_Size_40_Type_GP_PartyID_010017866', 'Port_MANZANILLO , MEXICO_Size_40_Type_GP_PartyID_01008144', 'Port_MANZANILLO , MEXICO_Size_40_Type_HC_PartyID_010004319', 'Port_MANZANILLO , MEXICO_Size_40_Type_HC_PartyID_010006338', 'Port_MANZANILLO , MEXICO_Size_40_Type_HC_PartyID_010017866', 'Port_MANZANILLO , MEXICO_Size_40_Type_HC_PartyID_01008144', 'Port_MANZANILLO , MEXICO_Size_40_Type_HC NOR_PartyID_010004319', 'Port_MANZANILLO , MEXICO_Size_40_Type_HC NOR_PartyID_010017866', 'Port_MANZANILLO, MEXICO_Size_20_Type_GP_PartyID_010017866', 'Port_MANZANILLO, MEXICO_Size_20_Type_GP_PartyID_010017867', 'Port_MANZANILLO, MEXICO_Size_40_Type_GP_PartyID_010017866', 'Port_MANZANILLO, MEXICO_Size_40_Type_HC_PartyID_010017866', 'Port_MANZANILLO, MEXICO_Size_40_Type_HC_PartyID_010017867', 'Port_MANZANILLO, MEXICO_Size_40_Type_HC NOR_PartyID_010017866', 'Port_MANZANILLO, MEXICO_Size_40_Type_HC NOR_PartyID_010017867', 'Port_MARSAXLOKK( MALTA )_Size_20_Type_GP_PartyID_010008325', 'Port_MARSAXLOKK( MALTA )_Size_20_Type_GP_PartyID_010018998', 'Port_MARSAXLOKK( MALTA )_Size_40_Type_GP_PartyID_010008325', 'Port_MARSAXLOKK( MALTA )_Size_40_Type_GP_PartyID_010018998', 'Port_MARSAXLOKK( MALTA )_Size_40_Type_HC_PartyID_010008325', 'Port_MARSAXLOKK( MALTA )_Size_40_Type_HC_PartyID_010018998', 'Port_MARSAXLOKK( MALTA )_Size_40_Type_HC NOR_PartyID_010018998', 'Port_MARSEILLE_Size_20_Type_GP_PartyID_01001088', 'Port_MARSEILLE_Size_20_Type_GP_PartyID_010019364', 'Port_MARSEILLE_Size_40_Type_GP_PartyID_01001088', 'Port_MARSEILLE_Size_40_Type_HC_PartyID_01001088', 'Port_MARSEILLE_Size_40_Type_HC_PartyID_010019364', 'Port_MARSEILLE_Size_40_Type_HC NOR_PartyID_01001088', 'Port_MARSEILLE_Size_40_Type_HC NOR_PartyID_010019364', 'Port_MELBOURNE_Size_20_Type_GP_PartyID_01002778', 'Port_MELBOURNE_Size_20_Type_GP_PartyID_01005078', 'Port_MELBOURNE_Size_40_Type_GP_PartyID_01002778', 'Port_MELBOURNE_Size_40_Type_HC_PartyID_01002778', 'Port_MELBOURNE_Size_40_Type_HC_PartyID_01002779', 'Port_MELBOURNE_Size_40_Type_HC NOR_PartyID_01002778', 'Port_MERSIN_Size_20_Type_GP_PartyID_01008316', 'Port_MERSIN_Size_40_Type_GP_PartyID_01008316', 'Port_MERSIN_Size_40_Type_HC_PartyID_01008316', 'Port_MIAMI_Size_20_Type_GP_PartyID_010008022', 'Port_MIAMI_Size_40_Type_GP_PartyID_010008022', 'Port_MIAMI_Size_40_Type_GP_PartyID_01001993', 'Port_MIAMI_Size_40_Type_HC_PartyID_010008022', 'Port_MIAMI_Size_40_Type_HC_PartyID_01001993', 'Port_MIAMI_Size_40_Type_HC NOR_PartyID_010008022', 'Port_MIAMI_Size_40_Type_HC NOR_PartyID_01001993', 'Port_MIAMI_Size_45_Type_GP_PartyID_01001993', 'Port_MOMBASA_Size_20_Type_GP_PartyID_01001963', 'Port_MOMBASA_Size_20_Type_GP_PartyID_010020691', 'Port_MOMBASA_Size_40_Type_GP_PartyID_01001963', 'Port_MOMBASA_Size_40_Type_HC_PartyID_01001963', 'Port_MOMBASA_Size_40_Type_HC_PartyID_010020691', 'Port_MOMBASA_Size_40_Type_HC NOR_PartyID_01001963', 'Port_MONTEVIDEO_Size_20_Type_GP_PartyID_01006065', 'Port_MONTEVIDEO_Size_40_Type_HC_PartyID_010021385', 'Port_MONTEVIDEO_Size_40_Type_HC_PartyID_01006065', 'Port_MONTEVIDEO_Size_40_Type_HC NOR_PartyID_010021385', 'Port_MONTEVIDEO_Size_40_Type_HC NOR_PartyID_010021505', 'Port_MONTEVIDEO_Size_40_Type_HC NOR_PartyID_01006065', 'Port_MUMBAI_Size_20_Type_GP_PartyID_01002787', 'Port_MUMBAI_Size_40_Type_GP_PartyID_01002787', 'Port_MUMBAI_Size_40_Type_HC_PartyID_01002787', 'Port_NAGOYA_Size_20_Type_GP_PartyID_010008038', 'Port_NAGOYA_Size_20_Type_GP_PartyID_01005565', 'Port_NAGOYA_Size_20_Type_GP_PartyID_01008573', 'Port_NAGOYA_Size_40_Type_HC_PartyID_010008038', 'Port_NEW DELHI_Size_20_Type_GP_PartyID_010003632', 'Port_NEW DELHI_Size_40_Type_HC_PartyID_010003632', 'Port_NEW DELHI (VIA NHAVA SHEVA)_Size_20_Type_GP_PartyID_010003632', 'Port_NEW DELHI (VIA NHAVA SHEVA)_Size_40_Type_HC_PartyID_010003632', 'Port_NEW YORK_Size_20_Type_GP_PartyID_01005886', 'Port_NEW YORK_Size_40_Type_GP_PartyID_01005886', 'Port_NEW YORK_Size_40_Type_HC_PartyID_0100028123', 'Port_NEW YORK_Size_40_Type_HC_PartyID_01005857', 'Port_NEW YORK_Size_40_Type_HC_PartyID_01005886', 'Port_NEW YORK_Size_40_Type_HC NOR_PartyID_01005886', 'Port_NEW YORK_Size_45_Type_HC_PartyID_01005886', 'Port_NHAVA SHEVA_Size_20_Type_GP_PartyID_01002787', 'Port_NHAVA SHEVA_Size_40_Type_HC_PartyID_01002787', 'Port_NHAVA SHEVA_Size_40_Type_HC (DG)_PartyID_01002787', 'Port_NHAVA SHEVA ( JNPT )_Size_20_Type_GP_PartyID_01002787', 'Port_NHAVA SHEVA ( JNPT )_Size_40_Type_GP_PartyID_01002787', 'Port_NHAVA SHEVA ( JNPT )_Size_40_Type_HC_PartyID_01002787', 'Port_NHAVA SHEVA, INDIA_Size_40_Type_HC_PartyID_01002787', 'Port_NHAVA SHEVA/NEW DELHI_Size_20_Type_GP_PartyID_010003632', 'Port_NHAVA SHEVA/NEW DELHI_Size_40_Type_HC_PartyID_010003632', 'Port_NINGBO_Size_20_Type_GP_PartyID_01001667', 'Port_NINGBO_Size_40_Type_HC_PartyID_01001667', 'Port_ODESSA_Size_20_Type_GP_PartyID_010019008', 'Port_ODESSA_Size_20_Type_GP_PartyID_010019966', 'Port_ODESSA_Size_40_Type_GP_PartyID_010019966', 'Port_ODESSA_Size_40_Type_HC_PartyID_010019008', 'Port_ODESSA_Size_40_Type_HC_PartyID_010019966', 'Port_OSAKA_Size_20_Type_GP_PartyID_01005564', 'Port_OSAKA_Size_40_Type_HC_PartyID_01005564', 'Port_OSAKA_Size_40_Type_HC_PartyID_01008573', 'Port_OSLO_Size_20_Type_GP_PartyID_0100027829', 'Port_OSLO_Size_20_Type_GP_PartyID_0100028192', 'Port_OSLO_Size_20_Type_GP_PartyID_010006665', 'Port_OSLO_Size_40_Type_HC_PartyID_0100027829', 'Port_OSLO_Size_40_Type_HC_PartyID_0100028192', 'Port_OSLO_Size_40_Type_HC_PartyID_010006665', 'Port_OSLO_Size_40_Type_HC NOR_PartyID_0100027829', 'Port_OSLO_Size_40_Type_HC NOR_PartyID_010006665', 'Port_PASIR GUDANG_Size_20_Type_GP_PartyID_010016702', 'Port_PASIR GUDANG_Size_20_Type_GP_PartyID_01002767', 'Port_PASIR GUDANG_Size_20_Type_GP (SOC)_PartyID_010016702', 'Port_PASIR GUDANG_Size_20_Type_GP (SOC)_PartyID_01002767', 'Port_PASIR GUDANG_Size_40_Type_GP_PartyID_01002767', 'Port_PASIR GUDANG_Size_40_Type_HC_PartyID_010016702', 'Port_PASIR GUDANG_Size_40_Type_HC_PartyID_01002767', 'Port_PASIR GUDANG_Size_40_Type_HC (SOC)_PartyID_01002767', 'Port_PENANG_Size_20_Type_GP_PartyID_010007888', 'Port_PENANG_Size_20_Type_GP_PartyID_01002765', 'Port_PENANG_Size_40_Type_HC_PartyID_010007888', 'Port_PENANG_Size_40_Type_HC_PartyID_01002765', 'Port_PHNOM PENH_Size_40_Type_HC_PartyID_010021748', 'Port_PIRAEUS_Size_20_Type_GP_PartyID_010006369', 'Port_PIRAEUS_Size_40_Type_GP_PartyID_010006369', 'Port_PIRAEUS_Size_40_Type_HC_PartyID_010006369', 'Port_PIRAEUS_Size_40_Type_HC NOR_PartyID_010006369', 'Port_POINTE DES GALETS_Size_20_Type_GP_PartyID_010007778', 'Port_POINTE DES GALETS_Size_40_Type_HC_PartyID_010007778', 'Port_POINTE DES GALETS/REUNION_Size_20_Type_GP_PartyID_010007778', 'Port_POINTE DES GALETS/REUNION_Size_20_Type_GP_PartyID_010026749', 'Port_POINTE DES GALETS/REUNION_Size_40_Type_GP_PartyID_010007778', 'Port_POINTE DES GALETS/REUNION_Size_40_Type_HC_PartyID_010007778', 'Port_POINTE DES GALETS/REUNION_Size_40_Type_HC_PartyID_010026749', 'Port_PORT ELIZABETH_Size_20_Type_GP_PartyID_010007919', 'Port_PORT ELIZABETH_Size_40_Type_GP_PartyID_010007919', 'Port_PORT ELIZABETH_Size_40_Type_HC_PartyID_010007919', 'Port_PORT ELIZABETH_Size_40_Type_HC NOR_PartyID_010007919', 'Port_PORT KELANG_Size_20_Type_GP_PartyID_01002769', 'Port_PORT KELANG_Size_40_Type_HC_PartyID_01002769', 'Port_PORT KLANG_Size_20_Type_GP_PartyID_01002769', 'Port_PORT KLANG_Size_20_Type_GP (DG)_PartyID_01002769', 'Port_PORT KLANG_Size_40_Type_HC_PartyID_01002769', 'Port_PORT KLANG (NORTH PORT)_Size_20_Type_GP_PartyID_01002769', 'Port_PORT KLANG (NORTH PORT)_Size_40_Type_HC_PartyID_01002769', 'Port_PORT KLANG (WEST PORT)_Size_20_Type_GP_PartyID_01002769', 'Port_PORT LOUIS_Size_20_Type_GP_PartyID_01000083', 'Port_PORT LOUIS_Size_20_Type_GP_PartyID_010007778', 'Port_PORT LOUIS_Size_20_Type_GP_PartyID_010009137', 'Port_PORT LOUIS_Size_20_Type_GP_PartyID_010026749', 'Port_PORT LOUIS_Size_40_Type_GP_PartyID_01000083', 'Port_PORT LOUIS_Size_40_Type_GP_PartyID_010007778', 'Port_PORT LOUIS_Size_40_Type_GP_PartyID_010009137', 'Port_PORT LOUIS_Size_40_Type_GP_PartyID_010026749', 'Port_PORT LOUIS_Size_40_Type_HC_PartyID_01000083', 'Port_PORT LOUIS_Size_40_Type_HC_PartyID_010007778', 'Port_PORT LOUIS_Size_40_Type_HC_PartyID_010007877', 'Port_PORT LOUIS_Size_40_Type_HC_PartyID_010009137', 'Port_PORT LOUIS_Size_40_Type_HC_PartyID_010026749', 'Port_PORT LOUIS_Size_40_Type_HC NOR_PartyID_010026749', 'Port_PORT MORESBY_Size_40_Type_GP_PartyID_01007594', 'Port_PORT SAID_Size_20_Type_GP_PartyID_010004995', 'Port_PORT SAID_Size_40_Type_GP_PartyID_010004995', 'Port_PORT SAID_Size_40_Type_HC_PartyID_010004995', 'Port_PORT SAID (WEST)_Size_20_Type_GP_PartyID_010004995', 'Port_PORT SAID (WEST)_Size_40_Type_HC_PartyID_010004995', 'Port_PORT TANGIER MEDITERRANEE (TANGIER PORT)_Size_20_Type_GP_PartyID_010006336', 'Port_PORT TANGIER MEDITERRANEE (TANGIER PORT)_Size_40_Type_HC_PartyID_010006336', 'Port_PORTO (LEIXOES)_Size_20_Type_GP_PartyID_010008857', 'Port_PORTO (LEIXOES)_Size_20_Type_GP NOR_PartyID_010008857', 'Port_PORTO (LEIXOES)_Size_40_Type_GP_PartyID_010008857', 'Port_PORTO (LEIXOES)_Size_40_Type_HC_PartyID_010008857', 'Port_PORTO (LEIXOES)_Size_40_Type_HC NOR_PartyID_010008857', 'Port_POTI_Size_20_Type_GP_PartyID_010020790', 'Port_POTI_Size_20_Type_GP_PartyID_010021426', 'Port_POTI_Size_20_Type_GP_PartyID_010021486', 'Port_POTI_Size_40_Type_HC_PartyID_010020790', 'Port_POTI_Size_40_Type_HC_PartyID_010021426', 'Port_PRAGUE_Size_20_Type_GP_PartyID_010007758', 'Port_PRAGUE_Size_40_Type_GP_PartyID_010007758', 'Port_PRAGUE_Size_40_Type_HC_PartyID_010007758', 'Port_PRAGUE_Size_40_Type_HC (SOC)_PartyID_010007758', 'Port_PRAGUE / PRAHA_Size_20_Type_GP_PartyID_010007758', 'Port_PRAGUE / PRAHA_Size_40_Type_GP_PartyID_010007758', 'Port_PRAGUE / PRAHA_Size_40_Type_HC_PartyID_010007758', 'Port_PRAGUE / PRAHA_Size_40_Type_HC (SOC)_PartyID_010007758', 'Port_QINGDAO_Size_20_Type_GP_PartyID_010007376', 'Port_QINGDAO_Size_40_Type_HC_PartyID_010007376', 'Port_QINGDAO_Size_40_Type_HC_PartyID_01001118', 'Port_QINGDAO_Size_40_Type_HC (SOC)_PartyID_01005854', 'Port_RIJEKA_Size_20_Type_GP_PartyID_010005276', 'Port_RIJEKA_Size_20_Type_GP_PartyID_010008166', 'Port_RIJEKA_Size_40_Type_GP_PartyID_010008166', 'Port_RIJEKA_Size_40_Type_HC_PartyID_010005276', 'Port_RIJEKA_Size_40_Type_HC_PartyID_010008166', 'Port_RIO DE JANEIRO_Size_40_Type_HC NOR_PartyID_01001602', 'Port_RIO GRANDE (BRAZIL)_Size_40_Type_HC NOR_PartyID_01001602', 'Port_ROSARIO_Size_20_Type_GP_PartyID_010006613', 'Port_ROSARIO_Size_40_Type_HC_PartyID_010006613', 'Port_ROTTERDAM_Size_20_Type_GP_PartyID_01001448', 'Port_ROTTERDAM_Size_40_Type_HC_PartyID_01001448', 'Port_ROTTERDAM_Size_40_Type_HC NOR_PartyID_01001448', 'Port_ROTTERDAM_Size_40_Type_HC NOR_PartyID_01008827', 'Port_SAN JOSE_Size_20_Type_GP_PartyID_010017587', 'Port_SAN JOSE_Size_40_Type_HC_PartyID_010017587', 'Port_SAN JOSE_Size_40_Type_HC NOR_PartyID_010017587', 'Port_SEMARANG_Size_20_Type_GP_PartyID_010007418', 'Port_SEMARANG_Size_20_Type_GP_PartyID_010008923', 'Port_SEMARANG_Size_20_Type_GP_PartyID_01006256', 'Port_SEMARANG_Size_40_Type_GP_PartyID_01006256', 'Port_SEMARANG_Size_40_Type_HC_PartyID_010007418', 'Port_SEMARANG_Size_40_Type_HC_PartyID_010008923', 'Port_SEMARANG_Size_40_Type_HC_PartyID_01006256', 'Port_SHANGHAI_Size_40_Type_HC_PartyID_010007376', 'Port_SHANGHAI_Size_40_Type_HC_PartyID_01005130', 'Port_SIHANOUKVILLE_Size_20_Type_GP_PartyID_010021748', 'Port_SIHANOUKVILLE_Size_20_Type_GP_PartyID_010027696', 'Port_SIHANOUKVILLE_Size_40_Type_HC_PartyID_010021748', 'Port_SIHANOUKVILLE_Size_40_Type_HC_PartyID_010027696', 'Port_SINES_Size_20_Type_GP_PartyID_010008857', 'Port_SINES_Size_40_Type_GP_PartyID_010008857', 'Port_SINES_Size_40_Type_HC_PartyID_010008857', 'Port_SINES (PORTUGAL)_Size_40_Type_HC_PartyID_010008857', 'Port_SOUTHAMPTON_Size_20_Type_GP_PartyID_01002303', 'Port_SURABAYA_Size_20_Type_GP_PartyID_010008922', 'Port_SURABAYA_Size_20_Type_GP_PartyID_01006257', 'Port_SURABAYA_Size_20_Type_GP (DG)_PartyID_010008922', 'Port_SURABAYA_Size_40_Type_GP_PartyID_01006257', 'Port_SURABAYA_Size_40_Type_HC_PartyID_010008922', 'Port_SURABAYA_Size_40_Type_HC_PartyID_01005114', 'Port_SURABAYA_Size_40_Type_HC_PartyID_01006257', 'Port_SUVA_Size_20_Type_GP_PartyID_01008681', 'Port_SUVA_Size_40_Type_GP_PartyID_01008681', 'Port_SUVA_Size_40_Type_HC_PartyID_01008681', 'Port_SYDNEY_Size_20_Type_GP_PartyID_01002779', 'Port_SYDNEY_Size_40_Type_GP_PartyID_01002779', 'Port_SYDNEY_Size_40_Type_HC_PartyID_01002779', 'Port_SYDNEY_Size_40_Type_HC_PartyID_01005078', 'Port_SYDNEY_Size_40_Type_HC NOR_PartyID_01002779', 'Port_SYDNEY(AU)_Size_20_Type_GP_PartyID_01002779', 'Port_SYDNEY(AU)_Size_40_Type_HC_PartyID_01002779', 'Port_SYDNEY(AU)_Size_40_Type_HC NOR_PartyID_01002779', 'Port_TALLINN_Size_20_Type_GP_PartyID_010018747', 'Port_TALLINN_Size_40_Type_GP_PartyID_010018747', 'Port_TALLINN_Size_40_Type_HC_PartyID_010018747', 'Port_TAMATAVE (TOAMASINA)_Size_20_Type_GP_PartyID_010007778', 'Port_TAMATAVE (TOAMASINA)_Size_20_Type_GP_PartyID_010026749', 'Port_TAMATAVE (TOAMASINA)_Size_40_Type_HC_PartyID_010007778', 'Port_TAMATAVE (TOAMASINA)_Size_40_Type_HC_PartyID_010026749', 'Port_TAMATAVE (TOMASINA)_Size_20_Type_GP_PartyID_010007778', 'Port_TAMATAVE (TOMASINA)_Size_20_Type_GP_PartyID_010008880', 'Port_TAMATAVE (TOMASINA)_Size_40_Type_GP_PartyID_010008880', 'Port_TAMATAVE (TOMASINA)_Size_40_Type_HC_PartyID_010007778', 'Port_TAMATAVE (TOMASINA)_Size_40_Type_HC_PartyID_010008880', 'Port_TAN CANG (NEW PORT)_Size_20_Type_GP_PartyID_010005256', 'Port_TAN CANG (NEW PORT)_Size_40_Type_HC_PartyID_010005256', 'Port_TANGIER PORT_Size_40_Type_HC_PartyID_010006336', 'Port_TEMA_Size_40_Type_HC_PartyID_010008832', 'Port_THESSALONIKI_Size_20_Type_GP_PartyID_010006487', 'Port_THESSALONIKI_Size_40_Type_GP_PartyID_010006487', 'Port_THESSALONIKI_Size_40_Type_HC_PartyID_010006487', 'Port_TOKYO_Size_20_Type_GP_PartyID_01005565', 'Port_TOKYO_Size_40_Type_HC_PartyID_01005552', 'Port_TOKYO_Size_40_Type_HC_PartyID_01005565', 'Port_TORONTO_Size_40_Type_HC NOR_PartyID_01002807', 'Port_TRIPOLI_Size_20_Type_GP_PartyID_010003651', 'Port_TRIPOLI_Size_40_Type_HC_PartyID_010003651', 'Port_TRIPOLI (LEBANON)_Size_20_Type_GP_PartyID_010003651', 'Port_VALENCIA_Size_20_Type_GP_PartyID_01008306', 'Port_VALENCIA_Size_40_Type_GP_PartyID_01008306', 'Port_VALENCIA_Size_40_Type_HC_PartyID_01008306', 'Port_VALENCIA_Size_40_Type_HC NOR_PartyID_01008306', 'Port_VALPARAISO_Size_20_Type_GP_PartyID_010006350', 'Port_VALPARAISO_Size_20_Type_GP_PartyID_01008304', 'Port_VALPARAISO_Size_40_Type_GP_PartyID_010006350', 'Port_VALPARAISO_Size_40_Type_GP_PartyID_01008304', 'Port_VALPARAISO_Size_40_Type_HC_PartyID_010006350', 'Port_VALPARAISO_Size_40_Type_HC_PartyID_01008304', 'Port_VALPARAISO_Size_40_Type_HC NOR_PartyID_010006350', 'Port_VALPARAISO_Size_40_Type_HC NOR_PartyID_01008304', 'Port_VANCOUVER_Size_40_Type_GP_PartyID_01002807', 'Port_VANCOUVER_Size_40_Type_HC_PartyID_010007790', 'Port_VANCOUVER_Size_40_Type_HC_PartyID_01002807', 'Port_VANCOUVER_Size_40_Type_HC NOR_PartyID_010007790', 'Port_VANCOUVER_Size_40_Type_HC NOR_PartyID_01002807', 'Port_VANCOUVER_Size_45_Type_GP_PartyID_01002807', 'Port_VANCOUVER_Size_45_Type_HC_PartyID_010007790', 'Port_VANCOUVER_Size_45_Type_HC_PartyID_01002807', 'Port_VARNA ( BULGARIA )_Size_20_Type_GP_PartyID_010007870', 'Port_VARNA ( BULGARIA )_Size_20_Type_GP_PartyID_010019070', 'Port_VARNA ( BULGARIA )_Size_40_Type_GP_PartyID_010007870', 'Port_VARNA ( BULGARIA )_Size_40_Type_HC_PartyID_010007870', 'Port_VARNA ( BULGARIA )_Size_40_Type_HC_PartyID_010019070', 'Port_VIENNA_Size_20_Type_GP_PartyID_010005265', 'Port_XIAMEN_Size_20_Type_GP_PartyID_01001667', 'Port_XIAMEN_Size_40_Type_HC_PartyID_01000498', 'Port_XIAMEN_Size_40_Type_HC_PartyID_01001667', 'Port_XINGANG_Size_20_Type_GP_PartyID_010007376', 'Port_XINGANG_Size_20_Type_GP (SOC)_PartyID_010007376', 'Port_XINGANG_Size_40_Type_GP_PartyID_01001118', 'Port_XINGANG_Size_40_Type_HC (SOC)_PartyID_010007376', 'Port_YANGON_Size_40_Type_HC_PartyID_010003639', 'Port_YANGON (AWPT)_Size_20_Type_GP_PartyID_010003639', 'Port_YANGON (AWPT)_Size_40_Type_GP_PartyID_010003639', 'Port_YANGON (AWPT)_Size_40_Type_HC_PartyID_010003639', 'Port_YANGON (AWT)_Size_20_Type_GP_PartyID_010003639', 'Port_YANGON (AWT)_Size_20_Type_GP NOR_PartyID_010003639', 'Port_YANGON (AWT)_Size_40_Type_HC_PartyID_010003639', 'Port_YANGON (AWT)_Size_40_Type_HC NOR_PartyID_010003639', 'Port_YANGON (BSW)_Size_40_Type_HC NOR_PartyID_010003639', 'Port_YANGON (MIP)_Size_20_Type_GP_PartyID_010003639', 'Port_YANGON (MIP)_Size_40_Type_HC_PartyID_010003639', 'Port_YOKOHAMA_Size_20_Type_GP_PartyID_01005565', 'Port_YOKOHAMA_Size_40_Type_HC_PartyID_01005565']\n",
      "799\n"
     ]
    }
   ],
   "source": [
    "# Creating keys from data\n",
    "print(\"Old Data keys:\")\n",
    "filtered_dataframe1 = filter_dataframe(df1)\n",
    "df_ids1 = list(filtered_dataframe1.keys())\n",
    "print(list(df_ids1))\n",
    "print(len(list(df_ids1)))\n",
    "\n",
    "print(\"\\nNew Data keys:\")\n",
    "filtered_dataframe2 = filter_dataframe(df2)\n",
    "df_ids2 = list(filtered_dataframe2.keys())\n",
    "print(list(df_ids2))\n",
    "print(len(list(df_ids2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Getting Top 5 ports keys</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTop5Ports(keybunch):\n",
    "    keybunch_pouch = []\n",
    "    \n",
    "    # Get a dictionary with key and number of rows for each dataframe in filtered_dataframes\n",
    "    key_row_counts = {key: len(keybunch[key]) for key in keybunch}\n",
    "\n",
    "    # Sort the key_row_counts dictionary by value (number of rows) in descending order\n",
    "    sorted_key_row_counts = sorted(key_row_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    # Get the top 5 keys with the most rows\n",
    "    top_5_keys_tuple = sorted_key_row_counts[:5]\n",
    "\n",
    "    # Create a dictionary with the top 5 keys and their corresponding dataframes (with up to 5 rows per dataframe)\n",
    "    keybunch_subset = {}\n",
    "\n",
    "    for key, row_count in top_5_keys_tuple:\n",
    "        keybunch_subset[key] = keybunch[key][:5]\n",
    "        print(f\"Number of rows in {key}: {row_count}\")\n",
    "        keybunch_pouch.append(key)\n",
    "    \n",
    "    # Return array of keys\n",
    "    return keybunch_pouch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Dataset Keybunch:\n",
      "Number of rows in Port_BUSAN_Size_40_Type_HC_PartyID_010004286: 1689\n",
      "Number of rows in Port_AUCKLAND_Size_40_Type_HC_PartyID_01005136: 1688\n",
      "Number of rows in Port_MELBOURNE_Size_40_Type_HC_PartyID_01002778: 1325\n",
      "Number of rows in Port_SYDNEY_Size_40_Type_HC_PartyID_01002779: 1300\n",
      "Number of rows in Port_DUBAI (JEBEL ALI)_Size_40_Type_HC_PartyID_01002788: 1052\n",
      "\n",
      "\n",
      "New Dataset Keybunch:\n",
      "Number of rows in Port_BUSAN_Size_40_Type_HC_PartyID_010004286: 1712\n",
      "Number of rows in Port_AUCKLAND_Size_40_Type_HC_PartyID_01005136: 1704\n",
      "Number of rows in Port_MELBOURNE_Size_40_Type_HC_PartyID_01002778: 1341\n",
      "Number of rows in Port_SYDNEY_Size_40_Type_HC_PartyID_01002779: 1308\n",
      "Number of rows in Port_DUBAI (JEBEL ALI)_Size_40_Type_HC_PartyID_01002788: 1070\n"
     ]
    }
   ],
   "source": [
    "print('Old Dataset Keybunch:')\n",
    "old_df = getTop5Ports(filtered_dataframe1)\n",
    "print('\\n')\n",
    "\n",
    "print('New Dataset Keybunch:')\n",
    "new_df = getTop5Ports(filtered_dataframe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CSL_ID</th>\n",
       "      <th>CNTR_ID</th>\n",
       "      <th>POD_ID</th>\n",
       "      <th>ETD_POL_D</th>\n",
       "      <th>PARTY_ID</th>\n",
       "      <th>PARTY_NAME</th>\n",
       "      <th>POD</th>\n",
       "      <th>CNTR_SIZE</th>\n",
       "      <th>CNTR_TYPE</th>\n",
       "      <th>RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECS010050800407</td>\n",
       "      <td>CTNR010050901151</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2005-10-03</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECS010050800407</td>\n",
       "      <td>CTNR010050901379</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2005-10-03</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECS010050900468</td>\n",
       "      <td>CTNR010051000081</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2005-10-07</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ECS010050900468</td>\n",
       "      <td>CTNR010050901461</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2005-10-07</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ECS010050900469</td>\n",
       "      <td>CTNR010051000434</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2005-10-14</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CSL_ID           CNTR_ID POD_ID ETD_POL_D   PARTY_ID  \\\n",
       "0  ECS010050800407  CTNR010050901151  BUSAN     KRPUS  010004286   \n",
       "1  ECS010050800407  CTNR010050901379  BUSAN     KRPUS  010004286   \n",
       "2  ECS010050900468  CTNR010051000081  BUSAN     KRPUS  010004286   \n",
       "3  ECS010050900468  CTNR010050901461  BUSAN     KRPUS  010004286   \n",
       "4  ECS010050900469  CTNR010051000434  BUSAN     KRPUS  010004286   \n",
       "\n",
       "                 PARTY_NAME        POD CNTR_SIZE CNTR_TYPE   RATE  \n",
       "0  GLOBELINK KOREA CO., LTD 2005-10-03        40        HC  390.0  \n",
       "1  GLOBELINK KOREA CO., LTD 2005-10-03        40        HC  390.0  \n",
       "2  GLOBELINK KOREA CO., LTD 2005-10-07        40        HC  390.0  \n",
       "3  GLOBELINK KOREA CO., LTD 2005-10-07        40        HC  390.0  \n",
       "4  GLOBELINK KOREA CO., LTD 2005-10-14        40        HC  390.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CSL_ID</th>\n",
       "      <th>CNTR_ID</th>\n",
       "      <th>POD_ID</th>\n",
       "      <th>ETD_POL_D</th>\n",
       "      <th>PARTY_ID</th>\n",
       "      <th>PARTY_NAME</th>\n",
       "      <th>POD</th>\n",
       "      <th>CNTR_SIZE</th>\n",
       "      <th>CNTR_TYPE</th>\n",
       "      <th>RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>ECS010230100126</td>\n",
       "      <td>010000391908</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2023-02-22</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>ECS010230100126</td>\n",
       "      <td>010000380884</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2023-02-22</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>ECS010230100127</td>\n",
       "      <td>010000407833</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>ECS010230100127</td>\n",
       "      <td>010000390366</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>ECS010230100127</td>\n",
       "      <td>010000401385</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CSL_ID       CNTR_ID POD_ID ETD_POL_D   PARTY_ID  \\\n",
       "1684  ECS010230100126  010000391908  BUSAN     KRPUS  010004286   \n",
       "1685  ECS010230100126  010000380884  BUSAN     KRPUS  010004286   \n",
       "1687  ECS010230100127  010000407833  BUSAN     KRPUS  010004286   \n",
       "1686  ECS010230100127  010000390366  BUSAN     KRPUS  010004286   \n",
       "1688  ECS010230100127  010000401385  BUSAN     KRPUS  010004286   \n",
       "\n",
       "                    PARTY_NAME        POD CNTR_SIZE CNTR_TYPE   RATE  \n",
       "1684  GLOBELINK KOREA CO., LTD 2023-02-22        40        HC  300.0  \n",
       "1685  GLOBELINK KOREA CO., LTD 2023-02-22        40        HC  300.0  \n",
       "1687  GLOBELINK KOREA CO., LTD 2023-02-28        40        HC  300.0  \n",
       "1686  GLOBELINK KOREA CO., LTD 2023-02-28        40        HC  300.0  \n",
       "1688  GLOBELINK KOREA CO., LTD 2023-02-28        40        HC  300.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1689 entries, 0 to 1688\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   CSL_ID      1689 non-null   object        \n",
      " 1   CNTR_ID     1689 non-null   object        \n",
      " 2   POD_ID      1689 non-null   object        \n",
      " 3   ETD_POL_D   1689 non-null   object        \n",
      " 4   PARTY_ID    1689 non-null   object        \n",
      " 5   PARTY_NAME  1689 non-null   object        \n",
      " 6   POD         1689 non-null   datetime64[ns]\n",
      " 7   CNTR_SIZE   1689 non-null   object        \n",
      " 8   CNTR_TYPE   1689 non-null   object        \n",
      " 9   RATE        1689 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(8)\n",
      "memory usage: 145.1+ KB\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CSL_ID</th>\n",
       "      <th>CNTR_ID</th>\n",
       "      <th>POD_ID</th>\n",
       "      <th>ETD_POL_D</th>\n",
       "      <th>PARTY_ID</th>\n",
       "      <th>PARTY_NAME</th>\n",
       "      <th>POD</th>\n",
       "      <th>CNTR_SIZE</th>\n",
       "      <th>CNTR_TYPE</th>\n",
       "      <th>RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECS010050800407</td>\n",
       "      <td>CTNR010050901151</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2005-10-03</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECS010050800407</td>\n",
       "      <td>CTNR010050901379</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2005-10-03</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECS010050900468</td>\n",
       "      <td>CTNR010051000081</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2005-10-07</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ECS010050900468</td>\n",
       "      <td>CTNR010050901461</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2005-10-07</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ECS010050900469</td>\n",
       "      <td>CTNR010051000434</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2005-10-14</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CSL_ID           CNTR_ID POD_ID ETD_POL_D   PARTY_ID  \\\n",
       "0  ECS010050800407  CTNR010050901151  BUSAN     KRPUS  010004286   \n",
       "1  ECS010050800407  CTNR010050901379  BUSAN     KRPUS  010004286   \n",
       "2  ECS010050900468  CTNR010051000081  BUSAN     KRPUS  010004286   \n",
       "3  ECS010050900468  CTNR010050901461  BUSAN     KRPUS  010004286   \n",
       "4  ECS010050900469  CTNR010051000434  BUSAN     KRPUS  010004286   \n",
       "\n",
       "                 PARTY_NAME        POD CNTR_SIZE CNTR_TYPE   RATE  \n",
       "0  GLOBELINK KOREA CO., LTD 2005-10-03        40        HC  390.0  \n",
       "1  GLOBELINK KOREA CO., LTD 2005-10-03        40        HC  390.0  \n",
       "2  GLOBELINK KOREA CO., LTD 2005-10-07        40        HC  390.0  \n",
       "3  GLOBELINK KOREA CO., LTD 2005-10-07        40        HC  390.0  \n",
       "4  GLOBELINK KOREA CO., LTD 2005-10-14        40        HC  390.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CSL_ID</th>\n",
       "      <th>CNTR_ID</th>\n",
       "      <th>POD_ID</th>\n",
       "      <th>ETD_POL_D</th>\n",
       "      <th>PARTY_ID</th>\n",
       "      <th>PARTY_NAME</th>\n",
       "      <th>POD</th>\n",
       "      <th>CNTR_SIZE</th>\n",
       "      <th>CNTR_TYPE</th>\n",
       "      <th>RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>ECS010230300113</td>\n",
       "      <td>010000512466</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>ECS010230300113</td>\n",
       "      <td>010000534846</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>ECS010230400203</td>\n",
       "      <td>010000544930</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>ECS010230400183</td>\n",
       "      <td>010000565100</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2023-05-17</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>ECS010230400183</td>\n",
       "      <td>010000554335</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2023-05-17</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CSL_ID       CNTR_ID POD_ID ETD_POL_D   PARTY_ID  \\\n",
       "1708  ECS010230300113  010000512466  BUSAN     KRPUS  010004286   \n",
       "1707  ECS010230300113  010000534846  BUSAN     KRPUS  010004286   \n",
       "1709  ECS010230400203  010000544930  BUSAN     KRPUS  010004286   \n",
       "1710  ECS010230400183  010000565100  BUSAN     KRPUS  010004286   \n",
       "1711  ECS010230400183  010000554335  BUSAN     KRPUS  010004286   \n",
       "\n",
       "                    PARTY_NAME        POD CNTR_SIZE CNTR_TYPE   RATE  \n",
       "1708  GLOBELINK KOREA CO., LTD 2023-05-03        40        HC  260.0  \n",
       "1707  GLOBELINK KOREA CO., LTD 2023-05-03        40        HC  260.0  \n",
       "1709  GLOBELINK KOREA CO., LTD 2023-05-10        40        HC  300.0  \n",
       "1710  GLOBELINK KOREA CO., LTD 2023-05-17        40        HC  260.0  \n",
       "1711  GLOBELINK KOREA CO., LTD 2023-05-17        40        HC  260.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1712 entries, 0 to 1711\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   CSL_ID      1712 non-null   object        \n",
      " 1   CNTR_ID     1712 non-null   object        \n",
      " 2   POD_ID      1712 non-null   object        \n",
      " 3   ETD_POL_D   1712 non-null   object        \n",
      " 4   PARTY_ID    1712 non-null   object        \n",
      " 5   PARTY_NAME  1712 non-null   object        \n",
      " 6   POD         1712 non-null   datetime64[ns]\n",
      " 7   CNTR_SIZE   1712 non-null   object        \n",
      " 8   CNTR_TYPE   1712 non-null   object        \n",
      " 9   RATE        1712 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(8)\n",
      "memory usage: 147.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Accessing the highest count in the each keypouch, new and old.\n",
    "sel_df = filtered_dataframe1[old_df[0]]\n",
    "sel_df.head(5)\n",
    "sel_df.tail(5)\n",
    "sel_df.info()\n",
    "print(\"\\n\")\n",
    "\n",
    "latest_sel_df = filtered_dataframe2[new_df[0]]\n",
    "latest_sel_df.head(5)\n",
    "latest_sel_df.tail(5)\n",
    "latest_sel_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POD</th>\n",
       "      <th>RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-10-03</td>\n",
       "      <td>2.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-10-03</td>\n",
       "      <td>2.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-10-07</td>\n",
       "      <td>2.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-10-07</td>\n",
       "      <td>2.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-10-14</td>\n",
       "      <td>2.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         POD      RATE\n",
       "0 2005-10-03  2.777778\n",
       "1 2005-10-03  2.777778\n",
       "2 2005-10-07  2.777778\n",
       "3 2005-10-07  2.777778\n",
       "4 2005-10-14  2.777778"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Select features\n",
    "sel_feat = ['POD','RATE']\n",
    "robust_df = sel_df[sel_feat].copy()  # make a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "# Robust Scaling\n",
    "scaler = RobustScaler()\n",
    "robust_df.loc[:, 'RATE'] = scaler.fit_transform(robust_df[['RATE']])\n",
    "robust_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Interpolate missing values in between dates</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POD</th>\n",
       "      <th>RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-10-03</td>\n",
       "      <td>4711.36688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-10-04</td>\n",
       "      <td>4711.36688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-10-05</td>\n",
       "      <td>4711.36688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-10-06</td>\n",
       "      <td>4711.36688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-10-07</td>\n",
       "      <td>4711.36688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         POD        RATE\n",
       "0 2005-10-03  4711.36688\n",
       "1 2005-10-04  4711.36688\n",
       "2 2005-10-05  4711.36688\n",
       "3 2005-10-06  4711.36688\n",
       "4 2005-10-07  4711.36688"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POD</th>\n",
       "      <th>RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6371</th>\n",
       "      <td>2023-02-24</td>\n",
       "      <td>2920.40688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6372</th>\n",
       "      <td>2023-02-25</td>\n",
       "      <td>2920.40688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6373</th>\n",
       "      <td>2023-02-26</td>\n",
       "      <td>2920.40688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6374</th>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>2920.40688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6375</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2920.40688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            POD        RATE\n",
       "6371 2023-02-24  2920.40688\n",
       "6372 2023-02-25  2920.40688\n",
       "6373 2023-02-26  2920.40688\n",
       "6374 2023-02-27  2920.40688\n",
       "6375 2023-02-28  2920.40688"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6376 entries, 0 to 6375\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   POD     6376 non-null   datetime64[ns]\n",
      " 1   RATE    6376 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 149.4 KB\n"
     ]
    }
   ],
   "source": [
    "# Interpolate using spline interpolation\n",
    "\n",
    "# Remove duplicated dates and cost rows\n",
    "robust_df = robust_df.drop_duplicates(subset=['POD', 'RATE']).reset_index(drop=True)\n",
    "\n",
    "# Create a new dataframe with a date range from min to max date in your dataframe\n",
    "new_df = pd.DataFrame()\n",
    "new_df['POD'] = pd.date_range(start=robust_df['POD'].min(), end=robust_df['POD'].max())\n",
    "\n",
    "# Merge the original dataframe with the new one. Missing dates in the original dataframe will be filled with NaN\n",
    "df_interpolated = pd.merge(new_df, robust_df, on='POD', how='left')  \n",
    "\n",
    "# Perform spline interpolation\n",
    "df_interpolated['RATE'] = df_interpolated['RATE'].interpolate(method='polynomial', order=1)\n",
    "\n",
    "df_interpolated['RATE'] = df_interpolated['RATE'].round(3)\n",
    "\n",
    "# Now we need to inverse the scaling\n",
    "df_interpolated['RATE'] = scaler.inverse_transform(df_interpolated[['RATE']])\n",
    "\n",
    "df_interpolated.head(5)\n",
    "df_interpolated.tail(5)\n",
    "df_interpolated.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Grouping it to week</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:21: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for group_name, group_df in grouped:\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2070211472.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  agg_df = agg_df.append(new_row, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearMonthWeek</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-10-03</td>\n",
       "      <td>390.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-10-10</td>\n",
       "      <td>390.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-10-17</td>\n",
       "      <td>390.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-10-24</td>\n",
       "      <td>390.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-10-31</td>\n",
       "      <td>390.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2005-11-07</td>\n",
       "      <td>390.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2005-11-14</td>\n",
       "      <td>390.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2005-11-21</td>\n",
       "      <td>390.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2005-11-28</td>\n",
       "      <td>390.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2005-12-05</td>\n",
       "      <td>390.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2005-12-12</td>\n",
       "      <td>390.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2005-12-19</td>\n",
       "      <td>390.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2005-12-26</td>\n",
       "      <td>390.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2006-01-02</td>\n",
       "      <td>390.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2006-01-09</td>\n",
       "      <td>390.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YearMonthWeek    Rate\n",
       "0     2005-10-03  390.02\n",
       "1     2005-10-10  390.02\n",
       "2     2005-10-17  390.02\n",
       "3     2005-10-24  390.02\n",
       "4     2005-10-31  390.02\n",
       "5     2005-11-07  390.02\n",
       "6     2005-11-14  390.02\n",
       "7     2005-11-21  390.02\n",
       "8     2005-11-28  390.02\n",
       "9     2005-12-05  390.02\n",
       "10    2005-12-12  390.02\n",
       "11    2005-12-19  390.02\n",
       "12    2005-12-26  390.02\n",
       "13    2006-01-02  390.02\n",
       "14    2006-01-09  390.02"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearMonthWeek</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>137.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>144.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>187.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>166.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>308.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>176.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>144.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>275.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>304.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>2023-01-16</td>\n",
       "      <td>298.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>241.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>186.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>233.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>2023-02-13</td>\n",
       "      <td>200.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>2023-02-20</td>\n",
       "      <td>302.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YearMonthWeek    Rate\n",
       "893    2022-11-14  137.40\n",
       "894    2022-11-21  144.41\n",
       "895    2022-11-28  187.83\n",
       "896    2022-12-05  166.34\n",
       "897    2022-12-12  308.47\n",
       "898    2022-12-19  176.55\n",
       "899    2022-12-26  144.63\n",
       "900    2023-01-02  275.87\n",
       "901    2023-01-09  304.75\n",
       "902    2023-01-16  298.66\n",
       "903    2023-01-23  241.97\n",
       "904    2023-01-30  186.25\n",
       "905    2023-02-06  233.82\n",
       "906    2023-02-13  200.44\n",
       "907    2023-02-20  302.10"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 908 entries, 0 to 907\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   YearMonthWeek  908 non-null    datetime64[ns]\n",
      " 1   Rate           908 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 14.3 KB\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Create YearMonthWeek directly from the 'POD'\n",
    "df_interpolated['YearMonthWeek'] = df_interpolated['POD'] - pd.to_timedelta(df_interpolated['POD'].dt.dayofweek, unit='D')\n",
    "\n",
    "# Create a new dataframe with every week in the range\n",
    "all_weeks = pd.date_range(start=df_interpolated['POD'].min(), end=df_interpolated['POD'].max(), freq='W')\n",
    "all_weeks_df = pd.DataFrame(all_weeks, columns=['POD'])\n",
    "\n",
    "# Create YearMonthWeek in all_weeks_df\n",
    "all_weeks_df['YearMonthWeek'] = all_weeks_df['POD'] - pd.to_timedelta(all_weeks_df['POD'].dt.dayofweek, unit='D')\n",
    "\n",
    "# Merge this with your original dataframe\n",
    "merged_df = pd.merge(all_weeks_df, df_interpolated, on=['YearMonthWeek'], how='left')\n",
    "\n",
    "# Now you can group by YearMonthWeek and compute your rate\n",
    "grouped = merged_df.groupby(['YearMonthWeek'])\n",
    "\n",
    "agg_df = pd.DataFrame(columns=['YearMonthWeek', 'Rate'])\n",
    "\n",
    "for group_name, group_df in grouped:\n",
    "    year_month_week = group_name\n",
    "\n",
    "    # Skip if no data for this week\n",
    "    if group_df['RATE'].isnull().all():\n",
    "        continue\n",
    "\n",
    "    # Calculate sum and skewness of RATE values\n",
    "    rate_sum = group_df['RATE'].sum()\n",
    "    rate_skew = group_df['RATE'].skew()\n",
    "\n",
    "    # Calculate trimmed mean of RATE values\n",
    "    rate_metric = stats.trim_mean(group_df['RATE'].dropna().values, 0.05) # trimming 10% from each end\n",
    "\n",
    "    new_row = {\n",
    "        'YearMonthWeek': year_month_week,\n",
    "        'Rate': rate_metric\n",
    "    }\n",
    "\n",
    "    # Append row to aggregated dataframe\n",
    "    agg_df = agg_df.append(new_row, ignore_index=True)\n",
    "\n",
    "agg_df = agg_df.sort_values(by='YearMonthWeek').reset_index(drop=True)\n",
    "agg_df['Rate'] = agg_df['Rate'].round(2)\n",
    "\n",
    "agg_df.head(15)\n",
    "agg_df.tail(15)\n",
    "agg_df.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Latest datapoints from Latest dataframe for comparing after forecasting (Measure accuracy)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CSL_ID</th>\n",
       "      <th>CNTR_ID</th>\n",
       "      <th>POD_ID</th>\n",
       "      <th>ETD_POL_D</th>\n",
       "      <th>PARTY_ID</th>\n",
       "      <th>PARTY_NAME</th>\n",
       "      <th>POD</th>\n",
       "      <th>CNTR_SIZE</th>\n",
       "      <th>CNTR_TYPE</th>\n",
       "      <th>RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECS010230200077</td>\n",
       "      <td>010000419950</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2023-03-08</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECS010230200077</td>\n",
       "      <td>010000406570</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2023-03-08</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ECS010230200078</td>\n",
       "      <td>010000432251</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CSL_ID       CNTR_ID POD_ID ETD_POL_D   PARTY_ID  \\\n",
       "0  ECS010230200077  010000419950  BUSAN     KRPUS  010004286   \n",
       "1  ECS010230200077  010000406570  BUSAN     KRPUS  010004286   \n",
       "2  ECS010230200078  010000432251  BUSAN     KRPUS  010004286   \n",
       "\n",
       "                 PARTY_NAME        POD CNTR_SIZE CNTR_TYPE   RATE  \n",
       "0  GLOBELINK KOREA CO., LTD 2023-03-08        40        HC  260.0  \n",
       "1  GLOBELINK KOREA CO., LTD 2023-03-08        40        HC  260.0  \n",
       "2  GLOBELINK KOREA CO., LTD 2023-03-15        40        HC  260.0  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CSL_ID</th>\n",
       "      <th>CNTR_ID</th>\n",
       "      <th>POD_ID</th>\n",
       "      <th>ETD_POL_D</th>\n",
       "      <th>PARTY_ID</th>\n",
       "      <th>PARTY_NAME</th>\n",
       "      <th>POD</th>\n",
       "      <th>CNTR_SIZE</th>\n",
       "      <th>CNTR_TYPE</th>\n",
       "      <th>RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ECS010230400203</td>\n",
       "      <td>010000544930</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ECS010230400183</td>\n",
       "      <td>010000565100</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2023-05-17</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ECS010230400183</td>\n",
       "      <td>010000554335</td>\n",
       "      <td>BUSAN</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>010004286</td>\n",
       "      <td>GLOBELINK KOREA CO., LTD</td>\n",
       "      <td>2023-05-17</td>\n",
       "      <td>40</td>\n",
       "      <td>HC</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CSL_ID       CNTR_ID POD_ID ETD_POL_D   PARTY_ID  \\\n",
       "20  ECS010230400203  010000544930  BUSAN     KRPUS  010004286   \n",
       "21  ECS010230400183  010000565100  BUSAN     KRPUS  010004286   \n",
       "22  ECS010230400183  010000554335  BUSAN     KRPUS  010004286   \n",
       "\n",
       "                  PARTY_NAME        POD CNTR_SIZE CNTR_TYPE   RATE  \n",
       "20  GLOBELINK KOREA CO., LTD 2023-05-10        40        HC  300.0  \n",
       "21  GLOBELINK KOREA CO., LTD 2023-05-17        40        HC  260.0  \n",
       "22  GLOBELINK KOREA CO., LTD 2023-05-17        40        HC  260.0  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23 entries, 0 to 22\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   CSL_ID      23 non-null     object        \n",
      " 1   CNTR_ID     23 non-null     object        \n",
      " 2   POD_ID      23 non-null     object        \n",
      " 3   ETD_POL_D   23 non-null     object        \n",
      " 4   PARTY_ID    23 non-null     object        \n",
      " 5   PARTY_NAME  23 non-null     object        \n",
      " 6   POD         23 non-null     datetime64[ns]\n",
      " 7   CNTR_SIZE   23 non-null     object        \n",
      " 8   CNTR_TYPE   23 non-null     object        \n",
      " 9   RATE        23 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(8)\n",
      "memory usage: 1.9+ KB\n"
     ]
    }
   ],
   "source": [
    "max_date_in_old = sel_df['POD'].max()\n",
    "\n",
    "# Create a new dataframe that only includes rows from the latest dataframe where the date is greater than the maximum date in the old dataframe\n",
    "new_dates_df = latest_sel_df[latest_sel_df['POD'] > max_date_in_old].reset_index(drop=True)\n",
    "\n",
    "# Print the new dataframe\n",
    "new_dates_df.head(3)\n",
    "new_dates_df.tail(3)\n",
    "new_dates_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(sel_df['POD'], sel_df['RATE'], color='blue', label=\"Actual Data\")\n",
    "plt.plot(agg_df['YearMonthWeek'], agg_df['Rate'], color='red', label=\"Aggregated Data(weeks)\")\n",
    "\n",
    "plt.xlabel('Date(Year Month Week)')\n",
    "plt.ylabel('Cost Rate(USD)')\n",
    "plt.title('Port_BUSAN_Size_40_Type_HC_PartyID_010004286')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>LSTM Regression<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Mean Square Error Function:\n",
    "def calculate_RMSE(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Restructure time series data for LSTM model\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back - 1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# Adjusted model creation function\n",
    "def create_LSTM_model(params, trainX, trainY, testX, testY, epoch):\n",
    "    layers = int(params['layers'])\n",
    "    units = int(params['units'])\n",
    "    learning_rate = params['learning_rate']\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, return_sequences=True, input_shape=(trainX.shape[1], trainX.shape[2]), activation='tanh', recurrent_activation='hard_sigmoid'))\n",
    "    model.add(Dropout(0.3))  # 30% dropout\n",
    "\n",
    "    for _ in range(layers-1):\n",
    "        model.add(LSTM(units, return_sequences=True, activation='tanh', recurrent_activation='hard_sigmoid'))\n",
    "        model.add(Dropout(0.3))  # 30% dropout\n",
    "\n",
    "    model.add(LSTM(units, activation='tanh'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))\n",
    "    model.summary()\n",
    "\n",
    "    # Fit the model and store the history\n",
    "    history = model.fit(trainX, trainY, epochs=epoch, batch_size=64, verbose=2, validation_data=(testX, testY))\n",
    "    return model, history\n",
    "\n",
    "# Objective function for BayesianOptimization\n",
    "def objective(layers, units, learning_rate, epoch):\n",
    "    layers = int(layers)\n",
    "    units = int(units)\n",
    "    learning_rate = learning_rate\n",
    "    epoch = int(epoch)\n",
    "\n",
    "    # Create a parameters dictionary to use in the LSTM model\n",
    "    params = {'layers': layers, 'units': units, 'learning_rate': learning_rate, 'epoch': epoch}\n",
    "\n",
    "    model, history = create_LSTM_model(params, trainX, trainY, testX, testY, epoch)\n",
    "    \n",
    "    # Compute RMSE on validation set\n",
    "    valPredict = model.predict(testX)\n",
    "    valPredict = scaler.inverse_transform(valPredict)\n",
    "    testY_orig = scaler.inverse_transform([testY])\n",
    "    rmse = calculate_RMSE(testY_orig[0], valPredict[:,0])\n",
    "    \n",
    "    # We want to minimize RMSE, so we return the negative value (since BayesianOptimization maximizes the function)\n",
    "    return -rmse\n",
    "\n",
    "\n",
    "def plot_train_val_loss(history):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model loss progress during training and validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   epoch   |  layers   | learni... |   units   |\n",
      "-------------------------------------------------------------------------\n",
      "Model: \"sequential_123\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_440 (LSTM)             (None, 1, 73)             23068     \n",
      "                                                                 \n",
      " dropout_317 (Dropout)       (None, 1, 73)             0         \n",
      "                                                                 \n",
      " lstm_441 (LSTM)             (None, 1, 73)             42924     \n",
      "                                                                 \n",
      " dropout_318 (Dropout)       (None, 1, 73)             0         \n",
      "                                                                 \n",
      " lstm_442 (LSTM)             (None, 1, 73)             42924     \n",
      "                                                                 \n",
      " dropout_319 (Dropout)       (None, 1, 73)             0         \n",
      "                                                                 \n",
      " lstm_443 (LSTM)             (None, 73)                42924     \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 1)                 74        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151,914\n",
      "Trainable params: 151,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/132\n",
      "10/10 - 8s - loss: 0.0254 - val_loss: 0.0159 - 8s/epoch - 841ms/step\n",
      "Epoch 2/132\n",
      "10/10 - 0s - loss: 0.0038 - val_loss: 0.0180 - 105ms/epoch - 10ms/step\n",
      "Epoch 3/132\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0166 - 103ms/epoch - 10ms/step\n",
      "Epoch 4/132\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0172 - 103ms/epoch - 10ms/step\n",
      "Epoch 5/132\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0167 - 100ms/epoch - 10ms/step\n",
      "Epoch 6/132\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0168 - 103ms/epoch - 10ms/step\n",
      "Epoch 7/132\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0165 - 103ms/epoch - 10ms/step\n",
      "Epoch 8/132\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0162 - 102ms/epoch - 10ms/step\n",
      "Epoch 9/132\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0149 - 103ms/epoch - 10ms/step\n",
      "Epoch 10/132\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0116 - 103ms/epoch - 10ms/step\n",
      "Epoch 11/132\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0084 - 108ms/epoch - 11ms/step\n",
      "Epoch 12/132\n",
      "10/10 - 0s - loss: 8.4627e-04 - val_loss: 0.0085 - 101ms/epoch - 10ms/step\n",
      "Epoch 13/132\n",
      "10/10 - 0s - loss: 6.3052e-04 - val_loss: 0.0085 - 126ms/epoch - 13ms/step\n",
      "Epoch 14/132\n",
      "10/10 - 0s - loss: 5.0919e-04 - val_loss: 0.0087 - 106ms/epoch - 11ms/step\n",
      "Epoch 15/132\n",
      "10/10 - 0s - loss: 6.0128e-04 - val_loss: 0.0084 - 101ms/epoch - 10ms/step\n",
      "Epoch 16/132\n",
      "10/10 - 0s - loss: 5.1519e-04 - val_loss: 0.0082 - 104ms/epoch - 10ms/step\n",
      "Epoch 17/132\n",
      "10/10 - 0s - loss: 4.6820e-04 - val_loss: 0.0082 - 103ms/epoch - 10ms/step\n",
      "Epoch 18/132\n",
      "10/10 - 0s - loss: 3.9441e-04 - val_loss: 0.0081 - 101ms/epoch - 10ms/step\n",
      "Epoch 19/132\n",
      "10/10 - 0s - loss: 3.7775e-04 - val_loss: 0.0082 - 104ms/epoch - 10ms/step\n",
      "Epoch 20/132\n",
      "10/10 - 0s - loss: 3.5748e-04 - val_loss: 0.0081 - 103ms/epoch - 10ms/step\n",
      "Epoch 21/132\n",
      "10/10 - 0s - loss: 3.7767e-04 - val_loss: 0.0082 - 101ms/epoch - 10ms/step\n",
      "Epoch 22/132\n",
      "10/10 - 0s - loss: 3.9708e-04 - val_loss: 0.0081 - 101ms/epoch - 10ms/step\n",
      "Epoch 23/132\n",
      "10/10 - 0s - loss: 4.1121e-04 - val_loss: 0.0080 - 99ms/epoch - 10ms/step\n",
      "Epoch 24/132\n",
      "10/10 - 0s - loss: 3.2564e-04 - val_loss: 0.0081 - 100ms/epoch - 10ms/step\n",
      "Epoch 25/132\n",
      "10/10 - 0s - loss: 3.3871e-04 - val_loss: 0.0080 - 100ms/epoch - 10ms/step\n",
      "Epoch 26/132\n",
      "10/10 - 0s - loss: 3.2369e-04 - val_loss: 0.0080 - 99ms/epoch - 10ms/step\n",
      "Epoch 27/132\n",
      "10/10 - 0s - loss: 2.8672e-04 - val_loss: 0.0080 - 101ms/epoch - 10ms/step\n",
      "Epoch 28/132\n",
      "10/10 - 0s - loss: 3.0401e-04 - val_loss: 0.0080 - 101ms/epoch - 10ms/step\n",
      "Epoch 29/132\n",
      "10/10 - 0s - loss: 3.0430e-04 - val_loss: 0.0080 - 100ms/epoch - 10ms/step\n",
      "Epoch 30/132\n",
      "10/10 - 0s - loss: 3.3403e-04 - val_loss: 0.0081 - 100ms/epoch - 10ms/step\n",
      "Epoch 31/132\n",
      "10/10 - 0s - loss: 3.0478e-04 - val_loss: 0.0080 - 100ms/epoch - 10ms/step\n",
      "Epoch 32/132\n",
      "10/10 - 0s - loss: 3.5493e-04 - val_loss: 0.0080 - 99ms/epoch - 10ms/step\n",
      "Epoch 33/132\n",
      "10/10 - 0s - loss: 3.8296e-04 - val_loss: 0.0081 - 100ms/epoch - 10ms/step\n",
      "Epoch 34/132\n",
      "10/10 - 0s - loss: 4.0868e-04 - val_loss: 0.0080 - 104ms/epoch - 10ms/step\n",
      "Epoch 35/132\n",
      "10/10 - 0s - loss: 3.0367e-04 - val_loss: 0.0080 - 104ms/epoch - 10ms/step\n",
      "Epoch 36/132\n",
      "10/10 - 0s - loss: 2.9463e-04 - val_loss: 0.0079 - 100ms/epoch - 10ms/step\n",
      "Epoch 37/132\n",
      "10/10 - 0s - loss: 2.7516e-04 - val_loss: 0.0079 - 110ms/epoch - 11ms/step\n",
      "Epoch 38/132\n",
      "10/10 - 0s - loss: 2.8967e-04 - val_loss: 0.0079 - 105ms/epoch - 11ms/step\n",
      "Epoch 39/132\n",
      "10/10 - 0s - loss: 2.9940e-04 - val_loss: 0.0079 - 103ms/epoch - 10ms/step\n",
      "Epoch 40/132\n",
      "10/10 - 0s - loss: 3.2294e-04 - val_loss: 0.0080 - 102ms/epoch - 10ms/step\n",
      "Epoch 41/132\n",
      "10/10 - 0s - loss: 2.8491e-04 - val_loss: 0.0079 - 100ms/epoch - 10ms/step\n",
      "Epoch 42/132\n",
      "10/10 - 0s - loss: 2.7695e-04 - val_loss: 0.0079 - 101ms/epoch - 10ms/step\n",
      "Epoch 43/132\n",
      "10/10 - 0s - loss: 2.5140e-04 - val_loss: 0.0079 - 104ms/epoch - 10ms/step\n",
      "Epoch 44/132\n",
      "10/10 - 0s - loss: 2.9166e-04 - val_loss: 0.0079 - 101ms/epoch - 10ms/step\n",
      "Epoch 45/132\n",
      "10/10 - 0s - loss: 2.8839e-04 - val_loss: 0.0079 - 107ms/epoch - 11ms/step\n",
      "Epoch 46/132\n",
      "10/10 - 0s - loss: 2.8433e-04 - val_loss: 0.0080 - 114ms/epoch - 11ms/step\n",
      "Epoch 47/132\n",
      "10/10 - 0s - loss: 2.7787e-04 - val_loss: 0.0079 - 109ms/epoch - 11ms/step\n",
      "Epoch 48/132\n",
      "10/10 - 0s - loss: 2.9393e-04 - val_loss: 0.0080 - 108ms/epoch - 11ms/step\n",
      "Epoch 49/132\n",
      "10/10 - 0s - loss: 2.8204e-04 - val_loss: 0.0079 - 134ms/epoch - 13ms/step\n",
      "Epoch 50/132\n",
      "10/10 - 0s - loss: 2.8107e-04 - val_loss: 0.0079 - 108ms/epoch - 11ms/step\n",
      "Epoch 51/132\n",
      "10/10 - 0s - loss: 2.7028e-04 - val_loss: 0.0079 - 104ms/epoch - 10ms/step\n",
      "Epoch 52/132\n",
      "10/10 - 0s - loss: 2.4623e-04 - val_loss: 0.0079 - 106ms/epoch - 11ms/step\n",
      "Epoch 53/132\n",
      "10/10 - 0s - loss: 2.7189e-04 - val_loss: 0.0079 - 112ms/epoch - 11ms/step\n",
      "Epoch 54/132\n",
      "10/10 - 0s - loss: 2.4124e-04 - val_loss: 0.0080 - 110ms/epoch - 11ms/step\n",
      "Epoch 55/132\n",
      "10/10 - 0s - loss: 2.4142e-04 - val_loss: 0.0079 - 110ms/epoch - 11ms/step\n",
      "Epoch 56/132\n",
      "10/10 - 0s - loss: 2.5490e-04 - val_loss: 0.0080 - 106ms/epoch - 11ms/step\n",
      "Epoch 57/132\n",
      "10/10 - 0s - loss: 2.6725e-04 - val_loss: 0.0079 - 108ms/epoch - 11ms/step\n",
      "Epoch 58/132\n",
      "10/10 - 0s - loss: 2.5223e-04 - val_loss: 0.0079 - 109ms/epoch - 11ms/step\n",
      "Epoch 59/132\n",
      "10/10 - 0s - loss: 2.5279e-04 - val_loss: 0.0080 - 111ms/epoch - 11ms/step\n",
      "Epoch 60/132\n",
      "10/10 - 0s - loss: 2.4106e-04 - val_loss: 0.0080 - 106ms/epoch - 11ms/step\n",
      "Epoch 61/132\n",
      "10/10 - 0s - loss: 2.4252e-04 - val_loss: 0.0080 - 103ms/epoch - 10ms/step\n",
      "Epoch 62/132\n",
      "10/10 - 0s - loss: 2.2947e-04 - val_loss: 0.0081 - 104ms/epoch - 10ms/step\n",
      "Epoch 63/132\n",
      "10/10 - 0s - loss: 2.8942e-04 - val_loss: 0.0081 - 102ms/epoch - 10ms/step\n",
      "Epoch 64/132\n",
      "10/10 - 0s - loss: 3.5040e-04 - val_loss: 0.0080 - 104ms/epoch - 10ms/step\n",
      "Epoch 65/132\n",
      "10/10 - 0s - loss: 2.6457e-04 - val_loss: 0.0081 - 103ms/epoch - 10ms/step\n",
      "Epoch 66/132\n",
      "10/10 - 0s - loss: 2.4605e-04 - val_loss: 0.0079 - 102ms/epoch - 10ms/step\n",
      "Epoch 67/132\n",
      "10/10 - 0s - loss: 2.3813e-04 - val_loss: 0.0080 - 108ms/epoch - 11ms/step\n",
      "Epoch 68/132\n",
      "10/10 - 0s - loss: 2.4590e-04 - val_loss: 0.0080 - 101ms/epoch - 10ms/step\n",
      "Epoch 69/132\n",
      "10/10 - 0s - loss: 2.4481e-04 - val_loss: 0.0080 - 136ms/epoch - 14ms/step\n",
      "Epoch 70/132\n",
      "10/10 - 0s - loss: 2.3700e-04 - val_loss: 0.0081 - 117ms/epoch - 12ms/step\n",
      "Epoch 71/132\n",
      "10/10 - 0s - loss: 2.2426e-04 - val_loss: 0.0079 - 111ms/epoch - 11ms/step\n",
      "Epoch 72/132\n",
      "10/10 - 0s - loss: 2.5013e-04 - val_loss: 0.0080 - 109ms/epoch - 11ms/step\n",
      "Epoch 73/132\n",
      "10/10 - 0s - loss: 2.4067e-04 - val_loss: 0.0080 - 105ms/epoch - 11ms/step\n",
      "Epoch 74/132\n",
      "10/10 - 0s - loss: 2.4204e-04 - val_loss: 0.0080 - 105ms/epoch - 11ms/step\n",
      "Epoch 75/132\n",
      "10/10 - 0s - loss: 2.3453e-04 - val_loss: 0.0080 - 102ms/epoch - 10ms/step\n",
      "Epoch 76/132\n",
      "10/10 - 0s - loss: 2.1565e-04 - val_loss: 0.0080 - 101ms/epoch - 10ms/step\n",
      "Epoch 77/132\n",
      "10/10 - 0s - loss: 2.3495e-04 - val_loss: 0.0081 - 112ms/epoch - 11ms/step\n",
      "Epoch 78/132\n",
      "10/10 - 0s - loss: 2.5699e-04 - val_loss: 0.0080 - 109ms/epoch - 11ms/step\n",
      "Epoch 79/132\n",
      "10/10 - 0s - loss: 2.3714e-04 - val_loss: 0.0081 - 117ms/epoch - 12ms/step\n",
      "Epoch 80/132\n",
      "10/10 - 0s - loss: 2.6713e-04 - val_loss: 0.0081 - 121ms/epoch - 12ms/step\n",
      "Epoch 81/132\n",
      "10/10 - 0s - loss: 2.5299e-04 - val_loss: 0.0082 - 111ms/epoch - 11ms/step\n",
      "Epoch 82/132\n",
      "10/10 - 0s - loss: 2.3229e-04 - val_loss: 0.0080 - 106ms/epoch - 11ms/step\n",
      "Epoch 83/132\n",
      "10/10 - 0s - loss: 2.1951e-04 - val_loss: 0.0081 - 113ms/epoch - 11ms/step\n",
      "Epoch 84/132\n",
      "10/10 - 0s - loss: 2.1876e-04 - val_loss: 0.0081 - 103ms/epoch - 10ms/step\n",
      "Epoch 85/132\n",
      "10/10 - 0s - loss: 2.1469e-04 - val_loss: 0.0082 - 100ms/epoch - 10ms/step\n",
      "Epoch 86/132\n",
      "10/10 - 0s - loss: 2.4096e-04 - val_loss: 0.0081 - 100ms/epoch - 10ms/step\n",
      "Epoch 87/132\n",
      "10/10 - 0s - loss: 2.3860e-04 - val_loss: 0.0081 - 103ms/epoch - 10ms/step\n",
      "Epoch 88/132\n",
      "10/10 - 0s - loss: 2.7268e-04 - val_loss: 0.0081 - 105ms/epoch - 10ms/step\n",
      "Epoch 89/132\n",
      "10/10 - 0s - loss: 2.4326e-04 - val_loss: 0.0082 - 100ms/epoch - 10ms/step\n",
      "Epoch 90/132\n",
      "10/10 - 0s - loss: 2.2519e-04 - val_loss: 0.0081 - 100ms/epoch - 10ms/step\n",
      "Epoch 91/132\n",
      "10/10 - 0s - loss: 2.4897e-04 - val_loss: 0.0082 - 123ms/epoch - 12ms/step\n",
      "Epoch 92/132\n",
      "10/10 - 0s - loss: 2.3150e-04 - val_loss: 0.0082 - 108ms/epoch - 11ms/step\n",
      "Epoch 93/132\n",
      "10/10 - 0s - loss: 2.4264e-04 - val_loss: 0.0081 - 104ms/epoch - 10ms/step\n",
      "Epoch 94/132\n",
      "10/10 - 0s - loss: 2.2505e-04 - val_loss: 0.0082 - 100ms/epoch - 10ms/step\n",
      "Epoch 95/132\n",
      "10/10 - 0s - loss: 2.6179e-04 - val_loss: 0.0081 - 128ms/epoch - 13ms/step\n",
      "Epoch 96/132\n",
      "10/10 - 0s - loss: 2.3649e-04 - val_loss: 0.0082 - 102ms/epoch - 10ms/step\n",
      "Epoch 97/132\n",
      "10/10 - 0s - loss: 2.0908e-04 - val_loss: 0.0082 - 101ms/epoch - 10ms/step\n",
      "Epoch 98/132\n",
      "10/10 - 0s - loss: 2.2394e-04 - val_loss: 0.0083 - 100ms/epoch - 10ms/step\n",
      "Epoch 99/132\n",
      "10/10 - 0s - loss: 2.7985e-04 - val_loss: 0.0083 - 101ms/epoch - 10ms/step\n",
      "Epoch 100/132\n",
      "10/10 - 0s - loss: 2.5762e-04 - val_loss: 0.0084 - 100ms/epoch - 10ms/step\n",
      "Epoch 101/132\n",
      "10/10 - 0s - loss: 2.2713e-04 - val_loss: 0.0084 - 100ms/epoch - 10ms/step\n",
      "Epoch 102/132\n",
      "10/10 - 0s - loss: 2.1524e-04 - val_loss: 0.0086 - 101ms/epoch - 10ms/step\n",
      "Epoch 103/132\n",
      "10/10 - 0s - loss: 2.3637e-04 - val_loss: 0.0083 - 100ms/epoch - 10ms/step\n",
      "Epoch 104/132\n",
      "10/10 - 0s - loss: 2.2278e-04 - val_loss: 0.0085 - 100ms/epoch - 10ms/step\n",
      "Epoch 105/132\n",
      "10/10 - 0s - loss: 2.3696e-04 - val_loss: 0.0084 - 101ms/epoch - 10ms/step\n",
      "Epoch 106/132\n",
      "10/10 - 0s - loss: 2.4724e-04 - val_loss: 0.0084 - 100ms/epoch - 10ms/step\n",
      "Epoch 107/132\n",
      "10/10 - 0s - loss: 2.3155e-04 - val_loss: 0.0085 - 99ms/epoch - 10ms/step\n",
      "Epoch 108/132\n",
      "10/10 - 0s - loss: 2.3244e-04 - val_loss: 0.0086 - 102ms/epoch - 10ms/step\n",
      "Epoch 109/132\n",
      "10/10 - 0s - loss: 2.4092e-04 - val_loss: 0.0088 - 101ms/epoch - 10ms/step\n",
      "Epoch 110/132\n",
      "10/10 - 0s - loss: 2.7903e-04 - val_loss: 0.0088 - 100ms/epoch - 10ms/step\n",
      "Epoch 111/132\n",
      "10/10 - 0s - loss: 2.5182e-04 - val_loss: 0.0088 - 101ms/epoch - 10ms/step\n",
      "Epoch 112/132\n",
      "10/10 - 0s - loss: 2.2150e-04 - val_loss: 0.0089 - 100ms/epoch - 10ms/step\n",
      "Epoch 113/132\n",
      "10/10 - 0s - loss: 2.3352e-04 - val_loss: 0.0090 - 104ms/epoch - 10ms/step\n",
      "Epoch 114/132\n",
      "10/10 - 0s - loss: 2.2553e-04 - val_loss: 0.0091 - 102ms/epoch - 10ms/step\n",
      "Epoch 115/132\n",
      "10/10 - 0s - loss: 2.1260e-04 - val_loss: 0.0094 - 103ms/epoch - 10ms/step\n",
      "Epoch 116/132\n",
      "10/10 - 0s - loss: 2.7429e-04 - val_loss: 0.0091 - 112ms/epoch - 11ms/step\n",
      "Epoch 117/132\n",
      "10/10 - 0s - loss: 2.4937e-04 - val_loss: 0.0096 - 112ms/epoch - 11ms/step\n",
      "Epoch 118/132\n",
      "10/10 - 0s - loss: 2.3493e-04 - val_loss: 0.0094 - 100ms/epoch - 10ms/step\n",
      "Epoch 119/132\n",
      "10/10 - 0s - loss: 2.1208e-04 - val_loss: 0.0098 - 100ms/epoch - 10ms/step\n",
      "Epoch 120/132\n",
      "10/10 - 0s - loss: 2.1621e-04 - val_loss: 0.0101 - 100ms/epoch - 10ms/step\n",
      "Epoch 121/132\n",
      "10/10 - 0s - loss: 2.2571e-04 - val_loss: 0.0100 - 101ms/epoch - 10ms/step\n",
      "Epoch 122/132\n",
      "10/10 - 0s - loss: 2.0935e-04 - val_loss: 0.0106 - 101ms/epoch - 10ms/step\n",
      "Epoch 123/132\n",
      "10/10 - 0s - loss: 2.3695e-04 - val_loss: 0.0105 - 102ms/epoch - 10ms/step\n",
      "Epoch 124/132\n",
      "10/10 - 0s - loss: 2.0791e-04 - val_loss: 0.0107 - 101ms/epoch - 10ms/step\n",
      "Epoch 125/132\n",
      "10/10 - 0s - loss: 2.3933e-04 - val_loss: 0.0107 - 99ms/epoch - 10ms/step\n",
      "Epoch 126/132\n",
      "10/10 - 0s - loss: 2.4098e-04 - val_loss: 0.0111 - 100ms/epoch - 10ms/step\n",
      "Epoch 127/132\n",
      "10/10 - 0s - loss: 2.7601e-04 - val_loss: 0.0111 - 100ms/epoch - 10ms/step\n",
      "Epoch 128/132\n",
      "10/10 - 0s - loss: 2.5327e-04 - val_loss: 0.0108 - 105ms/epoch - 10ms/step\n",
      "Epoch 129/132\n",
      "10/10 - 0s - loss: 2.7174e-04 - val_loss: 0.0119 - 107ms/epoch - 11ms/step\n",
      "Epoch 130/132\n",
      "10/10 - 0s - loss: 2.3403e-04 - val_loss: 0.0118 - 103ms/epoch - 10ms/step\n",
      "Epoch 131/132\n",
      "10/10 - 0s - loss: 2.1762e-04 - val_loss: 0.0119 - 99ms/epoch - 10ms/step\n",
      "Epoch 132/132\n",
      "10/10 - 0s - loss: 2.3090e-04 - val_loss: 0.0120 - 100ms/epoch - 10ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-196.6   \u001b[0m | \u001b[0m132.3    \u001b[0m | \u001b[0m3.861    \u001b[0m | \u001b[0m0.006032 \u001b[0m | \u001b[0m73.39    \u001b[0m |\n",
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_444 (LSTM)             (None, 1, 115)            55660     \n",
      "                                                                 \n",
      " dropout_320 (Dropout)       (None, 1, 115)            0         \n",
      "                                                                 \n",
      " lstm_445 (LSTM)             (None, 1, 115)            106260    \n",
      "                                                                 \n",
      " dropout_321 (Dropout)       (None, 1, 115)            0         \n",
      "                                                                 \n",
      " lstm_446 (LSTM)             (None, 1, 115)            106260    \n",
      "                                                                 \n",
      " dropout_322 (Dropout)       (None, 1, 115)            0         \n",
      "                                                                 \n",
      " lstm_447 (LSTM)             (None, 115)               106260    \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 1)                 116       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 374,556\n",
      "Trainable params: 374,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/113\n",
      "10/10 - 7s - loss: 0.0277 - val_loss: 0.0155 - 7s/epoch - 738ms/step\n",
      "Epoch 2/113\n",
      "10/10 - 0s - loss: 0.0040 - val_loss: 0.0179 - 131ms/epoch - 13ms/step\n",
      "Epoch 3/113\n",
      "10/10 - 0s - loss: 0.0032 - val_loss: 0.0164 - 127ms/epoch - 13ms/step\n",
      "Epoch 4/113\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0171 - 128ms/epoch - 13ms/step\n",
      "Epoch 5/113\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0162 - 128ms/epoch - 13ms/step\n",
      "Epoch 6/113\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0160 - 128ms/epoch - 13ms/step\n",
      "Epoch 7/113\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0153 - 127ms/epoch - 13ms/step\n",
      "Epoch 8/113\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0130 - 128ms/epoch - 13ms/step\n",
      "Epoch 9/113\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0098 - 128ms/epoch - 13ms/step\n",
      "Epoch 10/113\n",
      "10/10 - 0s - loss: 8.0888e-04 - val_loss: 0.0087 - 128ms/epoch - 13ms/step\n",
      "Epoch 11/113\n",
      "10/10 - 0s - loss: 7.1422e-04 - val_loss: 0.0084 - 128ms/epoch - 13ms/step\n",
      "Epoch 12/113\n",
      "10/10 - 0s - loss: 5.4661e-04 - val_loss: 0.0082 - 129ms/epoch - 13ms/step\n",
      "Epoch 13/113\n",
      "10/10 - 0s - loss: 4.6371e-04 - val_loss: 0.0084 - 127ms/epoch - 13ms/step\n",
      "Epoch 14/113\n",
      "10/10 - 0s - loss: 4.3520e-04 - val_loss: 0.0082 - 127ms/epoch - 13ms/step\n",
      "Epoch 15/113\n",
      "10/10 - 0s - loss: 3.9300e-04 - val_loss: 0.0082 - 127ms/epoch - 13ms/step\n",
      "Epoch 16/113\n",
      "10/10 - 0s - loss: 3.6181e-04 - val_loss: 0.0083 - 126ms/epoch - 13ms/step\n",
      "Epoch 17/113\n",
      "10/10 - 0s - loss: 3.2344e-04 - val_loss: 0.0082 - 128ms/epoch - 13ms/step\n",
      "Epoch 18/113\n",
      "10/10 - 0s - loss: 3.2328e-04 - val_loss: 0.0082 - 126ms/epoch - 13ms/step\n",
      "Epoch 19/113\n",
      "10/10 - 0s - loss: 3.3880e-04 - val_loss: 0.0082 - 126ms/epoch - 13ms/step\n",
      "Epoch 20/113\n",
      "10/10 - 0s - loss: 2.9468e-04 - val_loss: 0.0083 - 127ms/epoch - 13ms/step\n",
      "Epoch 21/113\n",
      "10/10 - 0s - loss: 3.2181e-04 - val_loss: 0.0082 - 126ms/epoch - 13ms/step\n",
      "Epoch 22/113\n",
      "10/10 - 0s - loss: 2.8258e-04 - val_loss: 0.0084 - 126ms/epoch - 13ms/step\n",
      "Epoch 23/113\n",
      "10/10 - 0s - loss: 3.0936e-04 - val_loss: 0.0083 - 126ms/epoch - 13ms/step\n",
      "Epoch 24/113\n",
      "10/10 - 0s - loss: 3.0997e-04 - val_loss: 0.0082 - 127ms/epoch - 13ms/step\n",
      "Epoch 25/113\n",
      "10/10 - 0s - loss: 2.8451e-04 - val_loss: 0.0083 - 129ms/epoch - 13ms/step\n",
      "Epoch 26/113\n",
      "10/10 - 0s - loss: 2.7975e-04 - val_loss: 0.0082 - 127ms/epoch - 13ms/step\n",
      "Epoch 27/113\n",
      "10/10 - 0s - loss: 2.6538e-04 - val_loss: 0.0082 - 132ms/epoch - 13ms/step\n",
      "Epoch 28/113\n",
      "10/10 - 0s - loss: 2.7186e-04 - val_loss: 0.0082 - 128ms/epoch - 13ms/step\n",
      "Epoch 29/113\n",
      "10/10 - 0s - loss: 2.6910e-04 - val_loss: 0.0082 - 127ms/epoch - 13ms/step\n",
      "Epoch 30/113\n",
      "10/10 - 0s - loss: 2.6741e-04 - val_loss: 0.0083 - 129ms/epoch - 13ms/step\n",
      "Epoch 31/113\n",
      "10/10 - 0s - loss: 2.8071e-04 - val_loss: 0.0082 - 129ms/epoch - 13ms/step\n",
      "Epoch 32/113\n",
      "10/10 - 0s - loss: 2.7557e-04 - val_loss: 0.0082 - 126ms/epoch - 13ms/step\n",
      "Epoch 33/113\n",
      "10/10 - 0s - loss: 2.5445e-04 - val_loss: 0.0082 - 129ms/epoch - 13ms/step\n",
      "Epoch 34/113\n",
      "10/10 - 0s - loss: 2.7090e-04 - val_loss: 0.0082 - 126ms/epoch - 13ms/step\n",
      "Epoch 35/113\n",
      "10/10 - 0s - loss: 2.3953e-04 - val_loss: 0.0082 - 126ms/epoch - 13ms/step\n",
      "Epoch 36/113\n",
      "10/10 - 0s - loss: 2.5880e-04 - val_loss: 0.0083 - 127ms/epoch - 13ms/step\n",
      "Epoch 37/113\n",
      "10/10 - 0s - loss: 2.6838e-04 - val_loss: 0.0081 - 129ms/epoch - 13ms/step\n",
      "Epoch 38/113\n",
      "10/10 - 0s - loss: 2.5481e-04 - val_loss: 0.0084 - 127ms/epoch - 13ms/step\n",
      "Epoch 39/113\n",
      "10/10 - 0s - loss: 3.0270e-04 - val_loss: 0.0082 - 126ms/epoch - 13ms/step\n",
      "Epoch 40/113\n",
      "10/10 - 0s - loss: 2.9143e-04 - val_loss: 0.0084 - 134ms/epoch - 13ms/step\n",
      "Epoch 41/113\n",
      "10/10 - 0s - loss: 2.7587e-04 - val_loss: 0.0082 - 139ms/epoch - 14ms/step\n",
      "Epoch 42/113\n",
      "10/10 - 0s - loss: 2.6111e-04 - val_loss: 0.0082 - 174ms/epoch - 17ms/step\n",
      "Epoch 43/113\n",
      "10/10 - 0s - loss: 2.5274e-04 - val_loss: 0.0082 - 137ms/epoch - 14ms/step\n",
      "Epoch 44/113\n",
      "10/10 - 0s - loss: 2.2907e-04 - val_loss: 0.0082 - 137ms/epoch - 14ms/step\n",
      "Epoch 45/113\n",
      "10/10 - 0s - loss: 2.5579e-04 - val_loss: 0.0082 - 135ms/epoch - 13ms/step\n",
      "Epoch 46/113\n",
      "10/10 - 0s - loss: 2.4276e-04 - val_loss: 0.0082 - 133ms/epoch - 13ms/step\n",
      "Epoch 47/113\n",
      "10/10 - 0s - loss: 2.2883e-04 - val_loss: 0.0083 - 136ms/epoch - 14ms/step\n",
      "Epoch 48/113\n",
      "10/10 - 0s - loss: 2.6619e-04 - val_loss: 0.0082 - 133ms/epoch - 13ms/step\n",
      "Epoch 49/113\n",
      "10/10 - 0s - loss: 2.3236e-04 - val_loss: 0.0083 - 132ms/epoch - 13ms/step\n",
      "Epoch 50/113\n",
      "10/10 - 0s - loss: 2.3497e-04 - val_loss: 0.0081 - 143ms/epoch - 14ms/step\n",
      "Epoch 51/113\n",
      "10/10 - 0s - loss: 2.3273e-04 - val_loss: 0.0083 - 129ms/epoch - 13ms/step\n",
      "Epoch 52/113\n",
      "10/10 - 0s - loss: 2.3274e-04 - val_loss: 0.0082 - 125ms/epoch - 12ms/step\n",
      "Epoch 53/113\n",
      "10/10 - 0s - loss: 2.2342e-04 - val_loss: 0.0085 - 128ms/epoch - 13ms/step\n",
      "Epoch 54/113\n",
      "10/10 - 0s - loss: 2.6222e-04 - val_loss: 0.0082 - 127ms/epoch - 13ms/step\n",
      "Epoch 55/113\n",
      "10/10 - 0s - loss: 2.7247e-04 - val_loss: 0.0084 - 128ms/epoch - 13ms/step\n",
      "Epoch 56/113\n",
      "10/10 - 0s - loss: 2.7681e-04 - val_loss: 0.0082 - 127ms/epoch - 13ms/step\n",
      "Epoch 57/113\n",
      "10/10 - 0s - loss: 2.7201e-04 - val_loss: 0.0082 - 127ms/epoch - 13ms/step\n",
      "Epoch 58/113\n",
      "10/10 - 0s - loss: 2.4171e-04 - val_loss: 0.0085 - 133ms/epoch - 13ms/step\n",
      "Epoch 59/113\n",
      "10/10 - 0s - loss: 2.4892e-04 - val_loss: 0.0082 - 131ms/epoch - 13ms/step\n",
      "Epoch 60/113\n",
      "10/10 - 0s - loss: 2.2420e-04 - val_loss: 0.0084 - 127ms/epoch - 13ms/step\n",
      "Epoch 61/113\n",
      "10/10 - 0s - loss: 2.5813e-04 - val_loss: 0.0083 - 128ms/epoch - 13ms/step\n",
      "Epoch 62/113\n",
      "10/10 - 0s - loss: 2.2129e-04 - val_loss: 0.0083 - 127ms/epoch - 13ms/step\n",
      "Epoch 63/113\n",
      "10/10 - 0s - loss: 2.4732e-04 - val_loss: 0.0084 - 140ms/epoch - 14ms/step\n",
      "Epoch 64/113\n",
      "10/10 - 0s - loss: 2.2344e-04 - val_loss: 0.0082 - 129ms/epoch - 13ms/step\n",
      "Epoch 65/113\n",
      "10/10 - 0s - loss: 2.3207e-04 - val_loss: 0.0083 - 126ms/epoch - 13ms/step\n",
      "Epoch 66/113\n",
      "10/10 - 0s - loss: 2.4558e-04 - val_loss: 0.0085 - 126ms/epoch - 13ms/step\n",
      "Epoch 67/113\n",
      "10/10 - 0s - loss: 2.3022e-04 - val_loss: 0.0084 - 127ms/epoch - 13ms/step\n",
      "Epoch 68/113\n",
      "10/10 - 0s - loss: 2.3312e-04 - val_loss: 0.0083 - 127ms/epoch - 13ms/step\n",
      "Epoch 69/113\n",
      "10/10 - 0s - loss: 2.2455e-04 - val_loss: 0.0084 - 127ms/epoch - 13ms/step\n",
      "Epoch 70/113\n",
      "10/10 - 0s - loss: 2.3542e-04 - val_loss: 0.0082 - 128ms/epoch - 13ms/step\n",
      "Epoch 71/113\n",
      "10/10 - 0s - loss: 2.2209e-04 - val_loss: 0.0084 - 127ms/epoch - 13ms/step\n",
      "Epoch 72/113\n",
      "10/10 - 0s - loss: 2.1277e-04 - val_loss: 0.0083 - 127ms/epoch - 13ms/step\n",
      "Epoch 73/113\n",
      "10/10 - 0s - loss: 2.0473e-04 - val_loss: 0.0084 - 127ms/epoch - 13ms/step\n",
      "Epoch 74/113\n",
      "10/10 - 0s - loss: 2.1111e-04 - val_loss: 0.0085 - 127ms/epoch - 13ms/step\n",
      "Epoch 75/113\n",
      "10/10 - 0s - loss: 2.0294e-04 - val_loss: 0.0083 - 127ms/epoch - 13ms/step\n",
      "Epoch 76/113\n",
      "10/10 - 0s - loss: 2.1179e-04 - val_loss: 0.0084 - 131ms/epoch - 13ms/step\n",
      "Epoch 77/113\n",
      "10/10 - 0s - loss: 2.4335e-04 - val_loss: 0.0083 - 128ms/epoch - 13ms/step\n",
      "Epoch 78/113\n",
      "10/10 - 0s - loss: 2.5567e-04 - val_loss: 0.0085 - 126ms/epoch - 13ms/step\n",
      "Epoch 79/113\n",
      "10/10 - 0s - loss: 2.0723e-04 - val_loss: 0.0085 - 126ms/epoch - 13ms/step\n",
      "Epoch 80/113\n",
      "10/10 - 0s - loss: 2.2380e-04 - val_loss: 0.0085 - 127ms/epoch - 13ms/step\n",
      "Epoch 81/113\n",
      "10/10 - 0s - loss: 1.8612e-04 - val_loss: 0.0084 - 128ms/epoch - 13ms/step\n",
      "Epoch 82/113\n",
      "10/10 - 0s - loss: 2.0352e-04 - val_loss: 0.0086 - 150ms/epoch - 15ms/step\n",
      "Epoch 83/113\n",
      "10/10 - 0s - loss: 2.1512e-04 - val_loss: 0.0084 - 129ms/epoch - 13ms/step\n",
      "Epoch 84/113\n",
      "10/10 - 0s - loss: 2.2603e-04 - val_loss: 0.0085 - 128ms/epoch - 13ms/step\n",
      "Epoch 85/113\n",
      "10/10 - 0s - loss: 2.0793e-04 - val_loss: 0.0085 - 127ms/epoch - 13ms/step\n",
      "Epoch 86/113\n",
      "10/10 - 0s - loss: 2.0851e-04 - val_loss: 0.0085 - 126ms/epoch - 13ms/step\n",
      "Epoch 87/113\n",
      "10/10 - 0s - loss: 2.4000e-04 - val_loss: 0.0086 - 127ms/epoch - 13ms/step\n",
      "Epoch 88/113\n",
      "10/10 - 0s - loss: 1.9791e-04 - val_loss: 0.0086 - 127ms/epoch - 13ms/step\n",
      "Epoch 89/113\n",
      "10/10 - 0s - loss: 1.9595e-04 - val_loss: 0.0086 - 128ms/epoch - 13ms/step\n",
      "Epoch 90/113\n",
      "10/10 - 0s - loss: 2.0497e-04 - val_loss: 0.0085 - 127ms/epoch - 13ms/step\n",
      "Epoch 91/113\n",
      "10/10 - 0s - loss: 2.0510e-04 - val_loss: 0.0085 - 127ms/epoch - 13ms/step\n",
      "Epoch 92/113\n",
      "10/10 - 0s - loss: 2.2214e-04 - val_loss: 0.0085 - 128ms/epoch - 13ms/step\n",
      "Epoch 93/113\n",
      "10/10 - 0s - loss: 2.3742e-04 - val_loss: 0.0086 - 127ms/epoch - 13ms/step\n",
      "Epoch 94/113\n",
      "10/10 - 0s - loss: 1.9269e-04 - val_loss: 0.0085 - 127ms/epoch - 13ms/step\n",
      "Epoch 95/113\n",
      "10/10 - 0s - loss: 2.1696e-04 - val_loss: 0.0084 - 126ms/epoch - 13ms/step\n",
      "Epoch 96/113\n",
      "10/10 - 0s - loss: 2.3347e-04 - val_loss: 0.0085 - 125ms/epoch - 13ms/step\n",
      "Epoch 97/113\n",
      "10/10 - 0s - loss: 2.0531e-04 - val_loss: 0.0085 - 126ms/epoch - 13ms/step\n",
      "Epoch 98/113\n",
      "10/10 - 0s - loss: 2.0575e-04 - val_loss: 0.0085 - 128ms/epoch - 13ms/step\n",
      "Epoch 99/113\n",
      "10/10 - 0s - loss: 2.3293e-04 - val_loss: 0.0085 - 126ms/epoch - 13ms/step\n",
      "Epoch 100/113\n",
      "10/10 - 0s - loss: 2.1039e-04 - val_loss: 0.0086 - 126ms/epoch - 13ms/step\n",
      "Epoch 101/113\n",
      "10/10 - 0s - loss: 1.9575e-04 - val_loss: 0.0086 - 127ms/epoch - 13ms/step\n",
      "Epoch 102/113\n",
      "10/10 - 0s - loss: 1.8856e-04 - val_loss: 0.0086 - 127ms/epoch - 13ms/step\n",
      "Epoch 103/113\n",
      "10/10 - 0s - loss: 2.1987e-04 - val_loss: 0.0086 - 126ms/epoch - 13ms/step\n",
      "Epoch 104/113\n",
      "10/10 - 0s - loss: 2.1519e-04 - val_loss: 0.0085 - 129ms/epoch - 13ms/step\n",
      "Epoch 105/113\n",
      "10/10 - 0s - loss: 2.0413e-04 - val_loss: 0.0087 - 127ms/epoch - 13ms/step\n",
      "Epoch 106/113\n",
      "10/10 - 0s - loss: 2.1334e-04 - val_loss: 0.0085 - 127ms/epoch - 13ms/step\n",
      "Epoch 107/113\n",
      "10/10 - 0s - loss: 2.0528e-04 - val_loss: 0.0085 - 128ms/epoch - 13ms/step\n",
      "Epoch 108/113\n",
      "10/10 - 0s - loss: 2.0537e-04 - val_loss: 0.0086 - 126ms/epoch - 13ms/step\n",
      "Epoch 109/113\n",
      "10/10 - 0s - loss: 2.1659e-04 - val_loss: 0.0085 - 124ms/epoch - 12ms/step\n",
      "Epoch 110/113\n",
      "10/10 - 0s - loss: 1.8923e-04 - val_loss: 0.0085 - 127ms/epoch - 13ms/step\n",
      "Epoch 111/113\n",
      "10/10 - 0s - loss: 1.9717e-04 - val_loss: 0.0085 - 127ms/epoch - 13ms/step\n",
      "Epoch 112/113\n",
      "10/10 - 0s - loss: 2.0469e-04 - val_loss: 0.0087 - 126ms/epoch - 13ms/step\n",
      "Epoch 113/113\n",
      "10/10 - 0s - loss: 2.3411e-04 - val_loss: 0.0087 - 128ms/epoch - 13ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-166.6   \u001b[0m | \u001b[95m113.5    \u001b[0m | \u001b[95m3.584    \u001b[0m | \u001b[95m0.004381 \u001b[0m | \u001b[95m115.0    \u001b[0m |\n",
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_448 (LSTM)             (None, 1, 71)             21868     \n",
      "                                                                 \n",
      " dropout_323 (Dropout)       (None, 1, 71)             0         \n",
      "                                                                 \n",
      " lstm_449 (LSTM)             (None, 1, 71)             40612     \n",
      "                                                                 \n",
      " dropout_324 (Dropout)       (None, 1, 71)             0         \n",
      "                                                                 \n",
      " lstm_450 (LSTM)             (None, 71)                40612     \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 1)                 72        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103,164\n",
      "Trainable params: 103,164\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/194\n",
      "10/10 - 6s - loss: 0.0249 - val_loss: 0.0144 - 6s/epoch - 562ms/step\n",
      "Epoch 2/194\n",
      "10/10 - 0s - loss: 0.0040 - val_loss: 0.0161 - 84ms/epoch - 8ms/step\n",
      "Epoch 3/194\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0159 - 83ms/epoch - 8ms/step\n",
      "Epoch 4/194\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0156 - 84ms/epoch - 8ms/step\n",
      "Epoch 5/194\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0149 - 86ms/epoch - 9ms/step\n",
      "Epoch 6/194\n",
      "10/10 - 0s - loss: 0.0023 - val_loss: 0.0128 - 88ms/epoch - 9ms/step\n",
      "Epoch 7/194\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0096 - 96ms/epoch - 10ms/step\n",
      "Epoch 8/194\n",
      "10/10 - 0s - loss: 8.4191e-04 - val_loss: 0.0087 - 98ms/epoch - 10ms/step\n",
      "Epoch 9/194\n",
      "10/10 - 0s - loss: 7.8379e-04 - val_loss: 0.0086 - 98ms/epoch - 10ms/step\n",
      "Epoch 10/194\n",
      "10/10 - 0s - loss: 5.5175e-04 - val_loss: 0.0084 - 91ms/epoch - 9ms/step\n",
      "Epoch 11/194\n",
      "10/10 - 0s - loss: 4.8558e-04 - val_loss: 0.0082 - 93ms/epoch - 9ms/step\n",
      "Epoch 12/194\n",
      "10/10 - 0s - loss: 3.6235e-04 - val_loss: 0.0088 - 90ms/epoch - 9ms/step\n",
      "Epoch 13/194\n",
      "10/10 - 0s - loss: 3.8265e-04 - val_loss: 0.0084 - 88ms/epoch - 9ms/step\n",
      "Epoch 14/194\n",
      "10/10 - 0s - loss: 3.7054e-04 - val_loss: 0.0083 - 88ms/epoch - 9ms/step\n",
      "Epoch 15/194\n",
      "10/10 - 0s - loss: 3.3365e-04 - val_loss: 0.0084 - 89ms/epoch - 9ms/step\n",
      "Epoch 16/194\n",
      "10/10 - 0s - loss: 3.7030e-04 - val_loss: 0.0084 - 87ms/epoch - 9ms/step\n",
      "Epoch 17/194\n",
      "10/10 - 0s - loss: 3.6652e-04 - val_loss: 0.0082 - 86ms/epoch - 9ms/step\n",
      "Epoch 18/194\n",
      "10/10 - 0s - loss: 3.4219e-04 - val_loss: 0.0086 - 88ms/epoch - 9ms/step\n",
      "Epoch 19/194\n",
      "10/10 - 0s - loss: 3.2701e-04 - val_loss: 0.0084 - 87ms/epoch - 9ms/step\n",
      "Epoch 20/194\n",
      "10/10 - 0s - loss: 3.0453e-04 - val_loss: 0.0083 - 90ms/epoch - 9ms/step\n",
      "Epoch 21/194\n",
      "10/10 - 0s - loss: 2.7832e-04 - val_loss: 0.0085 - 88ms/epoch - 9ms/step\n",
      "Epoch 22/194\n",
      "10/10 - 0s - loss: 2.7236e-04 - val_loss: 0.0084 - 87ms/epoch - 9ms/step\n",
      "Epoch 23/194\n",
      "10/10 - 0s - loss: 2.6024e-04 - val_loss: 0.0084 - 88ms/epoch - 9ms/step\n",
      "Epoch 24/194\n",
      "10/10 - 0s - loss: 2.7084e-04 - val_loss: 0.0084 - 86ms/epoch - 9ms/step\n",
      "Epoch 25/194\n",
      "10/10 - 0s - loss: 3.1976e-04 - val_loss: 0.0084 - 84ms/epoch - 8ms/step\n",
      "Epoch 26/194\n",
      "10/10 - 0s - loss: 3.1113e-04 - val_loss: 0.0084 - 84ms/epoch - 8ms/step\n",
      "Epoch 27/194\n",
      "10/10 - 0s - loss: 2.7606e-04 - val_loss: 0.0085 - 84ms/epoch - 8ms/step\n",
      "Epoch 28/194\n",
      "10/10 - 0s - loss: 3.3991e-04 - val_loss: 0.0084 - 84ms/epoch - 8ms/step\n",
      "Epoch 29/194\n",
      "10/10 - 0s - loss: 3.0461e-04 - val_loss: 0.0082 - 83ms/epoch - 8ms/step\n",
      "Epoch 30/194\n",
      "10/10 - 0s - loss: 2.6543e-04 - val_loss: 0.0084 - 82ms/epoch - 8ms/step\n",
      "Epoch 31/194\n",
      "10/10 - 0s - loss: 2.5754e-04 - val_loss: 0.0083 - 83ms/epoch - 8ms/step\n",
      "Epoch 32/194\n",
      "10/10 - 0s - loss: 2.2696e-04 - val_loss: 0.0085 - 83ms/epoch - 8ms/step\n",
      "Epoch 33/194\n",
      "10/10 - 0s - loss: 2.6588e-04 - val_loss: 0.0084 - 83ms/epoch - 8ms/step\n",
      "Epoch 34/194\n",
      "10/10 - 0s - loss: 2.8335e-04 - val_loss: 0.0083 - 83ms/epoch - 8ms/step\n",
      "Epoch 35/194\n",
      "10/10 - 0s - loss: 2.5239e-04 - val_loss: 0.0084 - 82ms/epoch - 8ms/step\n",
      "Epoch 36/194\n",
      "10/10 - 0s - loss: 2.3672e-04 - val_loss: 0.0084 - 82ms/epoch - 8ms/step\n",
      "Epoch 37/194\n",
      "10/10 - 0s - loss: 2.1557e-04 - val_loss: 0.0085 - 87ms/epoch - 9ms/step\n",
      "Epoch 38/194\n",
      "10/10 - 0s - loss: 2.4884e-04 - val_loss: 0.0084 - 108ms/epoch - 11ms/step\n",
      "Epoch 39/194\n",
      "10/10 - 0s - loss: 2.2537e-04 - val_loss: 0.0084 - 85ms/epoch - 8ms/step\n",
      "Epoch 40/194\n",
      "10/10 - 0s - loss: 2.6166e-04 - val_loss: 0.0086 - 86ms/epoch - 9ms/step\n",
      "Epoch 41/194\n",
      "10/10 - 0s - loss: 2.3145e-04 - val_loss: 0.0084 - 85ms/epoch - 9ms/step\n",
      "Epoch 42/194\n",
      "10/10 - 0s - loss: 2.3521e-04 - val_loss: 0.0086 - 83ms/epoch - 8ms/step\n",
      "Epoch 43/194\n",
      "10/10 - 0s - loss: 2.2762e-04 - val_loss: 0.0083 - 92ms/epoch - 9ms/step\n",
      "Epoch 44/194\n",
      "10/10 - 0s - loss: 2.2521e-04 - val_loss: 0.0085 - 84ms/epoch - 8ms/step\n",
      "Epoch 45/194\n",
      "10/10 - 0s - loss: 2.2027e-04 - val_loss: 0.0084 - 87ms/epoch - 9ms/step\n",
      "Epoch 46/194\n",
      "10/10 - 0s - loss: 2.1286e-04 - val_loss: 0.0084 - 86ms/epoch - 9ms/step\n",
      "Epoch 47/194\n",
      "10/10 - 0s - loss: 2.1278e-04 - val_loss: 0.0084 - 82ms/epoch - 8ms/step\n",
      "Epoch 48/194\n",
      "10/10 - 0s - loss: 2.1528e-04 - val_loss: 0.0085 - 87ms/epoch - 9ms/step\n",
      "Epoch 49/194\n",
      "10/10 - 0s - loss: 2.0888e-04 - val_loss: 0.0086 - 86ms/epoch - 9ms/step\n",
      "Epoch 50/194\n",
      "10/10 - 0s - loss: 2.3095e-04 - val_loss: 0.0084 - 85ms/epoch - 9ms/step\n",
      "Epoch 51/194\n",
      "10/10 - 0s - loss: 2.1964e-04 - val_loss: 0.0085 - 90ms/epoch - 9ms/step\n",
      "Epoch 52/194\n",
      "10/10 - 0s - loss: 2.1899e-04 - val_loss: 0.0086 - 84ms/epoch - 8ms/step\n",
      "Epoch 53/194\n",
      "10/10 - 0s - loss: 2.1329e-04 - val_loss: 0.0085 - 83ms/epoch - 8ms/step\n",
      "Epoch 54/194\n",
      "10/10 - 0s - loss: 2.0846e-04 - val_loss: 0.0087 - 82ms/epoch - 8ms/step\n",
      "Epoch 55/194\n",
      "10/10 - 0s - loss: 2.2032e-04 - val_loss: 0.0085 - 83ms/epoch - 8ms/step\n",
      "Epoch 56/194\n",
      "10/10 - 0s - loss: 2.2242e-04 - val_loss: 0.0085 - 82ms/epoch - 8ms/step\n",
      "Epoch 57/194\n",
      "10/10 - 0s - loss: 2.5361e-04 - val_loss: 0.0087 - 86ms/epoch - 9ms/step\n",
      "Epoch 58/194\n",
      "10/10 - 0s - loss: 2.3633e-04 - val_loss: 0.0086 - 82ms/epoch - 8ms/step\n",
      "Epoch 59/194\n",
      "10/10 - 0s - loss: 2.1348e-04 - val_loss: 0.0085 - 82ms/epoch - 8ms/step\n",
      "Epoch 60/194\n",
      "10/10 - 0s - loss: 2.1799e-04 - val_loss: 0.0086 - 83ms/epoch - 8ms/step\n",
      "Epoch 61/194\n",
      "10/10 - 0s - loss: 2.0680e-04 - val_loss: 0.0086 - 85ms/epoch - 8ms/step\n",
      "Epoch 62/194\n",
      "10/10 - 0s - loss: 2.1674e-04 - val_loss: 0.0086 - 88ms/epoch - 9ms/step\n",
      "Epoch 63/194\n",
      "10/10 - 0s - loss: 2.0791e-04 - val_loss: 0.0086 - 83ms/epoch - 8ms/step\n",
      "Epoch 64/194\n",
      "10/10 - 0s - loss: 2.0964e-04 - val_loss: 0.0087 - 82ms/epoch - 8ms/step\n",
      "Epoch 65/194\n",
      "10/10 - 0s - loss: 2.1558e-04 - val_loss: 0.0086 - 88ms/epoch - 9ms/step\n",
      "Epoch 66/194\n",
      "10/10 - 0s - loss: 2.0852e-04 - val_loss: 0.0086 - 84ms/epoch - 8ms/step\n",
      "Epoch 67/194\n",
      "10/10 - 0s - loss: 2.0523e-04 - val_loss: 0.0087 - 82ms/epoch - 8ms/step\n",
      "Epoch 68/194\n",
      "10/10 - 0s - loss: 2.2005e-04 - val_loss: 0.0086 - 83ms/epoch - 8ms/step\n",
      "Epoch 69/194\n",
      "10/10 - 0s - loss: 2.2998e-04 - val_loss: 0.0087 - 82ms/epoch - 8ms/step\n",
      "Epoch 70/194\n",
      "10/10 - 0s - loss: 2.5790e-04 - val_loss: 0.0088 - 83ms/epoch - 8ms/step\n",
      "Epoch 71/194\n",
      "10/10 - 0s - loss: 2.6527e-04 - val_loss: 0.0089 - 82ms/epoch - 8ms/step\n",
      "Epoch 72/194\n",
      "10/10 - 0s - loss: 2.8032e-04 - val_loss: 0.0088 - 83ms/epoch - 8ms/step\n",
      "Epoch 73/194\n",
      "10/10 - 0s - loss: 2.3966e-04 - val_loss: 0.0087 - 82ms/epoch - 8ms/step\n",
      "Epoch 74/194\n",
      "10/10 - 0s - loss: 2.2198e-04 - val_loss: 0.0086 - 81ms/epoch - 8ms/step\n",
      "Epoch 75/194\n",
      "10/10 - 0s - loss: 2.1335e-04 - val_loss: 0.0090 - 84ms/epoch - 8ms/step\n",
      "Epoch 76/194\n",
      "10/10 - 0s - loss: 2.8134e-04 - val_loss: 0.0085 - 104ms/epoch - 10ms/step\n",
      "Epoch 77/194\n",
      "10/10 - 0s - loss: 2.4475e-04 - val_loss: 0.0087 - 86ms/epoch - 9ms/step\n",
      "Epoch 78/194\n",
      "10/10 - 0s - loss: 2.3370e-04 - val_loss: 0.0087 - 87ms/epoch - 9ms/step\n",
      "Epoch 79/194\n",
      "10/10 - 0s - loss: 2.3915e-04 - val_loss: 0.0087 - 83ms/epoch - 8ms/step\n",
      "Epoch 80/194\n",
      "10/10 - 0s - loss: 2.1019e-04 - val_loss: 0.0087 - 87ms/epoch - 9ms/step\n",
      "Epoch 81/194\n",
      "10/10 - 0s - loss: 2.5843e-04 - val_loss: 0.0089 - 83ms/epoch - 8ms/step\n",
      "Epoch 82/194\n",
      "10/10 - 0s - loss: 2.6591e-04 - val_loss: 0.0085 - 82ms/epoch - 8ms/step\n",
      "Epoch 83/194\n",
      "10/10 - 0s - loss: 2.1464e-04 - val_loss: 0.0090 - 89ms/epoch - 9ms/step\n",
      "Epoch 84/194\n",
      "10/10 - 0s - loss: 2.0840e-04 - val_loss: 0.0086 - 83ms/epoch - 8ms/step\n",
      "Epoch 85/194\n",
      "10/10 - 0s - loss: 2.0259e-04 - val_loss: 0.0086 - 83ms/epoch - 8ms/step\n",
      "Epoch 86/194\n",
      "10/10 - 0s - loss: 2.1734e-04 - val_loss: 0.0088 - 88ms/epoch - 9ms/step\n",
      "Epoch 87/194\n",
      "10/10 - 0s - loss: 2.2541e-04 - val_loss: 0.0085 - 82ms/epoch - 8ms/step\n",
      "Epoch 88/194\n",
      "10/10 - 0s - loss: 2.0124e-04 - val_loss: 0.0089 - 84ms/epoch - 8ms/step\n",
      "Epoch 89/194\n",
      "10/10 - 0s - loss: 2.0721e-04 - val_loss: 0.0086 - 87ms/epoch - 9ms/step\n",
      "Epoch 90/194\n",
      "10/10 - 0s - loss: 2.1688e-04 - val_loss: 0.0086 - 83ms/epoch - 8ms/step\n",
      "Epoch 91/194\n",
      "10/10 - 0s - loss: 2.4144e-04 - val_loss: 0.0089 - 84ms/epoch - 8ms/step\n",
      "Epoch 92/194\n",
      "10/10 - 0s - loss: 2.0555e-04 - val_loss: 0.0087 - 87ms/epoch - 9ms/step\n",
      "Epoch 93/194\n",
      "10/10 - 0s - loss: 1.9173e-04 - val_loss: 0.0088 - 83ms/epoch - 8ms/step\n",
      "Epoch 94/194\n",
      "10/10 - 0s - loss: 1.9767e-04 - val_loss: 0.0086 - 86ms/epoch - 9ms/step\n",
      "Epoch 95/194\n",
      "10/10 - 0s - loss: 2.5684e-04 - val_loss: 0.0089 - 85ms/epoch - 9ms/step\n",
      "Epoch 96/194\n",
      "10/10 - 0s - loss: 3.0138e-04 - val_loss: 0.0086 - 83ms/epoch - 8ms/step\n",
      "Epoch 97/194\n",
      "10/10 - 0s - loss: 2.5814e-04 - val_loss: 0.0089 - 86ms/epoch - 9ms/step\n",
      "Epoch 98/194\n",
      "10/10 - 0s - loss: 2.1345e-04 - val_loss: 0.0088 - 83ms/epoch - 8ms/step\n",
      "Epoch 99/194\n",
      "10/10 - 0s - loss: 1.9483e-04 - val_loss: 0.0086 - 83ms/epoch - 8ms/step\n",
      "Epoch 100/194\n",
      "10/10 - 0s - loss: 1.9489e-04 - val_loss: 0.0088 - 89ms/epoch - 9ms/step\n",
      "Epoch 101/194\n",
      "10/10 - 0s - loss: 1.9945e-04 - val_loss: 0.0087 - 83ms/epoch - 8ms/step\n",
      "Epoch 102/194\n",
      "10/10 - 0s - loss: 2.2803e-04 - val_loss: 0.0086 - 85ms/epoch - 8ms/step\n",
      "Epoch 103/194\n",
      "10/10 - 0s - loss: 2.0721e-04 - val_loss: 0.0089 - 88ms/epoch - 9ms/step\n",
      "Epoch 104/194\n",
      "10/10 - 0s - loss: 2.2564e-04 - val_loss: 0.0087 - 85ms/epoch - 8ms/step\n",
      "Epoch 105/194\n",
      "10/10 - 0s - loss: 2.2776e-04 - val_loss: 0.0091 - 89ms/epoch - 9ms/step\n",
      "Epoch 106/194\n",
      "10/10 - 0s - loss: 1.9926e-04 - val_loss: 0.0087 - 85ms/epoch - 8ms/step\n",
      "Epoch 107/194\n",
      "10/10 - 0s - loss: 2.9325e-04 - val_loss: 0.0086 - 84ms/epoch - 8ms/step\n",
      "Epoch 108/194\n",
      "10/10 - 0s - loss: 2.3318e-04 - val_loss: 0.0090 - 87ms/epoch - 9ms/step\n",
      "Epoch 109/194\n",
      "10/10 - 0s - loss: 2.0629e-04 - val_loss: 0.0087 - 83ms/epoch - 8ms/step\n",
      "Epoch 110/194\n",
      "10/10 - 0s - loss: 1.9662e-04 - val_loss: 0.0086 - 85ms/epoch - 8ms/step\n",
      "Epoch 111/194\n",
      "10/10 - 0s - loss: 2.0766e-04 - val_loss: 0.0088 - 86ms/epoch - 9ms/step\n",
      "Epoch 112/194\n",
      "10/10 - 0s - loss: 2.2457e-04 - val_loss: 0.0087 - 104ms/epoch - 10ms/step\n",
      "Epoch 113/194\n",
      "10/10 - 0s - loss: 2.3230e-04 - val_loss: 0.0085 - 87ms/epoch - 9ms/step\n",
      "Epoch 114/194\n",
      "10/10 - 0s - loss: 2.2587e-04 - val_loss: 0.0086 - 85ms/epoch - 8ms/step\n",
      "Epoch 115/194\n",
      "10/10 - 0s - loss: 2.3307e-04 - val_loss: 0.0088 - 82ms/epoch - 8ms/step\n",
      "Epoch 116/194\n",
      "10/10 - 0s - loss: 2.0152e-04 - val_loss: 0.0086 - 82ms/epoch - 8ms/step\n",
      "Epoch 117/194\n",
      "10/10 - 0s - loss: 2.1652e-04 - val_loss: 0.0087 - 83ms/epoch - 8ms/step\n",
      "Epoch 118/194\n",
      "10/10 - 0s - loss: 2.0920e-04 - val_loss: 0.0091 - 83ms/epoch - 8ms/step\n",
      "Epoch 119/194\n",
      "10/10 - 0s - loss: 1.9934e-04 - val_loss: 0.0086 - 86ms/epoch - 9ms/step\n",
      "Epoch 120/194\n",
      "10/10 - 0s - loss: 2.2123e-04 - val_loss: 0.0088 - 87ms/epoch - 9ms/step\n",
      "Epoch 121/194\n",
      "10/10 - 0s - loss: 1.9769e-04 - val_loss: 0.0086 - 83ms/epoch - 8ms/step\n",
      "Epoch 122/194\n",
      "10/10 - 0s - loss: 2.0769e-04 - val_loss: 0.0088 - 84ms/epoch - 8ms/step\n",
      "Epoch 123/194\n",
      "10/10 - 0s - loss: 2.3186e-04 - val_loss: 0.0088 - 88ms/epoch - 9ms/step\n",
      "Epoch 124/194\n",
      "10/10 - 0s - loss: 2.2770e-04 - val_loss: 0.0087 - 84ms/epoch - 8ms/step\n",
      "Epoch 125/194\n",
      "10/10 - 0s - loss: 2.3787e-04 - val_loss: 0.0086 - 87ms/epoch - 9ms/step\n",
      "Epoch 126/194\n",
      "10/10 - 0s - loss: 2.0848e-04 - val_loss: 0.0086 - 85ms/epoch - 8ms/step\n",
      "Epoch 127/194\n",
      "10/10 - 0s - loss: 2.0005e-04 - val_loss: 0.0086 - 82ms/epoch - 8ms/step\n",
      "Epoch 128/194\n",
      "10/10 - 0s - loss: 2.1090e-04 - val_loss: 0.0087 - 85ms/epoch - 9ms/step\n",
      "Epoch 129/194\n",
      "10/10 - 0s - loss: 2.2098e-04 - val_loss: 0.0088 - 83ms/epoch - 8ms/step\n",
      "Epoch 130/194\n",
      "10/10 - 0s - loss: 1.9440e-04 - val_loss: 0.0086 - 83ms/epoch - 8ms/step\n",
      "Epoch 131/194\n",
      "10/10 - 0s - loss: 2.0699e-04 - val_loss: 0.0088 - 87ms/epoch - 9ms/step\n",
      "Epoch 132/194\n",
      "10/10 - 0s - loss: 1.9636e-04 - val_loss: 0.0087 - 84ms/epoch - 8ms/step\n",
      "Epoch 133/194\n",
      "10/10 - 0s - loss: 2.1243e-04 - val_loss: 0.0087 - 81ms/epoch - 8ms/step\n",
      "Epoch 134/194\n",
      "10/10 - 0s - loss: 2.2046e-04 - val_loss: 0.0088 - 82ms/epoch - 8ms/step\n",
      "Epoch 135/194\n",
      "10/10 - 0s - loss: 2.2864e-04 - val_loss: 0.0089 - 82ms/epoch - 8ms/step\n",
      "Epoch 136/194\n",
      "10/10 - 0s - loss: 2.1880e-04 - val_loss: 0.0088 - 87ms/epoch - 9ms/step\n",
      "Epoch 137/194\n",
      "10/10 - 0s - loss: 2.0737e-04 - val_loss: 0.0089 - 85ms/epoch - 9ms/step\n",
      "Epoch 138/194\n",
      "10/10 - 0s - loss: 1.9240e-04 - val_loss: 0.0088 - 83ms/epoch - 8ms/step\n",
      "Epoch 139/194\n",
      "10/10 - 0s - loss: 1.8930e-04 - val_loss: 0.0087 - 82ms/epoch - 8ms/step\n",
      "Epoch 140/194\n",
      "10/10 - 0s - loss: 1.8029e-04 - val_loss: 0.0089 - 84ms/epoch - 8ms/step\n",
      "Epoch 141/194\n",
      "10/10 - 0s - loss: 1.9411e-04 - val_loss: 0.0090 - 82ms/epoch - 8ms/step\n",
      "Epoch 142/194\n",
      "10/10 - 0s - loss: 2.2761e-04 - val_loss: 0.0089 - 83ms/epoch - 8ms/step\n",
      "Epoch 143/194\n",
      "10/10 - 0s - loss: 2.3602e-04 - val_loss: 0.0087 - 86ms/epoch - 9ms/step\n",
      "Epoch 144/194\n",
      "10/10 - 0s - loss: 2.5403e-04 - val_loss: 0.0088 - 84ms/epoch - 8ms/step\n",
      "Epoch 145/194\n",
      "10/10 - 0s - loss: 2.6726e-04 - val_loss: 0.0089 - 90ms/epoch - 9ms/step\n",
      "Epoch 146/194\n",
      "10/10 - 0s - loss: 2.3818e-04 - val_loss: 0.0086 - 84ms/epoch - 8ms/step\n",
      "Epoch 147/194\n",
      "10/10 - 0s - loss: 2.0774e-04 - val_loss: 0.0087 - 83ms/epoch - 8ms/step\n",
      "Epoch 148/194\n",
      "10/10 - 0s - loss: 2.9412e-04 - val_loss: 0.0085 - 83ms/epoch - 8ms/step\n",
      "Epoch 149/194\n",
      "10/10 - 0s - loss: 2.0980e-04 - val_loss: 0.0086 - 104ms/epoch - 10ms/step\n",
      "Epoch 150/194\n",
      "10/10 - 0s - loss: 2.3459e-04 - val_loss: 0.0089 - 83ms/epoch - 8ms/step\n",
      "Epoch 151/194\n",
      "10/10 - 0s - loss: 2.4654e-04 - val_loss: 0.0086 - 81ms/epoch - 8ms/step\n",
      "Epoch 152/194\n",
      "10/10 - 0s - loss: 1.8590e-04 - val_loss: 0.0086 - 81ms/epoch - 8ms/step\n",
      "Epoch 153/194\n",
      "10/10 - 0s - loss: 2.0365e-04 - val_loss: 0.0087 - 82ms/epoch - 8ms/step\n",
      "Epoch 154/194\n",
      "10/10 - 0s - loss: 1.8343e-04 - val_loss: 0.0087 - 106ms/epoch - 11ms/step\n",
      "Epoch 155/194\n",
      "10/10 - 0s - loss: 1.8644e-04 - val_loss: 0.0087 - 86ms/epoch - 9ms/step\n",
      "Epoch 156/194\n",
      "10/10 - 0s - loss: 2.1359e-04 - val_loss: 0.0088 - 84ms/epoch - 8ms/step\n",
      "Epoch 157/194\n",
      "10/10 - 0s - loss: 1.9030e-04 - val_loss: 0.0086 - 83ms/epoch - 8ms/step\n",
      "Epoch 158/194\n",
      "10/10 - 0s - loss: 2.0050e-04 - val_loss: 0.0086 - 82ms/epoch - 8ms/step\n",
      "Epoch 159/194\n",
      "10/10 - 0s - loss: 1.9850e-04 - val_loss: 0.0086 - 83ms/epoch - 8ms/step\n",
      "Epoch 160/194\n",
      "10/10 - 0s - loss: 2.0912e-04 - val_loss: 0.0089 - 84ms/epoch - 8ms/step\n",
      "Epoch 161/194\n",
      "10/10 - 0s - loss: 2.0526e-04 - val_loss: 0.0088 - 81ms/epoch - 8ms/step\n",
      "Epoch 162/194\n",
      "10/10 - 0s - loss: 2.0948e-04 - val_loss: 0.0086 - 86ms/epoch - 9ms/step\n",
      "Epoch 163/194\n",
      "10/10 - 0s - loss: 1.8900e-04 - val_loss: 0.0089 - 81ms/epoch - 8ms/step\n",
      "Epoch 164/194\n",
      "10/10 - 0s - loss: 2.2285e-04 - val_loss: 0.0087 - 82ms/epoch - 8ms/step\n",
      "Epoch 165/194\n",
      "10/10 - 0s - loss: 1.8786e-04 - val_loss: 0.0087 - 82ms/epoch - 8ms/step\n",
      "Epoch 166/194\n",
      "10/10 - 0s - loss: 1.9416e-04 - val_loss: 0.0087 - 83ms/epoch - 8ms/step\n",
      "Epoch 167/194\n",
      "10/10 - 0s - loss: 2.2449e-04 - val_loss: 0.0088 - 82ms/epoch - 8ms/step\n",
      "Epoch 168/194\n",
      "10/10 - 0s - loss: 2.3333e-04 - val_loss: 0.0089 - 82ms/epoch - 8ms/step\n",
      "Epoch 169/194\n",
      "10/10 - 0s - loss: 2.2126e-04 - val_loss: 0.0092 - 82ms/epoch - 8ms/step\n",
      "Epoch 170/194\n",
      "10/10 - 0s - loss: 2.0607e-04 - val_loss: 0.0090 - 81ms/epoch - 8ms/step\n",
      "Epoch 171/194\n",
      "10/10 - 0s - loss: 1.9566e-04 - val_loss: 0.0088 - 83ms/epoch - 8ms/step\n",
      "Epoch 172/194\n",
      "10/10 - 0s - loss: 2.0703e-04 - val_loss: 0.0088 - 83ms/epoch - 8ms/step\n",
      "Epoch 173/194\n",
      "10/10 - 0s - loss: 2.1834e-04 - val_loss: 0.0091 - 82ms/epoch - 8ms/step\n",
      "Epoch 174/194\n",
      "10/10 - 0s - loss: 2.6888e-04 - val_loss: 0.0093 - 83ms/epoch - 8ms/step\n",
      "Epoch 175/194\n",
      "10/10 - 0s - loss: 3.1512e-04 - val_loss: 0.0088 - 81ms/epoch - 8ms/step\n",
      "Epoch 176/194\n",
      "10/10 - 0s - loss: 2.0988e-04 - val_loss: 0.0088 - 81ms/epoch - 8ms/step\n",
      "Epoch 177/194\n",
      "10/10 - 0s - loss: 1.9908e-04 - val_loss: 0.0088 - 82ms/epoch - 8ms/step\n",
      "Epoch 178/194\n",
      "10/10 - 0s - loss: 1.9922e-04 - val_loss: 0.0087 - 83ms/epoch - 8ms/step\n",
      "Epoch 179/194\n",
      "10/10 - 0s - loss: 1.9223e-04 - val_loss: 0.0088 - 82ms/epoch - 8ms/step\n",
      "Epoch 180/194\n",
      "10/10 - 0s - loss: 2.0684e-04 - val_loss: 0.0091 - 82ms/epoch - 8ms/step\n",
      "Epoch 181/194\n",
      "10/10 - 0s - loss: 2.2271e-04 - val_loss: 0.0088 - 81ms/epoch - 8ms/step\n",
      "Epoch 182/194\n",
      "10/10 - 0s - loss: 2.1244e-04 - val_loss: 0.0089 - 81ms/epoch - 8ms/step\n",
      "Epoch 183/194\n",
      "10/10 - 0s - loss: 2.0690e-04 - val_loss: 0.0088 - 83ms/epoch - 8ms/step\n",
      "Epoch 184/194\n",
      "10/10 - 0s - loss: 2.1331e-04 - val_loss: 0.0087 - 82ms/epoch - 8ms/step\n",
      "Epoch 185/194\n",
      "10/10 - 0s - loss: 2.1650e-04 - val_loss: 0.0087 - 103ms/epoch - 10ms/step\n",
      "Epoch 186/194\n",
      "10/10 - 0s - loss: 2.2236e-04 - val_loss: 0.0086 - 83ms/epoch - 8ms/step\n",
      "Epoch 187/194\n",
      "10/10 - 0s - loss: 2.0453e-04 - val_loss: 0.0086 - 82ms/epoch - 8ms/step\n",
      "Epoch 188/194\n",
      "10/10 - 0s - loss: 1.9876e-04 - val_loss: 0.0087 - 82ms/epoch - 8ms/step\n",
      "Epoch 189/194\n",
      "10/10 - 0s - loss: 2.3329e-04 - val_loss: 0.0091 - 83ms/epoch - 8ms/step\n",
      "Epoch 190/194\n",
      "10/10 - 0s - loss: 2.1448e-04 - val_loss: 0.0087 - 83ms/epoch - 8ms/step\n",
      "Epoch 191/194\n",
      "10/10 - 0s - loss: 2.0447e-04 - val_loss: 0.0086 - 82ms/epoch - 8ms/step\n",
      "Epoch 192/194\n",
      "10/10 - 0s - loss: 1.9427e-04 - val_loss: 0.0085 - 82ms/epoch - 8ms/step\n",
      "Epoch 193/194\n",
      "10/10 - 0s - loss: 1.8409e-04 - val_loss: 0.0087 - 82ms/epoch - 8ms/step\n",
      "Epoch 194/194\n",
      "10/10 - 0s - loss: 1.8851e-04 - val_loss: 0.0088 - 82ms/epoch - 8ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-167.6   \u001b[0m | \u001b[0m194.5    \u001b[0m | \u001b[0m2.534    \u001b[0m | \u001b[0m0.007919 \u001b[0m | \u001b[0m71.47    \u001b[0m |\n",
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_451 (LSTM)             (None, 1, 18)             1728      \n",
      "                                                                 \n",
      " dropout_325 (Dropout)       (None, 1, 18)             0         \n",
      "                                                                 \n",
      " lstm_452 (LSTM)             (None, 1, 18)             2664      \n",
      "                                                                 \n",
      " dropout_326 (Dropout)       (None, 1, 18)             0         \n",
      "                                                                 \n",
      " lstm_453 (LSTM)             (None, 1, 18)             2664      \n",
      "                                                                 \n",
      " dropout_327 (Dropout)       (None, 1, 18)             0         \n",
      "                                                                 \n",
      " lstm_454 (LSTM)             (None, 1, 18)             2664      \n",
      "                                                                 \n",
      " dropout_328 (Dropout)       (None, 1, 18)             0         \n",
      "                                                                 \n",
      " lstm_455 (LSTM)             (None, 18)                2664      \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 1)                 19        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,403\n",
      "Trainable params: 12,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/135\n",
      "10/10 - 10s - loss: 0.0661 - val_loss: 0.0814 - 10s/epoch - 1s/step\n",
      "Epoch 2/135\n",
      "10/10 - 0s - loss: 0.0563 - val_loss: 0.0709 - 83ms/epoch - 8ms/step\n",
      "Epoch 3/135\n",
      "10/10 - 0s - loss: 0.0465 - val_loss: 0.0603 - 82ms/epoch - 8ms/step\n",
      "Epoch 4/135\n",
      "10/10 - 0s - loss: 0.0365 - val_loss: 0.0496 - 84ms/epoch - 8ms/step\n",
      "Epoch 5/135\n",
      "10/10 - 0s - loss: 0.0268 - val_loss: 0.0390 - 83ms/epoch - 8ms/step\n",
      "Epoch 6/135\n",
      "10/10 - 0s - loss: 0.0172 - val_loss: 0.0290 - 83ms/epoch - 8ms/step\n",
      "Epoch 7/135\n",
      "10/10 - 0s - loss: 0.0095 - val_loss: 0.0208 - 84ms/epoch - 8ms/step\n",
      "Epoch 8/135\n",
      "10/10 - 0s - loss: 0.0048 - val_loss: 0.0162 - 83ms/epoch - 8ms/step\n",
      "Epoch 9/135\n",
      "10/10 - 0s - loss: 0.0034 - val_loss: 0.0154 - 83ms/epoch - 8ms/step\n",
      "Epoch 10/135\n",
      "10/10 - 0s - loss: 0.0034 - val_loss: 0.0155 - 82ms/epoch - 8ms/step\n",
      "Epoch 11/135\n",
      "10/10 - 0s - loss: 0.0035 - val_loss: 0.0161 - 81ms/epoch - 8ms/step\n",
      "Epoch 12/135\n",
      "10/10 - 0s - loss: 0.0032 - val_loss: 0.0160 - 81ms/epoch - 8ms/step\n",
      "Epoch 13/135\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0157 - 80ms/epoch - 8ms/step\n",
      "Epoch 14/135\n",
      "10/10 - 0s - loss: 0.0034 - val_loss: 0.0157 - 79ms/epoch - 8ms/step\n",
      "Epoch 15/135\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0156 - 79ms/epoch - 8ms/step\n",
      "Epoch 16/135\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0155 - 79ms/epoch - 8ms/step\n",
      "Epoch 17/135\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0154 - 81ms/epoch - 8ms/step\n",
      "Epoch 18/135\n",
      "10/10 - 0s - loss: 0.0035 - val_loss: 0.0153 - 83ms/epoch - 8ms/step\n",
      "Epoch 19/135\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0153 - 79ms/epoch - 8ms/step\n",
      "Epoch 20/135\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0151 - 78ms/epoch - 8ms/step\n",
      "Epoch 21/135\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0150 - 79ms/epoch - 8ms/step\n",
      "Epoch 22/135\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0150 - 77ms/epoch - 8ms/step\n",
      "Epoch 23/135\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0148 - 78ms/epoch - 8ms/step\n",
      "Epoch 24/135\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0146 - 79ms/epoch - 8ms/step\n",
      "Epoch 25/135\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0143 - 78ms/epoch - 8ms/step\n",
      "Epoch 26/135\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0142 - 80ms/epoch - 8ms/step\n",
      "Epoch 27/135\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0140 - 81ms/epoch - 8ms/step\n",
      "Epoch 28/135\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0137 - 79ms/epoch - 8ms/step\n",
      "Epoch 29/135\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0136 - 80ms/epoch - 8ms/step\n",
      "Epoch 30/135\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0133 - 82ms/epoch - 8ms/step\n",
      "Epoch 31/135\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0131 - 78ms/epoch - 8ms/step\n",
      "Epoch 32/135\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0128 - 81ms/epoch - 8ms/step\n",
      "Epoch 33/135\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0122 - 79ms/epoch - 8ms/step\n",
      "Epoch 34/135\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0119 - 80ms/epoch - 8ms/step\n",
      "Epoch 35/135\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0115 - 80ms/epoch - 8ms/step\n",
      "Epoch 36/135\n",
      "10/10 - 0s - loss: 0.0021 - val_loss: 0.0111 - 80ms/epoch - 8ms/step\n",
      "Epoch 37/135\n",
      "10/10 - 0s - loss: 0.0021 - val_loss: 0.0108 - 80ms/epoch - 8ms/step\n",
      "Epoch 38/135\n",
      "10/10 - 0s - loss: 0.0020 - val_loss: 0.0105 - 79ms/epoch - 8ms/step\n",
      "Epoch 39/135\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0100 - 82ms/epoch - 8ms/step\n",
      "Epoch 40/135\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0099 - 79ms/epoch - 8ms/step\n",
      "Epoch 41/135\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0098 - 80ms/epoch - 8ms/step\n",
      "Epoch 42/135\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0093 - 106ms/epoch - 11ms/step\n",
      "Epoch 43/135\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0096 - 81ms/epoch - 8ms/step\n",
      "Epoch 44/135\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0093 - 79ms/epoch - 8ms/step\n",
      "Epoch 45/135\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0092 - 80ms/epoch - 8ms/step\n",
      "Epoch 46/135\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0093 - 79ms/epoch - 8ms/step\n",
      "Epoch 47/135\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0093 - 79ms/epoch - 8ms/step\n",
      "Epoch 48/135\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0095 - 79ms/epoch - 8ms/step\n",
      "Epoch 49/135\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0095 - 79ms/epoch - 8ms/step\n",
      "Epoch 50/135\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0096 - 78ms/epoch - 8ms/step\n",
      "Epoch 51/135\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0102 - 85ms/epoch - 8ms/step\n",
      "Epoch 52/135\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0100 - 80ms/epoch - 8ms/step\n",
      "Epoch 53/135\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0100 - 79ms/epoch - 8ms/step\n",
      "Epoch 54/135\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0101 - 82ms/epoch - 8ms/step\n",
      "Epoch 55/135\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0104 - 79ms/epoch - 8ms/step\n",
      "Epoch 56/135\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0100 - 82ms/epoch - 8ms/step\n",
      "Epoch 57/135\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0105 - 81ms/epoch - 8ms/step\n",
      "Epoch 58/135\n",
      "10/10 - 0s - loss: 8.6263e-04 - val_loss: 0.0103 - 81ms/epoch - 8ms/step\n",
      "Epoch 59/135\n",
      "10/10 - 0s - loss: 9.5267e-04 - val_loss: 0.0105 - 81ms/epoch - 8ms/step\n",
      "Epoch 60/135\n",
      "10/10 - 0s - loss: 8.8778e-04 - val_loss: 0.0108 - 78ms/epoch - 8ms/step\n",
      "Epoch 61/135\n",
      "10/10 - 0s - loss: 9.0300e-04 - val_loss: 0.0107 - 82ms/epoch - 8ms/step\n",
      "Epoch 62/135\n",
      "10/10 - 0s - loss: 8.0221e-04 - val_loss: 0.0110 - 81ms/epoch - 8ms/step\n",
      "Epoch 63/135\n",
      "10/10 - 0s - loss: 8.8095e-04 - val_loss: 0.0110 - 80ms/epoch - 8ms/step\n",
      "Epoch 64/135\n",
      "10/10 - 0s - loss: 7.8836e-04 - val_loss: 0.0112 - 80ms/epoch - 8ms/step\n",
      "Epoch 65/135\n",
      "10/10 - 0s - loss: 8.1488e-04 - val_loss: 0.0107 - 80ms/epoch - 8ms/step\n",
      "Epoch 66/135\n",
      "10/10 - 0s - loss: 7.2789e-04 - val_loss: 0.0113 - 80ms/epoch - 8ms/step\n",
      "Epoch 67/135\n",
      "10/10 - 0s - loss: 6.9792e-04 - val_loss: 0.0114 - 80ms/epoch - 8ms/step\n",
      "Epoch 68/135\n",
      "10/10 - 0s - loss: 8.6955e-04 - val_loss: 0.0113 - 80ms/epoch - 8ms/step\n",
      "Epoch 69/135\n",
      "10/10 - 0s - loss: 7.4465e-04 - val_loss: 0.0117 - 81ms/epoch - 8ms/step\n",
      "Epoch 70/135\n",
      "10/10 - 0s - loss: 8.0699e-04 - val_loss: 0.0112 - 81ms/epoch - 8ms/step\n",
      "Epoch 71/135\n",
      "10/10 - 0s - loss: 7.3601e-04 - val_loss: 0.0112 - 79ms/epoch - 8ms/step\n",
      "Epoch 72/135\n",
      "10/10 - 0s - loss: 7.2344e-04 - val_loss: 0.0110 - 81ms/epoch - 8ms/step\n",
      "Epoch 73/135\n",
      "10/10 - 0s - loss: 7.1890e-04 - val_loss: 0.0113 - 91ms/epoch - 9ms/step\n",
      "Epoch 74/135\n",
      "10/10 - 0s - loss: 6.6703e-04 - val_loss: 0.0115 - 83ms/epoch - 8ms/step\n",
      "Epoch 75/135\n",
      "10/10 - 0s - loss: 6.7912e-04 - val_loss: 0.0111 - 82ms/epoch - 8ms/step\n",
      "Epoch 76/135\n",
      "10/10 - 0s - loss: 6.0092e-04 - val_loss: 0.0114 - 80ms/epoch - 8ms/step\n",
      "Epoch 77/135\n",
      "10/10 - 0s - loss: 6.4718e-04 - val_loss: 0.0111 - 81ms/epoch - 8ms/step\n",
      "Epoch 78/135\n",
      "10/10 - 0s - loss: 6.4838e-04 - val_loss: 0.0113 - 81ms/epoch - 8ms/step\n",
      "Epoch 79/135\n",
      "10/10 - 0s - loss: 6.3939e-04 - val_loss: 0.0111 - 79ms/epoch - 8ms/step\n",
      "Epoch 80/135\n",
      "10/10 - 0s - loss: 6.3323e-04 - val_loss: 0.0112 - 80ms/epoch - 8ms/step\n",
      "Epoch 81/135\n",
      "10/10 - 0s - loss: 5.4191e-04 - val_loss: 0.0112 - 79ms/epoch - 8ms/step\n",
      "Epoch 82/135\n",
      "10/10 - 0s - loss: 6.5222e-04 - val_loss: 0.0107 - 81ms/epoch - 8ms/step\n",
      "Epoch 83/135\n",
      "10/10 - 0s - loss: 6.4474e-04 - val_loss: 0.0106 - 80ms/epoch - 8ms/step\n",
      "Epoch 84/135\n",
      "10/10 - 0s - loss: 5.9370e-04 - val_loss: 0.0106 - 105ms/epoch - 11ms/step\n",
      "Epoch 85/135\n",
      "10/10 - 0s - loss: 6.0899e-04 - val_loss: 0.0108 - 81ms/epoch - 8ms/step\n",
      "Epoch 86/135\n",
      "10/10 - 0s - loss: 6.4609e-04 - val_loss: 0.0105 - 80ms/epoch - 8ms/step\n",
      "Epoch 87/135\n",
      "10/10 - 0s - loss: 6.2725e-04 - val_loss: 0.0107 - 79ms/epoch - 8ms/step\n",
      "Epoch 88/135\n",
      "10/10 - 0s - loss: 5.6644e-04 - val_loss: 0.0106 - 77ms/epoch - 8ms/step\n",
      "Epoch 89/135\n",
      "10/10 - 0s - loss: 5.7644e-04 - val_loss: 0.0108 - 79ms/epoch - 8ms/step\n",
      "Epoch 90/135\n",
      "10/10 - 0s - loss: 5.6991e-04 - val_loss: 0.0107 - 81ms/epoch - 8ms/step\n",
      "Epoch 91/135\n",
      "10/10 - 0s - loss: 6.0972e-04 - val_loss: 0.0105 - 80ms/epoch - 8ms/step\n",
      "Epoch 92/135\n",
      "10/10 - 0s - loss: 5.5591e-04 - val_loss: 0.0105 - 79ms/epoch - 8ms/step\n",
      "Epoch 93/135\n",
      "10/10 - 0s - loss: 5.8974e-04 - val_loss: 0.0105 - 79ms/epoch - 8ms/step\n",
      "Epoch 94/135\n",
      "10/10 - 0s - loss: 5.2302e-04 - val_loss: 0.0103 - 82ms/epoch - 8ms/step\n",
      "Epoch 95/135\n",
      "10/10 - 0s - loss: 6.1192e-04 - val_loss: 0.0105 - 79ms/epoch - 8ms/step\n",
      "Epoch 96/135\n",
      "10/10 - 0s - loss: 5.4073e-04 - val_loss: 0.0105 - 78ms/epoch - 8ms/step\n",
      "Epoch 97/135\n",
      "10/10 - 0s - loss: 5.7112e-04 - val_loss: 0.0102 - 79ms/epoch - 8ms/step\n",
      "Epoch 98/135\n",
      "10/10 - 0s - loss: 6.2860e-04 - val_loss: 0.0102 - 80ms/epoch - 8ms/step\n",
      "Epoch 99/135\n",
      "10/10 - 0s - loss: 5.5120e-04 - val_loss: 0.0098 - 79ms/epoch - 8ms/step\n",
      "Epoch 100/135\n",
      "10/10 - 0s - loss: 5.8571e-04 - val_loss: 0.0099 - 78ms/epoch - 8ms/step\n",
      "Epoch 101/135\n",
      "10/10 - 0s - loss: 5.9401e-04 - val_loss: 0.0098 - 78ms/epoch - 8ms/step\n",
      "Epoch 102/135\n",
      "10/10 - 0s - loss: 5.5354e-04 - val_loss: 0.0100 - 79ms/epoch - 8ms/step\n",
      "Epoch 103/135\n",
      "10/10 - 0s - loss: 5.3994e-04 - val_loss: 0.0099 - 80ms/epoch - 8ms/step\n",
      "Epoch 104/135\n",
      "10/10 - 0s - loss: 5.4912e-04 - val_loss: 0.0099 - 86ms/epoch - 9ms/step\n",
      "Epoch 105/135\n",
      "10/10 - 0s - loss: 5.3602e-04 - val_loss: 0.0098 - 78ms/epoch - 8ms/step\n",
      "Epoch 106/135\n",
      "10/10 - 0s - loss: 5.2039e-04 - val_loss: 0.0096 - 79ms/epoch - 8ms/step\n",
      "Epoch 107/135\n",
      "10/10 - 0s - loss: 6.0420e-04 - val_loss: 0.0096 - 78ms/epoch - 8ms/step\n",
      "Epoch 108/135\n",
      "10/10 - 0s - loss: 5.8386e-04 - val_loss: 0.0095 - 79ms/epoch - 8ms/step\n",
      "Epoch 109/135\n",
      "10/10 - 0s - loss: 5.0802e-04 - val_loss: 0.0096 - 80ms/epoch - 8ms/step\n",
      "Epoch 110/135\n",
      "10/10 - 0s - loss: 5.1914e-04 - val_loss: 0.0096 - 82ms/epoch - 8ms/step\n",
      "Epoch 111/135\n",
      "10/10 - 0s - loss: 4.9736e-04 - val_loss: 0.0096 - 79ms/epoch - 8ms/step\n",
      "Epoch 112/135\n",
      "10/10 - 0s - loss: 5.6150e-04 - val_loss: 0.0095 - 79ms/epoch - 8ms/step\n",
      "Epoch 113/135\n",
      "10/10 - 0s - loss: 5.1357e-04 - val_loss: 0.0096 - 81ms/epoch - 8ms/step\n",
      "Epoch 114/135\n",
      "10/10 - 0s - loss: 5.4290e-04 - val_loss: 0.0095 - 80ms/epoch - 8ms/step\n",
      "Epoch 115/135\n",
      "10/10 - 0s - loss: 5.7490e-04 - val_loss: 0.0094 - 79ms/epoch - 8ms/step\n",
      "Epoch 116/135\n",
      "10/10 - 0s - loss: 5.6472e-04 - val_loss: 0.0092 - 79ms/epoch - 8ms/step\n",
      "Epoch 117/135\n",
      "10/10 - 0s - loss: 5.2591e-04 - val_loss: 0.0093 - 80ms/epoch - 8ms/step\n",
      "Epoch 118/135\n",
      "10/10 - 0s - loss: 5.1938e-04 - val_loss: 0.0092 - 79ms/epoch - 8ms/step\n",
      "Epoch 119/135\n",
      "10/10 - 0s - loss: 5.7376e-04 - val_loss: 0.0091 - 79ms/epoch - 8ms/step\n",
      "Epoch 120/135\n",
      "10/10 - 0s - loss: 5.6979e-04 - val_loss: 0.0091 - 79ms/epoch - 8ms/step\n",
      "Epoch 121/135\n",
      "10/10 - 0s - loss: 5.2504e-04 - val_loss: 0.0091 - 82ms/epoch - 8ms/step\n",
      "Epoch 122/135\n",
      "10/10 - 0s - loss: 4.9115e-04 - val_loss: 0.0091 - 108ms/epoch - 11ms/step\n",
      "Epoch 123/135\n",
      "10/10 - 0s - loss: 5.0764e-04 - val_loss: 0.0090 - 82ms/epoch - 8ms/step\n",
      "Epoch 124/135\n",
      "10/10 - 0s - loss: 5.4822e-04 - val_loss: 0.0090 - 79ms/epoch - 8ms/step\n",
      "Epoch 125/135\n",
      "10/10 - 0s - loss: 5.6602e-04 - val_loss: 0.0090 - 79ms/epoch - 8ms/step\n",
      "Epoch 126/135\n",
      "10/10 - 0s - loss: 5.2644e-04 - val_loss: 0.0089 - 86ms/epoch - 9ms/step\n",
      "Epoch 127/135\n",
      "10/10 - 0s - loss: 4.4777e-04 - val_loss: 0.0089 - 99ms/epoch - 10ms/step\n",
      "Epoch 128/135\n",
      "10/10 - 0s - loss: 5.6494e-04 - val_loss: 0.0088 - 82ms/epoch - 8ms/step\n",
      "Epoch 129/135\n",
      "10/10 - 0s - loss: 5.1843e-04 - val_loss: 0.0088 - 93ms/epoch - 9ms/step\n",
      "Epoch 130/135\n",
      "10/10 - 0s - loss: 5.2832e-04 - val_loss: 0.0087 - 91ms/epoch - 9ms/step\n",
      "Epoch 131/135\n",
      "10/10 - 0s - loss: 5.2558e-04 - val_loss: 0.0087 - 89ms/epoch - 9ms/step\n",
      "Epoch 132/135\n",
      "10/10 - 0s - loss: 4.8363e-04 - val_loss: 0.0088 - 86ms/epoch - 9ms/step\n",
      "Epoch 133/135\n",
      "10/10 - 0s - loss: 4.9769e-04 - val_loss: 0.0088 - 86ms/epoch - 9ms/step\n",
      "Epoch 134/135\n",
      "10/10 - 0s - loss: 4.6221e-04 - val_loss: 0.0088 - 94ms/epoch - 9ms/step\n",
      "Epoch 135/135\n",
      "10/10 - 0s - loss: 4.8193e-04 - val_loss: 0.0087 - 85ms/epoch - 8ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-167.3   \u001b[0m | \u001b[0m135.2    \u001b[0m | \u001b[0m4.702    \u001b[0m | \u001b[0m0.0007197\u001b[0m | \u001b[0m18.46    \u001b[0m |\n",
      "Model: \"sequential_127\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_456 (LSTM)             (None, 1, 112)            52864     \n",
      "                                                                 \n",
      " dropout_329 (Dropout)       (None, 1, 112)            0         \n",
      "                                                                 \n",
      " lstm_457 (LSTM)             (None, 1, 112)            100800    \n",
      "                                                                 \n",
      " dropout_330 (Dropout)       (None, 1, 112)            0         \n",
      "                                                                 \n",
      " lstm_458 (LSTM)             (None, 1, 112)            100800    \n",
      "                                                                 \n",
      " dropout_331 (Dropout)       (None, 1, 112)            0         \n",
      "                                                                 \n",
      " lstm_459 (LSTM)             (None, 1, 112)            100800    \n",
      "                                                                 \n",
      " dropout_332 (Dropout)       (None, 1, 112)            0         \n",
      "                                                                 \n",
      " lstm_460 (LSTM)             (None, 112)               100800    \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 1)                 113       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 456,177\n",
      "Trainable params: 456,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/53\n",
      "10/10 - 10s - loss: 0.0209 - val_loss: 0.0178 - 10s/epoch - 959ms/step\n",
      "Epoch 2/53\n",
      "10/10 - 0s - loss: 0.0033 - val_loss: 0.0168 - 149ms/epoch - 15ms/step\n",
      "Epoch 3/53\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0171 - 151ms/epoch - 15ms/step\n",
      "Epoch 4/53\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0141 - 162ms/epoch - 16ms/step\n",
      "Epoch 5/53\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0097 - 152ms/epoch - 15ms/step\n",
      "Epoch 6/53\n",
      "10/10 - 0s - loss: 7.6224e-04 - val_loss: 0.0088 - 152ms/epoch - 15ms/step\n",
      "Epoch 7/53\n",
      "10/10 - 0s - loss: 6.4268e-04 - val_loss: 0.0083 - 154ms/epoch - 15ms/step\n",
      "Epoch 8/53\n",
      "10/10 - 0s - loss: 5.5456e-04 - val_loss: 0.0081 - 159ms/epoch - 16ms/step\n",
      "Epoch 9/53\n",
      "10/10 - 0s - loss: 3.6808e-04 - val_loss: 0.0080 - 152ms/epoch - 15ms/step\n",
      "Epoch 10/53\n",
      "10/10 - 0s - loss: 3.2460e-04 - val_loss: 0.0079 - 168ms/epoch - 17ms/step\n",
      "Epoch 11/53\n",
      "10/10 - 0s - loss: 2.8393e-04 - val_loss: 0.0080 - 151ms/epoch - 15ms/step\n",
      "Epoch 12/53\n",
      "10/10 - 0s - loss: 2.7585e-04 - val_loss: 0.0080 - 151ms/epoch - 15ms/step\n",
      "Epoch 13/53\n",
      "10/10 - 0s - loss: 2.7879e-04 - val_loss: 0.0079 - 156ms/epoch - 16ms/step\n",
      "Epoch 14/53\n",
      "10/10 - 0s - loss: 2.7480e-04 - val_loss: 0.0079 - 155ms/epoch - 15ms/step\n",
      "Epoch 15/53\n",
      "10/10 - 0s - loss: 2.7605e-04 - val_loss: 0.0079 - 151ms/epoch - 15ms/step\n",
      "Epoch 16/53\n",
      "10/10 - 0s - loss: 2.5833e-04 - val_loss: 0.0080 - 153ms/epoch - 15ms/step\n",
      "Epoch 17/53\n",
      "10/10 - 0s - loss: 2.9685e-04 - val_loss: 0.0079 - 151ms/epoch - 15ms/step\n",
      "Epoch 18/53\n",
      "10/10 - 0s - loss: 2.5103e-04 - val_loss: 0.0080 - 155ms/epoch - 16ms/step\n",
      "Epoch 19/53\n",
      "10/10 - 0s - loss: 2.5935e-04 - val_loss: 0.0080 - 172ms/epoch - 17ms/step\n",
      "Epoch 20/53\n",
      "10/10 - 0s - loss: 2.6615e-04 - val_loss: 0.0080 - 152ms/epoch - 15ms/step\n",
      "Epoch 21/53\n",
      "10/10 - 0s - loss: 2.7035e-04 - val_loss: 0.0080 - 149ms/epoch - 15ms/step\n",
      "Epoch 22/53\n",
      "10/10 - 0s - loss: 2.8359e-04 - val_loss: 0.0079 - 155ms/epoch - 16ms/step\n",
      "Epoch 23/53\n",
      "10/10 - 0s - loss: 2.8398e-04 - val_loss: 0.0080 - 148ms/epoch - 15ms/step\n",
      "Epoch 24/53\n",
      "10/10 - 0s - loss: 2.5686e-04 - val_loss: 0.0079 - 152ms/epoch - 15ms/step\n",
      "Epoch 25/53\n",
      "10/10 - 0s - loss: 2.5352e-04 - val_loss: 0.0080 - 155ms/epoch - 16ms/step\n",
      "Epoch 26/53\n",
      "10/10 - 0s - loss: 2.5329e-04 - val_loss: 0.0081 - 154ms/epoch - 15ms/step\n",
      "Epoch 27/53\n",
      "10/10 - 0s - loss: 2.6181e-04 - val_loss: 0.0080 - 150ms/epoch - 15ms/step\n",
      "Epoch 28/53\n",
      "10/10 - 0s - loss: 2.4149e-04 - val_loss: 0.0081 - 162ms/epoch - 16ms/step\n",
      "Epoch 29/53\n",
      "10/10 - 0s - loss: 2.4194e-04 - val_loss: 0.0081 - 153ms/epoch - 15ms/step\n",
      "Epoch 30/53\n",
      "10/10 - 0s - loss: 2.3946e-04 - val_loss: 0.0080 - 151ms/epoch - 15ms/step\n",
      "Epoch 31/53\n",
      "10/10 - 0s - loss: 2.4122e-04 - val_loss: 0.0080 - 150ms/epoch - 15ms/step\n",
      "Epoch 32/53\n",
      "10/10 - 0s - loss: 2.3846e-04 - val_loss: 0.0080 - 154ms/epoch - 15ms/step\n",
      "Epoch 33/53\n",
      "10/10 - 0s - loss: 2.6515e-04 - val_loss: 0.0081 - 153ms/epoch - 15ms/step\n",
      "Epoch 34/53\n",
      "10/10 - 0s - loss: 2.5555e-04 - val_loss: 0.0082 - 148ms/epoch - 15ms/step\n",
      "Epoch 35/53\n",
      "10/10 - 0s - loss: 2.3238e-04 - val_loss: 0.0081 - 149ms/epoch - 15ms/step\n",
      "Epoch 36/53\n",
      "10/10 - 0s - loss: 2.5339e-04 - val_loss: 0.0081 - 149ms/epoch - 15ms/step\n",
      "Epoch 37/53\n",
      "10/10 - 0s - loss: 2.4414e-04 - val_loss: 0.0080 - 147ms/epoch - 15ms/step\n",
      "Epoch 38/53\n",
      "10/10 - 0s - loss: 2.5426e-04 - val_loss: 0.0081 - 150ms/epoch - 15ms/step\n",
      "Epoch 39/53\n",
      "10/10 - 0s - loss: 2.5617e-04 - val_loss: 0.0081 - 150ms/epoch - 15ms/step\n",
      "Epoch 40/53\n",
      "10/10 - 0s - loss: 2.1723e-04 - val_loss: 0.0082 - 148ms/epoch - 15ms/step\n",
      "Epoch 41/53\n",
      "10/10 - 0s - loss: 2.5344e-04 - val_loss: 0.0083 - 147ms/epoch - 15ms/step\n",
      "Epoch 42/53\n",
      "10/10 - 0s - loss: 2.5175e-04 - val_loss: 0.0081 - 148ms/epoch - 15ms/step\n",
      "Epoch 43/53\n",
      "10/10 - 0s - loss: 2.3868e-04 - val_loss: 0.0082 - 148ms/epoch - 15ms/step\n",
      "Epoch 44/53\n",
      "10/10 - 0s - loss: 2.7399e-04 - val_loss: 0.0082 - 148ms/epoch - 15ms/step\n",
      "Epoch 45/53\n",
      "10/10 - 0s - loss: 3.4215e-04 - val_loss: 0.0080 - 163ms/epoch - 16ms/step\n",
      "Epoch 46/53\n",
      "10/10 - 0s - loss: 2.6070e-04 - val_loss: 0.0081 - 156ms/epoch - 16ms/step\n",
      "Epoch 47/53\n",
      "10/10 - 0s - loss: 2.2279e-04 - val_loss: 0.0080 - 175ms/epoch - 18ms/step\n",
      "Epoch 48/53\n",
      "10/10 - 0s - loss: 2.1841e-04 - val_loss: 0.0081 - 149ms/epoch - 15ms/step\n",
      "Epoch 49/53\n",
      "10/10 - 0s - loss: 2.2484e-04 - val_loss: 0.0081 - 147ms/epoch - 15ms/step\n",
      "Epoch 50/53\n",
      "10/10 - 0s - loss: 2.2678e-04 - val_loss: 0.0082 - 147ms/epoch - 15ms/step\n",
      "Epoch 51/53\n",
      "10/10 - 0s - loss: 2.4146e-04 - val_loss: 0.0081 - 154ms/epoch - 15ms/step\n",
      "Epoch 52/53\n",
      "10/10 - 0s - loss: 2.1862e-04 - val_loss: 0.0081 - 162ms/epoch - 16ms/step\n",
      "Epoch 53/53\n",
      "10/10 - 0s - loss: 2.5227e-04 - val_loss: 0.0082 - 157ms/epoch - 16ms/step\n",
      "9/9 [==============================] - 1s 3ms/step\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m-162.6   \u001b[0m | \u001b[95m53.03    \u001b[0m | \u001b[95m4.33     \u001b[0m | \u001b[95m0.007784 \u001b[0m | \u001b[95m112.4    \u001b[0m |\n",
      "Model: \"sequential_128\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_461 (LSTM)             (None, 1, 101)            43228     \n",
      "                                                                 \n",
      " dropout_333 (Dropout)       (None, 1, 101)            0         \n",
      "                                                                 \n",
      " lstm_462 (LSTM)             (None, 1, 101)            82012     \n",
      "                                                                 \n",
      " dropout_334 (Dropout)       (None, 1, 101)            0         \n",
      "                                                                 \n",
      " lstm_463 (LSTM)             (None, 1, 101)            82012     \n",
      "                                                                 \n",
      " dropout_335 (Dropout)       (None, 1, 101)            0         \n",
      "                                                                 \n",
      " lstm_464 (LSTM)             (None, 1, 101)            82012     \n",
      "                                                                 \n",
      " dropout_336 (Dropout)       (None, 1, 101)            0         \n",
      "                                                                 \n",
      " lstm_465 (LSTM)             (None, 101)               82012     \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 1)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 371,378\n",
      "Trainable params: 371,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/196\n",
      "10/10 - 10s - loss: 0.0274 - val_loss: 0.0181 - 10s/epoch - 1s/step\n",
      "Epoch 2/196\n",
      "10/10 - 0s - loss: 0.0037 - val_loss: 0.0185 - 144ms/epoch - 14ms/step\n",
      "Epoch 3/196\n",
      "10/10 - 0s - loss: 0.0033 - val_loss: 0.0168 - 140ms/epoch - 14ms/step\n",
      "Epoch 4/196\n",
      "10/10 - 0s - loss: 0.0032 - val_loss: 0.0172 - 137ms/epoch - 14ms/step\n",
      "Epoch 5/196\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0169 - 137ms/epoch - 14ms/step\n",
      "Epoch 6/196\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0170 - 137ms/epoch - 14ms/step\n",
      "Epoch 7/196\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0169 - 137ms/epoch - 14ms/step\n",
      "Epoch 8/196\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0167 - 137ms/epoch - 14ms/step\n",
      "Epoch 9/196\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0162 - 137ms/epoch - 14ms/step\n",
      "Epoch 10/196\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0134 - 136ms/epoch - 14ms/step\n",
      "Epoch 11/196\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0085 - 138ms/epoch - 14ms/step\n",
      "Epoch 12/196\n",
      "10/10 - 0s - loss: 8.0716e-04 - val_loss: 0.0085 - 137ms/epoch - 14ms/step\n",
      "Epoch 13/196\n",
      "10/10 - 0s - loss: 5.7554e-04 - val_loss: 0.0080 - 136ms/epoch - 14ms/step\n",
      "Epoch 14/196\n",
      "10/10 - 0s - loss: 4.9160e-04 - val_loss: 0.0080 - 137ms/epoch - 14ms/step\n",
      "Epoch 15/196\n",
      "10/10 - 0s - loss: 4.7632e-04 - val_loss: 0.0081 - 138ms/epoch - 14ms/step\n",
      "Epoch 16/196\n",
      "10/10 - 0s - loss: 4.1259e-04 - val_loss: 0.0080 - 140ms/epoch - 14ms/step\n",
      "Epoch 17/196\n",
      "10/10 - 0s - loss: 3.3756e-04 - val_loss: 0.0080 - 145ms/epoch - 14ms/step\n",
      "Epoch 18/196\n",
      "10/10 - 0s - loss: 3.0922e-04 - val_loss: 0.0080 - 167ms/epoch - 17ms/step\n",
      "Epoch 19/196\n",
      "10/10 - 0s - loss: 3.1680e-04 - val_loss: 0.0079 - 141ms/epoch - 14ms/step\n",
      "Epoch 20/196\n",
      "10/10 - 0s - loss: 3.0506e-04 - val_loss: 0.0080 - 141ms/epoch - 14ms/step\n",
      "Epoch 21/196\n",
      "10/10 - 0s - loss: 3.0543e-04 - val_loss: 0.0079 - 141ms/epoch - 14ms/step\n",
      "Epoch 22/196\n",
      "10/10 - 0s - loss: 3.2010e-04 - val_loss: 0.0079 - 147ms/epoch - 15ms/step\n",
      "Epoch 23/196\n",
      "10/10 - 0s - loss: 3.1426e-04 - val_loss: 0.0079 - 139ms/epoch - 14ms/step\n",
      "Epoch 24/196\n",
      "10/10 - 0s - loss: 2.9077e-04 - val_loss: 0.0080 - 138ms/epoch - 14ms/step\n",
      "Epoch 25/196\n",
      "10/10 - 0s - loss: 3.1365e-04 - val_loss: 0.0079 - 138ms/epoch - 14ms/step\n",
      "Epoch 26/196\n",
      "10/10 - 0s - loss: 3.3666e-04 - val_loss: 0.0079 - 137ms/epoch - 14ms/step\n",
      "Epoch 27/196\n",
      "10/10 - 0s - loss: 3.6819e-04 - val_loss: 0.0082 - 149ms/epoch - 15ms/step\n",
      "Epoch 28/196\n",
      "10/10 - 0s - loss: 3.2106e-04 - val_loss: 0.0078 - 137ms/epoch - 14ms/step\n",
      "Epoch 29/196\n",
      "10/10 - 0s - loss: 3.1997e-04 - val_loss: 0.0080 - 141ms/epoch - 14ms/step\n",
      "Epoch 30/196\n",
      "10/10 - 0s - loss: 2.7223e-04 - val_loss: 0.0079 - 140ms/epoch - 14ms/step\n",
      "Epoch 31/196\n",
      "10/10 - 0s - loss: 2.6256e-04 - val_loss: 0.0078 - 156ms/epoch - 16ms/step\n",
      "Epoch 32/196\n",
      "10/10 - 0s - loss: 2.7034e-04 - val_loss: 0.0080 - 159ms/epoch - 16ms/step\n",
      "Epoch 33/196\n",
      "10/10 - 0s - loss: 2.6335e-04 - val_loss: 0.0080 - 142ms/epoch - 14ms/step\n",
      "Epoch 34/196\n",
      "10/10 - 0s - loss: 2.8082e-04 - val_loss: 0.0079 - 147ms/epoch - 15ms/step\n",
      "Epoch 35/196\n",
      "10/10 - 0s - loss: 2.7795e-04 - val_loss: 0.0078 - 147ms/epoch - 15ms/step\n",
      "Epoch 36/196\n",
      "10/10 - 0s - loss: 2.6336e-04 - val_loss: 0.0079 - 161ms/epoch - 16ms/step\n",
      "Epoch 37/196\n",
      "10/10 - 0s - loss: 2.6729e-04 - val_loss: 0.0080 - 146ms/epoch - 15ms/step\n",
      "Epoch 38/196\n",
      "10/10 - 0s - loss: 2.8642e-04 - val_loss: 0.0079 - 144ms/epoch - 14ms/step\n",
      "Epoch 39/196\n",
      "10/10 - 0s - loss: 2.7264e-04 - val_loss: 0.0079 - 143ms/epoch - 14ms/step\n",
      "Epoch 40/196\n",
      "10/10 - 0s - loss: 2.4054e-04 - val_loss: 0.0080 - 158ms/epoch - 16ms/step\n",
      "Epoch 41/196\n",
      "10/10 - 0s - loss: 2.6019e-04 - val_loss: 0.0079 - 146ms/epoch - 15ms/step\n",
      "Epoch 42/196\n",
      "10/10 - 0s - loss: 2.6292e-04 - val_loss: 0.0079 - 144ms/epoch - 14ms/step\n",
      "Epoch 43/196\n",
      "10/10 - 0s - loss: 2.5195e-04 - val_loss: 0.0079 - 141ms/epoch - 14ms/step\n",
      "Epoch 44/196\n",
      "10/10 - 0s - loss: 2.5097e-04 - val_loss: 0.0080 - 139ms/epoch - 14ms/step\n",
      "Epoch 45/196\n",
      "10/10 - 0s - loss: 2.4481e-04 - val_loss: 0.0081 - 146ms/epoch - 15ms/step\n",
      "Epoch 46/196\n",
      "10/10 - 0s - loss: 2.5427e-04 - val_loss: 0.0083 - 157ms/epoch - 16ms/step\n",
      "Epoch 47/196\n",
      "10/10 - 0s - loss: 2.8125e-04 - val_loss: 0.0080 - 155ms/epoch - 15ms/step\n",
      "Epoch 48/196\n",
      "10/10 - 0s - loss: 2.2943e-04 - val_loss: 0.0081 - 138ms/epoch - 14ms/step\n",
      "Epoch 49/196\n",
      "10/10 - 0s - loss: 2.3868e-04 - val_loss: 0.0084 - 138ms/epoch - 14ms/step\n",
      "Epoch 50/196\n",
      "10/10 - 0s - loss: 2.5922e-04 - val_loss: 0.0082 - 137ms/epoch - 14ms/step\n",
      "Epoch 51/196\n",
      "10/10 - 0s - loss: 2.6017e-04 - val_loss: 0.0082 - 137ms/epoch - 14ms/step\n",
      "Epoch 52/196\n",
      "10/10 - 0s - loss: 2.4896e-04 - val_loss: 0.0081 - 137ms/epoch - 14ms/step\n",
      "Epoch 53/196\n",
      "10/10 - 0s - loss: 2.2332e-04 - val_loss: 0.0085 - 151ms/epoch - 15ms/step\n",
      "Epoch 54/196\n",
      "10/10 - 0s - loss: 2.5654e-04 - val_loss: 0.0085 - 166ms/epoch - 17ms/step\n",
      "Epoch 55/196\n",
      "10/10 - 0s - loss: 2.5346e-04 - val_loss: 0.0084 - 156ms/epoch - 16ms/step\n",
      "Epoch 56/196\n",
      "10/10 - 0s - loss: 2.3836e-04 - val_loss: 0.0086 - 165ms/epoch - 17ms/step\n",
      "Epoch 57/196\n",
      "10/10 - 0s - loss: 2.3289e-04 - val_loss: 0.0086 - 153ms/epoch - 15ms/step\n",
      "Epoch 58/196\n",
      "10/10 - 0s - loss: 2.4052e-04 - val_loss: 0.0087 - 145ms/epoch - 15ms/step\n",
      "Epoch 59/196\n",
      "10/10 - 0s - loss: 2.2292e-04 - val_loss: 0.0089 - 144ms/epoch - 14ms/step\n",
      "Epoch 60/196\n",
      "10/10 - 0s - loss: 2.3877e-04 - val_loss: 0.0091 - 151ms/epoch - 15ms/step\n",
      "Epoch 61/196\n",
      "10/10 - 0s - loss: 2.1467e-04 - val_loss: 0.0094 - 171ms/epoch - 17ms/step\n",
      "Epoch 62/196\n",
      "10/10 - 0s - loss: 2.2034e-04 - val_loss: 0.0097 - 139ms/epoch - 14ms/step\n",
      "Epoch 63/196\n",
      "10/10 - 0s - loss: 2.3360e-04 - val_loss: 0.0097 - 138ms/epoch - 14ms/step\n",
      "Epoch 64/196\n",
      "10/10 - 0s - loss: 2.3100e-04 - val_loss: 0.0101 - 137ms/epoch - 14ms/step\n",
      "Epoch 65/196\n",
      "10/10 - 0s - loss: 2.5493e-04 - val_loss: 0.0105 - 138ms/epoch - 14ms/step\n",
      "Epoch 66/196\n",
      "10/10 - 0s - loss: 2.7545e-04 - val_loss: 0.0106 - 139ms/epoch - 14ms/step\n",
      "Epoch 67/196\n",
      "10/10 - 0s - loss: 2.3888e-04 - val_loss: 0.0109 - 138ms/epoch - 14ms/step\n",
      "Epoch 68/196\n",
      "10/10 - 0s - loss: 2.3317e-04 - val_loss: 0.0108 - 139ms/epoch - 14ms/step\n",
      "Epoch 69/196\n",
      "10/10 - 0s - loss: 2.2203e-04 - val_loss: 0.0119 - 137ms/epoch - 14ms/step\n",
      "Epoch 70/196\n",
      "10/10 - 0s - loss: 2.3195e-04 - val_loss: 0.0120 - 138ms/epoch - 14ms/step\n",
      "Epoch 71/196\n",
      "10/10 - 0s - loss: 2.2387e-04 - val_loss: 0.0125 - 137ms/epoch - 14ms/step\n",
      "Epoch 72/196\n",
      "10/10 - 0s - loss: 2.4381e-04 - val_loss: 0.0122 - 137ms/epoch - 14ms/step\n",
      "Epoch 73/196\n",
      "10/10 - 0s - loss: 2.1882e-04 - val_loss: 0.0128 - 145ms/epoch - 14ms/step\n",
      "Epoch 74/196\n",
      "10/10 - 0s - loss: 2.3506e-04 - val_loss: 0.0146 - 141ms/epoch - 14ms/step\n",
      "Epoch 75/196\n",
      "10/10 - 0s - loss: 2.2139e-04 - val_loss: 0.0154 - 136ms/epoch - 14ms/step\n",
      "Epoch 76/196\n",
      "10/10 - 0s - loss: 2.3462e-04 - val_loss: 0.0150 - 136ms/epoch - 14ms/step\n",
      "Epoch 77/196\n",
      "10/10 - 0s - loss: 2.1773e-04 - val_loss: 0.0152 - 137ms/epoch - 14ms/step\n",
      "Epoch 78/196\n",
      "10/10 - 0s - loss: 2.2295e-04 - val_loss: 0.0153 - 138ms/epoch - 14ms/step\n",
      "Epoch 79/196\n",
      "10/10 - 0s - loss: 2.3382e-04 - val_loss: 0.0163 - 142ms/epoch - 14ms/step\n",
      "Epoch 80/196\n",
      "10/10 - 0s - loss: 2.4730e-04 - val_loss: 0.0164 - 155ms/epoch - 16ms/step\n",
      "Epoch 81/196\n",
      "10/10 - 0s - loss: 2.0479e-04 - val_loss: 0.0168 - 157ms/epoch - 16ms/step\n",
      "Epoch 82/196\n",
      "10/10 - 0s - loss: 2.0561e-04 - val_loss: 0.0175 - 147ms/epoch - 15ms/step\n",
      "Epoch 83/196\n",
      "10/10 - 0s - loss: 2.2968e-04 - val_loss: 0.0181 - 142ms/epoch - 14ms/step\n",
      "Epoch 84/196\n",
      "10/10 - 0s - loss: 2.4263e-04 - val_loss: 0.0177 - 141ms/epoch - 14ms/step\n",
      "Epoch 85/196\n",
      "10/10 - 0s - loss: 2.2747e-04 - val_loss: 0.0184 - 140ms/epoch - 14ms/step\n",
      "Epoch 86/196\n",
      "10/10 - 0s - loss: 2.2428e-04 - val_loss: 0.0192 - 138ms/epoch - 14ms/step\n",
      "Epoch 87/196\n",
      "10/10 - 0s - loss: 2.3169e-04 - val_loss: 0.0190 - 142ms/epoch - 14ms/step\n",
      "Epoch 88/196\n",
      "10/10 - 0s - loss: 2.0398e-04 - val_loss: 0.0192 - 137ms/epoch - 14ms/step\n",
      "Epoch 89/196\n",
      "10/10 - 0s - loss: 2.0471e-04 - val_loss: 0.0198 - 170ms/epoch - 17ms/step\n",
      "Epoch 90/196\n",
      "10/10 - 0s - loss: 2.1185e-04 - val_loss: 0.0187 - 152ms/epoch - 15ms/step\n",
      "Epoch 91/196\n",
      "10/10 - 0s - loss: 2.4324e-04 - val_loss: 0.0199 - 152ms/epoch - 15ms/step\n",
      "Epoch 92/196\n",
      "10/10 - 0s - loss: 2.2010e-04 - val_loss: 0.0195 - 141ms/epoch - 14ms/step\n",
      "Epoch 93/196\n",
      "10/10 - 0s - loss: 2.1770e-04 - val_loss: 0.0203 - 144ms/epoch - 14ms/step\n",
      "Epoch 94/196\n",
      "10/10 - 0s - loss: 2.0923e-04 - val_loss: 0.0204 - 144ms/epoch - 14ms/step\n",
      "Epoch 95/196\n",
      "10/10 - 0s - loss: 2.4263e-04 - val_loss: 0.0194 - 144ms/epoch - 14ms/step\n",
      "Epoch 96/196\n",
      "10/10 - 0s - loss: 2.2752e-04 - val_loss: 0.0197 - 157ms/epoch - 16ms/step\n",
      "Epoch 97/196\n",
      "10/10 - 0s - loss: 2.2290e-04 - val_loss: 0.0204 - 138ms/epoch - 14ms/step\n",
      "Epoch 98/196\n",
      "10/10 - 0s - loss: 2.0946e-04 - val_loss: 0.0205 - 139ms/epoch - 14ms/step\n",
      "Epoch 99/196\n",
      "10/10 - 0s - loss: 1.9876e-04 - val_loss: 0.0205 - 142ms/epoch - 14ms/step\n",
      "Epoch 100/196\n",
      "10/10 - 0s - loss: 2.3789e-04 - val_loss: 0.0217 - 141ms/epoch - 14ms/step\n",
      "Epoch 101/196\n",
      "10/10 - 0s - loss: 2.2711e-04 - val_loss: 0.0195 - 148ms/epoch - 15ms/step\n",
      "Epoch 102/196\n",
      "10/10 - 0s - loss: 2.5198e-04 - val_loss: 0.0212 - 151ms/epoch - 15ms/step\n",
      "Epoch 103/196\n",
      "10/10 - 0s - loss: 2.6895e-04 - val_loss: 0.0208 - 146ms/epoch - 15ms/step\n",
      "Epoch 104/196\n",
      "10/10 - 0s - loss: 2.4869e-04 - val_loss: 0.0209 - 139ms/epoch - 14ms/step\n",
      "Epoch 105/196\n",
      "10/10 - 0s - loss: 2.0721e-04 - val_loss: 0.0230 - 145ms/epoch - 15ms/step\n",
      "Epoch 106/196\n",
      "10/10 - 0s - loss: 2.1156e-04 - val_loss: 0.0213 - 152ms/epoch - 15ms/step\n",
      "Epoch 107/196\n",
      "10/10 - 0s - loss: 1.9484e-04 - val_loss: 0.0221 - 139ms/epoch - 14ms/step\n",
      "Epoch 108/196\n",
      "10/10 - 0s - loss: 2.3917e-04 - val_loss: 0.0230 - 152ms/epoch - 15ms/step\n",
      "Epoch 109/196\n",
      "10/10 - 0s - loss: 2.0840e-04 - val_loss: 0.0215 - 159ms/epoch - 16ms/step\n",
      "Epoch 110/196\n",
      "10/10 - 0s - loss: 2.1107e-04 - val_loss: 0.0224 - 204ms/epoch - 20ms/step\n",
      "Epoch 111/196\n",
      "10/10 - 0s - loss: 2.0454e-04 - val_loss: 0.0211 - 164ms/epoch - 16ms/step\n",
      "Epoch 112/196\n",
      "10/10 - 0s - loss: 2.1340e-04 - val_loss: 0.0214 - 158ms/epoch - 16ms/step\n",
      "Epoch 113/196\n",
      "10/10 - 0s - loss: 2.6043e-04 - val_loss: 0.0217 - 163ms/epoch - 16ms/step\n",
      "Epoch 114/196\n",
      "10/10 - 0s - loss: 2.1362e-04 - val_loss: 0.0214 - 156ms/epoch - 16ms/step\n",
      "Epoch 115/196\n",
      "10/10 - 0s - loss: 1.9561e-04 - val_loss: 0.0227 - 186ms/epoch - 19ms/step\n",
      "Epoch 116/196\n",
      "10/10 - 0s - loss: 2.3282e-04 - val_loss: 0.0209 - 148ms/epoch - 15ms/step\n",
      "Epoch 117/196\n",
      "10/10 - 0s - loss: 1.9428e-04 - val_loss: 0.0222 - 145ms/epoch - 14ms/step\n",
      "Epoch 118/196\n",
      "10/10 - 0s - loss: 2.1502e-04 - val_loss: 0.0199 - 149ms/epoch - 15ms/step\n",
      "Epoch 119/196\n",
      "10/10 - 0s - loss: 2.2106e-04 - val_loss: 0.0208 - 144ms/epoch - 14ms/step\n",
      "Epoch 120/196\n",
      "10/10 - 0s - loss: 2.1521e-04 - val_loss: 0.0209 - 166ms/epoch - 17ms/step\n",
      "Epoch 121/196\n",
      "10/10 - 0s - loss: 2.1036e-04 - val_loss: 0.0212 - 174ms/epoch - 17ms/step\n",
      "Epoch 122/196\n",
      "10/10 - 0s - loss: 2.1278e-04 - val_loss: 0.0217 - 155ms/epoch - 15ms/step\n",
      "Epoch 123/196\n",
      "10/10 - 0s - loss: 1.9098e-04 - val_loss: 0.0207 - 149ms/epoch - 15ms/step\n",
      "Epoch 124/196\n",
      "10/10 - 0s - loss: 2.0506e-04 - val_loss: 0.0199 - 151ms/epoch - 15ms/step\n",
      "Epoch 125/196\n",
      "10/10 - 0s - loss: 2.3916e-04 - val_loss: 0.0214 - 146ms/epoch - 15ms/step\n",
      "Epoch 126/196\n",
      "10/10 - 0s - loss: 2.2072e-04 - val_loss: 0.0205 - 146ms/epoch - 15ms/step\n",
      "Epoch 127/196\n",
      "10/10 - 0s - loss: 2.3211e-04 - val_loss: 0.0206 - 148ms/epoch - 15ms/step\n",
      "Epoch 128/196\n",
      "10/10 - 0s - loss: 2.3753e-04 - val_loss: 0.0218 - 175ms/epoch - 18ms/step\n",
      "Epoch 129/196\n",
      "10/10 - 0s - loss: 2.0323e-04 - val_loss: 0.0212 - 145ms/epoch - 14ms/step\n",
      "Epoch 130/196\n",
      "10/10 - 0s - loss: 1.9634e-04 - val_loss: 0.0215 - 146ms/epoch - 15ms/step\n",
      "Epoch 131/196\n",
      "10/10 - 0s - loss: 1.9992e-04 - val_loss: 0.0215 - 146ms/epoch - 15ms/step\n",
      "Epoch 132/196\n",
      "10/10 - 0s - loss: 2.2492e-04 - val_loss: 0.0214 - 147ms/epoch - 15ms/step\n",
      "Epoch 133/196\n",
      "10/10 - 0s - loss: 2.2292e-04 - val_loss: 0.0227 - 144ms/epoch - 14ms/step\n",
      "Epoch 134/196\n",
      "10/10 - 0s - loss: 2.1538e-04 - val_loss: 0.0211 - 152ms/epoch - 15ms/step\n",
      "Epoch 135/196\n",
      "10/10 - 0s - loss: 2.0321e-04 - val_loss: 0.0228 - 154ms/epoch - 15ms/step\n",
      "Epoch 136/196\n",
      "10/10 - 0s - loss: 2.0120e-04 - val_loss: 0.0220 - 147ms/epoch - 15ms/step\n",
      "Epoch 137/196\n",
      "10/10 - 0s - loss: 2.1196e-04 - val_loss: 0.0218 - 144ms/epoch - 14ms/step\n",
      "Epoch 138/196\n",
      "10/10 - 0s - loss: 2.0191e-04 - val_loss: 0.0219 - 143ms/epoch - 14ms/step\n",
      "Epoch 139/196\n",
      "10/10 - 0s - loss: 1.8605e-04 - val_loss: 0.0219 - 158ms/epoch - 16ms/step\n",
      "Epoch 140/196\n",
      "10/10 - 0s - loss: 1.9706e-04 - val_loss: 0.0212 - 149ms/epoch - 15ms/step\n",
      "Epoch 141/196\n",
      "10/10 - 0s - loss: 1.9577e-04 - val_loss: 0.0226 - 152ms/epoch - 15ms/step\n",
      "Epoch 142/196\n",
      "10/10 - 0s - loss: 2.2436e-04 - val_loss: 0.0213 - 148ms/epoch - 15ms/step\n",
      "Epoch 143/196\n",
      "10/10 - 0s - loss: 2.3200e-04 - val_loss: 0.0223 - 142ms/epoch - 14ms/step\n",
      "Epoch 144/196\n",
      "10/10 - 0s - loss: 1.8020e-04 - val_loss: 0.0227 - 144ms/epoch - 14ms/step\n",
      "Epoch 145/196\n",
      "10/10 - 0s - loss: 2.0656e-04 - val_loss: 0.0215 - 145ms/epoch - 14ms/step\n",
      "Epoch 146/196\n",
      "10/10 - 0s - loss: 2.0127e-04 - val_loss: 0.0221 - 145ms/epoch - 14ms/step\n",
      "Epoch 147/196\n",
      "10/10 - 0s - loss: 2.0308e-04 - val_loss: 0.0221 - 149ms/epoch - 15ms/step\n",
      "Epoch 148/196\n",
      "10/10 - 0s - loss: 1.9373e-04 - val_loss: 0.0222 - 147ms/epoch - 15ms/step\n",
      "Epoch 149/196\n",
      "10/10 - 0s - loss: 2.5507e-04 - val_loss: 0.0232 - 143ms/epoch - 14ms/step\n",
      "Epoch 150/196\n",
      "10/10 - 0s - loss: 2.1578e-04 - val_loss: 0.0217 - 144ms/epoch - 14ms/step\n",
      "Epoch 151/196\n",
      "10/10 - 0s - loss: 1.9551e-04 - val_loss: 0.0227 - 195ms/epoch - 19ms/step\n",
      "Epoch 152/196\n",
      "10/10 - 0s - loss: 1.9898e-04 - val_loss: 0.0221 - 149ms/epoch - 15ms/step\n",
      "Epoch 153/196\n",
      "10/10 - 0s - loss: 2.2195e-04 - val_loss: 0.0228 - 155ms/epoch - 15ms/step\n",
      "Epoch 154/196\n",
      "10/10 - 0s - loss: 2.6304e-04 - val_loss: 0.0230 - 173ms/epoch - 17ms/step\n",
      "Epoch 155/196\n",
      "10/10 - 0s - loss: 2.2032e-04 - val_loss: 0.0235 - 157ms/epoch - 16ms/step\n",
      "Epoch 156/196\n",
      "10/10 - 0s - loss: 1.9369e-04 - val_loss: 0.0233 - 144ms/epoch - 14ms/step\n",
      "Epoch 157/196\n",
      "10/10 - 0s - loss: 2.1416e-04 - val_loss: 0.0235 - 146ms/epoch - 15ms/step\n",
      "Epoch 158/196\n",
      "10/10 - 0s - loss: 1.9519e-04 - val_loss: 0.0238 - 148ms/epoch - 15ms/step\n",
      "Epoch 159/196\n",
      "10/10 - 0s - loss: 2.0256e-04 - val_loss: 0.0229 - 195ms/epoch - 20ms/step\n",
      "Epoch 160/196\n",
      "10/10 - 0s - loss: 1.9835e-04 - val_loss: 0.0230 - 146ms/epoch - 15ms/step\n",
      "Epoch 161/196\n",
      "10/10 - 0s - loss: 2.0369e-04 - val_loss: 0.0227 - 145ms/epoch - 14ms/step\n",
      "Epoch 162/196\n",
      "10/10 - 0s - loss: 2.2305e-04 - val_loss: 0.0247 - 149ms/epoch - 15ms/step\n",
      "Epoch 163/196\n",
      "10/10 - 0s - loss: 2.4990e-04 - val_loss: 0.0221 - 157ms/epoch - 16ms/step\n",
      "Epoch 164/196\n",
      "10/10 - 0s - loss: 2.1318e-04 - val_loss: 0.0233 - 146ms/epoch - 15ms/step\n",
      "Epoch 165/196\n",
      "10/10 - 0s - loss: 2.0876e-04 - val_loss: 0.0220 - 146ms/epoch - 15ms/step\n",
      "Epoch 166/196\n",
      "10/10 - 0s - loss: 2.0133e-04 - val_loss: 0.0230 - 156ms/epoch - 16ms/step\n",
      "Epoch 167/196\n",
      "10/10 - 0s - loss: 1.9070e-04 - val_loss: 0.0213 - 149ms/epoch - 15ms/step\n",
      "Epoch 168/196\n",
      "10/10 - 0s - loss: 2.0030e-04 - val_loss: 0.0232 - 143ms/epoch - 14ms/step\n",
      "Epoch 169/196\n",
      "10/10 - 0s - loss: 2.3290e-04 - val_loss: 0.0212 - 177ms/epoch - 18ms/step\n",
      "Epoch 170/196\n",
      "10/10 - 0s - loss: 2.0615e-04 - val_loss: 0.0228 - 160ms/epoch - 16ms/step\n",
      "Epoch 171/196\n",
      "10/10 - 0s - loss: 1.8859e-04 - val_loss: 0.0222 - 155ms/epoch - 15ms/step\n",
      "Epoch 172/196\n",
      "10/10 - 0s - loss: 2.0368e-04 - val_loss: 0.0227 - 152ms/epoch - 15ms/step\n",
      "Epoch 173/196\n",
      "10/10 - 0s - loss: 2.0003e-04 - val_loss: 0.0227 - 147ms/epoch - 15ms/step\n",
      "Epoch 174/196\n",
      "10/10 - 0s - loss: 2.0869e-04 - val_loss: 0.0224 - 144ms/epoch - 14ms/step\n",
      "Epoch 175/196\n",
      "10/10 - 0s - loss: 2.3293e-04 - val_loss: 0.0229 - 153ms/epoch - 15ms/step\n",
      "Epoch 176/196\n",
      "10/10 - 0s - loss: 2.1564e-04 - val_loss: 0.0231 - 153ms/epoch - 15ms/step\n",
      "Epoch 177/196\n",
      "10/10 - 0s - loss: 2.0368e-04 - val_loss: 0.0223 - 155ms/epoch - 15ms/step\n",
      "Epoch 178/196\n",
      "10/10 - 0s - loss: 2.1304e-04 - val_loss: 0.0232 - 145ms/epoch - 14ms/step\n",
      "Epoch 179/196\n",
      "10/10 - 0s - loss: 1.9742e-04 - val_loss: 0.0232 - 148ms/epoch - 15ms/step\n",
      "Epoch 180/196\n",
      "10/10 - 0s - loss: 2.1450e-04 - val_loss: 0.0228 - 158ms/epoch - 16ms/step\n",
      "Epoch 181/196\n",
      "10/10 - 0s - loss: 1.9433e-04 - val_loss: 0.0230 - 171ms/epoch - 17ms/step\n",
      "Epoch 182/196\n",
      "10/10 - 0s - loss: 2.6720e-04 - val_loss: 0.0236 - 160ms/epoch - 16ms/step\n",
      "Epoch 183/196\n",
      "10/10 - 0s - loss: 2.2184e-04 - val_loss: 0.0238 - 146ms/epoch - 15ms/step\n",
      "Epoch 184/196\n",
      "10/10 - 0s - loss: 2.2693e-04 - val_loss: 0.0232 - 144ms/epoch - 14ms/step\n",
      "Epoch 185/196\n",
      "10/10 - 0s - loss: 2.0597e-04 - val_loss: 0.0230 - 145ms/epoch - 15ms/step\n",
      "Epoch 186/196\n",
      "10/10 - 0s - loss: 2.3980e-04 - val_loss: 0.0239 - 143ms/epoch - 14ms/step\n",
      "Epoch 187/196\n",
      "10/10 - 0s - loss: 2.6404e-04 - val_loss: 0.0221 - 145ms/epoch - 14ms/step\n",
      "Epoch 188/196\n",
      "10/10 - 0s - loss: 2.7079e-04 - val_loss: 0.0255 - 146ms/epoch - 15ms/step\n",
      "Epoch 189/196\n",
      "10/10 - 0s - loss: 2.1675e-04 - val_loss: 0.0208 - 144ms/epoch - 14ms/step\n",
      "Epoch 190/196\n",
      "10/10 - 0s - loss: 2.6146e-04 - val_loss: 0.0230 - 146ms/epoch - 15ms/step\n",
      "Epoch 191/196\n",
      "10/10 - 0s - loss: 2.3595e-04 - val_loss: 0.0229 - 147ms/epoch - 15ms/step\n",
      "Epoch 192/196\n",
      "10/10 - 0s - loss: 2.6724e-04 - val_loss: 0.0233 - 144ms/epoch - 14ms/step\n",
      "Epoch 193/196\n",
      "10/10 - 0s - loss: 2.8417e-04 - val_loss: 0.0227 - 146ms/epoch - 15ms/step\n",
      "Epoch 194/196\n",
      "10/10 - 0s - loss: 2.5715e-04 - val_loss: 0.0221 - 144ms/epoch - 14ms/step\n",
      "Epoch 195/196\n",
      "10/10 - 0s - loss: 2.3750e-04 - val_loss: 0.0227 - 145ms/epoch - 14ms/step\n",
      "Epoch 196/196\n",
      "10/10 - 0s - loss: 1.8357e-04 - val_loss: 0.0232 - 144ms/epoch - 14ms/step\n",
      "9/9 [==============================] - 1s 3ms/step\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-272.5   \u001b[0m | \u001b[0m196.8    \u001b[0m | \u001b[0m4.197    \u001b[0m | \u001b[0m0.00462  \u001b[0m | \u001b[0m101.7    \u001b[0m |\n",
      "Model: \"sequential_129\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_466 (LSTM)             (None, 1, 121)            61468     \n",
      "                                                                 \n",
      " dropout_337 (Dropout)       (None, 1, 121)            0         \n",
      "                                                                 \n",
      " lstm_467 (LSTM)             (None, 1, 121)            117612    \n",
      "                                                                 \n",
      " dropout_338 (Dropout)       (None, 1, 121)            0         \n",
      "                                                                 \n",
      " lstm_468 (LSTM)             (None, 1, 121)            117612    \n",
      "                                                                 \n",
      " dropout_339 (Dropout)       (None, 1, 121)            0         \n",
      "                                                                 \n",
      " lstm_469 (LSTM)             (None, 121)               117612    \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 1)                 122       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 414,426\n",
      "Trainable params: 414,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/67\n",
      "10/10 - 8s - loss: 0.0517 - val_loss: 0.0407 - 8s/epoch - 790ms/step\n",
      "Epoch 2/67\n",
      "10/10 - 0s - loss: 0.0098 - val_loss: 0.0170 - 138ms/epoch - 14ms/step\n",
      "Epoch 3/67\n",
      "10/10 - 0s - loss: 0.0041 - val_loss: 0.0175 - 144ms/epoch - 14ms/step\n",
      "Epoch 4/67\n",
      "10/10 - 0s - loss: 0.0034 - val_loss: 0.0147 - 142ms/epoch - 14ms/step\n",
      "Epoch 5/67\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0142 - 138ms/epoch - 14ms/step\n",
      "Epoch 6/67\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0148 - 133ms/epoch - 13ms/step\n",
      "Epoch 7/67\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0137 - 133ms/epoch - 13ms/step\n",
      "Epoch 8/67\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0135 - 135ms/epoch - 14ms/step\n",
      "Epoch 9/67\n",
      "10/10 - 0s - loss: 0.0021 - val_loss: 0.0127 - 134ms/epoch - 13ms/step\n",
      "Epoch 10/67\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0123 - 136ms/epoch - 14ms/step\n",
      "Epoch 11/67\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0112 - 135ms/epoch - 14ms/step\n",
      "Epoch 12/67\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0105 - 137ms/epoch - 14ms/step\n",
      "Epoch 13/67\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0098 - 134ms/epoch - 13ms/step\n",
      "Epoch 14/67\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0087 - 136ms/epoch - 14ms/step\n",
      "Epoch 15/67\n",
      "10/10 - 0s - loss: 7.4937e-04 - val_loss: 0.0083 - 134ms/epoch - 13ms/step\n",
      "Epoch 16/67\n",
      "10/10 - 0s - loss: 5.8337e-04 - val_loss: 0.0083 - 135ms/epoch - 13ms/step\n",
      "Epoch 17/67\n",
      "10/10 - 0s - loss: 5.3126e-04 - val_loss: 0.0085 - 159ms/epoch - 16ms/step\n",
      "Epoch 18/67\n",
      "10/10 - 0s - loss: 5.1370e-04 - val_loss: 0.0086 - 133ms/epoch - 13ms/step\n",
      "Epoch 19/67\n",
      "10/10 - 0s - loss: 4.6741e-04 - val_loss: 0.0086 - 136ms/epoch - 14ms/step\n",
      "Epoch 20/67\n",
      "10/10 - 0s - loss: 4.4368e-04 - val_loss: 0.0086 - 134ms/epoch - 13ms/step\n",
      "Epoch 21/67\n",
      "10/10 - 0s - loss: 5.3538e-04 - val_loss: 0.0085 - 143ms/epoch - 14ms/step\n",
      "Epoch 22/67\n",
      "10/10 - 0s - loss: 4.4265e-04 - val_loss: 0.0085 - 135ms/epoch - 13ms/step\n",
      "Epoch 23/67\n",
      "10/10 - 0s - loss: 3.9009e-04 - val_loss: 0.0086 - 133ms/epoch - 13ms/step\n",
      "Epoch 24/67\n",
      "10/10 - 0s - loss: 4.5229e-04 - val_loss: 0.0085 - 134ms/epoch - 13ms/step\n",
      "Epoch 25/67\n",
      "10/10 - 0s - loss: 4.1826e-04 - val_loss: 0.0084 - 135ms/epoch - 14ms/step\n",
      "Epoch 26/67\n",
      "10/10 - 0s - loss: 4.1953e-04 - val_loss: 0.0084 - 134ms/epoch - 13ms/step\n",
      "Epoch 27/67\n",
      "10/10 - 0s - loss: 4.0479e-04 - val_loss: 0.0084 - 139ms/epoch - 14ms/step\n",
      "Epoch 28/67\n",
      "10/10 - 0s - loss: 3.8133e-04 - val_loss: 0.0086 - 144ms/epoch - 14ms/step\n",
      "Epoch 29/67\n",
      "10/10 - 0s - loss: 4.2002e-04 - val_loss: 0.0086 - 150ms/epoch - 15ms/step\n",
      "Epoch 30/67\n",
      "10/10 - 0s - loss: 3.7158e-04 - val_loss: 0.0085 - 153ms/epoch - 15ms/step\n",
      "Epoch 31/67\n",
      "10/10 - 0s - loss: 3.7800e-04 - val_loss: 0.0085 - 150ms/epoch - 15ms/step\n",
      "Epoch 32/67\n",
      "10/10 - 0s - loss: 3.5571e-04 - val_loss: 0.0084 - 150ms/epoch - 15ms/step\n",
      "Epoch 33/67\n",
      "10/10 - 0s - loss: 3.6959e-04 - val_loss: 0.0084 - 151ms/epoch - 15ms/step\n",
      "Epoch 34/67\n",
      "10/10 - 0s - loss: 3.7833e-04 - val_loss: 0.0085 - 150ms/epoch - 15ms/step\n",
      "Epoch 35/67\n",
      "10/10 - 0s - loss: 3.6717e-04 - val_loss: 0.0085 - 148ms/epoch - 15ms/step\n",
      "Epoch 36/67\n",
      "10/10 - 0s - loss: 3.4119e-04 - val_loss: 0.0085 - 150ms/epoch - 15ms/step\n",
      "Epoch 37/67\n",
      "10/10 - 0s - loss: 3.2953e-04 - val_loss: 0.0084 - 149ms/epoch - 15ms/step\n",
      "Epoch 38/67\n",
      "10/10 - 0s - loss: 3.2517e-04 - val_loss: 0.0084 - 150ms/epoch - 15ms/step\n",
      "Epoch 39/67\n",
      "10/10 - 0s - loss: 3.3845e-04 - val_loss: 0.0084 - 152ms/epoch - 15ms/step\n",
      "Epoch 40/67\n",
      "10/10 - 0s - loss: 3.0254e-04 - val_loss: 0.0083 - 148ms/epoch - 15ms/step\n",
      "Epoch 41/67\n",
      "10/10 - 0s - loss: 3.0324e-04 - val_loss: 0.0085 - 149ms/epoch - 15ms/step\n",
      "Epoch 42/67\n",
      "10/10 - 0s - loss: 2.9893e-04 - val_loss: 0.0086 - 151ms/epoch - 15ms/step\n",
      "Epoch 43/67\n",
      "10/10 - 0s - loss: 3.0081e-04 - val_loss: 0.0085 - 176ms/epoch - 18ms/step\n",
      "Epoch 44/67\n",
      "10/10 - 0s - loss: 2.6678e-04 - val_loss: 0.0085 - 147ms/epoch - 15ms/step\n",
      "Epoch 45/67\n",
      "10/10 - 0s - loss: 2.9733e-04 - val_loss: 0.0085 - 150ms/epoch - 15ms/step\n",
      "Epoch 46/67\n",
      "10/10 - 0s - loss: 2.8685e-04 - val_loss: 0.0086 - 149ms/epoch - 15ms/step\n",
      "Epoch 47/67\n",
      "10/10 - 0s - loss: 2.8525e-04 - val_loss: 0.0086 - 148ms/epoch - 15ms/step\n",
      "Epoch 48/67\n",
      "10/10 - 0s - loss: 2.7823e-04 - val_loss: 0.0085 - 146ms/epoch - 15ms/step\n",
      "Epoch 49/67\n",
      "10/10 - 0s - loss: 2.8825e-04 - val_loss: 0.0085 - 148ms/epoch - 15ms/step\n",
      "Epoch 50/67\n",
      "10/10 - 0s - loss: 2.6673e-04 - val_loss: 0.0084 - 147ms/epoch - 15ms/step\n",
      "Epoch 51/67\n",
      "10/10 - 0s - loss: 2.8388e-04 - val_loss: 0.0084 - 148ms/epoch - 15ms/step\n",
      "Epoch 52/67\n",
      "10/10 - 0s - loss: 2.7305e-04 - val_loss: 0.0085 - 149ms/epoch - 15ms/step\n",
      "Epoch 53/67\n",
      "10/10 - 0s - loss: 2.9673e-04 - val_loss: 0.0085 - 148ms/epoch - 15ms/step\n",
      "Epoch 54/67\n",
      "10/10 - 0s - loss: 3.0329e-04 - val_loss: 0.0087 - 147ms/epoch - 15ms/step\n",
      "Epoch 55/67\n",
      "10/10 - 0s - loss: 3.1617e-04 - val_loss: 0.0085 - 150ms/epoch - 15ms/step\n",
      "Epoch 56/67\n",
      "10/10 - 0s - loss: 2.7897e-04 - val_loss: 0.0086 - 148ms/epoch - 15ms/step\n",
      "Epoch 57/67\n",
      "10/10 - 0s - loss: 2.6359e-04 - val_loss: 0.0086 - 149ms/epoch - 15ms/step\n",
      "Epoch 58/67\n",
      "10/10 - 0s - loss: 2.5884e-04 - val_loss: 0.0085 - 148ms/epoch - 15ms/step\n",
      "Epoch 59/67\n",
      "10/10 - 0s - loss: 2.4595e-04 - val_loss: 0.0085 - 146ms/epoch - 15ms/step\n",
      "Epoch 60/67\n",
      "10/10 - 0s - loss: 2.5281e-04 - val_loss: 0.0085 - 176ms/epoch - 18ms/step\n",
      "Epoch 61/67\n",
      "10/10 - 0s - loss: 2.5741e-04 - val_loss: 0.0085 - 148ms/epoch - 15ms/step\n",
      "Epoch 62/67\n",
      "10/10 - 0s - loss: 2.3310e-04 - val_loss: 0.0085 - 155ms/epoch - 15ms/step\n",
      "Epoch 63/67\n",
      "10/10 - 0s - loss: 2.2498e-04 - val_loss: 0.0086 - 149ms/epoch - 15ms/step\n",
      "Epoch 64/67\n",
      "10/10 - 0s - loss: 2.3311e-04 - val_loss: 0.0085 - 149ms/epoch - 15ms/step\n",
      "Epoch 65/67\n",
      "10/10 - 0s - loss: 2.2981e-04 - val_loss: 0.0085 - 149ms/epoch - 15ms/step\n",
      "Epoch 66/67\n",
      "10/10 - 0s - loss: 2.3620e-04 - val_loss: 0.0087 - 148ms/epoch - 15ms/step\n",
      "Epoch 67/67\n",
      "10/10 - 0s - loss: 2.3649e-04 - val_loss: 0.0086 - 145ms/epoch - 15ms/step\n",
      "9/9 [==============================] - 1s 3ms/step\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-166.6   \u001b[0m | \u001b[0m67.74    \u001b[0m | \u001b[0m3.56     \u001b[0m | \u001b[0m0.001442 \u001b[0m | \u001b[0m121.4    \u001b[0m |\n",
      "Model: \"sequential_130\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_470 (LSTM)             (None, 1, 100)            42400     \n",
      "                                                                 \n",
      " dropout_340 (Dropout)       (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_471 (LSTM)             (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " dropout_341 (Dropout)       (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_472 (LSTM)             (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 203,301\n",
      "Trainable params: 203,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/128\n",
      "10/10 - 6s - loss: 0.0334 - val_loss: 0.0128 - 6s/epoch - 608ms/step\n",
      "Epoch 2/128\n",
      "10/10 - 0s - loss: 0.0060 - val_loss: 0.0156 - 99ms/epoch - 10ms/step\n",
      "Epoch 3/128\n",
      "10/10 - 0s - loss: 0.0038 - val_loss: 0.0141 - 102ms/epoch - 10ms/step\n",
      "Epoch 4/128\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0130 - 102ms/epoch - 10ms/step\n",
      "Epoch 5/128\n",
      "10/10 - 0s - loss: 0.0021 - val_loss: 0.0136 - 130ms/epoch - 13ms/step\n",
      "Epoch 6/128\n",
      "10/10 - 0s - loss: 0.0020 - val_loss: 0.0124 - 103ms/epoch - 10ms/step\n",
      "Epoch 7/128\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0122 - 110ms/epoch - 11ms/step\n",
      "Epoch 8/128\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0112 - 104ms/epoch - 10ms/step\n",
      "Epoch 9/128\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0105 - 102ms/epoch - 10ms/step\n",
      "Epoch 10/128\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0099 - 102ms/epoch - 10ms/step\n",
      "Epoch 11/128\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0090 - 105ms/epoch - 10ms/step\n",
      "Epoch 12/128\n",
      "10/10 - 0s - loss: 7.8025e-04 - val_loss: 0.0085 - 102ms/epoch - 10ms/step\n",
      "Epoch 13/128\n",
      "10/10 - 0s - loss: 5.9078e-04 - val_loss: 0.0084 - 99ms/epoch - 10ms/step\n",
      "Epoch 14/128\n",
      "10/10 - 0s - loss: 5.5382e-04 - val_loss: 0.0086 - 100ms/epoch - 10ms/step\n",
      "Epoch 15/128\n",
      "10/10 - 0s - loss: 4.9274e-04 - val_loss: 0.0088 - 100ms/epoch - 10ms/step\n",
      "Epoch 16/128\n",
      "10/10 - 0s - loss: 5.0612e-04 - val_loss: 0.0089 - 103ms/epoch - 10ms/step\n",
      "Epoch 17/128\n",
      "10/10 - 0s - loss: 4.6895e-04 - val_loss: 0.0087 - 103ms/epoch - 10ms/step\n",
      "Epoch 18/128\n",
      "10/10 - 0s - loss: 4.3457e-04 - val_loss: 0.0087 - 104ms/epoch - 10ms/step\n",
      "Epoch 19/128\n",
      "10/10 - 0s - loss: 4.4107e-04 - val_loss: 0.0087 - 101ms/epoch - 10ms/step\n",
      "Epoch 20/128\n",
      "10/10 - 0s - loss: 4.4509e-04 - val_loss: 0.0087 - 113ms/epoch - 11ms/step\n",
      "Epoch 21/128\n",
      "10/10 - 0s - loss: 4.0042e-04 - val_loss: 0.0087 - 107ms/epoch - 11ms/step\n",
      "Epoch 22/128\n",
      "10/10 - 0s - loss: 4.0334e-04 - val_loss: 0.0087 - 105ms/epoch - 11ms/step\n",
      "Epoch 23/128\n",
      "10/10 - 0s - loss: 4.0823e-04 - val_loss: 0.0086 - 111ms/epoch - 11ms/step\n",
      "Epoch 24/128\n",
      "10/10 - 0s - loss: 3.8840e-04 - val_loss: 0.0086 - 116ms/epoch - 12ms/step\n",
      "Epoch 25/128\n",
      "10/10 - 0s - loss: 3.3698e-04 - val_loss: 0.0086 - 110ms/epoch - 11ms/step\n",
      "Epoch 26/128\n",
      "10/10 - 0s - loss: 3.1289e-04 - val_loss: 0.0086 - 125ms/epoch - 13ms/step\n",
      "Epoch 27/128\n",
      "10/10 - 0s - loss: 3.0376e-04 - val_loss: 0.0086 - 117ms/epoch - 12ms/step\n",
      "Epoch 28/128\n",
      "10/10 - 0s - loss: 3.1467e-04 - val_loss: 0.0087 - 101ms/epoch - 10ms/step\n",
      "Epoch 29/128\n",
      "10/10 - 0s - loss: 3.5090e-04 - val_loss: 0.0086 - 102ms/epoch - 10ms/step\n",
      "Epoch 30/128\n",
      "10/10 - 0s - loss: 3.0834e-04 - val_loss: 0.0085 - 101ms/epoch - 10ms/step\n",
      "Epoch 31/128\n",
      "10/10 - 0s - loss: 3.2508e-04 - val_loss: 0.0086 - 100ms/epoch - 10ms/step\n",
      "Epoch 32/128\n",
      "10/10 - 0s - loss: 3.3446e-04 - val_loss: 0.0086 - 100ms/epoch - 10ms/step\n",
      "Epoch 33/128\n",
      "10/10 - 0s - loss: 3.3525e-04 - val_loss: 0.0086 - 104ms/epoch - 10ms/step\n",
      "Epoch 34/128\n",
      "10/10 - 0s - loss: 3.1312e-04 - val_loss: 0.0086 - 102ms/epoch - 10ms/step\n",
      "Epoch 35/128\n",
      "10/10 - 0s - loss: 2.8502e-04 - val_loss: 0.0087 - 101ms/epoch - 10ms/step\n",
      "Epoch 36/128\n",
      "10/10 - 0s - loss: 2.9976e-04 - val_loss: 0.0087 - 104ms/epoch - 10ms/step\n",
      "Epoch 37/128\n",
      "10/10 - 0s - loss: 2.5596e-04 - val_loss: 0.0087 - 101ms/epoch - 10ms/step\n",
      "Epoch 38/128\n",
      "10/10 - 0s - loss: 2.7435e-04 - val_loss: 0.0087 - 100ms/epoch - 10ms/step\n",
      "Epoch 39/128\n",
      "10/10 - 0s - loss: 2.4608e-04 - val_loss: 0.0087 - 101ms/epoch - 10ms/step\n",
      "Epoch 40/128\n",
      "10/10 - 0s - loss: 2.5055e-04 - val_loss: 0.0087 - 101ms/epoch - 10ms/step\n",
      "Epoch 41/128\n",
      "10/10 - 0s - loss: 3.1577e-04 - val_loss: 0.0089 - 100ms/epoch - 10ms/step\n",
      "Epoch 42/128\n",
      "10/10 - 0s - loss: 2.9634e-04 - val_loss: 0.0086 - 101ms/epoch - 10ms/step\n",
      "Epoch 43/128\n",
      "10/10 - 0s - loss: 2.5928e-04 - val_loss: 0.0086 - 99ms/epoch - 10ms/step\n",
      "Epoch 44/128\n",
      "10/10 - 0s - loss: 2.3442e-04 - val_loss: 0.0087 - 105ms/epoch - 11ms/step\n",
      "Epoch 45/128\n",
      "10/10 - 0s - loss: 2.5642e-04 - val_loss: 0.0086 - 104ms/epoch - 10ms/step\n",
      "Epoch 46/128\n",
      "10/10 - 0s - loss: 2.2589e-04 - val_loss: 0.0086 - 100ms/epoch - 10ms/step\n",
      "Epoch 47/128\n",
      "10/10 - 0s - loss: 2.2882e-04 - val_loss: 0.0087 - 101ms/epoch - 10ms/step\n",
      "Epoch 48/128\n",
      "10/10 - 0s - loss: 2.3275e-04 - val_loss: 0.0087 - 100ms/epoch - 10ms/step\n",
      "Epoch 49/128\n",
      "10/10 - 0s - loss: 2.3828e-04 - val_loss: 0.0087 - 106ms/epoch - 11ms/step\n",
      "Epoch 50/128\n",
      "10/10 - 0s - loss: 2.2352e-04 - val_loss: 0.0087 - 115ms/epoch - 11ms/step\n",
      "Epoch 51/128\n",
      "10/10 - 0s - loss: 2.2261e-04 - val_loss: 0.0087 - 140ms/epoch - 14ms/step\n",
      "Epoch 52/128\n",
      "10/10 - 0s - loss: 2.3068e-04 - val_loss: 0.0088 - 109ms/epoch - 11ms/step\n",
      "Epoch 53/128\n",
      "10/10 - 0s - loss: 2.1694e-04 - val_loss: 0.0088 - 115ms/epoch - 12ms/step\n",
      "Epoch 54/128\n",
      "10/10 - 0s - loss: 2.2865e-04 - val_loss: 0.0087 - 114ms/epoch - 11ms/step\n",
      "Epoch 55/128\n",
      "10/10 - 0s - loss: 2.5512e-04 - val_loss: 0.0087 - 112ms/epoch - 11ms/step\n",
      "Epoch 56/128\n",
      "10/10 - 0s - loss: 2.3183e-04 - val_loss: 0.0087 - 109ms/epoch - 11ms/step\n",
      "Epoch 57/128\n",
      "10/10 - 0s - loss: 2.0709e-04 - val_loss: 0.0088 - 119ms/epoch - 12ms/step\n",
      "Epoch 58/128\n",
      "10/10 - 0s - loss: 2.1664e-04 - val_loss: 0.0088 - 120ms/epoch - 12ms/step\n",
      "Epoch 59/128\n",
      "10/10 - 0s - loss: 2.0808e-04 - val_loss: 0.0088 - 116ms/epoch - 12ms/step\n",
      "Epoch 60/128\n",
      "10/10 - 0s - loss: 2.0177e-04 - val_loss: 0.0088 - 107ms/epoch - 11ms/step\n",
      "Epoch 61/128\n",
      "10/10 - 0s - loss: 2.1003e-04 - val_loss: 0.0089 - 108ms/epoch - 11ms/step\n",
      "Epoch 62/128\n",
      "10/10 - 0s - loss: 2.2649e-04 - val_loss: 0.0089 - 101ms/epoch - 10ms/step\n",
      "Epoch 63/128\n",
      "10/10 - 0s - loss: 2.2980e-04 - val_loss: 0.0087 - 101ms/epoch - 10ms/step\n",
      "Epoch 64/128\n",
      "10/10 - 0s - loss: 2.3548e-04 - val_loss: 0.0090 - 100ms/epoch - 10ms/step\n",
      "Epoch 65/128\n",
      "10/10 - 0s - loss: 2.2162e-04 - val_loss: 0.0089 - 104ms/epoch - 10ms/step\n",
      "Epoch 66/128\n",
      "10/10 - 0s - loss: 1.9403e-04 - val_loss: 0.0090 - 136ms/epoch - 14ms/step\n",
      "Epoch 67/128\n",
      "10/10 - 0s - loss: 2.2902e-04 - val_loss: 0.0088 - 106ms/epoch - 11ms/step\n",
      "Epoch 68/128\n",
      "10/10 - 0s - loss: 2.0045e-04 - val_loss: 0.0088 - 101ms/epoch - 10ms/step\n",
      "Epoch 69/128\n",
      "10/10 - 0s - loss: 2.0096e-04 - val_loss: 0.0091 - 103ms/epoch - 10ms/step\n",
      "Epoch 70/128\n",
      "10/10 - 0s - loss: 2.1188e-04 - val_loss: 0.0089 - 108ms/epoch - 11ms/step\n",
      "Epoch 71/128\n",
      "10/10 - 0s - loss: 2.0545e-04 - val_loss: 0.0089 - 114ms/epoch - 11ms/step\n",
      "Epoch 72/128\n",
      "10/10 - 0s - loss: 1.9790e-04 - val_loss: 0.0090 - 111ms/epoch - 11ms/step\n",
      "Epoch 73/128\n",
      "10/10 - 0s - loss: 2.1007e-04 - val_loss: 0.0090 - 105ms/epoch - 11ms/step\n",
      "Epoch 74/128\n",
      "10/10 - 0s - loss: 2.1283e-04 - val_loss: 0.0089 - 100ms/epoch - 10ms/step\n",
      "Epoch 75/128\n",
      "10/10 - 0s - loss: 1.9889e-04 - val_loss: 0.0090 - 105ms/epoch - 11ms/step\n",
      "Epoch 76/128\n",
      "10/10 - 0s - loss: 1.9619e-04 - val_loss: 0.0089 - 104ms/epoch - 10ms/step\n",
      "Epoch 77/128\n",
      "10/10 - 0s - loss: 1.9953e-04 - val_loss: 0.0091 - 101ms/epoch - 10ms/step\n",
      "Epoch 78/128\n",
      "10/10 - 0s - loss: 1.8590e-04 - val_loss: 0.0091 - 99ms/epoch - 10ms/step\n",
      "Epoch 79/128\n",
      "10/10 - 0s - loss: 1.9858e-04 - val_loss: 0.0089 - 128ms/epoch - 13ms/step\n",
      "Epoch 80/128\n",
      "10/10 - 0s - loss: 1.9660e-04 - val_loss: 0.0090 - 106ms/epoch - 11ms/step\n",
      "Epoch 81/128\n",
      "10/10 - 0s - loss: 1.9969e-04 - val_loss: 0.0090 - 100ms/epoch - 10ms/step\n",
      "Epoch 82/128\n",
      "10/10 - 0s - loss: 1.9274e-04 - val_loss: 0.0090 - 101ms/epoch - 10ms/step\n",
      "Epoch 83/128\n",
      "10/10 - 0s - loss: 2.1439e-04 - val_loss: 0.0090 - 99ms/epoch - 10ms/step\n",
      "Epoch 84/128\n",
      "10/10 - 0s - loss: 2.0296e-04 - val_loss: 0.0091 - 101ms/epoch - 10ms/step\n",
      "Epoch 85/128\n",
      "10/10 - 0s - loss: 2.0475e-04 - val_loss: 0.0090 - 101ms/epoch - 10ms/step\n",
      "Epoch 86/128\n",
      "10/10 - 0s - loss: 1.9441e-04 - val_loss: 0.0089 - 100ms/epoch - 10ms/step\n",
      "Epoch 87/128\n",
      "10/10 - 0s - loss: 1.9693e-04 - val_loss: 0.0094 - 100ms/epoch - 10ms/step\n",
      "Epoch 88/128\n",
      "10/10 - 0s - loss: 2.1166e-04 - val_loss: 0.0090 - 100ms/epoch - 10ms/step\n",
      "Epoch 89/128\n",
      "10/10 - 0s - loss: 1.9734e-04 - val_loss: 0.0092 - 118ms/epoch - 12ms/step\n",
      "Epoch 90/128\n",
      "10/10 - 0s - loss: 2.3164e-04 - val_loss: 0.0091 - 110ms/epoch - 11ms/step\n",
      "Epoch 91/128\n",
      "10/10 - 0s - loss: 2.1962e-04 - val_loss: 0.0092 - 114ms/epoch - 11ms/step\n",
      "Epoch 92/128\n",
      "10/10 - 0s - loss: 2.3456e-04 - val_loss: 0.0090 - 111ms/epoch - 11ms/step\n",
      "Epoch 93/128\n",
      "10/10 - 0s - loss: 2.2894e-04 - val_loss: 0.0090 - 113ms/epoch - 11ms/step\n",
      "Epoch 94/128\n",
      "10/10 - 0s - loss: 2.2080e-04 - val_loss: 0.0091 - 112ms/epoch - 11ms/step\n",
      "Epoch 95/128\n",
      "10/10 - 0s - loss: 2.0473e-04 - val_loss: 0.0091 - 140ms/epoch - 14ms/step\n",
      "Epoch 96/128\n",
      "10/10 - 0s - loss: 1.8976e-04 - val_loss: 0.0091 - 118ms/epoch - 12ms/step\n",
      "Epoch 97/128\n",
      "10/10 - 0s - loss: 2.1697e-04 - val_loss: 0.0091 - 107ms/epoch - 11ms/step\n",
      "Epoch 98/128\n",
      "10/10 - 0s - loss: 2.2822e-04 - val_loss: 0.0089 - 102ms/epoch - 10ms/step\n",
      "Epoch 99/128\n",
      "10/10 - 0s - loss: 2.1130e-04 - val_loss: 0.0090 - 99ms/epoch - 10ms/step\n",
      "Epoch 100/128\n",
      "10/10 - 0s - loss: 2.0245e-04 - val_loss: 0.0091 - 112ms/epoch - 11ms/step\n",
      "Epoch 101/128\n",
      "10/10 - 0s - loss: 1.9094e-04 - val_loss: 0.0090 - 113ms/epoch - 11ms/step\n",
      "Epoch 102/128\n",
      "10/10 - 0s - loss: 2.0312e-04 - val_loss: 0.0093 - 103ms/epoch - 10ms/step\n",
      "Epoch 103/128\n",
      "10/10 - 0s - loss: 2.1281e-04 - val_loss: 0.0091 - 106ms/epoch - 11ms/step\n",
      "Epoch 104/128\n",
      "10/10 - 0s - loss: 1.9742e-04 - val_loss: 0.0090 - 105ms/epoch - 10ms/step\n",
      "Epoch 105/128\n",
      "10/10 - 0s - loss: 2.1109e-04 - val_loss: 0.0090 - 104ms/epoch - 10ms/step\n",
      "Epoch 106/128\n",
      "10/10 - 0s - loss: 1.8570e-04 - val_loss: 0.0092 - 110ms/epoch - 11ms/step\n",
      "Epoch 107/128\n",
      "10/10 - 0s - loss: 1.8650e-04 - val_loss: 0.0091 - 109ms/epoch - 11ms/step\n",
      "Epoch 108/128\n",
      "10/10 - 0s - loss: 1.9128e-04 - val_loss: 0.0091 - 110ms/epoch - 11ms/step\n",
      "Epoch 109/128\n",
      "10/10 - 0s - loss: 1.9126e-04 - val_loss: 0.0092 - 110ms/epoch - 11ms/step\n",
      "Epoch 110/128\n",
      "10/10 - 0s - loss: 1.9347e-04 - val_loss: 0.0090 - 100ms/epoch - 10ms/step\n",
      "Epoch 111/128\n",
      "10/10 - 0s - loss: 2.0574e-04 - val_loss: 0.0091 - 106ms/epoch - 11ms/step\n",
      "Epoch 112/128\n",
      "10/10 - 0s - loss: 1.8477e-04 - val_loss: 0.0092 - 124ms/epoch - 12ms/step\n",
      "Epoch 113/128\n",
      "10/10 - 0s - loss: 2.0264e-04 - val_loss: 0.0090 - 125ms/epoch - 12ms/step\n",
      "Epoch 114/128\n",
      "10/10 - 0s - loss: 2.0145e-04 - val_loss: 0.0091 - 106ms/epoch - 11ms/step\n",
      "Epoch 115/128\n",
      "10/10 - 0s - loss: 1.8860e-04 - val_loss: 0.0092 - 103ms/epoch - 10ms/step\n",
      "Epoch 116/128\n",
      "10/10 - 0s - loss: 1.9653e-04 - val_loss: 0.0092 - 104ms/epoch - 10ms/step\n",
      "Epoch 117/128\n",
      "10/10 - 0s - loss: 2.0516e-04 - val_loss: 0.0091 - 106ms/epoch - 11ms/step\n",
      "Epoch 118/128\n",
      "10/10 - 0s - loss: 1.8436e-04 - val_loss: 0.0092 - 104ms/epoch - 10ms/step\n",
      "Epoch 119/128\n",
      "10/10 - 0s - loss: 1.9308e-04 - val_loss: 0.0092 - 103ms/epoch - 10ms/step\n",
      "Epoch 120/128\n",
      "10/10 - 0s - loss: 1.9127e-04 - val_loss: 0.0092 - 108ms/epoch - 11ms/step\n",
      "Epoch 121/128\n",
      "10/10 - 0s - loss: 1.9054e-04 - val_loss: 0.0094 - 105ms/epoch - 10ms/step\n",
      "Epoch 122/128\n",
      "10/10 - 0s - loss: 1.8384e-04 - val_loss: 0.0092 - 109ms/epoch - 11ms/step\n",
      "Epoch 123/128\n",
      "10/10 - 0s - loss: 1.9722e-04 - val_loss: 0.0094 - 105ms/epoch - 11ms/step\n",
      "Epoch 124/128\n",
      "10/10 - 0s - loss: 2.1459e-04 - val_loss: 0.0091 - 103ms/epoch - 10ms/step\n",
      "Epoch 125/128\n",
      "10/10 - 0s - loss: 2.0330e-04 - val_loss: 0.0093 - 110ms/epoch - 11ms/step\n",
      "Epoch 126/128\n",
      "10/10 - 0s - loss: 1.7929e-04 - val_loss: 0.0093 - 109ms/epoch - 11ms/step\n",
      "Epoch 127/128\n",
      "10/10 - 0s - loss: 1.9496e-04 - val_loss: 0.0094 - 108ms/epoch - 11ms/step\n",
      "Epoch 128/128\n",
      "10/10 - 0s - loss: 1.8820e-04 - val_loss: 0.0091 - 123ms/epoch - 12ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-170.8   \u001b[0m | \u001b[0m128.3    \u001b[0m | \u001b[0m2.659    \u001b[0m | \u001b[0m0.002653 \u001b[0m | \u001b[0m100.9    \u001b[0m |\n",
      "Model: \"sequential_131\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_473 (LSTM)             (None, 1, 82)             28864     \n",
      "                                                                 \n",
      " dropout_342 (Dropout)       (None, 1, 82)             0         \n",
      "                                                                 \n",
      " lstm_474 (LSTM)             (None, 1, 82)             54120     \n",
      "                                                                 \n",
      " dropout_343 (Dropout)       (None, 1, 82)             0         \n",
      "                                                                 \n",
      " lstm_475 (LSTM)             (None, 1, 82)             54120     \n",
      "                                                                 \n",
      " dropout_344 (Dropout)       (None, 1, 82)             0         \n",
      "                                                                 \n",
      " lstm_476 (LSTM)             (None, 82)                54120     \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 1)                 83        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 191,307\n",
      "Trainable params: 191,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/118\n",
      "10/10 - 10s - loss: 0.0687 - val_loss: 0.0873 - 10s/epoch - 990ms/step\n",
      "Epoch 2/118\n",
      "10/10 - 0s - loss: 0.0643 - val_loss: 0.0824 - 129ms/epoch - 13ms/step\n",
      "Epoch 3/118\n",
      "10/10 - 0s - loss: 0.0596 - val_loss: 0.0771 - 132ms/epoch - 13ms/step\n",
      "Epoch 4/118\n",
      "10/10 - 0s - loss: 0.0543 - val_loss: 0.0711 - 131ms/epoch - 13ms/step\n",
      "Epoch 5/118\n",
      "10/10 - 0s - loss: 0.0484 - val_loss: 0.0640 - 127ms/epoch - 13ms/step\n",
      "Epoch 6/118\n",
      "10/10 - 0s - loss: 0.0414 - val_loss: 0.0556 - 124ms/epoch - 12ms/step\n",
      "Epoch 7/118\n",
      "10/10 - 0s - loss: 0.0333 - val_loss: 0.0457 - 123ms/epoch - 12ms/step\n",
      "Epoch 8/118\n",
      "10/10 - 0s - loss: 0.0242 - val_loss: 0.0346 - 125ms/epoch - 12ms/step\n",
      "Epoch 9/118\n",
      "10/10 - 0s - loss: 0.0147 - val_loss: 0.0236 - 124ms/epoch - 12ms/step\n",
      "Epoch 10/118\n",
      "10/10 - 0s - loss: 0.0065 - val_loss: 0.0153 - 122ms/epoch - 12ms/step\n",
      "Epoch 11/118\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0121 - 122ms/epoch - 12ms/step\n",
      "Epoch 12/118\n",
      "10/10 - 0s - loss: 0.0021 - val_loss: 0.0118 - 123ms/epoch - 12ms/step\n",
      "Epoch 13/118\n",
      "10/10 - 0s - loss: 0.0021 - val_loss: 0.0119 - 140ms/epoch - 14ms/step\n",
      "Epoch 14/118\n",
      "10/10 - 0s - loss: 0.0021 - val_loss: 0.0122 - 129ms/epoch - 13ms/step\n",
      "Epoch 15/118\n",
      "10/10 - 0s - loss: 0.0020 - val_loss: 0.0123 - 126ms/epoch - 13ms/step\n",
      "Epoch 16/118\n",
      "10/10 - 0s - loss: 0.0020 - val_loss: 0.0120 - 133ms/epoch - 13ms/step\n",
      "Epoch 17/118\n",
      "10/10 - 0s - loss: 0.0020 - val_loss: 0.0119 - 134ms/epoch - 13ms/step\n",
      "Epoch 18/118\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0118 - 140ms/epoch - 14ms/step\n",
      "Epoch 19/118\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0118 - 146ms/epoch - 15ms/step\n",
      "Epoch 20/118\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0117 - 122ms/epoch - 12ms/step\n",
      "Epoch 21/118\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0117 - 123ms/epoch - 12ms/step\n",
      "Epoch 22/118\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0116 - 126ms/epoch - 13ms/step\n",
      "Epoch 23/118\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0115 - 131ms/epoch - 13ms/step\n",
      "Epoch 24/118\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0114 - 120ms/epoch - 12ms/step\n",
      "Epoch 25/118\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0113 - 121ms/epoch - 12ms/step\n",
      "Epoch 26/118\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0112 - 113ms/epoch - 11ms/step\n",
      "Epoch 27/118\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0112 - 122ms/epoch - 12ms/step\n",
      "Epoch 28/118\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0112 - 117ms/epoch - 12ms/step\n",
      "Epoch 29/118\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0111 - 115ms/epoch - 11ms/step\n",
      "Epoch 30/118\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0109 - 135ms/epoch - 14ms/step\n",
      "Epoch 31/118\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0108 - 115ms/epoch - 11ms/step\n",
      "Epoch 32/118\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0108 - 111ms/epoch - 11ms/step\n",
      "Epoch 33/118\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0107 - 115ms/epoch - 11ms/step\n",
      "Epoch 34/118\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0105 - 111ms/epoch - 11ms/step\n",
      "Epoch 35/118\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0104 - 116ms/epoch - 12ms/step\n",
      "Epoch 36/118\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0105 - 144ms/epoch - 14ms/step\n",
      "Epoch 37/118\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0104 - 115ms/epoch - 12ms/step\n",
      "Epoch 38/118\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0102 - 110ms/epoch - 11ms/step\n",
      "Epoch 39/118\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0101 - 113ms/epoch - 11ms/step\n",
      "Epoch 40/118\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0100 - 112ms/epoch - 11ms/step\n",
      "Epoch 41/118\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0099 - 110ms/epoch - 11ms/step\n",
      "Epoch 42/118\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0098 - 114ms/epoch - 11ms/step\n",
      "Epoch 43/118\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0097 - 115ms/epoch - 11ms/step\n",
      "Epoch 44/118\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0096 - 112ms/epoch - 11ms/step\n",
      "Epoch 45/118\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0095 - 112ms/epoch - 11ms/step\n",
      "Epoch 46/118\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0095 - 113ms/epoch - 11ms/step\n",
      "Epoch 47/118\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0093 - 111ms/epoch - 11ms/step\n",
      "Epoch 48/118\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0092 - 116ms/epoch - 12ms/step\n",
      "Epoch 49/118\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0093 - 115ms/epoch - 12ms/step\n",
      "Epoch 50/118\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0091 - 115ms/epoch - 11ms/step\n",
      "Epoch 51/118\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0090 - 113ms/epoch - 11ms/step\n",
      "Epoch 52/118\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0090 - 115ms/epoch - 12ms/step\n",
      "Epoch 53/118\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0089 - 121ms/epoch - 12ms/step\n",
      "Epoch 54/118\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0089 - 157ms/epoch - 16ms/step\n",
      "Epoch 55/118\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0088 - 123ms/epoch - 12ms/step\n",
      "Epoch 56/118\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0088 - 113ms/epoch - 11ms/step\n",
      "Epoch 57/118\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0087 - 111ms/epoch - 11ms/step\n",
      "Epoch 58/118\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0087 - 127ms/epoch - 13ms/step\n",
      "Epoch 59/118\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0086 - 116ms/epoch - 12ms/step\n",
      "Epoch 60/118\n",
      "10/10 - 0s - loss: 9.6795e-04 - val_loss: 0.0086 - 111ms/epoch - 11ms/step\n",
      "Epoch 61/118\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0085 - 113ms/epoch - 11ms/step\n",
      "Epoch 62/118\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0085 - 113ms/epoch - 11ms/step\n",
      "Epoch 63/118\n",
      "10/10 - 0s - loss: 9.6056e-04 - val_loss: 0.0085 - 113ms/epoch - 11ms/step\n",
      "Epoch 64/118\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0085 - 142ms/epoch - 14ms/step\n",
      "Epoch 65/118\n",
      "10/10 - 0s - loss: 9.5262e-04 - val_loss: 0.0085 - 110ms/epoch - 11ms/step\n",
      "Epoch 66/118\n",
      "10/10 - 0s - loss: 9.4920e-04 - val_loss: 0.0085 - 112ms/epoch - 11ms/step\n",
      "Epoch 67/118\n",
      "10/10 - 0s - loss: 9.4952e-04 - val_loss: 0.0085 - 112ms/epoch - 11ms/step\n",
      "Epoch 68/118\n",
      "10/10 - 0s - loss: 9.7167e-04 - val_loss: 0.0085 - 111ms/epoch - 11ms/step\n",
      "Epoch 69/118\n",
      "10/10 - 0s - loss: 9.6587e-04 - val_loss: 0.0085 - 111ms/epoch - 11ms/step\n",
      "Epoch 70/118\n",
      "10/10 - 0s - loss: 9.1593e-04 - val_loss: 0.0085 - 110ms/epoch - 11ms/step\n",
      "Epoch 71/118\n",
      "10/10 - 0s - loss: 9.1762e-04 - val_loss: 0.0085 - 112ms/epoch - 11ms/step\n",
      "Epoch 72/118\n",
      "10/10 - 0s - loss: 8.0173e-04 - val_loss: 0.0085 - 123ms/epoch - 12ms/step\n",
      "Epoch 73/118\n",
      "10/10 - 0s - loss: 7.9957e-04 - val_loss: 0.0085 - 115ms/epoch - 11ms/step\n",
      "Epoch 74/118\n",
      "10/10 - 0s - loss: 8.1346e-04 - val_loss: 0.0085 - 115ms/epoch - 12ms/step\n",
      "Epoch 75/118\n",
      "10/10 - 0s - loss: 8.6431e-04 - val_loss: 0.0085 - 118ms/epoch - 12ms/step\n",
      "Epoch 76/118\n",
      "10/10 - 0s - loss: 8.0676e-04 - val_loss: 0.0086 - 113ms/epoch - 11ms/step\n",
      "Epoch 77/118\n",
      "10/10 - 0s - loss: 8.2662e-04 - val_loss: 0.0086 - 112ms/epoch - 11ms/step\n",
      "Epoch 78/118\n",
      "10/10 - 0s - loss: 7.8244e-04 - val_loss: 0.0086 - 110ms/epoch - 11ms/step\n",
      "Epoch 79/118\n",
      "10/10 - 0s - loss: 7.8412e-04 - val_loss: 0.0086 - 110ms/epoch - 11ms/step\n",
      "Epoch 80/118\n",
      "10/10 - 0s - loss: 7.9253e-04 - val_loss: 0.0086 - 113ms/epoch - 11ms/step\n",
      "Epoch 81/118\n",
      "10/10 - 0s - loss: 8.3482e-04 - val_loss: 0.0087 - 126ms/epoch - 13ms/step\n",
      "Epoch 82/118\n",
      "10/10 - 0s - loss: 7.5219e-04 - val_loss: 0.0087 - 132ms/epoch - 13ms/step\n",
      "Epoch 83/118\n",
      "10/10 - 0s - loss: 7.8521e-04 - val_loss: 0.0088 - 112ms/epoch - 11ms/step\n",
      "Epoch 84/118\n",
      "10/10 - 0s - loss: 8.9330e-04 - val_loss: 0.0088 - 115ms/epoch - 12ms/step\n",
      "Epoch 85/118\n",
      "10/10 - 0s - loss: 7.2311e-04 - val_loss: 0.0088 - 110ms/epoch - 11ms/step\n",
      "Epoch 86/118\n",
      "10/10 - 0s - loss: 8.2203e-04 - val_loss: 0.0087 - 113ms/epoch - 11ms/step\n",
      "Epoch 87/118\n",
      "10/10 - 0s - loss: 7.2643e-04 - val_loss: 0.0088 - 112ms/epoch - 11ms/step\n",
      "Epoch 88/118\n",
      "10/10 - 0s - loss: 7.3749e-04 - val_loss: 0.0088 - 112ms/epoch - 11ms/step\n",
      "Epoch 89/118\n",
      "10/10 - 0s - loss: 7.1890e-04 - val_loss: 0.0088 - 119ms/epoch - 12ms/step\n",
      "Epoch 90/118\n",
      "10/10 - 0s - loss: 7.4221e-04 - val_loss: 0.0088 - 114ms/epoch - 11ms/step\n",
      "Epoch 91/118\n",
      "10/10 - 0s - loss: 7.0189e-04 - val_loss: 0.0088 - 118ms/epoch - 12ms/step\n",
      "Epoch 92/118\n",
      "10/10 - 0s - loss: 8.0882e-04 - val_loss: 0.0088 - 112ms/epoch - 11ms/step\n",
      "Epoch 93/118\n",
      "10/10 - 0s - loss: 7.2202e-04 - val_loss: 0.0089 - 112ms/epoch - 11ms/step\n",
      "Epoch 94/118\n",
      "10/10 - 0s - loss: 7.3020e-04 - val_loss: 0.0088 - 115ms/epoch - 12ms/step\n",
      "Epoch 95/118\n",
      "10/10 - 0s - loss: 6.7457e-04 - val_loss: 0.0089 - 112ms/epoch - 11ms/step\n",
      "Epoch 96/118\n",
      "10/10 - 0s - loss: 7.2411e-04 - val_loss: 0.0088 - 113ms/epoch - 11ms/step\n",
      "Epoch 97/118\n",
      "10/10 - 0s - loss: 7.3178e-04 - val_loss: 0.0088 - 117ms/epoch - 12ms/step\n",
      "Epoch 98/118\n",
      "10/10 - 0s - loss: 6.9384e-04 - val_loss: 0.0089 - 119ms/epoch - 12ms/step\n",
      "Epoch 99/118\n",
      "10/10 - 0s - loss: 6.8562e-04 - val_loss: 0.0088 - 117ms/epoch - 12ms/step\n",
      "Epoch 100/118\n",
      "10/10 - 0s - loss: 7.6745e-04 - val_loss: 0.0088 - 115ms/epoch - 11ms/step\n",
      "Epoch 101/118\n",
      "10/10 - 0s - loss: 7.4583e-04 - val_loss: 0.0088 - 125ms/epoch - 12ms/step\n",
      "Epoch 102/118\n",
      "10/10 - 0s - loss: 7.0786e-04 - val_loss: 0.0089 - 120ms/epoch - 12ms/step\n",
      "Epoch 103/118\n",
      "10/10 - 0s - loss: 7.2605e-04 - val_loss: 0.0088 - 124ms/epoch - 12ms/step\n",
      "Epoch 104/118\n",
      "10/10 - 0s - loss: 7.1074e-04 - val_loss: 0.0088 - 123ms/epoch - 12ms/step\n",
      "Epoch 105/118\n",
      "10/10 - 0s - loss: 7.0944e-04 - val_loss: 0.0088 - 114ms/epoch - 11ms/step\n",
      "Epoch 106/118\n",
      "10/10 - 0s - loss: 7.1406e-04 - val_loss: 0.0089 - 116ms/epoch - 12ms/step\n",
      "Epoch 107/118\n",
      "10/10 - 0s - loss: 7.0790e-04 - val_loss: 0.0088 - 145ms/epoch - 15ms/step\n",
      "Epoch 108/118\n",
      "10/10 - 0s - loss: 7.8505e-04 - val_loss: 0.0090 - 115ms/epoch - 12ms/step\n",
      "Epoch 109/118\n",
      "10/10 - 0s - loss: 7.1777e-04 - val_loss: 0.0089 - 112ms/epoch - 11ms/step\n",
      "Epoch 110/118\n",
      "10/10 - 0s - loss: 7.1276e-04 - val_loss: 0.0089 - 111ms/epoch - 11ms/step\n",
      "Epoch 111/118\n",
      "10/10 - 0s - loss: 6.4821e-04 - val_loss: 0.0089 - 110ms/epoch - 11ms/step\n",
      "Epoch 112/118\n",
      "10/10 - 0s - loss: 6.8901e-04 - val_loss: 0.0088 - 113ms/epoch - 11ms/step\n",
      "Epoch 113/118\n",
      "10/10 - 0s - loss: 6.0999e-04 - val_loss: 0.0089 - 109ms/epoch - 11ms/step\n",
      "Epoch 114/118\n",
      "10/10 - 0s - loss: 6.5057e-04 - val_loss: 0.0090 - 110ms/epoch - 11ms/step\n",
      "Epoch 115/118\n",
      "10/10 - 0s - loss: 6.6433e-04 - val_loss: 0.0089 - 115ms/epoch - 11ms/step\n",
      "Epoch 116/118\n",
      "10/10 - 0s - loss: 5.9904e-04 - val_loss: 0.0089 - 114ms/epoch - 11ms/step\n",
      "Epoch 117/118\n",
      "10/10 - 0s - loss: 6.2026e-04 - val_loss: 0.0089 - 112ms/epoch - 11ms/step\n",
      "Epoch 118/118\n",
      "10/10 - 0s - loss: 5.9892e-04 - val_loss: 0.0089 - 111ms/epoch - 11ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-168.6   \u001b[0m | \u001b[0m118.4    \u001b[0m | \u001b[0m3.274    \u001b[0m | \u001b[0m0.0001977\u001b[0m | \u001b[0m82.12    \u001b[0m |\n",
      "Model: \"sequential_132\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_477 (LSTM)             (None, 1, 89)             33820     \n",
      "                                                                 \n",
      " dropout_345 (Dropout)       (None, 1, 89)             0         \n",
      "                                                                 \n",
      " lstm_478 (LSTM)             (None, 1, 89)             63724     \n",
      "                                                                 \n",
      " dropout_346 (Dropout)       (None, 1, 89)             0         \n",
      "                                                                 \n",
      " lstm_479 (LSTM)             (None, 1, 89)             63724     \n",
      "                                                                 \n",
      " dropout_347 (Dropout)       (None, 1, 89)             0         \n",
      "                                                                 \n",
      " lstm_480 (LSTM)             (None, 89)                63724     \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 1)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225,082\n",
      "Trainable params: 225,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/141\n",
      "10/10 - 8s - loss: 0.0193 - val_loss: 0.0189 - 8s/epoch - 815ms/step\n",
      "Epoch 2/141\n",
      "10/10 - 0s - loss: 0.0034 - val_loss: 0.0167 - 122ms/epoch - 12ms/step\n",
      "Epoch 3/141\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0175 - 119ms/epoch - 12ms/step\n",
      "Epoch 4/141\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0170 - 122ms/epoch - 12ms/step\n",
      "Epoch 5/141\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0167 - 134ms/epoch - 13ms/step\n",
      "Epoch 6/141\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0168 - 124ms/epoch - 12ms/step\n",
      "Epoch 7/141\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0155 - 121ms/epoch - 12ms/step\n",
      "Epoch 8/141\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0117 - 120ms/epoch - 12ms/step\n",
      "Epoch 9/141\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0085 - 118ms/epoch - 12ms/step\n",
      "Epoch 10/141\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0088 - 133ms/epoch - 13ms/step\n",
      "Epoch 11/141\n",
      "10/10 - 0s - loss: 6.8044e-04 - val_loss: 0.0084 - 126ms/epoch - 13ms/step\n",
      "Epoch 12/141\n",
      "10/10 - 0s - loss: 4.5808e-04 - val_loss: 0.0083 - 126ms/epoch - 13ms/step\n",
      "Epoch 13/141\n",
      "10/10 - 0s - loss: 3.8346e-04 - val_loss: 0.0085 - 119ms/epoch - 12ms/step\n",
      "Epoch 14/141\n",
      "10/10 - 0s - loss: 4.3388e-04 - val_loss: 0.0082 - 135ms/epoch - 13ms/step\n",
      "Epoch 15/141\n",
      "10/10 - 0s - loss: 3.4204e-04 - val_loss: 0.0086 - 119ms/epoch - 12ms/step\n",
      "Epoch 16/141\n",
      "10/10 - 0s - loss: 3.3852e-04 - val_loss: 0.0081 - 117ms/epoch - 12ms/step\n",
      "Epoch 17/141\n",
      "10/10 - 0s - loss: 3.4820e-04 - val_loss: 0.0081 - 119ms/epoch - 12ms/step\n",
      "Epoch 18/141\n",
      "10/10 - 0s - loss: 3.2551e-04 - val_loss: 0.0083 - 117ms/epoch - 12ms/step\n",
      "Epoch 19/141\n",
      "10/10 - 0s - loss: 3.7394e-04 - val_loss: 0.0082 - 133ms/epoch - 13ms/step\n",
      "Epoch 20/141\n",
      "10/10 - 0s - loss: 3.5704e-04 - val_loss: 0.0081 - 136ms/epoch - 14ms/step\n",
      "Epoch 21/141\n",
      "10/10 - 0s - loss: 3.5263e-04 - val_loss: 0.0080 - 123ms/epoch - 12ms/step\n",
      "Epoch 22/141\n",
      "10/10 - 0s - loss: 3.3217e-04 - val_loss: 0.0080 - 120ms/epoch - 12ms/step\n",
      "Epoch 23/141\n",
      "10/10 - 0s - loss: 3.4380e-04 - val_loss: 0.0081 - 139ms/epoch - 14ms/step\n",
      "Epoch 24/141\n",
      "10/10 - 0s - loss: 2.8862e-04 - val_loss: 0.0080 - 124ms/epoch - 12ms/step\n",
      "Epoch 25/141\n",
      "10/10 - 0s - loss: 2.6768e-04 - val_loss: 0.0080 - 118ms/epoch - 12ms/step\n",
      "Epoch 26/141\n",
      "10/10 - 0s - loss: 2.8164e-04 - val_loss: 0.0079 - 114ms/epoch - 11ms/step\n",
      "Epoch 27/141\n",
      "10/10 - 0s - loss: 2.7431e-04 - val_loss: 0.0080 - 123ms/epoch - 12ms/step\n",
      "Epoch 28/141\n",
      "10/10 - 0s - loss: 2.8122e-04 - val_loss: 0.0080 - 118ms/epoch - 12ms/step\n",
      "Epoch 29/141\n",
      "10/10 - 0s - loss: 3.0872e-04 - val_loss: 0.0079 - 117ms/epoch - 12ms/step\n",
      "Epoch 30/141\n",
      "10/10 - 0s - loss: 2.9730e-04 - val_loss: 0.0080 - 120ms/epoch - 12ms/step\n",
      "Epoch 31/141\n",
      "10/10 - 0s - loss: 2.7878e-04 - val_loss: 0.0079 - 118ms/epoch - 12ms/step\n",
      "Epoch 32/141\n",
      "10/10 - 0s - loss: 2.6733e-04 - val_loss: 0.0079 - 113ms/epoch - 11ms/step\n",
      "Epoch 33/141\n",
      "10/10 - 0s - loss: 2.7352e-04 - val_loss: 0.0079 - 112ms/epoch - 11ms/step\n",
      "Epoch 34/141\n",
      "10/10 - 0s - loss: 2.5014e-04 - val_loss: 0.0081 - 117ms/epoch - 12ms/step\n",
      "Epoch 35/141\n",
      "10/10 - 0s - loss: 3.1933e-04 - val_loss: 0.0079 - 120ms/epoch - 12ms/step\n",
      "Epoch 36/141\n",
      "10/10 - 0s - loss: 3.0509e-04 - val_loss: 0.0079 - 119ms/epoch - 12ms/step\n",
      "Epoch 37/141\n",
      "10/10 - 0s - loss: 2.4959e-04 - val_loss: 0.0079 - 134ms/epoch - 13ms/step\n",
      "Epoch 38/141\n",
      "10/10 - 0s - loss: 2.7334e-04 - val_loss: 0.0079 - 121ms/epoch - 12ms/step\n",
      "Epoch 39/141\n",
      "10/10 - 0s - loss: 2.7031e-04 - val_loss: 0.0080 - 131ms/epoch - 13ms/step\n",
      "Epoch 40/141\n",
      "10/10 - 0s - loss: 2.8350e-04 - val_loss: 0.0080 - 133ms/epoch - 13ms/step\n",
      "Epoch 41/141\n",
      "10/10 - 0s - loss: 2.8699e-04 - val_loss: 0.0082 - 136ms/epoch - 14ms/step\n",
      "Epoch 42/141\n",
      "10/10 - 0s - loss: 2.8907e-04 - val_loss: 0.0079 - 139ms/epoch - 14ms/step\n",
      "Epoch 43/141\n",
      "10/10 - 0s - loss: 2.5791e-04 - val_loss: 0.0081 - 159ms/epoch - 16ms/step\n",
      "Epoch 44/141\n",
      "10/10 - 0s - loss: 2.4564e-04 - val_loss: 0.0081 - 135ms/epoch - 14ms/step\n",
      "Epoch 45/141\n",
      "10/10 - 0s - loss: 2.5612e-04 - val_loss: 0.0080 - 133ms/epoch - 13ms/step\n",
      "Epoch 46/141\n",
      "10/10 - 0s - loss: 2.5308e-04 - val_loss: 0.0080 - 136ms/epoch - 14ms/step\n",
      "Epoch 47/141\n",
      "10/10 - 0s - loss: 2.4588e-04 - val_loss: 0.0080 - 132ms/epoch - 13ms/step\n",
      "Epoch 48/141\n",
      "10/10 - 0s - loss: 3.0192e-04 - val_loss: 0.0080 - 134ms/epoch - 13ms/step\n",
      "Epoch 49/141\n",
      "10/10 - 0s - loss: 3.3480e-04 - val_loss: 0.0082 - 155ms/epoch - 16ms/step\n",
      "Epoch 50/141\n",
      "10/10 - 0s - loss: 3.4585e-04 - val_loss: 0.0079 - 165ms/epoch - 17ms/step\n",
      "Epoch 51/141\n",
      "10/10 - 0s - loss: 2.7582e-04 - val_loss: 0.0079 - 133ms/epoch - 13ms/step\n",
      "Epoch 52/141\n",
      "10/10 - 0s - loss: 2.6145e-04 - val_loss: 0.0081 - 132ms/epoch - 13ms/step\n",
      "Epoch 53/141\n",
      "10/10 - 0s - loss: 3.0519e-04 - val_loss: 0.0083 - 132ms/epoch - 13ms/step\n",
      "Epoch 54/141\n",
      "10/10 - 0s - loss: 3.1143e-04 - val_loss: 0.0080 - 135ms/epoch - 13ms/step\n",
      "Epoch 55/141\n",
      "10/10 - 0s - loss: 2.5974e-04 - val_loss: 0.0080 - 136ms/epoch - 14ms/step\n",
      "Epoch 56/141\n",
      "10/10 - 0s - loss: 2.6260e-04 - val_loss: 0.0080 - 132ms/epoch - 13ms/step\n",
      "Epoch 57/141\n",
      "10/10 - 0s - loss: 2.6600e-04 - val_loss: 0.0081 - 155ms/epoch - 16ms/step\n",
      "Epoch 58/141\n",
      "10/10 - 0s - loss: 2.3264e-04 - val_loss: 0.0080 - 134ms/epoch - 13ms/step\n",
      "Epoch 59/141\n",
      "10/10 - 0s - loss: 2.5463e-04 - val_loss: 0.0081 - 133ms/epoch - 13ms/step\n",
      "Epoch 60/141\n",
      "10/10 - 0s - loss: 2.7256e-04 - val_loss: 0.0081 - 131ms/epoch - 13ms/step\n",
      "Epoch 61/141\n",
      "10/10 - 0s - loss: 2.3413e-04 - val_loss: 0.0080 - 138ms/epoch - 14ms/step\n",
      "Epoch 62/141\n",
      "10/10 - 0s - loss: 2.4379e-04 - val_loss: 0.0082 - 133ms/epoch - 13ms/step\n",
      "Epoch 63/141\n",
      "10/10 - 0s - loss: 2.5596e-04 - val_loss: 0.0081 - 137ms/epoch - 14ms/step\n",
      "Epoch 64/141\n",
      "10/10 - 0s - loss: 2.7473e-04 - val_loss: 0.0081 - 132ms/epoch - 13ms/step\n",
      "Epoch 65/141\n",
      "10/10 - 0s - loss: 3.2122e-04 - val_loss: 0.0080 - 150ms/epoch - 15ms/step\n",
      "Epoch 66/141\n",
      "10/10 - 0s - loss: 2.5922e-04 - val_loss: 0.0081 - 140ms/epoch - 14ms/step\n",
      "Epoch 67/141\n",
      "10/10 - 0s - loss: 2.2298e-04 - val_loss: 0.0080 - 137ms/epoch - 14ms/step\n",
      "Epoch 68/141\n",
      "10/10 - 0s - loss: 2.3633e-04 - val_loss: 0.0081 - 139ms/epoch - 14ms/step\n",
      "Epoch 69/141\n",
      "10/10 - 0s - loss: 2.4022e-04 - val_loss: 0.0082 - 136ms/epoch - 14ms/step\n",
      "Epoch 70/141\n",
      "10/10 - 0s - loss: 2.3101e-04 - val_loss: 0.0081 - 131ms/epoch - 13ms/step\n",
      "Epoch 71/141\n",
      "10/10 - 0s - loss: 2.1787e-04 - val_loss: 0.0081 - 164ms/epoch - 16ms/step\n",
      "Epoch 72/141\n",
      "10/10 - 0s - loss: 2.4437e-04 - val_loss: 0.0081 - 130ms/epoch - 13ms/step\n",
      "Epoch 73/141\n",
      "10/10 - 0s - loss: 2.4073e-04 - val_loss: 0.0081 - 126ms/epoch - 13ms/step\n",
      "Epoch 74/141\n",
      "10/10 - 0s - loss: 2.5368e-04 - val_loss: 0.0082 - 134ms/epoch - 13ms/step\n",
      "Epoch 75/141\n",
      "10/10 - 0s - loss: 2.2011e-04 - val_loss: 0.0082 - 130ms/epoch - 13ms/step\n",
      "Epoch 76/141\n",
      "10/10 - 0s - loss: 2.0404e-04 - val_loss: 0.0081 - 127ms/epoch - 13ms/step\n",
      "Epoch 77/141\n",
      "10/10 - 0s - loss: 2.3736e-04 - val_loss: 0.0083 - 128ms/epoch - 13ms/step\n",
      "Epoch 78/141\n",
      "10/10 - 0s - loss: 2.3447e-04 - val_loss: 0.0085 - 129ms/epoch - 13ms/step\n",
      "Epoch 79/141\n",
      "10/10 - 0s - loss: 3.0941e-04 - val_loss: 0.0082 - 126ms/epoch - 13ms/step\n",
      "Epoch 80/141\n",
      "10/10 - 0s - loss: 2.8662e-04 - val_loss: 0.0082 - 127ms/epoch - 13ms/step\n",
      "Epoch 81/141\n",
      "10/10 - 0s - loss: 2.4566e-04 - val_loss: 0.0082 - 127ms/epoch - 13ms/step\n",
      "Epoch 82/141\n",
      "10/10 - 0s - loss: 2.2986e-04 - val_loss: 0.0084 - 154ms/epoch - 15ms/step\n",
      "Epoch 83/141\n",
      "10/10 - 0s - loss: 2.6664e-04 - val_loss: 0.0082 - 147ms/epoch - 15ms/step\n",
      "Epoch 84/141\n",
      "10/10 - 0s - loss: 2.1862e-04 - val_loss: 0.0082 - 150ms/epoch - 15ms/step\n",
      "Epoch 85/141\n",
      "10/10 - 0s - loss: 2.1855e-04 - val_loss: 0.0083 - 135ms/epoch - 13ms/step\n",
      "Epoch 86/141\n",
      "10/10 - 0s - loss: 2.1401e-04 - val_loss: 0.0082 - 135ms/epoch - 14ms/step\n",
      "Epoch 87/141\n",
      "10/10 - 0s - loss: 2.3689e-04 - val_loss: 0.0083 - 152ms/epoch - 15ms/step\n",
      "Epoch 88/141\n",
      "10/10 - 0s - loss: 2.1449e-04 - val_loss: 0.0084 - 154ms/epoch - 15ms/step\n",
      "Epoch 89/141\n",
      "10/10 - 0s - loss: 2.4717e-04 - val_loss: 0.0083 - 140ms/epoch - 14ms/step\n",
      "Epoch 90/141\n",
      "10/10 - 0s - loss: 2.5418e-04 - val_loss: 0.0083 - 129ms/epoch - 13ms/step\n",
      "Epoch 91/141\n",
      "10/10 - 0s - loss: 2.4111e-04 - val_loss: 0.0087 - 158ms/epoch - 16ms/step\n",
      "Epoch 92/141\n",
      "10/10 - 0s - loss: 3.1159e-04 - val_loss: 0.0083 - 128ms/epoch - 13ms/step\n",
      "Epoch 93/141\n",
      "10/10 - 0s - loss: 2.7136e-04 - val_loss: 0.0083 - 135ms/epoch - 14ms/step\n",
      "Epoch 94/141\n",
      "10/10 - 0s - loss: 2.4029e-04 - val_loss: 0.0085 - 148ms/epoch - 15ms/step\n",
      "Epoch 95/141\n",
      "10/10 - 0s - loss: 2.2620e-04 - val_loss: 0.0086 - 142ms/epoch - 14ms/step\n",
      "Epoch 96/141\n",
      "10/10 - 0s - loss: 2.3529e-04 - val_loss: 0.0085 - 159ms/epoch - 16ms/step\n",
      "Epoch 97/141\n",
      "10/10 - 0s - loss: 2.5496e-04 - val_loss: 0.0085 - 137ms/epoch - 14ms/step\n",
      "Epoch 98/141\n",
      "10/10 - 0s - loss: 2.2229e-04 - val_loss: 0.0085 - 148ms/epoch - 15ms/step\n",
      "Epoch 99/141\n",
      "10/10 - 0s - loss: 2.7768e-04 - val_loss: 0.0084 - 176ms/epoch - 18ms/step\n",
      "Epoch 100/141\n",
      "10/10 - 0s - loss: 2.4577e-04 - val_loss: 0.0084 - 145ms/epoch - 14ms/step\n",
      "Epoch 101/141\n",
      "10/10 - 0s - loss: 2.7086e-04 - val_loss: 0.0085 - 137ms/epoch - 14ms/step\n",
      "Epoch 102/141\n",
      "10/10 - 0s - loss: 2.8230e-04 - val_loss: 0.0091 - 144ms/epoch - 14ms/step\n",
      "Epoch 103/141\n",
      "10/10 - 0s - loss: 2.8269e-04 - val_loss: 0.0086 - 145ms/epoch - 14ms/step\n",
      "Epoch 104/141\n",
      "10/10 - 0s - loss: 2.4652e-04 - val_loss: 0.0087 - 171ms/epoch - 17ms/step\n",
      "Epoch 105/141\n",
      "10/10 - 0s - loss: 2.1454e-04 - val_loss: 0.0088 - 134ms/epoch - 13ms/step\n",
      "Epoch 106/141\n",
      "10/10 - 0s - loss: 2.5945e-04 - val_loss: 0.0088 - 139ms/epoch - 14ms/step\n",
      "Epoch 107/141\n",
      "10/10 - 0s - loss: 3.0730e-04 - val_loss: 0.0086 - 138ms/epoch - 14ms/step\n",
      "Epoch 108/141\n",
      "10/10 - 0s - loss: 2.2555e-04 - val_loss: 0.0087 - 177ms/epoch - 18ms/step\n",
      "Epoch 109/141\n",
      "10/10 - 0s - loss: 2.3250e-04 - val_loss: 0.0089 - 135ms/epoch - 14ms/step\n",
      "Epoch 110/141\n",
      "10/10 - 0s - loss: 2.1480e-04 - val_loss: 0.0090 - 133ms/epoch - 13ms/step\n",
      "Epoch 111/141\n",
      "10/10 - 0s - loss: 2.0969e-04 - val_loss: 0.0093 - 151ms/epoch - 15ms/step\n",
      "Epoch 112/141\n",
      "10/10 - 0s - loss: 2.3047e-04 - val_loss: 0.0091 - 135ms/epoch - 13ms/step\n",
      "Epoch 113/141\n",
      "10/10 - 0s - loss: 3.1977e-04 - val_loss: 0.0091 - 137ms/epoch - 14ms/step\n",
      "Epoch 114/141\n",
      "10/10 - 0s - loss: 3.0973e-04 - val_loss: 0.0092 - 132ms/epoch - 13ms/step\n",
      "Epoch 115/141\n",
      "10/10 - 0s - loss: 2.4610e-04 - val_loss: 0.0093 - 131ms/epoch - 13ms/step\n",
      "Epoch 116/141\n",
      "10/10 - 0s - loss: 2.0970e-04 - val_loss: 0.0092 - 126ms/epoch - 13ms/step\n",
      "Epoch 117/141\n",
      "10/10 - 0s - loss: 2.0392e-04 - val_loss: 0.0090 - 117ms/epoch - 12ms/step\n",
      "Epoch 118/141\n",
      "10/10 - 0s - loss: 2.1878e-04 - val_loss: 0.0090 - 126ms/epoch - 13ms/step\n",
      "Epoch 119/141\n",
      "10/10 - 0s - loss: 2.3899e-04 - val_loss: 0.0095 - 130ms/epoch - 13ms/step\n",
      "Epoch 120/141\n",
      "10/10 - 0s - loss: 2.9892e-04 - val_loss: 0.0090 - 116ms/epoch - 12ms/step\n",
      "Epoch 121/141\n",
      "10/10 - 0s - loss: 2.6535e-04 - val_loss: 0.0091 - 118ms/epoch - 12ms/step\n",
      "Epoch 122/141\n",
      "10/10 - 0s - loss: 2.4159e-04 - val_loss: 0.0094 - 114ms/epoch - 11ms/step\n",
      "Epoch 123/141\n",
      "10/10 - 0s - loss: 2.3373e-04 - val_loss: 0.0094 - 119ms/epoch - 12ms/step\n",
      "Epoch 124/141\n",
      "10/10 - 0s - loss: 1.9996e-04 - val_loss: 0.0095 - 183ms/epoch - 18ms/step\n",
      "Epoch 125/141\n",
      "10/10 - 0s - loss: 2.1477e-04 - val_loss: 0.0094 - 120ms/epoch - 12ms/step\n",
      "Epoch 126/141\n",
      "10/10 - 0s - loss: 2.3216e-04 - val_loss: 0.0094 - 116ms/epoch - 12ms/step\n",
      "Epoch 127/141\n",
      "10/10 - 0s - loss: 1.9363e-04 - val_loss: 0.0093 - 120ms/epoch - 12ms/step\n",
      "Epoch 128/141\n",
      "10/10 - 0s - loss: 2.2856e-04 - val_loss: 0.0091 - 117ms/epoch - 12ms/step\n",
      "Epoch 129/141\n",
      "10/10 - 0s - loss: 2.1529e-04 - val_loss: 0.0092 - 123ms/epoch - 12ms/step\n",
      "Epoch 130/141\n",
      "10/10 - 0s - loss: 2.3633e-04 - val_loss: 0.0094 - 124ms/epoch - 12ms/step\n",
      "Epoch 131/141\n",
      "10/10 - 0s - loss: 2.0329e-04 - val_loss: 0.0094 - 122ms/epoch - 12ms/step\n",
      "Epoch 132/141\n",
      "10/10 - 0s - loss: 2.2096e-04 - val_loss: 0.0096 - 119ms/epoch - 12ms/step\n",
      "Epoch 133/141\n",
      "10/10 - 0s - loss: 2.0504e-04 - val_loss: 0.0095 - 118ms/epoch - 12ms/step\n",
      "Epoch 134/141\n",
      "10/10 - 0s - loss: 1.9835e-04 - val_loss: 0.0094 - 117ms/epoch - 12ms/step\n",
      "Epoch 135/141\n",
      "10/10 - 0s - loss: 2.2009e-04 - val_loss: 0.0095 - 138ms/epoch - 14ms/step\n",
      "Epoch 136/141\n",
      "10/10 - 0s - loss: 2.0864e-04 - val_loss: 0.0094 - 129ms/epoch - 13ms/step\n",
      "Epoch 137/141\n",
      "10/10 - 0s - loss: 2.1500e-04 - val_loss: 0.0100 - 122ms/epoch - 12ms/step\n",
      "Epoch 138/141\n",
      "10/10 - 0s - loss: 1.9781e-04 - val_loss: 0.0096 - 122ms/epoch - 12ms/step\n",
      "Epoch 139/141\n",
      "10/10 - 0s - loss: 2.2100e-04 - val_loss: 0.0099 - 130ms/epoch - 13ms/step\n",
      "Epoch 140/141\n",
      "10/10 - 0s - loss: 2.0378e-04 - val_loss: 0.0102 - 131ms/epoch - 13ms/step\n",
      "Epoch 141/141\n",
      "10/10 - 0s - loss: 2.2005e-04 - val_loss: 0.0098 - 131ms/epoch - 13ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-177.5   \u001b[0m | \u001b[0m141.8    \u001b[0m | \u001b[0m3.468    \u001b[0m | \u001b[0m0.009438 \u001b[0m | \u001b[0m89.82    \u001b[0m |\n",
      "Model: \"sequential_133\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_481 (LSTM)             (None, 1, 93)             36828     \n",
      "                                                                 \n",
      " dropout_348 (Dropout)       (None, 1, 93)             0         \n",
      "                                                                 \n",
      " lstm_482 (LSTM)             (None, 1, 93)             69564     \n",
      "                                                                 \n",
      " dropout_349 (Dropout)       (None, 1, 93)             0         \n",
      "                                                                 \n",
      " lstm_483 (LSTM)             (None, 1, 93)             69564     \n",
      "                                                                 \n",
      " dropout_350 (Dropout)       (None, 1, 93)             0         \n",
      "                                                                 \n",
      " lstm_484 (LSTM)             (None, 93)                69564     \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 1)                 94        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 245,614\n",
      "Trainable params: 245,614\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/88\n",
      "10/10 - 8s - loss: 0.0439 - val_loss: 0.0207 - 8s/epoch - 837ms/step\n",
      "Epoch 2/88\n",
      "10/10 - 0s - loss: 0.0064 - val_loss: 0.0147 - 113ms/epoch - 11ms/step\n",
      "Epoch 3/88\n",
      "10/10 - 0s - loss: 0.0036 - val_loss: 0.0173 - 144ms/epoch - 14ms/step\n",
      "Epoch 4/88\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0151 - 114ms/epoch - 11ms/step\n",
      "Epoch 5/88\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0155 - 122ms/epoch - 12ms/step\n",
      "Epoch 6/88\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0149 - 123ms/epoch - 12ms/step\n",
      "Epoch 7/88\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0145 - 115ms/epoch - 12ms/step\n",
      "Epoch 8/88\n",
      "10/10 - 0s - loss: 0.0023 - val_loss: 0.0137 - 112ms/epoch - 11ms/step\n",
      "Epoch 9/88\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0126 - 114ms/epoch - 11ms/step\n",
      "Epoch 10/88\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0114 - 113ms/epoch - 11ms/step\n",
      "Epoch 11/88\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0097 - 118ms/epoch - 12ms/step\n",
      "Epoch 12/88\n",
      "10/10 - 0s - loss: 9.4899e-04 - val_loss: 0.0085 - 118ms/epoch - 12ms/step\n",
      "Epoch 13/88\n",
      "10/10 - 0s - loss: 7.2366e-04 - val_loss: 0.0087 - 115ms/epoch - 12ms/step\n",
      "Epoch 14/88\n",
      "10/10 - 0s - loss: 6.4760e-04 - val_loss: 0.0089 - 109ms/epoch - 11ms/step\n",
      "Epoch 15/88\n",
      "10/10 - 0s - loss: 5.8804e-04 - val_loss: 0.0086 - 110ms/epoch - 11ms/step\n",
      "Epoch 16/88\n",
      "10/10 - 0s - loss: 5.5532e-04 - val_loss: 0.0085 - 113ms/epoch - 11ms/step\n",
      "Epoch 17/88\n",
      "10/10 - 0s - loss: 5.4509e-04 - val_loss: 0.0086 - 110ms/epoch - 11ms/step\n",
      "Epoch 18/88\n",
      "10/10 - 0s - loss: 5.3835e-04 - val_loss: 0.0085 - 111ms/epoch - 11ms/step\n",
      "Epoch 19/88\n",
      "10/10 - 0s - loss: 4.7857e-04 - val_loss: 0.0084 - 112ms/epoch - 11ms/step\n",
      "Epoch 20/88\n",
      "10/10 - 0s - loss: 4.5829e-04 - val_loss: 0.0084 - 125ms/epoch - 13ms/step\n",
      "Epoch 21/88\n",
      "10/10 - 0s - loss: 4.0074e-04 - val_loss: 0.0085 - 133ms/epoch - 13ms/step\n",
      "Epoch 22/88\n",
      "10/10 - 0s - loss: 4.1534e-04 - val_loss: 0.0084 - 113ms/epoch - 11ms/step\n",
      "Epoch 23/88\n",
      "10/10 - 0s - loss: 4.1447e-04 - val_loss: 0.0085 - 110ms/epoch - 11ms/step\n",
      "Epoch 24/88\n",
      "10/10 - 0s - loss: 3.6420e-04 - val_loss: 0.0085 - 110ms/epoch - 11ms/step\n",
      "Epoch 25/88\n",
      "10/10 - 0s - loss: 4.2762e-04 - val_loss: 0.0086 - 114ms/epoch - 11ms/step\n",
      "Epoch 26/88\n",
      "10/10 - 0s - loss: 3.7491e-04 - val_loss: 0.0084 - 123ms/epoch - 12ms/step\n",
      "Epoch 27/88\n",
      "10/10 - 0s - loss: 3.5310e-04 - val_loss: 0.0085 - 118ms/epoch - 12ms/step\n",
      "Epoch 28/88\n",
      "10/10 - 0s - loss: 3.6759e-04 - val_loss: 0.0084 - 129ms/epoch - 13ms/step\n",
      "Epoch 29/88\n",
      "10/10 - 0s - loss: 3.3473e-04 - val_loss: 0.0086 - 115ms/epoch - 12ms/step\n",
      "Epoch 30/88\n",
      "10/10 - 0s - loss: 3.7851e-04 - val_loss: 0.0084 - 115ms/epoch - 12ms/step\n",
      "Epoch 31/88\n",
      "10/10 - 0s - loss: 3.3731e-04 - val_loss: 0.0084 - 118ms/epoch - 12ms/step\n",
      "Epoch 32/88\n",
      "10/10 - 0s - loss: 3.5281e-04 - val_loss: 0.0084 - 115ms/epoch - 11ms/step\n",
      "Epoch 33/88\n",
      "10/10 - 0s - loss: 3.4344e-04 - val_loss: 0.0084 - 110ms/epoch - 11ms/step\n",
      "Epoch 34/88\n",
      "10/10 - 0s - loss: 3.0564e-04 - val_loss: 0.0085 - 114ms/epoch - 11ms/step\n",
      "Epoch 35/88\n",
      "10/10 - 0s - loss: 3.1055e-04 - val_loss: 0.0085 - 144ms/epoch - 14ms/step\n",
      "Epoch 36/88\n",
      "10/10 - 0s - loss: 2.8708e-04 - val_loss: 0.0084 - 117ms/epoch - 12ms/step\n",
      "Epoch 37/88\n",
      "10/10 - 0s - loss: 2.8690e-04 - val_loss: 0.0085 - 110ms/epoch - 11ms/step\n",
      "Epoch 38/88\n",
      "10/10 - 0s - loss: 2.9841e-04 - val_loss: 0.0084 - 108ms/epoch - 11ms/step\n",
      "Epoch 39/88\n",
      "10/10 - 0s - loss: 2.9941e-04 - val_loss: 0.0086 - 110ms/epoch - 11ms/step\n",
      "Epoch 40/88\n",
      "10/10 - 0s - loss: 2.9780e-04 - val_loss: 0.0085 - 113ms/epoch - 11ms/step\n",
      "Epoch 41/88\n",
      "10/10 - 0s - loss: 2.8136e-04 - val_loss: 0.0085 - 108ms/epoch - 11ms/step\n",
      "Epoch 42/88\n",
      "10/10 - 0s - loss: 2.8979e-04 - val_loss: 0.0084 - 110ms/epoch - 11ms/step\n",
      "Epoch 43/88\n",
      "10/10 - 0s - loss: 2.9702e-04 - val_loss: 0.0084 - 110ms/epoch - 11ms/step\n",
      "Epoch 44/88\n",
      "10/10 - 0s - loss: 2.7152e-04 - val_loss: 0.0085 - 112ms/epoch - 11ms/step\n",
      "Epoch 45/88\n",
      "10/10 - 0s - loss: 2.7874e-04 - val_loss: 0.0085 - 136ms/epoch - 14ms/step\n",
      "Epoch 46/88\n",
      "10/10 - 0s - loss: 2.5854e-04 - val_loss: 0.0086 - 135ms/epoch - 13ms/step\n",
      "Epoch 47/88\n",
      "10/10 - 0s - loss: 2.7793e-04 - val_loss: 0.0085 - 130ms/epoch - 13ms/step\n",
      "Epoch 48/88\n",
      "10/10 - 0s - loss: 2.6771e-04 - val_loss: 0.0084 - 127ms/epoch - 13ms/step\n",
      "Epoch 49/88\n",
      "10/10 - 0s - loss: 2.9387e-04 - val_loss: 0.0084 - 118ms/epoch - 12ms/step\n",
      "Epoch 50/88\n",
      "10/10 - 0s - loss: 2.5681e-04 - val_loss: 0.0085 - 122ms/epoch - 12ms/step\n",
      "Epoch 51/88\n",
      "10/10 - 0s - loss: 2.6700e-04 - val_loss: 0.0084 - 118ms/epoch - 12ms/step\n",
      "Epoch 52/88\n",
      "10/10 - 0s - loss: 2.6761e-04 - val_loss: 0.0084 - 111ms/epoch - 11ms/step\n",
      "Epoch 53/88\n",
      "10/10 - 0s - loss: 2.4707e-04 - val_loss: 0.0084 - 120ms/epoch - 12ms/step\n",
      "Epoch 54/88\n",
      "10/10 - 0s - loss: 2.6321e-04 - val_loss: 0.0084 - 124ms/epoch - 12ms/step\n",
      "Epoch 55/88\n",
      "10/10 - 0s - loss: 2.3824e-04 - val_loss: 0.0084 - 124ms/epoch - 12ms/step\n",
      "Epoch 56/88\n",
      "10/10 - 0s - loss: 2.5636e-04 - val_loss: 0.0085 - 115ms/epoch - 11ms/step\n",
      "Epoch 57/88\n",
      "10/10 - 0s - loss: 2.5907e-04 - val_loss: 0.0084 - 113ms/epoch - 11ms/step\n",
      "Epoch 58/88\n",
      "10/10 - 0s - loss: 2.4215e-04 - val_loss: 0.0086 - 116ms/epoch - 12ms/step\n",
      "Epoch 59/88\n",
      "10/10 - 0s - loss: 2.5938e-04 - val_loss: 0.0084 - 114ms/epoch - 11ms/step\n",
      "Epoch 60/88\n",
      "10/10 - 0s - loss: 2.3370e-04 - val_loss: 0.0084 - 125ms/epoch - 12ms/step\n",
      "Epoch 61/88\n",
      "10/10 - 0s - loss: 2.3480e-04 - val_loss: 0.0086 - 113ms/epoch - 11ms/step\n",
      "Epoch 62/88\n",
      "10/10 - 0s - loss: 2.3898e-04 - val_loss: 0.0084 - 119ms/epoch - 12ms/step\n",
      "Epoch 63/88\n",
      "10/10 - 0s - loss: 2.3709e-04 - val_loss: 0.0085 - 116ms/epoch - 12ms/step\n",
      "Epoch 64/88\n",
      "10/10 - 0s - loss: 2.2491e-04 - val_loss: 0.0085 - 111ms/epoch - 11ms/step\n",
      "Epoch 65/88\n",
      "10/10 - 0s - loss: 2.3592e-04 - val_loss: 0.0085 - 116ms/epoch - 12ms/step\n",
      "Epoch 66/88\n",
      "10/10 - 0s - loss: 2.4163e-04 - val_loss: 0.0085 - 121ms/epoch - 12ms/step\n",
      "Epoch 67/88\n",
      "10/10 - 0s - loss: 2.2239e-04 - val_loss: 0.0086 - 135ms/epoch - 14ms/step\n",
      "Epoch 68/88\n",
      "10/10 - 0s - loss: 2.3680e-04 - val_loss: 0.0086 - 110ms/epoch - 11ms/step\n",
      "Epoch 69/88\n",
      "10/10 - 0s - loss: 2.3966e-04 - val_loss: 0.0084 - 111ms/epoch - 11ms/step\n",
      "Epoch 70/88\n",
      "10/10 - 0s - loss: 2.4108e-04 - val_loss: 0.0086 - 110ms/epoch - 11ms/step\n",
      "Epoch 71/88\n",
      "10/10 - 0s - loss: 2.3193e-04 - val_loss: 0.0086 - 122ms/epoch - 12ms/step\n",
      "Epoch 72/88\n",
      "10/10 - 0s - loss: 2.1738e-04 - val_loss: 0.0085 - 110ms/epoch - 11ms/step\n",
      "Epoch 73/88\n",
      "10/10 - 0s - loss: 2.1693e-04 - val_loss: 0.0086 - 109ms/epoch - 11ms/step\n",
      "Epoch 74/88\n",
      "10/10 - 0s - loss: 2.1555e-04 - val_loss: 0.0085 - 112ms/epoch - 11ms/step\n",
      "Epoch 75/88\n",
      "10/10 - 0s - loss: 2.3512e-04 - val_loss: 0.0085 - 110ms/epoch - 11ms/step\n",
      "Epoch 76/88\n",
      "10/10 - 0s - loss: 2.2095e-04 - val_loss: 0.0085 - 108ms/epoch - 11ms/step\n",
      "Epoch 77/88\n",
      "10/10 - 0s - loss: 2.5323e-04 - val_loss: 0.0086 - 111ms/epoch - 11ms/step\n",
      "Epoch 78/88\n",
      "10/10 - 0s - loss: 2.4743e-04 - val_loss: 0.0086 - 110ms/epoch - 11ms/step\n",
      "Epoch 79/88\n",
      "10/10 - 0s - loss: 2.2854e-04 - val_loss: 0.0086 - 113ms/epoch - 11ms/step\n",
      "Epoch 80/88\n",
      "10/10 - 0s - loss: 2.2480e-04 - val_loss: 0.0086 - 110ms/epoch - 11ms/step\n",
      "Epoch 81/88\n",
      "10/10 - 0s - loss: 2.1546e-04 - val_loss: 0.0086 - 108ms/epoch - 11ms/step\n",
      "Epoch 82/88\n",
      "10/10 - 0s - loss: 2.3487e-04 - val_loss: 0.0086 - 109ms/epoch - 11ms/step\n",
      "Epoch 83/88\n",
      "10/10 - 0s - loss: 2.1978e-04 - val_loss: 0.0086 - 113ms/epoch - 11ms/step\n",
      "Epoch 84/88\n",
      "10/10 - 0s - loss: 2.3171e-04 - val_loss: 0.0085 - 110ms/epoch - 11ms/step\n",
      "Epoch 85/88\n",
      "10/10 - 0s - loss: 2.1948e-04 - val_loss: 0.0087 - 109ms/epoch - 11ms/step\n",
      "Epoch 86/88\n",
      "10/10 - 0s - loss: 1.9553e-04 - val_loss: 0.0087 - 108ms/epoch - 11ms/step\n",
      "Epoch 87/88\n",
      "10/10 - 0s - loss: 2.2159e-04 - val_loss: 0.0086 - 108ms/epoch - 11ms/step\n",
      "Epoch 88/88\n",
      "10/10 - 0s - loss: 2.2027e-04 - val_loss: 0.0086 - 109ms/epoch - 11ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-165.9   \u001b[0m | \u001b[0m88.72    \u001b[0m | \u001b[0m3.5      \u001b[0m | \u001b[0m0.00235  \u001b[0m | \u001b[0m93.32    \u001b[0m |\n",
      "Model: \"sequential_134\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_485 (LSTM)             (None, 1, 29)             4060      \n",
      "                                                                 \n",
      " dropout_351 (Dropout)       (None, 1, 29)             0         \n",
      "                                                                 \n",
      " lstm_486 (LSTM)             (None, 29)                6844      \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 1)                 30        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,934\n",
      "Trainable params: 10,934\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/117\n",
      "10/10 - 5s - loss: 0.0278 - val_loss: 0.0133 - 5s/epoch - 470ms/step\n",
      "Epoch 2/117\n",
      "10/10 - 0s - loss: 0.0059 - val_loss: 0.0136 - 73ms/epoch - 7ms/step\n",
      "Epoch 3/117\n",
      "10/10 - 0s - loss: 0.0034 - val_loss: 0.0135 - 59ms/epoch - 6ms/step\n",
      "Epoch 4/117\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0121 - 57ms/epoch - 6ms/step\n",
      "Epoch 5/117\n",
      "10/10 - 0s - loss: 0.0021 - val_loss: 0.0127 - 59ms/epoch - 6ms/step\n",
      "Epoch 6/117\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0116 - 57ms/epoch - 6ms/step\n",
      "Epoch 7/117\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0113 - 58ms/epoch - 6ms/step\n",
      "Epoch 8/117\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0107 - 58ms/epoch - 6ms/step\n",
      "Epoch 9/117\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0100 - 58ms/epoch - 6ms/step\n",
      "Epoch 10/117\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0092 - 57ms/epoch - 6ms/step\n",
      "Epoch 11/117\n",
      "10/10 - 0s - loss: 9.7741e-04 - val_loss: 0.0086 - 56ms/epoch - 6ms/step\n",
      "Epoch 12/117\n",
      "10/10 - 0s - loss: 8.4732e-04 - val_loss: 0.0083 - 57ms/epoch - 6ms/step\n",
      "Epoch 13/117\n",
      "10/10 - 0s - loss: 6.7803e-04 - val_loss: 0.0083 - 57ms/epoch - 6ms/step\n",
      "Epoch 14/117\n",
      "10/10 - 0s - loss: 6.0268e-04 - val_loss: 0.0085 - 57ms/epoch - 6ms/step\n",
      "Epoch 15/117\n",
      "10/10 - 0s - loss: 5.0650e-04 - val_loss: 0.0087 - 57ms/epoch - 6ms/step\n",
      "Epoch 16/117\n",
      "10/10 - 0s - loss: 4.8321e-04 - val_loss: 0.0089 - 56ms/epoch - 6ms/step\n",
      "Epoch 17/117\n",
      "10/10 - 0s - loss: 5.5098e-04 - val_loss: 0.0089 - 57ms/epoch - 6ms/step\n",
      "Epoch 18/117\n",
      "10/10 - 0s - loss: 4.1379e-04 - val_loss: 0.0088 - 57ms/epoch - 6ms/step\n",
      "Epoch 19/117\n",
      "10/10 - 0s - loss: 4.1304e-04 - val_loss: 0.0087 - 56ms/epoch - 6ms/step\n",
      "Epoch 20/117\n",
      "10/10 - 0s - loss: 4.2073e-04 - val_loss: 0.0088 - 56ms/epoch - 6ms/step\n",
      "Epoch 21/117\n",
      "10/10 - 0s - loss: 3.8510e-04 - val_loss: 0.0087 - 56ms/epoch - 6ms/step\n",
      "Epoch 22/117\n",
      "10/10 - 0s - loss: 4.0519e-04 - val_loss: 0.0087 - 56ms/epoch - 6ms/step\n",
      "Epoch 23/117\n",
      "10/10 - 0s - loss: 3.2779e-04 - val_loss: 0.0087 - 56ms/epoch - 6ms/step\n",
      "Epoch 24/117\n",
      "10/10 - 0s - loss: 3.3289e-04 - val_loss: 0.0087 - 56ms/epoch - 6ms/step\n",
      "Epoch 25/117\n",
      "10/10 - 0s - loss: 3.0121e-04 - val_loss: 0.0088 - 56ms/epoch - 6ms/step\n",
      "Epoch 26/117\n",
      "10/10 - 0s - loss: 3.4584e-04 - val_loss: 0.0088 - 57ms/epoch - 6ms/step\n",
      "Epoch 27/117\n",
      "10/10 - 0s - loss: 3.3815e-04 - val_loss: 0.0090 - 56ms/epoch - 6ms/step\n",
      "Epoch 28/117\n",
      "10/10 - 0s - loss: 2.9562e-04 - val_loss: 0.0088 - 57ms/epoch - 6ms/step\n",
      "Epoch 29/117\n",
      "10/10 - 0s - loss: 3.1183e-04 - val_loss: 0.0090 - 56ms/epoch - 6ms/step\n",
      "Epoch 30/117\n",
      "10/10 - 0s - loss: 2.8666e-04 - val_loss: 0.0090 - 56ms/epoch - 6ms/step\n",
      "Epoch 31/117\n",
      "10/10 - 0s - loss: 2.9161e-04 - val_loss: 0.0092 - 58ms/epoch - 6ms/step\n",
      "Epoch 32/117\n",
      "10/10 - 0s - loss: 2.6235e-04 - val_loss: 0.0092 - 58ms/epoch - 6ms/step\n",
      "Epoch 33/117\n",
      "10/10 - 0s - loss: 2.8685e-04 - val_loss: 0.0089 - 55ms/epoch - 6ms/step\n",
      "Epoch 34/117\n",
      "10/10 - 0s - loss: 2.6460e-04 - val_loss: 0.0089 - 56ms/epoch - 6ms/step\n",
      "Epoch 35/117\n",
      "10/10 - 0s - loss: 2.7796e-04 - val_loss: 0.0089 - 56ms/epoch - 6ms/step\n",
      "Epoch 36/117\n",
      "10/10 - 0s - loss: 2.7516e-04 - val_loss: 0.0092 - 56ms/epoch - 6ms/step\n",
      "Epoch 37/117\n",
      "10/10 - 0s - loss: 2.4938e-04 - val_loss: 0.0090 - 56ms/epoch - 6ms/step\n",
      "Epoch 38/117\n",
      "10/10 - 0s - loss: 2.5322e-04 - val_loss: 0.0090 - 56ms/epoch - 6ms/step\n",
      "Epoch 39/117\n",
      "10/10 - 0s - loss: 2.6185e-04 - val_loss: 0.0089 - 56ms/epoch - 6ms/step\n",
      "Epoch 40/117\n",
      "10/10 - 0s - loss: 2.5062e-04 - val_loss: 0.0088 - 55ms/epoch - 6ms/step\n",
      "Epoch 41/117\n",
      "10/10 - 0s - loss: 2.7122e-04 - val_loss: 0.0091 - 55ms/epoch - 5ms/step\n",
      "Epoch 42/117\n",
      "10/10 - 0s - loss: 2.6666e-04 - val_loss: 0.0089 - 55ms/epoch - 6ms/step\n",
      "Epoch 43/117\n",
      "10/10 - 0s - loss: 2.5224e-04 - val_loss: 0.0089 - 74ms/epoch - 7ms/step\n",
      "Epoch 44/117\n",
      "10/10 - 0s - loss: 2.4450e-04 - val_loss: 0.0090 - 63ms/epoch - 6ms/step\n",
      "Epoch 45/117\n",
      "10/10 - 0s - loss: 2.4665e-04 - val_loss: 0.0091 - 57ms/epoch - 6ms/step\n",
      "Epoch 46/117\n",
      "10/10 - 0s - loss: 2.5169e-04 - val_loss: 0.0091 - 56ms/epoch - 6ms/step\n",
      "Epoch 47/117\n",
      "10/10 - 0s - loss: 2.5247e-04 - val_loss: 0.0089 - 56ms/epoch - 6ms/step\n",
      "Epoch 48/117\n",
      "10/10 - 0s - loss: 2.4949e-04 - val_loss: 0.0089 - 56ms/epoch - 6ms/step\n",
      "Epoch 49/117\n",
      "10/10 - 0s - loss: 2.2657e-04 - val_loss: 0.0093 - 56ms/epoch - 6ms/step\n",
      "Epoch 50/117\n",
      "10/10 - 0s - loss: 2.8359e-04 - val_loss: 0.0089 - 56ms/epoch - 6ms/step\n",
      "Epoch 51/117\n",
      "10/10 - 0s - loss: 2.5277e-04 - val_loss: 0.0088 - 56ms/epoch - 6ms/step\n",
      "Epoch 52/117\n",
      "10/10 - 0s - loss: 2.3593e-04 - val_loss: 0.0090 - 56ms/epoch - 6ms/step\n",
      "Epoch 53/117\n",
      "10/10 - 0s - loss: 2.2211e-04 - val_loss: 0.0089 - 56ms/epoch - 6ms/step\n",
      "Epoch 54/117\n",
      "10/10 - 0s - loss: 2.4530e-04 - val_loss: 0.0090 - 59ms/epoch - 6ms/step\n",
      "Epoch 55/117\n",
      "10/10 - 0s - loss: 2.1825e-04 - val_loss: 0.0091 - 57ms/epoch - 6ms/step\n",
      "Epoch 56/117\n",
      "10/10 - 0s - loss: 2.2969e-04 - val_loss: 0.0090 - 56ms/epoch - 6ms/step\n",
      "Epoch 57/117\n",
      "10/10 - 0s - loss: 2.3438e-04 - val_loss: 0.0088 - 56ms/epoch - 6ms/step\n",
      "Epoch 58/117\n",
      "10/10 - 0s - loss: 2.2836e-04 - val_loss: 0.0090 - 56ms/epoch - 6ms/step\n",
      "Epoch 59/117\n",
      "10/10 - 0s - loss: 2.3048e-04 - val_loss: 0.0091 - 58ms/epoch - 6ms/step\n",
      "Epoch 60/117\n",
      "10/10 - 0s - loss: 2.3623e-04 - val_loss: 0.0090 - 56ms/epoch - 6ms/step\n",
      "Epoch 61/117\n",
      "10/10 - 0s - loss: 2.2915e-04 - val_loss: 0.0089 - 57ms/epoch - 6ms/step\n",
      "Epoch 62/117\n",
      "10/10 - 0s - loss: 2.2354e-04 - val_loss: 0.0089 - 59ms/epoch - 6ms/step\n",
      "Epoch 63/117\n",
      "10/10 - 0s - loss: 2.2546e-04 - val_loss: 0.0090 - 57ms/epoch - 6ms/step\n",
      "Epoch 64/117\n",
      "10/10 - 0s - loss: 2.3288e-04 - val_loss: 0.0091 - 57ms/epoch - 6ms/step\n",
      "Epoch 65/117\n",
      "10/10 - 0s - loss: 2.2844e-04 - val_loss: 0.0091 - 57ms/epoch - 6ms/step\n",
      "Epoch 66/117\n",
      "10/10 - 0s - loss: 2.1122e-04 - val_loss: 0.0089 - 55ms/epoch - 5ms/step\n",
      "Epoch 67/117\n",
      "10/10 - 0s - loss: 2.1390e-04 - val_loss: 0.0090 - 56ms/epoch - 6ms/step\n",
      "Epoch 68/117\n",
      "10/10 - 0s - loss: 2.1164e-04 - val_loss: 0.0090 - 57ms/epoch - 6ms/step\n",
      "Epoch 69/117\n",
      "10/10 - 0s - loss: 2.1418e-04 - val_loss: 0.0091 - 56ms/epoch - 6ms/step\n",
      "Epoch 70/117\n",
      "10/10 - 0s - loss: 2.1533e-04 - val_loss: 0.0091 - 56ms/epoch - 6ms/step\n",
      "Epoch 71/117\n",
      "10/10 - 0s - loss: 2.1991e-04 - val_loss: 0.0091 - 57ms/epoch - 6ms/step\n",
      "Epoch 72/117\n",
      "10/10 - 0s - loss: 2.1830e-04 - val_loss: 0.0090 - 56ms/epoch - 6ms/step\n",
      "Epoch 73/117\n",
      "10/10 - 0s - loss: 2.4406e-04 - val_loss: 0.0091 - 56ms/epoch - 6ms/step\n",
      "Epoch 74/117\n",
      "10/10 - 0s - loss: 2.1321e-04 - val_loss: 0.0091 - 56ms/epoch - 6ms/step\n",
      "Epoch 75/117\n",
      "10/10 - 0s - loss: 2.1710e-04 - val_loss: 0.0092 - 57ms/epoch - 6ms/step\n",
      "Epoch 76/117\n",
      "10/10 - 0s - loss: 2.2259e-04 - val_loss: 0.0092 - 55ms/epoch - 6ms/step\n",
      "Epoch 77/117\n",
      "10/10 - 0s - loss: 2.1172e-04 - val_loss: 0.0092 - 57ms/epoch - 6ms/step\n",
      "Epoch 78/117\n",
      "10/10 - 0s - loss: 2.1091e-04 - val_loss: 0.0091 - 61ms/epoch - 6ms/step\n",
      "Epoch 79/117\n",
      "10/10 - 0s - loss: 2.0836e-04 - val_loss: 0.0092 - 95ms/epoch - 9ms/step\n",
      "Epoch 80/117\n",
      "10/10 - 0s - loss: 2.3416e-04 - val_loss: 0.0095 - 79ms/epoch - 8ms/step\n",
      "Epoch 81/117\n",
      "10/10 - 0s - loss: 2.2808e-04 - val_loss: 0.0091 - 67ms/epoch - 7ms/step\n",
      "Epoch 82/117\n",
      "10/10 - 0s - loss: 2.2628e-04 - val_loss: 0.0093 - 72ms/epoch - 7ms/step\n",
      "Epoch 83/117\n",
      "10/10 - 0s - loss: 2.0930e-04 - val_loss: 0.0092 - 66ms/epoch - 7ms/step\n",
      "Epoch 84/117\n",
      "10/10 - 0s - loss: 2.0361e-04 - val_loss: 0.0092 - 59ms/epoch - 6ms/step\n",
      "Epoch 85/117\n",
      "10/10 - 0s - loss: 2.0289e-04 - val_loss: 0.0092 - 58ms/epoch - 6ms/step\n",
      "Epoch 86/117\n",
      "10/10 - 0s - loss: 2.1803e-04 - val_loss: 0.0095 - 59ms/epoch - 6ms/step\n",
      "Epoch 87/117\n",
      "10/10 - 0s - loss: 2.1076e-04 - val_loss: 0.0092 - 56ms/epoch - 6ms/step\n",
      "Epoch 88/117\n",
      "10/10 - 0s - loss: 2.3758e-04 - val_loss: 0.0093 - 57ms/epoch - 6ms/step\n",
      "Epoch 89/117\n",
      "10/10 - 0s - loss: 2.3132e-04 - val_loss: 0.0091 - 59ms/epoch - 6ms/step\n",
      "Epoch 90/117\n",
      "10/10 - 0s - loss: 2.1367e-04 - val_loss: 0.0091 - 57ms/epoch - 6ms/step\n",
      "Epoch 91/117\n",
      "10/10 - 0s - loss: 2.0426e-04 - val_loss: 0.0092 - 56ms/epoch - 6ms/step\n",
      "Epoch 92/117\n",
      "10/10 - 0s - loss: 2.1153e-04 - val_loss: 0.0093 - 56ms/epoch - 6ms/step\n",
      "Epoch 93/117\n",
      "10/10 - 0s - loss: 1.9014e-04 - val_loss: 0.0092 - 56ms/epoch - 6ms/step\n",
      "Epoch 94/117\n",
      "10/10 - 0s - loss: 2.0527e-04 - val_loss: 0.0091 - 56ms/epoch - 6ms/step\n",
      "Epoch 95/117\n",
      "10/10 - 0s - loss: 2.1121e-04 - val_loss: 0.0094 - 55ms/epoch - 6ms/step\n",
      "Epoch 96/117\n",
      "10/10 - 0s - loss: 2.3810e-04 - val_loss: 0.0092 - 56ms/epoch - 6ms/step\n",
      "Epoch 97/117\n",
      "10/10 - 0s - loss: 2.0254e-04 - val_loss: 0.0092 - 56ms/epoch - 6ms/step\n",
      "Epoch 98/117\n",
      "10/10 - 0s - loss: 2.1770e-04 - val_loss: 0.0094 - 57ms/epoch - 6ms/step\n",
      "Epoch 99/117\n",
      "10/10 - 0s - loss: 2.5697e-04 - val_loss: 0.0092 - 56ms/epoch - 6ms/step\n",
      "Epoch 100/117\n",
      "10/10 - 0s - loss: 2.5253e-04 - val_loss: 0.0092 - 56ms/epoch - 6ms/step\n",
      "Epoch 101/117\n",
      "10/10 - 0s - loss: 2.5234e-04 - val_loss: 0.0094 - 55ms/epoch - 5ms/step\n",
      "Epoch 102/117\n",
      "10/10 - 0s - loss: 2.3375e-04 - val_loss: 0.0091 - 56ms/epoch - 6ms/step\n",
      "Epoch 103/117\n",
      "10/10 - 0s - loss: 2.0972e-04 - val_loss: 0.0091 - 56ms/epoch - 6ms/step\n",
      "Epoch 104/117\n",
      "10/10 - 0s - loss: 2.0466e-04 - val_loss: 0.0092 - 56ms/epoch - 6ms/step\n",
      "Epoch 105/117\n",
      "10/10 - 0s - loss: 2.3129e-04 - val_loss: 0.0091 - 57ms/epoch - 6ms/step\n",
      "Epoch 106/117\n",
      "10/10 - 0s - loss: 2.2138e-04 - val_loss: 0.0091 - 56ms/epoch - 6ms/step\n",
      "Epoch 107/117\n",
      "10/10 - 0s - loss: 1.9563e-04 - val_loss: 0.0091 - 58ms/epoch - 6ms/step\n",
      "Epoch 108/117\n",
      "10/10 - 0s - loss: 2.1118e-04 - val_loss: 0.0092 - 83ms/epoch - 8ms/step\n",
      "Epoch 109/117\n",
      "10/10 - 0s - loss: 2.0367e-04 - val_loss: 0.0091 - 61ms/epoch - 6ms/step\n",
      "Epoch 110/117\n",
      "10/10 - 0s - loss: 2.0812e-04 - val_loss: 0.0091 - 56ms/epoch - 6ms/step\n",
      "Epoch 111/117\n",
      "10/10 - 0s - loss: 1.9232e-04 - val_loss: 0.0092 - 56ms/epoch - 6ms/step\n",
      "Epoch 112/117\n",
      "10/10 - 0s - loss: 2.1404e-04 - val_loss: 0.0091 - 57ms/epoch - 6ms/step\n",
      "Epoch 113/117\n",
      "10/10 - 0s - loss: 2.0562e-04 - val_loss: 0.0093 - 62ms/epoch - 6ms/step\n",
      "Epoch 114/117\n",
      "10/10 - 0s - loss: 1.9223e-04 - val_loss: 0.0092 - 57ms/epoch - 6ms/step\n",
      "Epoch 115/117\n",
      "10/10 - 0s - loss: 1.8894e-04 - val_loss: 0.0092 - 57ms/epoch - 6ms/step\n",
      "Epoch 116/117\n",
      "10/10 - 0s - loss: 2.1994e-04 - val_loss: 0.0092 - 57ms/epoch - 6ms/step\n",
      "Epoch 117/117\n",
      "10/10 - 0s - loss: 2.4200e-04 - val_loss: 0.0093 - 62ms/epoch - 6ms/step\n",
      "9/9 [==============================] - 1s 1ms/step\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-172.4   \u001b[0m | \u001b[0m117.0    \u001b[0m | \u001b[0m1.523    \u001b[0m | \u001b[0m0.006397 \u001b[0m | \u001b[0m29.15    \u001b[0m |\n",
      "Model: \"sequential_135\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_487 (LSTM)             (None, 1, 82)             28864     \n",
      "                                                                 \n",
      " dropout_352 (Dropout)       (None, 1, 82)             0         \n",
      "                                                                 \n",
      " lstm_488 (LSTM)             (None, 1, 82)             54120     \n",
      "                                                                 \n",
      " dropout_353 (Dropout)       (None, 1, 82)             0         \n",
      "                                                                 \n",
      " lstm_489 (LSTM)             (None, 1, 82)             54120     \n",
      "                                                                 \n",
      " dropout_354 (Dropout)       (None, 1, 82)             0         \n",
      "                                                                 \n",
      " lstm_490 (LSTM)             (None, 1, 82)             54120     \n",
      "                                                                 \n",
      " dropout_355 (Dropout)       (None, 1, 82)             0         \n",
      "                                                                 \n",
      " lstm_491 (LSTM)             (None, 82)                54120     \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 1)                 83        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 245,427\n",
      "Trainable params: 245,427\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/142\n",
      "10/10 - 9s - loss: 0.0225 - val_loss: 0.0175 - 9s/epoch - 948ms/step\n",
      "Epoch 2/142\n",
      "10/10 - 0s - loss: 0.0036 - val_loss: 0.0169 - 125ms/epoch - 12ms/step\n",
      "Epoch 3/142\n",
      "10/10 - 0s - loss: 0.0033 - val_loss: 0.0169 - 129ms/epoch - 13ms/step\n",
      "Epoch 4/142\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0168 - 132ms/epoch - 13ms/step\n",
      "Epoch 5/142\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0163 - 129ms/epoch - 13ms/step\n",
      "Epoch 6/142\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0136 - 158ms/epoch - 16ms/step\n",
      "Epoch 7/142\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0090 - 133ms/epoch - 13ms/step\n",
      "Epoch 8/142\n",
      "10/10 - 0s - loss: 8.2703e-04 - val_loss: 0.0083 - 129ms/epoch - 13ms/step\n",
      "Epoch 9/142\n",
      "10/10 - 0s - loss: 5.4785e-04 - val_loss: 0.0085 - 123ms/epoch - 12ms/step\n",
      "Epoch 10/142\n",
      "10/10 - 0s - loss: 4.7337e-04 - val_loss: 0.0083 - 124ms/epoch - 12ms/step\n",
      "Epoch 11/142\n",
      "10/10 - 0s - loss: 4.5426e-04 - val_loss: 0.0081 - 130ms/epoch - 13ms/step\n",
      "Epoch 12/142\n",
      "10/10 - 0s - loss: 4.1172e-04 - val_loss: 0.0080 - 128ms/epoch - 13ms/step\n",
      "Epoch 13/142\n",
      "10/10 - 0s - loss: 3.5704e-04 - val_loss: 0.0080 - 126ms/epoch - 13ms/step\n",
      "Epoch 14/142\n",
      "10/10 - 0s - loss: 3.3066e-04 - val_loss: 0.0079 - 128ms/epoch - 13ms/step\n",
      "Epoch 15/142\n",
      "10/10 - 0s - loss: 3.8400e-04 - val_loss: 0.0079 - 124ms/epoch - 12ms/step\n",
      "Epoch 16/142\n",
      "10/10 - 0s - loss: 3.2843e-04 - val_loss: 0.0079 - 123ms/epoch - 12ms/step\n",
      "Epoch 17/142\n",
      "10/10 - 0s - loss: 3.2070e-04 - val_loss: 0.0078 - 128ms/epoch - 13ms/step\n",
      "Epoch 18/142\n",
      "10/10 - 0s - loss: 3.0267e-04 - val_loss: 0.0079 - 129ms/epoch - 13ms/step\n",
      "Epoch 19/142\n",
      "10/10 - 0s - loss: 3.0651e-04 - val_loss: 0.0078 - 132ms/epoch - 13ms/step\n",
      "Epoch 20/142\n",
      "10/10 - 0s - loss: 3.0300e-04 - val_loss: 0.0080 - 126ms/epoch - 13ms/step\n",
      "Epoch 21/142\n",
      "10/10 - 0s - loss: 3.0913e-04 - val_loss: 0.0080 - 123ms/epoch - 12ms/step\n",
      "Epoch 22/142\n",
      "10/10 - 0s - loss: 3.2116e-04 - val_loss: 0.0081 - 131ms/epoch - 13ms/step\n",
      "Epoch 23/142\n",
      "10/10 - 0s - loss: 3.6075e-04 - val_loss: 0.0078 - 131ms/epoch - 13ms/step\n",
      "Epoch 24/142\n",
      "10/10 - 0s - loss: 3.4696e-04 - val_loss: 0.0081 - 129ms/epoch - 13ms/step\n",
      "Epoch 25/142\n",
      "10/10 - 0s - loss: 2.9632e-04 - val_loss: 0.0078 - 130ms/epoch - 13ms/step\n",
      "Epoch 26/142\n",
      "10/10 - 0s - loss: 3.1035e-04 - val_loss: 0.0079 - 127ms/epoch - 13ms/step\n",
      "Epoch 27/142\n",
      "10/10 - 0s - loss: 2.6242e-04 - val_loss: 0.0079 - 155ms/epoch - 16ms/step\n",
      "Epoch 28/142\n",
      "10/10 - 0s - loss: 2.5433e-04 - val_loss: 0.0079 - 138ms/epoch - 14ms/step\n",
      "Epoch 29/142\n",
      "10/10 - 0s - loss: 2.6545e-04 - val_loss: 0.0079 - 124ms/epoch - 12ms/step\n",
      "Epoch 30/142\n",
      "10/10 - 0s - loss: 2.6051e-04 - val_loss: 0.0079 - 126ms/epoch - 13ms/step\n",
      "Epoch 31/142\n",
      "10/10 - 0s - loss: 2.5163e-04 - val_loss: 0.0080 - 133ms/epoch - 13ms/step\n",
      "Epoch 32/142\n",
      "10/10 - 0s - loss: 3.0112e-04 - val_loss: 0.0080 - 126ms/epoch - 13ms/step\n",
      "Epoch 33/142\n",
      "10/10 - 0s - loss: 3.1227e-04 - val_loss: 0.0081 - 130ms/epoch - 13ms/step\n",
      "Epoch 34/142\n",
      "10/10 - 0s - loss: 3.0858e-04 - val_loss: 0.0084 - 126ms/epoch - 13ms/step\n",
      "Epoch 35/142\n",
      "10/10 - 0s - loss: 3.3767e-04 - val_loss: 0.0080 - 129ms/epoch - 13ms/step\n",
      "Epoch 36/142\n",
      "10/10 - 0s - loss: 3.3236e-04 - val_loss: 0.0084 - 129ms/epoch - 13ms/step\n",
      "Epoch 37/142\n",
      "10/10 - 0s - loss: 3.0755e-04 - val_loss: 0.0082 - 129ms/epoch - 13ms/step\n",
      "Epoch 38/142\n",
      "10/10 - 0s - loss: 2.6060e-04 - val_loss: 0.0084 - 124ms/epoch - 12ms/step\n",
      "Epoch 39/142\n",
      "10/10 - 0s - loss: 2.4629e-04 - val_loss: 0.0086 - 134ms/epoch - 13ms/step\n",
      "Epoch 40/142\n",
      "10/10 - 0s - loss: 2.6681e-04 - val_loss: 0.0084 - 124ms/epoch - 12ms/step\n",
      "Epoch 41/142\n",
      "10/10 - 0s - loss: 2.6480e-04 - val_loss: 0.0084 - 125ms/epoch - 12ms/step\n",
      "Epoch 42/142\n",
      "10/10 - 0s - loss: 2.4833e-04 - val_loss: 0.0086 - 122ms/epoch - 12ms/step\n",
      "Epoch 43/142\n",
      "10/10 - 0s - loss: 2.5170e-04 - val_loss: 0.0086 - 124ms/epoch - 12ms/step\n",
      "Epoch 44/142\n",
      "10/10 - 0s - loss: 2.7978e-04 - val_loss: 0.0087 - 132ms/epoch - 13ms/step\n",
      "Epoch 45/142\n",
      "10/10 - 0s - loss: 2.7773e-04 - val_loss: 0.0087 - 133ms/epoch - 13ms/step\n",
      "Epoch 46/142\n",
      "10/10 - 0s - loss: 2.6023e-04 - val_loss: 0.0087 - 124ms/epoch - 12ms/step\n",
      "Epoch 47/142\n",
      "10/10 - 0s - loss: 2.5936e-04 - val_loss: 0.0087 - 124ms/epoch - 12ms/step\n",
      "Epoch 48/142\n",
      "10/10 - 0s - loss: 2.8192e-04 - val_loss: 0.0089 - 126ms/epoch - 13ms/step\n",
      "Epoch 49/142\n",
      "10/10 - 0s - loss: 2.7784e-04 - val_loss: 0.0089 - 153ms/epoch - 15ms/step\n",
      "Epoch 50/142\n",
      "10/10 - 0s - loss: 3.1301e-04 - val_loss: 0.0091 - 127ms/epoch - 13ms/step\n",
      "Epoch 51/142\n",
      "10/10 - 0s - loss: 2.6511e-04 - val_loss: 0.0093 - 124ms/epoch - 12ms/step\n",
      "Epoch 52/142\n",
      "10/10 - 0s - loss: 2.6380e-04 - val_loss: 0.0097 - 123ms/epoch - 12ms/step\n",
      "Epoch 53/142\n",
      "10/10 - 0s - loss: 2.2081e-04 - val_loss: 0.0097 - 125ms/epoch - 13ms/step\n",
      "Epoch 54/142\n",
      "10/10 - 0s - loss: 2.6309e-04 - val_loss: 0.0100 - 124ms/epoch - 12ms/step\n",
      "Epoch 55/142\n",
      "10/10 - 0s - loss: 2.4359e-04 - val_loss: 0.0100 - 124ms/epoch - 12ms/step\n",
      "Epoch 56/142\n",
      "10/10 - 0s - loss: 2.5572e-04 - val_loss: 0.0101 - 123ms/epoch - 12ms/step\n",
      "Epoch 57/142\n",
      "10/10 - 0s - loss: 2.5732e-04 - val_loss: 0.0100 - 148ms/epoch - 15ms/step\n",
      "Epoch 58/142\n",
      "10/10 - 0s - loss: 2.3900e-04 - val_loss: 0.0102 - 127ms/epoch - 13ms/step\n",
      "Epoch 59/142\n",
      "10/10 - 0s - loss: 2.2676e-04 - val_loss: 0.0103 - 123ms/epoch - 12ms/step\n",
      "Epoch 60/142\n",
      "10/10 - 0s - loss: 2.3084e-04 - val_loss: 0.0103 - 125ms/epoch - 13ms/step\n",
      "Epoch 61/142\n",
      "10/10 - 0s - loss: 2.4382e-04 - val_loss: 0.0102 - 126ms/epoch - 13ms/step\n",
      "Epoch 62/142\n",
      "10/10 - 0s - loss: 2.4652e-04 - val_loss: 0.0107 - 128ms/epoch - 13ms/step\n",
      "Epoch 63/142\n",
      "10/10 - 0s - loss: 2.3235e-04 - val_loss: 0.0107 - 127ms/epoch - 13ms/step\n",
      "Epoch 64/142\n",
      "10/10 - 0s - loss: 2.4513e-04 - val_loss: 0.0109 - 135ms/epoch - 13ms/step\n",
      "Epoch 65/142\n",
      "10/10 - 0s - loss: 2.7132e-04 - val_loss: 0.0110 - 134ms/epoch - 13ms/step\n",
      "Epoch 66/142\n",
      "10/10 - 0s - loss: 2.4686e-04 - val_loss: 0.0110 - 128ms/epoch - 13ms/step\n",
      "Epoch 67/142\n",
      "10/10 - 0s - loss: 2.3843e-04 - val_loss: 0.0113 - 126ms/epoch - 13ms/step\n",
      "Epoch 68/142\n",
      "10/10 - 0s - loss: 2.3659e-04 - val_loss: 0.0111 - 130ms/epoch - 13ms/step\n",
      "Epoch 69/142\n",
      "10/10 - 0s - loss: 2.2934e-04 - val_loss: 0.0114 - 126ms/epoch - 13ms/step\n",
      "Epoch 70/142\n",
      "10/10 - 0s - loss: 2.2932e-04 - val_loss: 0.0118 - 124ms/epoch - 12ms/step\n",
      "Epoch 71/142\n",
      "10/10 - 0s - loss: 2.4827e-04 - val_loss: 0.0120 - 123ms/epoch - 12ms/step\n",
      "Epoch 72/142\n",
      "10/10 - 0s - loss: 2.6648e-04 - val_loss: 0.0117 - 132ms/epoch - 13ms/step\n",
      "Epoch 73/142\n",
      "10/10 - 0s - loss: 2.3215e-04 - val_loss: 0.0118 - 135ms/epoch - 13ms/step\n",
      "Epoch 74/142\n",
      "10/10 - 0s - loss: 2.4203e-04 - val_loss: 0.0122 - 150ms/epoch - 15ms/step\n",
      "Epoch 75/142\n",
      "10/10 - 0s - loss: 2.3330e-04 - val_loss: 0.0116 - 139ms/epoch - 14ms/step\n",
      "Epoch 76/142\n",
      "10/10 - 0s - loss: 2.3612e-04 - val_loss: 0.0116 - 128ms/epoch - 13ms/step\n",
      "Epoch 77/142\n",
      "10/10 - 0s - loss: 2.9826e-04 - val_loss: 0.0121 - 127ms/epoch - 13ms/step\n",
      "Epoch 78/142\n",
      "10/10 - 0s - loss: 2.7675e-04 - val_loss: 0.0126 - 136ms/epoch - 14ms/step\n",
      "Epoch 79/142\n",
      "10/10 - 0s - loss: 2.4568e-04 - val_loss: 0.0129 - 131ms/epoch - 13ms/step\n",
      "Epoch 80/142\n",
      "10/10 - 0s - loss: 3.1231e-04 - val_loss: 0.0128 - 140ms/epoch - 14ms/step\n",
      "Epoch 81/142\n",
      "10/10 - 0s - loss: 2.5526e-04 - val_loss: 0.0122 - 127ms/epoch - 13ms/step\n",
      "Epoch 82/142\n",
      "10/10 - 0s - loss: 2.2009e-04 - val_loss: 0.0126 - 134ms/epoch - 13ms/step\n",
      "Epoch 83/142\n",
      "10/10 - 0s - loss: 1.9766e-04 - val_loss: 0.0121 - 133ms/epoch - 13ms/step\n",
      "Epoch 84/142\n",
      "10/10 - 0s - loss: 2.2076e-04 - val_loss: 0.0122 - 131ms/epoch - 13ms/step\n",
      "Epoch 85/142\n",
      "10/10 - 0s - loss: 2.2169e-04 - val_loss: 0.0127 - 130ms/epoch - 13ms/step\n",
      "Epoch 86/142\n",
      "10/10 - 0s - loss: 1.9488e-04 - val_loss: 0.0126 - 127ms/epoch - 13ms/step\n",
      "Epoch 87/142\n",
      "10/10 - 0s - loss: 2.3729e-04 - val_loss: 0.0124 - 126ms/epoch - 13ms/step\n",
      "Epoch 88/142\n",
      "10/10 - 0s - loss: 2.1244e-04 - val_loss: 0.0127 - 125ms/epoch - 13ms/step\n",
      "Epoch 89/142\n",
      "10/10 - 0s - loss: 2.7817e-04 - val_loss: 0.0127 - 126ms/epoch - 13ms/step\n",
      "Epoch 90/142\n",
      "10/10 - 0s - loss: 2.4024e-04 - val_loss: 0.0128 - 147ms/epoch - 15ms/step\n",
      "Epoch 91/142\n",
      "10/10 - 0s - loss: 2.2562e-04 - val_loss: 0.0125 - 123ms/epoch - 12ms/step\n",
      "Epoch 92/142\n",
      "10/10 - 0s - loss: 2.2311e-04 - val_loss: 0.0127 - 124ms/epoch - 12ms/step\n",
      "Epoch 93/142\n",
      "10/10 - 0s - loss: 2.2417e-04 - val_loss: 0.0123 - 125ms/epoch - 13ms/step\n",
      "Epoch 94/142\n",
      "10/10 - 0s - loss: 2.2163e-04 - val_loss: 0.0126 - 125ms/epoch - 12ms/step\n",
      "Epoch 95/142\n",
      "10/10 - 0s - loss: 2.2090e-04 - val_loss: 0.0128 - 125ms/epoch - 13ms/step\n",
      "Epoch 96/142\n",
      "10/10 - 0s - loss: 2.5010e-04 - val_loss: 0.0125 - 126ms/epoch - 13ms/step\n",
      "Epoch 97/142\n",
      "10/10 - 0s - loss: 2.4418e-04 - val_loss: 0.0129 - 125ms/epoch - 12ms/step\n",
      "Epoch 98/142\n",
      "10/10 - 0s - loss: 3.0562e-04 - val_loss: 0.0128 - 124ms/epoch - 12ms/step\n",
      "Epoch 99/142\n",
      "10/10 - 0s - loss: 2.2728e-04 - val_loss: 0.0127 - 124ms/epoch - 12ms/step\n",
      "Epoch 100/142\n",
      "10/10 - 0s - loss: 2.1820e-04 - val_loss: 0.0130 - 123ms/epoch - 12ms/step\n",
      "Epoch 101/142\n",
      "10/10 - 0s - loss: 2.1506e-04 - val_loss: 0.0130 - 130ms/epoch - 13ms/step\n",
      "Epoch 102/142\n",
      "10/10 - 0s - loss: 2.1116e-04 - val_loss: 0.0128 - 123ms/epoch - 12ms/step\n",
      "Epoch 103/142\n",
      "10/10 - 0s - loss: 2.4555e-04 - val_loss: 0.0129 - 124ms/epoch - 12ms/step\n",
      "Epoch 104/142\n",
      "10/10 - 0s - loss: 2.5510e-04 - val_loss: 0.0130 - 125ms/epoch - 12ms/step\n",
      "Epoch 105/142\n",
      "10/10 - 0s - loss: 2.3984e-04 - val_loss: 0.0128 - 127ms/epoch - 13ms/step\n",
      "Epoch 106/142\n",
      "10/10 - 0s - loss: 2.3211e-04 - val_loss: 0.0126 - 139ms/epoch - 14ms/step\n",
      "Epoch 107/142\n",
      "10/10 - 0s - loss: 2.2831e-04 - val_loss: 0.0127 - 136ms/epoch - 14ms/step\n",
      "Epoch 108/142\n",
      "10/10 - 0s - loss: 2.2432e-04 - val_loss: 0.0128 - 133ms/epoch - 13ms/step\n",
      "Epoch 109/142\n",
      "10/10 - 0s - loss: 2.0887e-04 - val_loss: 0.0126 - 132ms/epoch - 13ms/step\n",
      "Epoch 110/142\n",
      "10/10 - 0s - loss: 2.1444e-04 - val_loss: 0.0130 - 130ms/epoch - 13ms/step\n",
      "Epoch 111/142\n",
      "10/10 - 0s - loss: 2.6138e-04 - val_loss: 0.0128 - 150ms/epoch - 15ms/step\n",
      "Epoch 112/142\n",
      "10/10 - 0s - loss: 2.6995e-04 - val_loss: 0.0128 - 127ms/epoch - 13ms/step\n",
      "Epoch 113/142\n",
      "10/10 - 0s - loss: 2.3593e-04 - val_loss: 0.0126 - 139ms/epoch - 14ms/step\n",
      "Epoch 114/142\n",
      "10/10 - 0s - loss: 2.2315e-04 - val_loss: 0.0125 - 145ms/epoch - 14ms/step\n",
      "Epoch 115/142\n",
      "10/10 - 0s - loss: 2.2562e-04 - val_loss: 0.0127 - 130ms/epoch - 13ms/step\n",
      "Epoch 116/142\n",
      "10/10 - 0s - loss: 2.2068e-04 - val_loss: 0.0131 - 127ms/epoch - 13ms/step\n",
      "Epoch 117/142\n",
      "10/10 - 0s - loss: 2.1617e-04 - val_loss: 0.0127 - 129ms/epoch - 13ms/step\n",
      "Epoch 118/142\n",
      "10/10 - 0s - loss: 2.1418e-04 - val_loss: 0.0131 - 127ms/epoch - 13ms/step\n",
      "Epoch 119/142\n",
      "10/10 - 0s - loss: 2.3166e-04 - val_loss: 0.0128 - 128ms/epoch - 13ms/step\n",
      "Epoch 120/142\n",
      "10/10 - 0s - loss: 2.0416e-04 - val_loss: 0.0126 - 127ms/epoch - 13ms/step\n",
      "Epoch 121/142\n",
      "10/10 - 0s - loss: 2.1196e-04 - val_loss: 0.0131 - 129ms/epoch - 13ms/step\n",
      "Epoch 122/142\n",
      "10/10 - 0s - loss: 2.3454e-04 - val_loss: 0.0130 - 130ms/epoch - 13ms/step\n",
      "Epoch 123/142\n",
      "10/10 - 0s - loss: 2.5742e-04 - val_loss: 0.0128 - 134ms/epoch - 13ms/step\n",
      "Epoch 124/142\n",
      "10/10 - 0s - loss: 2.5006e-04 - val_loss: 0.0129 - 129ms/epoch - 13ms/step\n",
      "Epoch 125/142\n",
      "10/10 - 0s - loss: 2.2745e-04 - val_loss: 0.0131 - 129ms/epoch - 13ms/step\n",
      "Epoch 126/142\n",
      "10/10 - 0s - loss: 2.1592e-04 - val_loss: 0.0129 - 137ms/epoch - 14ms/step\n",
      "Epoch 127/142\n",
      "10/10 - 0s - loss: 2.2476e-04 - val_loss: 0.0128 - 143ms/epoch - 14ms/step\n",
      "Epoch 128/142\n",
      "10/10 - 0s - loss: 2.1804e-04 - val_loss: 0.0128 - 156ms/epoch - 16ms/step\n",
      "Epoch 129/142\n",
      "10/10 - 0s - loss: 2.1993e-04 - val_loss: 0.0129 - 138ms/epoch - 14ms/step\n",
      "Epoch 130/142\n",
      "10/10 - 0s - loss: 2.0673e-04 - val_loss: 0.0129 - 127ms/epoch - 13ms/step\n",
      "Epoch 131/142\n",
      "10/10 - 0s - loss: 2.0350e-04 - val_loss: 0.0129 - 130ms/epoch - 13ms/step\n",
      "Epoch 132/142\n",
      "10/10 - 0s - loss: 2.1398e-04 - val_loss: 0.0131 - 134ms/epoch - 13ms/step\n",
      "Epoch 133/142\n",
      "10/10 - 0s - loss: 2.5035e-04 - val_loss: 0.0127 - 152ms/epoch - 15ms/step\n",
      "Epoch 134/142\n",
      "10/10 - 0s - loss: 2.1049e-04 - val_loss: 0.0130 - 131ms/epoch - 13ms/step\n",
      "Epoch 135/142\n",
      "10/10 - 0s - loss: 2.2379e-04 - val_loss: 0.0134 - 134ms/epoch - 13ms/step\n",
      "Epoch 136/142\n",
      "10/10 - 0s - loss: 2.2593e-04 - val_loss: 0.0132 - 143ms/epoch - 14ms/step\n",
      "Epoch 137/142\n",
      "10/10 - 0s - loss: 2.2904e-04 - val_loss: 0.0131 - 130ms/epoch - 13ms/step\n",
      "Epoch 138/142\n",
      "10/10 - 0s - loss: 2.5902e-04 - val_loss: 0.0129 - 129ms/epoch - 13ms/step\n",
      "Epoch 139/142\n",
      "10/10 - 0s - loss: 2.1515e-04 - val_loss: 0.0132 - 135ms/epoch - 13ms/step\n",
      "Epoch 140/142\n",
      "10/10 - 0s - loss: 2.1986e-04 - val_loss: 0.0133 - 159ms/epoch - 16ms/step\n",
      "Epoch 141/142\n",
      "10/10 - 0s - loss: 2.8524e-04 - val_loss: 0.0130 - 139ms/epoch - 14ms/step\n",
      "Epoch 142/142\n",
      "10/10 - 0s - loss: 3.2513e-04 - val_loss: 0.0134 - 132ms/epoch - 13ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-207.2   \u001b[0m | \u001b[0m142.2    \u001b[0m | \u001b[0m4.426    \u001b[0m | \u001b[0m0.008359 \u001b[0m | \u001b[0m82.46    \u001b[0m |\n",
      "Model: \"sequential_136\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_492 (LSTM)             (None, 1, 18)             1728      \n",
      "                                                                 \n",
      " dropout_356 (Dropout)       (None, 1, 18)             0         \n",
      "                                                                 \n",
      " lstm_493 (LSTM)             (None, 1, 18)             2664      \n",
      "                                                                 \n",
      " dropout_357 (Dropout)       (None, 1, 18)             0         \n",
      "                                                                 \n",
      " lstm_494 (LSTM)             (None, 18)                2664      \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 1)                 19        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,075\n",
      "Trainable params: 7,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/186\n",
      "10/10 - 6s - loss: 0.0348 - val_loss: 0.0152 - 6s/epoch - 575ms/step\n",
      "Epoch 2/186\n",
      "10/10 - 0s - loss: 0.0061 - val_loss: 0.0150 - 68ms/epoch - 7ms/step\n",
      "Epoch 3/186\n",
      "10/10 - 0s - loss: 0.0032 - val_loss: 0.0178 - 67ms/epoch - 7ms/step\n",
      "Epoch 4/186\n",
      "10/10 - 0s - loss: 0.0032 - val_loss: 0.0158 - 66ms/epoch - 7ms/step\n",
      "Epoch 5/186\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0157 - 66ms/epoch - 7ms/step\n",
      "Epoch 6/186\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0160 - 84ms/epoch - 8ms/step\n",
      "Epoch 7/186\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0153 - 93ms/epoch - 9ms/step\n",
      "Epoch 8/186\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0151 - 71ms/epoch - 7ms/step\n",
      "Epoch 9/186\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0145 - 71ms/epoch - 7ms/step\n",
      "Epoch 10/186\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0139 - 66ms/epoch - 7ms/step\n",
      "Epoch 11/186\n",
      "10/10 - 0s - loss: 0.0023 - val_loss: 0.0126 - 67ms/epoch - 7ms/step\n",
      "Epoch 12/186\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0113 - 79ms/epoch - 8ms/step\n",
      "Epoch 13/186\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0096 - 75ms/epoch - 8ms/step\n",
      "Epoch 14/186\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0087 - 69ms/epoch - 7ms/step\n",
      "Epoch 15/186\n",
      "10/10 - 0s - loss: 7.7488e-04 - val_loss: 0.0091 - 70ms/epoch - 7ms/step\n",
      "Epoch 16/186\n",
      "10/10 - 0s - loss: 7.2340e-04 - val_loss: 0.0095 - 68ms/epoch - 7ms/step\n",
      "Epoch 17/186\n",
      "10/10 - 0s - loss: 6.7102e-04 - val_loss: 0.0093 - 67ms/epoch - 7ms/step\n",
      "Epoch 18/186\n",
      "10/10 - 0s - loss: 5.6519e-04 - val_loss: 0.0091 - 75ms/epoch - 8ms/step\n",
      "Epoch 19/186\n",
      "10/10 - 0s - loss: 5.2974e-04 - val_loss: 0.0091 - 71ms/epoch - 7ms/step\n",
      "Epoch 20/186\n",
      "10/10 - 0s - loss: 4.2397e-04 - val_loss: 0.0094 - 68ms/epoch - 7ms/step\n",
      "Epoch 21/186\n",
      "10/10 - 0s - loss: 4.5868e-04 - val_loss: 0.0093 - 66ms/epoch - 7ms/step\n",
      "Epoch 22/186\n",
      "10/10 - 0s - loss: 4.3304e-04 - val_loss: 0.0091 - 68ms/epoch - 7ms/step\n",
      "Epoch 23/186\n",
      "10/10 - 0s - loss: 4.0654e-04 - val_loss: 0.0090 - 94ms/epoch - 9ms/step\n",
      "Epoch 24/186\n",
      "10/10 - 0s - loss: 4.2126e-04 - val_loss: 0.0090 - 80ms/epoch - 8ms/step\n",
      "Epoch 25/186\n",
      "10/10 - 0s - loss: 4.3035e-04 - val_loss: 0.0089 - 69ms/epoch - 7ms/step\n",
      "Epoch 26/186\n",
      "10/10 - 0s - loss: 3.8934e-04 - val_loss: 0.0089 - 68ms/epoch - 7ms/step\n",
      "Epoch 27/186\n",
      "10/10 - 0s - loss: 3.8784e-04 - val_loss: 0.0090 - 65ms/epoch - 7ms/step\n",
      "Epoch 28/186\n",
      "10/10 - 0s - loss: 3.9793e-04 - val_loss: 0.0088 - 67ms/epoch - 7ms/step\n",
      "Epoch 29/186\n",
      "10/10 - 0s - loss: 3.6544e-04 - val_loss: 0.0087 - 66ms/epoch - 7ms/step\n",
      "Epoch 30/186\n",
      "10/10 - 0s - loss: 3.7549e-04 - val_loss: 0.0087 - 75ms/epoch - 8ms/step\n",
      "Epoch 31/186\n",
      "10/10 - 0s - loss: 3.9401e-04 - val_loss: 0.0087 - 72ms/epoch - 7ms/step\n",
      "Epoch 32/186\n",
      "10/10 - 0s - loss: 3.5127e-04 - val_loss: 0.0086 - 75ms/epoch - 8ms/step\n",
      "Epoch 33/186\n",
      "10/10 - 0s - loss: 3.8017e-04 - val_loss: 0.0087 - 76ms/epoch - 8ms/step\n",
      "Epoch 34/186\n",
      "10/10 - 0s - loss: 3.6148e-04 - val_loss: 0.0086 - 80ms/epoch - 8ms/step\n",
      "Epoch 35/186\n",
      "10/10 - 0s - loss: 3.6548e-04 - val_loss: 0.0087 - 68ms/epoch - 7ms/step\n",
      "Epoch 36/186\n",
      "10/10 - 0s - loss: 4.0254e-04 - val_loss: 0.0086 - 80ms/epoch - 8ms/step\n",
      "Epoch 37/186\n",
      "10/10 - 0s - loss: 3.9786e-04 - val_loss: 0.0084 - 70ms/epoch - 7ms/step\n",
      "Epoch 38/186\n",
      "10/10 - 0s - loss: 3.5638e-04 - val_loss: 0.0085 - 69ms/epoch - 7ms/step\n",
      "Epoch 39/186\n",
      "10/10 - 0s - loss: 3.6125e-04 - val_loss: 0.0085 - 70ms/epoch - 7ms/step\n",
      "Epoch 40/186\n",
      "10/10 - 0s - loss: 3.5512e-04 - val_loss: 0.0086 - 70ms/epoch - 7ms/step\n",
      "Epoch 41/186\n",
      "10/10 - 0s - loss: 3.7654e-04 - val_loss: 0.0085 - 66ms/epoch - 7ms/step\n",
      "Epoch 42/186\n",
      "10/10 - 0s - loss: 3.4618e-04 - val_loss: 0.0084 - 110ms/epoch - 11ms/step\n",
      "Epoch 43/186\n",
      "10/10 - 0s - loss: 3.0127e-04 - val_loss: 0.0084 - 67ms/epoch - 7ms/step\n",
      "Epoch 44/186\n",
      "10/10 - 0s - loss: 3.1009e-04 - val_loss: 0.0085 - 66ms/epoch - 7ms/step\n",
      "Epoch 45/186\n",
      "10/10 - 0s - loss: 3.9266e-04 - val_loss: 0.0084 - 64ms/epoch - 6ms/step\n",
      "Epoch 46/186\n",
      "10/10 - 0s - loss: 3.5688e-04 - val_loss: 0.0084 - 66ms/epoch - 7ms/step\n",
      "Epoch 47/186\n",
      "10/10 - 0s - loss: 3.4085e-04 - val_loss: 0.0084 - 64ms/epoch - 6ms/step\n",
      "Epoch 48/186\n",
      "10/10 - 0s - loss: 3.6966e-04 - val_loss: 0.0083 - 75ms/epoch - 8ms/step\n",
      "Epoch 49/186\n",
      "10/10 - 0s - loss: 3.5101e-04 - val_loss: 0.0083 - 65ms/epoch - 7ms/step\n",
      "Epoch 50/186\n",
      "10/10 - 0s - loss: 3.2750e-04 - val_loss: 0.0083 - 66ms/epoch - 7ms/step\n",
      "Epoch 51/186\n",
      "10/10 - 0s - loss: 3.4504e-04 - val_loss: 0.0084 - 67ms/epoch - 7ms/step\n",
      "Epoch 52/186\n",
      "10/10 - 0s - loss: 3.6835e-04 - val_loss: 0.0083 - 70ms/epoch - 7ms/step\n",
      "Epoch 53/186\n",
      "10/10 - 0s - loss: 3.0560e-04 - val_loss: 0.0083 - 77ms/epoch - 8ms/step\n",
      "Epoch 54/186\n",
      "10/10 - 0s - loss: 3.3305e-04 - val_loss: 0.0084 - 86ms/epoch - 9ms/step\n",
      "Epoch 55/186\n",
      "10/10 - 0s - loss: 3.4378e-04 - val_loss: 0.0083 - 67ms/epoch - 7ms/step\n",
      "Epoch 56/186\n",
      "10/10 - 0s - loss: 3.1832e-04 - val_loss: 0.0083 - 65ms/epoch - 6ms/step\n",
      "Epoch 57/186\n",
      "10/10 - 0s - loss: 3.2148e-04 - val_loss: 0.0083 - 64ms/epoch - 6ms/step\n",
      "Epoch 58/186\n",
      "10/10 - 0s - loss: 3.2418e-04 - val_loss: 0.0082 - 65ms/epoch - 6ms/step\n",
      "Epoch 59/186\n",
      "10/10 - 0s - loss: 3.1776e-04 - val_loss: 0.0083 - 64ms/epoch - 6ms/step\n",
      "Epoch 60/186\n",
      "10/10 - 0s - loss: 3.0631e-04 - val_loss: 0.0082 - 76ms/epoch - 8ms/step\n",
      "Epoch 61/186\n",
      "10/10 - 0s - loss: 2.9890e-04 - val_loss: 0.0082 - 65ms/epoch - 7ms/step\n",
      "Epoch 62/186\n",
      "10/10 - 0s - loss: 3.2248e-04 - val_loss: 0.0082 - 67ms/epoch - 7ms/step\n",
      "Epoch 63/186\n",
      "10/10 - 0s - loss: 3.0959e-04 - val_loss: 0.0082 - 64ms/epoch - 6ms/step\n",
      "Epoch 64/186\n",
      "10/10 - 0s - loss: 3.2639e-04 - val_loss: 0.0082 - 64ms/epoch - 6ms/step\n",
      "Epoch 65/186\n",
      "10/10 - 0s - loss: 3.2743e-04 - val_loss: 0.0082 - 64ms/epoch - 6ms/step\n",
      "Epoch 66/186\n",
      "10/10 - 0s - loss: 3.1823e-04 - val_loss: 0.0082 - 73ms/epoch - 7ms/step\n",
      "Epoch 67/186\n",
      "10/10 - 0s - loss: 3.2273e-04 - val_loss: 0.0082 - 64ms/epoch - 6ms/step\n",
      "Epoch 68/186\n",
      "10/10 - 0s - loss: 3.3058e-04 - val_loss: 0.0081 - 65ms/epoch - 7ms/step\n",
      "Epoch 69/186\n",
      "10/10 - 0s - loss: 3.0759e-04 - val_loss: 0.0082 - 65ms/epoch - 7ms/step\n",
      "Epoch 70/186\n",
      "10/10 - 0s - loss: 3.2843e-04 - val_loss: 0.0081 - 64ms/epoch - 6ms/step\n",
      "Epoch 71/186\n",
      "10/10 - 0s - loss: 3.3343e-04 - val_loss: 0.0081 - 89ms/epoch - 9ms/step\n",
      "Epoch 72/186\n",
      "10/10 - 0s - loss: 2.9278e-04 - val_loss: 0.0082 - 77ms/epoch - 8ms/step\n",
      "Epoch 73/186\n",
      "10/10 - 0s - loss: 3.3517e-04 - val_loss: 0.0082 - 66ms/epoch - 7ms/step\n",
      "Epoch 74/186\n",
      "10/10 - 0s - loss: 3.4155e-04 - val_loss: 0.0081 - 64ms/epoch - 6ms/step\n",
      "Epoch 75/186\n",
      "10/10 - 0s - loss: 3.1063e-04 - val_loss: 0.0083 - 65ms/epoch - 7ms/step\n",
      "Epoch 76/186\n",
      "10/10 - 0s - loss: 3.5465e-04 - val_loss: 0.0080 - 69ms/epoch - 7ms/step\n",
      "Epoch 77/186\n",
      "10/10 - 0s - loss: 3.1032e-04 - val_loss: 0.0080 - 65ms/epoch - 7ms/step\n",
      "Epoch 78/186\n",
      "10/10 - 0s - loss: 3.0536e-04 - val_loss: 0.0081 - 72ms/epoch - 7ms/step\n",
      "Epoch 79/186\n",
      "10/10 - 0s - loss: 3.2827e-04 - val_loss: 0.0080 - 67ms/epoch - 7ms/step\n",
      "Epoch 80/186\n",
      "10/10 - 0s - loss: 2.8226e-04 - val_loss: 0.0080 - 63ms/epoch - 6ms/step\n",
      "Epoch 81/186\n",
      "10/10 - 0s - loss: 3.1151e-04 - val_loss: 0.0081 - 66ms/epoch - 7ms/step\n",
      "Epoch 82/186\n",
      "10/10 - 0s - loss: 3.2147e-04 - val_loss: 0.0080 - 64ms/epoch - 6ms/step\n",
      "Epoch 83/186\n",
      "10/10 - 0s - loss: 3.0471e-04 - val_loss: 0.0080 - 65ms/epoch - 7ms/step\n",
      "Epoch 84/186\n",
      "10/10 - 0s - loss: 2.9115e-04 - val_loss: 0.0080 - 70ms/epoch - 7ms/step\n",
      "Epoch 85/186\n",
      "10/10 - 0s - loss: 2.9349e-04 - val_loss: 0.0081 - 65ms/epoch - 6ms/step\n",
      "Epoch 86/186\n",
      "10/10 - 0s - loss: 2.7243e-04 - val_loss: 0.0080 - 64ms/epoch - 6ms/step\n",
      "Epoch 87/186\n",
      "10/10 - 0s - loss: 3.3186e-04 - val_loss: 0.0081 - 64ms/epoch - 6ms/step\n",
      "Epoch 88/186\n",
      "10/10 - 0s - loss: 2.9863e-04 - val_loss: 0.0081 - 65ms/epoch - 7ms/step\n",
      "Epoch 89/186\n",
      "10/10 - 0s - loss: 3.2509e-04 - val_loss: 0.0080 - 64ms/epoch - 6ms/step\n",
      "Epoch 90/186\n",
      "10/10 - 0s - loss: 3.1133e-04 - val_loss: 0.0080 - 74ms/epoch - 7ms/step\n",
      "Epoch 91/186\n",
      "10/10 - 0s - loss: 3.1754e-04 - val_loss: 0.0080 - 65ms/epoch - 7ms/step\n",
      "Epoch 92/186\n",
      "10/10 - 0s - loss: 3.0944e-04 - val_loss: 0.0080 - 87ms/epoch - 9ms/step\n",
      "Epoch 93/186\n",
      "10/10 - 0s - loss: 3.3631e-04 - val_loss: 0.0080 - 65ms/epoch - 7ms/step\n",
      "Epoch 94/186\n",
      "10/10 - 0s - loss: 3.2320e-04 - val_loss: 0.0081 - 65ms/epoch - 7ms/step\n",
      "Epoch 95/186\n",
      "10/10 - 0s - loss: 3.1820e-04 - val_loss: 0.0080 - 66ms/epoch - 7ms/step\n",
      "Epoch 96/186\n",
      "10/10 - 0s - loss: 2.9720e-04 - val_loss: 0.0080 - 73ms/epoch - 7ms/step\n",
      "Epoch 97/186\n",
      "10/10 - 0s - loss: 3.0577e-04 - val_loss: 0.0080 - 65ms/epoch - 7ms/step\n",
      "Epoch 98/186\n",
      "10/10 - 0s - loss: 3.2926e-04 - val_loss: 0.0080 - 66ms/epoch - 7ms/step\n",
      "Epoch 99/186\n",
      "10/10 - 0s - loss: 2.7747e-04 - val_loss: 0.0083 - 67ms/epoch - 7ms/step\n",
      "Epoch 100/186\n",
      "10/10 - 0s - loss: 3.2157e-04 - val_loss: 0.0081 - 64ms/epoch - 6ms/step\n",
      "Epoch 101/186\n",
      "10/10 - 0s - loss: 3.0092e-04 - val_loss: 0.0080 - 65ms/epoch - 6ms/step\n",
      "Epoch 102/186\n",
      "10/10 - 0s - loss: 2.9131e-04 - val_loss: 0.0080 - 71ms/epoch - 7ms/step\n",
      "Epoch 103/186\n",
      "10/10 - 0s - loss: 2.9000e-04 - val_loss: 0.0080 - 64ms/epoch - 6ms/step\n",
      "Epoch 104/186\n",
      "10/10 - 0s - loss: 2.7825e-04 - val_loss: 0.0080 - 64ms/epoch - 6ms/step\n",
      "Epoch 105/186\n",
      "10/10 - 0s - loss: 3.0352e-04 - val_loss: 0.0080 - 65ms/epoch - 6ms/step\n",
      "Epoch 106/186\n",
      "10/10 - 0s - loss: 2.9063e-04 - val_loss: 0.0080 - 66ms/epoch - 7ms/step\n",
      "Epoch 107/186\n",
      "10/10 - 0s - loss: 2.7536e-04 - val_loss: 0.0080 - 70ms/epoch - 7ms/step\n",
      "Epoch 108/186\n",
      "10/10 - 0s - loss: 3.0414e-04 - val_loss: 0.0080 - 112ms/epoch - 11ms/step\n",
      "Epoch 109/186\n",
      "10/10 - 0s - loss: 3.0974e-04 - val_loss: 0.0080 - 92ms/epoch - 9ms/step\n",
      "Epoch 110/186\n",
      "10/10 - 0s - loss: 3.0298e-04 - val_loss: 0.0080 - 78ms/epoch - 8ms/step\n",
      "Epoch 111/186\n",
      "10/10 - 0s - loss: 3.1829e-04 - val_loss: 0.0084 - 74ms/epoch - 7ms/step\n",
      "Epoch 112/186\n",
      "10/10 - 0s - loss: 3.3142e-04 - val_loss: 0.0082 - 70ms/epoch - 7ms/step\n",
      "Epoch 113/186\n",
      "10/10 - 0s - loss: 2.9164e-04 - val_loss: 0.0081 - 70ms/epoch - 7ms/step\n",
      "Epoch 114/186\n",
      "10/10 - 0s - loss: 2.9523e-04 - val_loss: 0.0080 - 75ms/epoch - 8ms/step\n",
      "Epoch 115/186\n",
      "10/10 - 0s - loss: 2.8144e-04 - val_loss: 0.0082 - 67ms/epoch - 7ms/step\n",
      "Epoch 116/186\n",
      "10/10 - 0s - loss: 3.0963e-04 - val_loss: 0.0081 - 65ms/epoch - 6ms/step\n",
      "Epoch 117/186\n",
      "10/10 - 0s - loss: 2.9372e-04 - val_loss: 0.0081 - 65ms/epoch - 6ms/step\n",
      "Epoch 118/186\n",
      "10/10 - 0s - loss: 3.1778e-04 - val_loss: 0.0082 - 65ms/epoch - 6ms/step\n",
      "Epoch 119/186\n",
      "10/10 - 0s - loss: 3.1376e-04 - val_loss: 0.0083 - 66ms/epoch - 7ms/step\n",
      "Epoch 120/186\n",
      "10/10 - 0s - loss: 2.9948e-04 - val_loss: 0.0083 - 64ms/epoch - 6ms/step\n",
      "Epoch 121/186\n",
      "10/10 - 0s - loss: 3.0769e-04 - val_loss: 0.0083 - 73ms/epoch - 7ms/step\n",
      "Epoch 122/186\n",
      "10/10 - 0s - loss: 2.8596e-04 - val_loss: 0.0082 - 64ms/epoch - 6ms/step\n",
      "Epoch 123/186\n",
      "10/10 - 0s - loss: 2.5129e-04 - val_loss: 0.0084 - 66ms/epoch - 7ms/step\n",
      "Epoch 124/186\n",
      "10/10 - 0s - loss: 2.8823e-04 - val_loss: 0.0085 - 65ms/epoch - 7ms/step\n",
      "Epoch 125/186\n",
      "10/10 - 0s - loss: 2.9012e-04 - val_loss: 0.0084 - 64ms/epoch - 6ms/step\n",
      "Epoch 126/186\n",
      "10/10 - 0s - loss: 2.8537e-04 - val_loss: 0.0085 - 64ms/epoch - 6ms/step\n",
      "Epoch 127/186\n",
      "10/10 - 0s - loss: 2.7888e-04 - val_loss: 0.0087 - 83ms/epoch - 8ms/step\n",
      "Epoch 128/186\n",
      "10/10 - 0s - loss: 2.9881e-04 - val_loss: 0.0087 - 81ms/epoch - 8ms/step\n",
      "Epoch 129/186\n",
      "10/10 - 0s - loss: 2.8699e-04 - val_loss: 0.0089 - 66ms/epoch - 7ms/step\n",
      "Epoch 130/186\n",
      "10/10 - 0s - loss: 2.7149e-04 - val_loss: 0.0090 - 64ms/epoch - 6ms/step\n",
      "Epoch 131/186\n",
      "10/10 - 0s - loss: 2.7830e-04 - val_loss: 0.0092 - 64ms/epoch - 6ms/step\n",
      "Epoch 132/186\n",
      "10/10 - 0s - loss: 2.9382e-04 - val_loss: 0.0093 - 66ms/epoch - 7ms/step\n",
      "Epoch 133/186\n",
      "10/10 - 0s - loss: 3.0254e-04 - val_loss: 0.0091 - 65ms/epoch - 7ms/step\n",
      "Epoch 134/186\n",
      "10/10 - 0s - loss: 2.9156e-04 - val_loss: 0.0092 - 76ms/epoch - 8ms/step\n",
      "Epoch 135/186\n",
      "10/10 - 0s - loss: 2.8024e-04 - val_loss: 0.0095 - 66ms/epoch - 7ms/step\n",
      "Epoch 136/186\n",
      "10/10 - 0s - loss: 2.9399e-04 - val_loss: 0.0096 - 65ms/epoch - 7ms/step\n",
      "Epoch 137/186\n",
      "10/10 - 0s - loss: 2.6762e-04 - val_loss: 0.0098 - 65ms/epoch - 7ms/step\n",
      "Epoch 138/186\n",
      "10/10 - 0s - loss: 2.6057e-04 - val_loss: 0.0100 - 64ms/epoch - 6ms/step\n",
      "Epoch 139/186\n",
      "10/10 - 0s - loss: 2.7012e-04 - val_loss: 0.0098 - 65ms/epoch - 7ms/step\n",
      "Epoch 140/186\n",
      "10/10 - 0s - loss: 2.5927e-04 - val_loss: 0.0099 - 69ms/epoch - 7ms/step\n",
      "Epoch 141/186\n",
      "10/10 - 0s - loss: 2.5644e-04 - val_loss: 0.0102 - 76ms/epoch - 8ms/step\n",
      "Epoch 142/186\n",
      "10/10 - 0s - loss: 2.6735e-04 - val_loss: 0.0101 - 66ms/epoch - 7ms/step\n",
      "Epoch 143/186\n",
      "10/10 - 0s - loss: 2.7257e-04 - val_loss: 0.0101 - 70ms/epoch - 7ms/step\n",
      "Epoch 144/186\n",
      "10/10 - 0s - loss: 2.5427e-04 - val_loss: 0.0103 - 101ms/epoch - 10ms/step\n",
      "Epoch 145/186\n",
      "10/10 - 0s - loss: 2.4246e-04 - val_loss: 0.0105 - 72ms/epoch - 7ms/step\n",
      "Epoch 146/186\n",
      "10/10 - 0s - loss: 2.4564e-04 - val_loss: 0.0108 - 71ms/epoch - 7ms/step\n",
      "Epoch 147/186\n",
      "10/10 - 0s - loss: 2.7187e-04 - val_loss: 0.0111 - 85ms/epoch - 8ms/step\n",
      "Epoch 148/186\n",
      "10/10 - 0s - loss: 2.8001e-04 - val_loss: 0.0114 - 66ms/epoch - 7ms/step\n",
      "Epoch 149/186\n",
      "10/10 - 0s - loss: 2.3814e-04 - val_loss: 0.0118 - 64ms/epoch - 6ms/step\n",
      "Epoch 150/186\n",
      "10/10 - 0s - loss: 2.5606e-04 - val_loss: 0.0116 - 63ms/epoch - 6ms/step\n",
      "Epoch 151/186\n",
      "10/10 - 0s - loss: 2.6022e-04 - val_loss: 0.0120 - 64ms/epoch - 6ms/step\n",
      "Epoch 152/186\n",
      "10/10 - 0s - loss: 2.6788e-04 - val_loss: 0.0121 - 64ms/epoch - 6ms/step\n",
      "Epoch 153/186\n",
      "10/10 - 0s - loss: 2.4777e-04 - val_loss: 0.0119 - 64ms/epoch - 6ms/step\n",
      "Epoch 154/186\n",
      "10/10 - 0s - loss: 2.3012e-04 - val_loss: 0.0122 - 79ms/epoch - 8ms/step\n",
      "Epoch 155/186\n",
      "10/10 - 0s - loss: 2.8084e-04 - val_loss: 0.0117 - 66ms/epoch - 7ms/step\n",
      "Epoch 156/186\n",
      "10/10 - 0s - loss: 2.8973e-04 - val_loss: 0.0125 - 65ms/epoch - 6ms/step\n",
      "Epoch 157/186\n",
      "10/10 - 0s - loss: 2.7730e-04 - val_loss: 0.0124 - 65ms/epoch - 7ms/step\n",
      "Epoch 158/186\n",
      "10/10 - 0s - loss: 2.5283e-04 - val_loss: 0.0128 - 64ms/epoch - 6ms/step\n",
      "Epoch 159/186\n",
      "10/10 - 0s - loss: 2.5098e-04 - val_loss: 0.0126 - 68ms/epoch - 7ms/step\n",
      "Epoch 160/186\n",
      "10/10 - 0s - loss: 2.3452e-04 - val_loss: 0.0128 - 71ms/epoch - 7ms/step\n",
      "Epoch 161/186\n",
      "10/10 - 0s - loss: 2.3385e-04 - val_loss: 0.0127 - 89ms/epoch - 9ms/step\n",
      "Epoch 162/186\n",
      "10/10 - 0s - loss: 2.4274e-04 - val_loss: 0.0136 - 71ms/epoch - 7ms/step\n",
      "Epoch 163/186\n",
      "10/10 - 0s - loss: 2.4540e-04 - val_loss: 0.0136 - 63ms/epoch - 6ms/step\n",
      "Epoch 164/186\n",
      "10/10 - 0s - loss: 2.6375e-04 - val_loss: 0.0138 - 65ms/epoch - 7ms/step\n",
      "Epoch 165/186\n",
      "10/10 - 0s - loss: 2.6983e-04 - val_loss: 0.0136 - 64ms/epoch - 6ms/step\n",
      "Epoch 166/186\n",
      "10/10 - 0s - loss: 2.4447e-04 - val_loss: 0.0136 - 65ms/epoch - 6ms/step\n",
      "Epoch 167/186\n",
      "10/10 - 0s - loss: 2.4681e-04 - val_loss: 0.0139 - 75ms/epoch - 8ms/step\n",
      "Epoch 168/186\n",
      "10/10 - 0s - loss: 2.4466e-04 - val_loss: 0.0143 - 64ms/epoch - 6ms/step\n",
      "Epoch 169/186\n",
      "10/10 - 0s - loss: 2.4469e-04 - val_loss: 0.0145 - 64ms/epoch - 6ms/step\n",
      "Epoch 170/186\n",
      "10/10 - 0s - loss: 2.4629e-04 - val_loss: 0.0149 - 64ms/epoch - 6ms/step\n",
      "Epoch 171/186\n",
      "10/10 - 0s - loss: 2.8751e-04 - val_loss: 0.0142 - 67ms/epoch - 7ms/step\n",
      "Epoch 172/186\n",
      "10/10 - 0s - loss: 2.3439e-04 - val_loss: 0.0143 - 67ms/epoch - 7ms/step\n",
      "Epoch 173/186\n",
      "10/10 - 0s - loss: 2.0893e-04 - val_loss: 0.0152 - 74ms/epoch - 7ms/step\n",
      "Epoch 174/186\n",
      "10/10 - 0s - loss: 2.5831e-04 - val_loss: 0.0150 - 64ms/epoch - 6ms/step\n",
      "Epoch 175/186\n",
      "10/10 - 0s - loss: 2.5818e-04 - val_loss: 0.0147 - 65ms/epoch - 7ms/step\n",
      "Epoch 176/186\n",
      "10/10 - 0s - loss: 2.5349e-04 - val_loss: 0.0149 - 63ms/epoch - 6ms/step\n",
      "Epoch 177/186\n",
      "10/10 - 0s - loss: 2.9570e-04 - val_loss: 0.0153 - 65ms/epoch - 7ms/step\n",
      "Epoch 178/186\n",
      "10/10 - 0s - loss: 2.6310e-04 - val_loss: 0.0153 - 66ms/epoch - 7ms/step\n",
      "Epoch 179/186\n",
      "10/10 - 0s - loss: 2.5289e-04 - val_loss: 0.0152 - 75ms/epoch - 8ms/step\n",
      "Epoch 180/186\n",
      "10/10 - 0s - loss: 2.2572e-04 - val_loss: 0.0147 - 65ms/epoch - 7ms/step\n",
      "Epoch 181/186\n",
      "10/10 - 0s - loss: 2.5045e-04 - val_loss: 0.0156 - 70ms/epoch - 7ms/step\n",
      "Epoch 182/186\n",
      "10/10 - 0s - loss: 2.2961e-04 - val_loss: 0.0160 - 89ms/epoch - 9ms/step\n",
      "Epoch 183/186\n",
      "10/10 - 0s - loss: 2.2717e-04 - val_loss: 0.0153 - 76ms/epoch - 8ms/step\n",
      "Epoch 184/186\n",
      "10/10 - 0s - loss: 2.4681e-04 - val_loss: 0.0156 - 73ms/epoch - 7ms/step\n",
      "Epoch 185/186\n",
      "10/10 - 0s - loss: 2.4581e-04 - val_loss: 0.0155 - 64ms/epoch - 6ms/step\n",
      "Epoch 186/186\n",
      "10/10 - 0s - loss: 2.4256e-04 - val_loss: 0.0157 - 68ms/epoch - 7ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-224.5   \u001b[0m | \u001b[0m186.9    \u001b[0m | \u001b[0m2.134    \u001b[0m | \u001b[0m0.006671 \u001b[0m | \u001b[0m18.27    \u001b[0m |\n",
      "Model: \"sequential_137\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_495 (LSTM)             (None, 1, 76)             24928     \n",
      "                                                                 \n",
      " dropout_358 (Dropout)       (None, 1, 76)             0         \n",
      "                                                                 \n",
      " lstm_496 (LSTM)             (None, 1, 76)             46512     \n",
      "                                                                 \n",
      " dropout_359 (Dropout)       (None, 1, 76)             0         \n",
      "                                                                 \n",
      " lstm_497 (LSTM)             (None, 1, 76)             46512     \n",
      "                                                                 \n",
      " dropout_360 (Dropout)       (None, 1, 76)             0         \n",
      "                                                                 \n",
      " lstm_498 (LSTM)             (None, 76)                46512     \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 1)                 77        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164,541\n",
      "Trainable params: 164,541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/176\n",
      "10/10 - 9s - loss: 0.0342 - val_loss: 0.0166 - 9s/epoch - 853ms/step\n",
      "Epoch 2/176\n",
      "10/10 - 0s - loss: 0.0061 - val_loss: 0.0182 - 105ms/epoch - 11ms/step\n",
      "Epoch 3/176\n",
      "10/10 - 0s - loss: 0.0039 - val_loss: 0.0167 - 104ms/epoch - 10ms/step\n",
      "Epoch 4/176\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0161 - 134ms/epoch - 13ms/step\n",
      "Epoch 5/176\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0167 - 105ms/epoch - 11ms/step\n",
      "Epoch 6/176\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0160 - 104ms/epoch - 10ms/step\n",
      "Epoch 7/176\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0157 - 116ms/epoch - 12ms/step\n",
      "Epoch 8/176\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0148 - 105ms/epoch - 11ms/step\n",
      "Epoch 9/176\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0137 - 107ms/epoch - 11ms/step\n",
      "Epoch 10/176\n",
      "10/10 - 0s - loss: 0.0020 - val_loss: 0.0115 - 105ms/epoch - 11ms/step\n",
      "Epoch 11/176\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0092 - 105ms/epoch - 11ms/step\n",
      "Epoch 12/176\n",
      "10/10 - 0s - loss: 8.1822e-04 - val_loss: 0.0086 - 104ms/epoch - 10ms/step\n",
      "Epoch 13/176\n",
      "10/10 - 0s - loss: 6.8319e-04 - val_loss: 0.0087 - 117ms/epoch - 12ms/step\n",
      "Epoch 14/176\n",
      "10/10 - 0s - loss: 5.0525e-04 - val_loss: 0.0085 - 104ms/epoch - 10ms/step\n",
      "Epoch 15/176\n",
      "10/10 - 0s - loss: 5.5242e-04 - val_loss: 0.0086 - 102ms/epoch - 10ms/step\n",
      "Epoch 16/176\n",
      "10/10 - 0s - loss: 5.3734e-04 - val_loss: 0.0086 - 103ms/epoch - 10ms/step\n",
      "Epoch 17/176\n",
      "10/10 - 0s - loss: 4.9190e-04 - val_loss: 0.0085 - 103ms/epoch - 10ms/step\n",
      "Epoch 18/176\n",
      "10/10 - 0s - loss: 4.2444e-04 - val_loss: 0.0084 - 103ms/epoch - 10ms/step\n",
      "Epoch 19/176\n",
      "10/10 - 0s - loss: 3.9532e-04 - val_loss: 0.0084 - 116ms/epoch - 12ms/step\n",
      "Epoch 20/176\n",
      "10/10 - 0s - loss: 4.1704e-04 - val_loss: 0.0084 - 104ms/epoch - 10ms/step\n",
      "Epoch 21/176\n",
      "10/10 - 0s - loss: 3.7891e-04 - val_loss: 0.0084 - 102ms/epoch - 10ms/step\n",
      "Epoch 22/176\n",
      "10/10 - 0s - loss: 4.2867e-04 - val_loss: 0.0083 - 103ms/epoch - 10ms/step\n",
      "Epoch 23/176\n",
      "10/10 - 0s - loss: 3.9388e-04 - val_loss: 0.0083 - 107ms/epoch - 11ms/step\n",
      "Epoch 24/176\n",
      "10/10 - 0s - loss: 3.6783e-04 - val_loss: 0.0085 - 103ms/epoch - 10ms/step\n",
      "Epoch 25/176\n",
      "10/10 - 0s - loss: 3.4286e-04 - val_loss: 0.0084 - 156ms/epoch - 16ms/step\n",
      "Epoch 26/176\n",
      "10/10 - 0s - loss: 3.0264e-04 - val_loss: 0.0083 - 105ms/epoch - 11ms/step\n",
      "Epoch 27/176\n",
      "10/10 - 0s - loss: 3.0031e-04 - val_loss: 0.0084 - 104ms/epoch - 10ms/step\n",
      "Epoch 28/176\n",
      "10/10 - 0s - loss: 2.9156e-04 - val_loss: 0.0083 - 104ms/epoch - 10ms/step\n",
      "Epoch 29/176\n",
      "10/10 - 0s - loss: 3.2922e-04 - val_loss: 0.0084 - 105ms/epoch - 11ms/step\n",
      "Epoch 30/176\n",
      "10/10 - 0s - loss: 3.1041e-04 - val_loss: 0.0083 - 104ms/epoch - 10ms/step\n",
      "Epoch 31/176\n",
      "10/10 - 0s - loss: 3.1510e-04 - val_loss: 0.0084 - 118ms/epoch - 12ms/step\n",
      "Epoch 32/176\n",
      "10/10 - 0s - loss: 3.0232e-04 - val_loss: 0.0081 - 104ms/epoch - 10ms/step\n",
      "Epoch 33/176\n",
      "10/10 - 0s - loss: 2.9032e-04 - val_loss: 0.0083 - 103ms/epoch - 10ms/step\n",
      "Epoch 34/176\n",
      "10/10 - 0s - loss: 2.9481e-04 - val_loss: 0.0083 - 103ms/epoch - 10ms/step\n",
      "Epoch 35/176\n",
      "10/10 - 0s - loss: 3.0037e-04 - val_loss: 0.0084 - 103ms/epoch - 10ms/step\n",
      "Epoch 36/176\n",
      "10/10 - 0s - loss: 2.9980e-04 - val_loss: 0.0082 - 102ms/epoch - 10ms/step\n",
      "Epoch 37/176\n",
      "10/10 - 0s - loss: 3.0923e-04 - val_loss: 0.0082 - 114ms/epoch - 11ms/step\n",
      "Epoch 38/176\n",
      "10/10 - 0s - loss: 2.6334e-04 - val_loss: 0.0083 - 106ms/epoch - 11ms/step\n",
      "Epoch 39/176\n",
      "10/10 - 0s - loss: 2.8957e-04 - val_loss: 0.0082 - 104ms/epoch - 10ms/step\n",
      "Epoch 40/176\n",
      "10/10 - 0s - loss: 2.6465e-04 - val_loss: 0.0082 - 104ms/epoch - 10ms/step\n",
      "Epoch 41/176\n",
      "10/10 - 0s - loss: 2.6864e-04 - val_loss: 0.0083 - 105ms/epoch - 11ms/step\n",
      "Epoch 42/176\n",
      "10/10 - 0s - loss: 2.6830e-04 - val_loss: 0.0081 - 104ms/epoch - 10ms/step\n",
      "Epoch 43/176\n",
      "10/10 - 0s - loss: 2.7706e-04 - val_loss: 0.0082 - 118ms/epoch - 12ms/step\n",
      "Epoch 44/176\n",
      "10/10 - 0s - loss: 2.7822e-04 - val_loss: 0.0082 - 102ms/epoch - 10ms/step\n",
      "Epoch 45/176\n",
      "10/10 - 0s - loss: 2.6687e-04 - val_loss: 0.0081 - 103ms/epoch - 10ms/step\n",
      "Epoch 46/176\n",
      "10/10 - 0s - loss: 2.8046e-04 - val_loss: 0.0082 - 105ms/epoch - 11ms/step\n",
      "Epoch 47/176\n",
      "10/10 - 0s - loss: 2.5680e-04 - val_loss: 0.0082 - 103ms/epoch - 10ms/step\n",
      "Epoch 48/176\n",
      "10/10 - 0s - loss: 2.9230e-04 - val_loss: 0.0082 - 129ms/epoch - 13ms/step\n",
      "Epoch 49/176\n",
      "10/10 - 0s - loss: 2.8031e-04 - val_loss: 0.0083 - 121ms/epoch - 12ms/step\n",
      "Epoch 50/176\n",
      "10/10 - 0s - loss: 2.6665e-04 - val_loss: 0.0081 - 103ms/epoch - 10ms/step\n",
      "Epoch 51/176\n",
      "10/10 - 0s - loss: 2.5543e-04 - val_loss: 0.0081 - 103ms/epoch - 10ms/step\n",
      "Epoch 52/176\n",
      "10/10 - 0s - loss: 2.5454e-04 - val_loss: 0.0082 - 102ms/epoch - 10ms/step\n",
      "Epoch 53/176\n",
      "10/10 - 0s - loss: 2.5856e-04 - val_loss: 0.0081 - 103ms/epoch - 10ms/step\n",
      "Epoch 54/176\n",
      "10/10 - 0s - loss: 2.4208e-04 - val_loss: 0.0083 - 103ms/epoch - 10ms/step\n",
      "Epoch 55/176\n",
      "10/10 - 0s - loss: 2.3216e-04 - val_loss: 0.0082 - 103ms/epoch - 10ms/step\n",
      "Epoch 56/176\n",
      "10/10 - 0s - loss: 2.5614e-04 - val_loss: 0.0083 - 114ms/epoch - 11ms/step\n",
      "Epoch 57/176\n",
      "10/10 - 0s - loss: 2.8592e-04 - val_loss: 0.0081 - 104ms/epoch - 10ms/step\n",
      "Epoch 58/176\n",
      "10/10 - 0s - loss: 2.6344e-04 - val_loss: 0.0083 - 104ms/epoch - 10ms/step\n",
      "Epoch 59/176\n",
      "10/10 - 0s - loss: 2.5027e-04 - val_loss: 0.0081 - 103ms/epoch - 10ms/step\n",
      "Epoch 60/176\n",
      "10/10 - 0s - loss: 2.5289e-04 - val_loss: 0.0082 - 104ms/epoch - 10ms/step\n",
      "Epoch 61/176\n",
      "10/10 - 0s - loss: 2.4913e-04 - val_loss: 0.0082 - 103ms/epoch - 10ms/step\n",
      "Epoch 62/176\n",
      "10/10 - 0s - loss: 2.6373e-04 - val_loss: 0.0081 - 112ms/epoch - 11ms/step\n",
      "Epoch 63/176\n",
      "10/10 - 0s - loss: 2.5126e-04 - val_loss: 0.0082 - 105ms/epoch - 11ms/step\n",
      "Epoch 64/176\n",
      "10/10 - 0s - loss: 2.2690e-04 - val_loss: 0.0081 - 103ms/epoch - 10ms/step\n",
      "Epoch 65/176\n",
      "10/10 - 0s - loss: 2.4676e-04 - val_loss: 0.0082 - 105ms/epoch - 10ms/step\n",
      "Epoch 66/176\n",
      "10/10 - 0s - loss: 2.4346e-04 - val_loss: 0.0082 - 106ms/epoch - 11ms/step\n",
      "Epoch 67/176\n",
      "10/10 - 0s - loss: 2.5191e-04 - val_loss: 0.0082 - 103ms/epoch - 10ms/step\n",
      "Epoch 68/176\n",
      "10/10 - 0s - loss: 2.3409e-04 - val_loss: 0.0081 - 117ms/epoch - 12ms/step\n",
      "Epoch 69/176\n",
      "10/10 - 0s - loss: 2.3959e-04 - val_loss: 0.0083 - 105ms/epoch - 11ms/step\n",
      "Epoch 70/176\n",
      "10/10 - 0s - loss: 2.4013e-04 - val_loss: 0.0082 - 131ms/epoch - 13ms/step\n",
      "Epoch 71/176\n",
      "10/10 - 0s - loss: 2.5108e-04 - val_loss: 0.0082 - 105ms/epoch - 10ms/step\n",
      "Epoch 72/176\n",
      "10/10 - 0s - loss: 2.2936e-04 - val_loss: 0.0082 - 103ms/epoch - 10ms/step\n",
      "Epoch 73/176\n",
      "10/10 - 0s - loss: 2.3970e-04 - val_loss: 0.0083 - 102ms/epoch - 10ms/step\n",
      "Epoch 74/176\n",
      "10/10 - 0s - loss: 2.4417e-04 - val_loss: 0.0084 - 115ms/epoch - 12ms/step\n",
      "Epoch 75/176\n",
      "10/10 - 0s - loss: 2.5687e-04 - val_loss: 0.0082 - 104ms/epoch - 10ms/step\n",
      "Epoch 76/176\n",
      "10/10 - 0s - loss: 2.3238e-04 - val_loss: 0.0082 - 102ms/epoch - 10ms/step\n",
      "Epoch 77/176\n",
      "10/10 - 0s - loss: 2.6185e-04 - val_loss: 0.0082 - 104ms/epoch - 10ms/step\n",
      "Epoch 78/176\n",
      "10/10 - 0s - loss: 2.3810e-04 - val_loss: 0.0082 - 103ms/epoch - 10ms/step\n",
      "Epoch 79/176\n",
      "10/10 - 0s - loss: 2.2863e-04 - val_loss: 0.0084 - 102ms/epoch - 10ms/step\n",
      "Epoch 80/176\n",
      "10/10 - 0s - loss: 2.4351e-04 - val_loss: 0.0082 - 118ms/epoch - 12ms/step\n",
      "Epoch 81/176\n",
      "10/10 - 0s - loss: 2.4521e-04 - val_loss: 0.0084 - 102ms/epoch - 10ms/step\n",
      "Epoch 82/176\n",
      "10/10 - 0s - loss: 2.1673e-04 - val_loss: 0.0082 - 103ms/epoch - 10ms/step\n",
      "Epoch 83/176\n",
      "10/10 - 0s - loss: 2.6267e-04 - val_loss: 0.0083 - 103ms/epoch - 10ms/step\n",
      "Epoch 84/176\n",
      "10/10 - 0s - loss: 2.3885e-04 - val_loss: 0.0083 - 103ms/epoch - 10ms/step\n",
      "Epoch 85/176\n",
      "10/10 - 0s - loss: 2.4916e-04 - val_loss: 0.0083 - 103ms/epoch - 10ms/step\n",
      "Epoch 86/176\n",
      "10/10 - 0s - loss: 2.5583e-04 - val_loss: 0.0082 - 144ms/epoch - 14ms/step\n",
      "Epoch 87/176\n",
      "10/10 - 0s - loss: 2.2321e-04 - val_loss: 0.0083 - 105ms/epoch - 11ms/step\n",
      "Epoch 88/176\n",
      "10/10 - 0s - loss: 2.2963e-04 - val_loss: 0.0082 - 103ms/epoch - 10ms/step\n",
      "Epoch 89/176\n",
      "10/10 - 0s - loss: 2.1887e-04 - val_loss: 0.0082 - 104ms/epoch - 10ms/step\n",
      "Epoch 90/176\n",
      "10/10 - 0s - loss: 2.2811e-04 - val_loss: 0.0083 - 102ms/epoch - 10ms/step\n",
      "Epoch 91/176\n",
      "10/10 - 0s - loss: 2.3037e-04 - val_loss: 0.0082 - 103ms/epoch - 10ms/step\n",
      "Epoch 92/176\n",
      "10/10 - 0s - loss: 2.3303e-04 - val_loss: 0.0084 - 118ms/epoch - 12ms/step\n",
      "Epoch 93/176\n",
      "10/10 - 0s - loss: 2.2902e-04 - val_loss: 0.0083 - 103ms/epoch - 10ms/step\n",
      "Epoch 94/176\n",
      "10/10 - 0s - loss: 2.2851e-04 - val_loss: 0.0083 - 102ms/epoch - 10ms/step\n",
      "Epoch 95/176\n",
      "10/10 - 0s - loss: 2.3646e-04 - val_loss: 0.0084 - 103ms/epoch - 10ms/step\n",
      "Epoch 96/176\n",
      "10/10 - 0s - loss: 2.5701e-04 - val_loss: 0.0083 - 108ms/epoch - 11ms/step\n",
      "Epoch 97/176\n",
      "10/10 - 0s - loss: 2.9484e-04 - val_loss: 0.0084 - 102ms/epoch - 10ms/step\n",
      "Epoch 98/176\n",
      "10/10 - 0s - loss: 2.5323e-04 - val_loss: 0.0082 - 117ms/epoch - 12ms/step\n",
      "Epoch 99/176\n",
      "10/10 - 0s - loss: 2.5812e-04 - val_loss: 0.0082 - 104ms/epoch - 10ms/step\n",
      "Epoch 100/176\n",
      "10/10 - 0s - loss: 2.2606e-04 - val_loss: 0.0083 - 104ms/epoch - 10ms/step\n",
      "Epoch 101/176\n",
      "10/10 - 0s - loss: 2.2911e-04 - val_loss: 0.0083 - 104ms/epoch - 10ms/step\n",
      "Epoch 102/176\n",
      "10/10 - 0s - loss: 2.1743e-04 - val_loss: 0.0083 - 103ms/epoch - 10ms/step\n",
      "Epoch 103/176\n",
      "10/10 - 0s - loss: 2.2917e-04 - val_loss: 0.0083 - 111ms/epoch - 11ms/step\n",
      "Epoch 104/176\n",
      "10/10 - 0s - loss: 2.2182e-04 - val_loss: 0.0083 - 129ms/epoch - 13ms/step\n",
      "Epoch 105/176\n",
      "10/10 - 0s - loss: 2.1840e-04 - val_loss: 0.0083 - 107ms/epoch - 11ms/step\n",
      "Epoch 106/176\n",
      "10/10 - 0s - loss: 2.2508e-04 - val_loss: 0.0083 - 111ms/epoch - 11ms/step\n",
      "Epoch 107/176\n",
      "10/10 - 0s - loss: 2.1514e-04 - val_loss: 0.0084 - 108ms/epoch - 11ms/step\n",
      "Epoch 108/176\n",
      "10/10 - 0s - loss: 2.0508e-04 - val_loss: 0.0083 - 134ms/epoch - 13ms/step\n",
      "Epoch 109/176\n",
      "10/10 - 0s - loss: 2.2048e-04 - val_loss: 0.0083 - 122ms/epoch - 12ms/step\n",
      "Epoch 110/176\n",
      "10/10 - 0s - loss: 2.2090e-04 - val_loss: 0.0084 - 105ms/epoch - 11ms/step\n",
      "Epoch 111/176\n",
      "10/10 - 0s - loss: 2.1660e-04 - val_loss: 0.0083 - 106ms/epoch - 11ms/step\n",
      "Epoch 112/176\n",
      "10/10 - 0s - loss: 2.0230e-04 - val_loss: 0.0084 - 103ms/epoch - 10ms/step\n",
      "Epoch 113/176\n",
      "10/10 - 0s - loss: 2.2660e-04 - val_loss: 0.0083 - 103ms/epoch - 10ms/step\n",
      "Epoch 114/176\n",
      "10/10 - 0s - loss: 2.4539e-04 - val_loss: 0.0083 - 105ms/epoch - 11ms/step\n",
      "Epoch 115/176\n",
      "10/10 - 0s - loss: 2.2964e-04 - val_loss: 0.0083 - 115ms/epoch - 12ms/step\n",
      "Epoch 116/176\n",
      "10/10 - 0s - loss: 2.1095e-04 - val_loss: 0.0084 - 105ms/epoch - 11ms/step\n",
      "Epoch 117/176\n",
      "10/10 - 0s - loss: 2.4829e-04 - val_loss: 0.0082 - 103ms/epoch - 10ms/step\n",
      "Epoch 118/176\n",
      "10/10 - 0s - loss: 2.2705e-04 - val_loss: 0.0083 - 104ms/epoch - 10ms/step\n",
      "Epoch 119/176\n",
      "10/10 - 0s - loss: 2.1279e-04 - val_loss: 0.0083 - 104ms/epoch - 10ms/step\n",
      "Epoch 120/176\n",
      "10/10 - 0s - loss: 2.4288e-04 - val_loss: 0.0083 - 102ms/epoch - 10ms/step\n",
      "Epoch 121/176\n",
      "10/10 - 0s - loss: 2.4599e-04 - val_loss: 0.0085 - 104ms/epoch - 10ms/step\n",
      "Epoch 122/176\n",
      "10/10 - 0s - loss: 2.0835e-04 - val_loss: 0.0083 - 117ms/epoch - 12ms/step\n",
      "Epoch 123/176\n",
      "10/10 - 0s - loss: 2.3693e-04 - val_loss: 0.0084 - 106ms/epoch - 11ms/step\n",
      "Epoch 124/176\n",
      "10/10 - 0s - loss: 2.1156e-04 - val_loss: 0.0083 - 104ms/epoch - 10ms/step\n",
      "Epoch 125/176\n",
      "10/10 - 0s - loss: 2.0603e-04 - val_loss: 0.0084 - 104ms/epoch - 10ms/step\n",
      "Epoch 126/176\n",
      "10/10 - 0s - loss: 1.8778e-04 - val_loss: 0.0083 - 104ms/epoch - 10ms/step\n",
      "Epoch 127/176\n",
      "10/10 - 0s - loss: 2.0637e-04 - val_loss: 0.0083 - 128ms/epoch - 13ms/step\n",
      "Epoch 128/176\n",
      "10/10 - 0s - loss: 2.4080e-04 - val_loss: 0.0084 - 117ms/epoch - 12ms/step\n",
      "Epoch 129/176\n",
      "10/10 - 0s - loss: 2.3484e-04 - val_loss: 0.0083 - 104ms/epoch - 10ms/step\n",
      "Epoch 130/176\n",
      "10/10 - 0s - loss: 2.1178e-04 - val_loss: 0.0084 - 104ms/epoch - 10ms/step\n",
      "Epoch 131/176\n",
      "10/10 - 0s - loss: 2.1080e-04 - val_loss: 0.0083 - 104ms/epoch - 10ms/step\n",
      "Epoch 132/176\n",
      "10/10 - 0s - loss: 2.1711e-04 - val_loss: 0.0084 - 102ms/epoch - 10ms/step\n",
      "Epoch 133/176\n",
      "10/10 - 0s - loss: 2.1214e-04 - val_loss: 0.0084 - 103ms/epoch - 10ms/step\n",
      "Epoch 134/176\n",
      "10/10 - 0s - loss: 2.0991e-04 - val_loss: 0.0084 - 103ms/epoch - 10ms/step\n",
      "Epoch 135/176\n",
      "10/10 - 0s - loss: 2.2380e-04 - val_loss: 0.0086 - 117ms/epoch - 12ms/step\n",
      "Epoch 136/176\n",
      "10/10 - 0s - loss: 2.6264e-04 - val_loss: 0.0083 - 103ms/epoch - 10ms/step\n",
      "Epoch 137/176\n",
      "10/10 - 0s - loss: 2.1238e-04 - val_loss: 0.0085 - 103ms/epoch - 10ms/step\n",
      "Epoch 138/176\n",
      "10/10 - 0s - loss: 2.2095e-04 - val_loss: 0.0084 - 102ms/epoch - 10ms/step\n",
      "Epoch 139/176\n",
      "10/10 - 0s - loss: 2.1293e-04 - val_loss: 0.0084 - 103ms/epoch - 10ms/step\n",
      "Epoch 140/176\n",
      "10/10 - 0s - loss: 2.0915e-04 - val_loss: 0.0084 - 114ms/epoch - 11ms/step\n",
      "Epoch 141/176\n",
      "10/10 - 0s - loss: 2.2538e-04 - val_loss: 0.0084 - 103ms/epoch - 10ms/step\n",
      "Epoch 142/176\n",
      "10/10 - 0s - loss: 2.1616e-04 - val_loss: 0.0084 - 104ms/epoch - 10ms/step\n",
      "Epoch 143/176\n",
      "10/10 - 0s - loss: 2.1645e-04 - val_loss: 0.0084 - 105ms/epoch - 10ms/step\n",
      "Epoch 144/176\n",
      "10/10 - 0s - loss: 2.2117e-04 - val_loss: 0.0084 - 131ms/epoch - 13ms/step\n",
      "Epoch 145/176\n",
      "10/10 - 0s - loss: 2.0452e-04 - val_loss: 0.0085 - 104ms/epoch - 10ms/step\n",
      "Epoch 146/176\n",
      "10/10 - 0s - loss: 2.4128e-04 - val_loss: 0.0083 - 119ms/epoch - 12ms/step\n",
      "Epoch 147/176\n",
      "10/10 - 0s - loss: 2.8259e-04 - val_loss: 0.0085 - 103ms/epoch - 10ms/step\n",
      "Epoch 148/176\n",
      "10/10 - 0s - loss: 2.2670e-04 - val_loss: 0.0084 - 103ms/epoch - 10ms/step\n",
      "Epoch 149/176\n",
      "10/10 - 0s - loss: 2.0914e-04 - val_loss: 0.0083 - 103ms/epoch - 10ms/step\n",
      "Epoch 150/176\n",
      "10/10 - 0s - loss: 2.2582e-04 - val_loss: 0.0084 - 116ms/epoch - 12ms/step\n",
      "Epoch 151/176\n",
      "10/10 - 0s - loss: 2.0782e-04 - val_loss: 0.0085 - 104ms/epoch - 10ms/step\n",
      "Epoch 152/176\n",
      "10/10 - 0s - loss: 2.3397e-04 - val_loss: 0.0084 - 104ms/epoch - 10ms/step\n",
      "Epoch 153/176\n",
      "10/10 - 0s - loss: 2.2043e-04 - val_loss: 0.0085 - 107ms/epoch - 11ms/step\n",
      "Epoch 154/176\n",
      "10/10 - 0s - loss: 2.3004e-04 - val_loss: 0.0085 - 104ms/epoch - 10ms/step\n",
      "Epoch 155/176\n",
      "10/10 - 0s - loss: 2.1336e-04 - val_loss: 0.0083 - 118ms/epoch - 12ms/step\n",
      "Epoch 156/176\n",
      "10/10 - 0s - loss: 2.3330e-04 - val_loss: 0.0085 - 103ms/epoch - 10ms/step\n",
      "Epoch 157/176\n",
      "10/10 - 0s - loss: 2.3317e-04 - val_loss: 0.0084 - 105ms/epoch - 11ms/step\n",
      "Epoch 158/176\n",
      "10/10 - 0s - loss: 2.1958e-04 - val_loss: 0.0084 - 105ms/epoch - 11ms/step\n",
      "Epoch 159/176\n",
      "10/10 - 0s - loss: 2.0307e-04 - val_loss: 0.0084 - 103ms/epoch - 10ms/step\n",
      "Epoch 160/176\n",
      "10/10 - 0s - loss: 2.2503e-04 - val_loss: 0.0085 - 129ms/epoch - 13ms/step\n",
      "Epoch 161/176\n",
      "10/10 - 0s - loss: 2.5607e-04 - val_loss: 0.0084 - 104ms/epoch - 10ms/step\n",
      "Epoch 162/176\n",
      "10/10 - 0s - loss: 2.9750e-04 - val_loss: 0.0086 - 115ms/epoch - 11ms/step\n",
      "Epoch 163/176\n",
      "10/10 - 0s - loss: 2.5761e-04 - val_loss: 0.0083 - 104ms/epoch - 10ms/step\n",
      "Epoch 164/176\n",
      "10/10 - 0s - loss: 2.4571e-04 - val_loss: 0.0085 - 103ms/epoch - 10ms/step\n",
      "Epoch 165/176\n",
      "10/10 - 0s - loss: 2.1623e-04 - val_loss: 0.0084 - 103ms/epoch - 10ms/step\n",
      "Epoch 166/176\n",
      "10/10 - 0s - loss: 2.3773e-04 - val_loss: 0.0083 - 104ms/epoch - 10ms/step\n",
      "Epoch 167/176\n",
      "10/10 - 0s - loss: 2.4841e-04 - val_loss: 0.0085 - 105ms/epoch - 10ms/step\n",
      "Epoch 168/176\n",
      "10/10 - 0s - loss: 2.1391e-04 - val_loss: 0.0085 - 130ms/epoch - 13ms/step\n",
      "Epoch 169/176\n",
      "10/10 - 0s - loss: 2.1101e-04 - val_loss: 0.0084 - 128ms/epoch - 13ms/step\n",
      "Epoch 170/176\n",
      "10/10 - 0s - loss: 1.9880e-04 - val_loss: 0.0084 - 115ms/epoch - 12ms/step\n",
      "Epoch 171/176\n",
      "10/10 - 0s - loss: 2.0385e-04 - val_loss: 0.0085 - 109ms/epoch - 11ms/step\n",
      "Epoch 172/176\n",
      "10/10 - 0s - loss: 2.1926e-04 - val_loss: 0.0084 - 108ms/epoch - 11ms/step\n",
      "Epoch 173/176\n",
      "10/10 - 0s - loss: 2.1988e-04 - val_loss: 0.0084 - 112ms/epoch - 11ms/step\n",
      "Epoch 174/176\n",
      "10/10 - 0s - loss: 2.2142e-04 - val_loss: 0.0085 - 106ms/epoch - 11ms/step\n",
      "Epoch 175/176\n",
      "10/10 - 0s - loss: 2.1255e-04 - val_loss: 0.0084 - 120ms/epoch - 12ms/step\n",
      "Epoch 176/176\n",
      "10/10 - 0s - loss: 2.4131e-04 - val_loss: 0.0084 - 106ms/epoch - 11ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-164.6   \u001b[0m | \u001b[0m176.9    \u001b[0m | \u001b[0m3.967    \u001b[0m | \u001b[0m0.003451 \u001b[0m | \u001b[0m76.56    \u001b[0m |\n",
      "Model: \"sequential_138\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_499 (LSTM)             (None, 1, 115)            55660     \n",
      "                                                                 \n",
      " dropout_361 (Dropout)       (None, 1, 115)            0         \n",
      "                                                                 \n",
      " lstm_500 (LSTM)             (None, 1, 115)            106260    \n",
      "                                                                 \n",
      " dropout_362 (Dropout)       (None, 1, 115)            0         \n",
      "                                                                 \n",
      " lstm_501 (LSTM)             (None, 1, 115)            106260    \n",
      "                                                                 \n",
      " dropout_363 (Dropout)       (None, 1, 115)            0         \n",
      "                                                                 \n",
      " lstm_502 (LSTM)             (None, 115)               106260    \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 1)                 116       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 374,556\n",
      "Trainable params: 374,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/113\n",
      "10/10 - 8s - loss: 0.0216 - val_loss: 0.0187 - 8s/epoch - 786ms/step\n",
      "Epoch 2/113\n",
      "10/10 - 0s - loss: 0.0036 - val_loss: 0.0167 - 136ms/epoch - 14ms/step\n",
      "Epoch 3/113\n",
      "10/10 - 0s - loss: 0.0032 - val_loss: 0.0173 - 132ms/epoch - 13ms/step\n",
      "Epoch 4/113\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0166 - 130ms/epoch - 13ms/step\n",
      "Epoch 5/113\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0163 - 132ms/epoch - 13ms/step\n",
      "Epoch 6/113\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0136 - 152ms/epoch - 15ms/step\n",
      "Epoch 7/113\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0085 - 135ms/epoch - 14ms/step\n",
      "Epoch 8/113\n",
      "10/10 - 0s - loss: 7.7369e-04 - val_loss: 0.0086 - 132ms/epoch - 13ms/step\n",
      "Epoch 9/113\n",
      "10/10 - 0s - loss: 7.1436e-04 - val_loss: 0.0087 - 132ms/epoch - 13ms/step\n",
      "Epoch 10/113\n",
      "10/10 - 0s - loss: 5.5281e-04 - val_loss: 0.0088 - 135ms/epoch - 13ms/step\n",
      "Epoch 11/113\n",
      "10/10 - 0s - loss: 4.7938e-04 - val_loss: 0.0085 - 132ms/epoch - 13ms/step\n",
      "Epoch 12/113\n",
      "10/10 - 0s - loss: 4.3280e-04 - val_loss: 0.0086 - 145ms/epoch - 15ms/step\n",
      "Epoch 13/113\n",
      "10/10 - 0s - loss: 3.3450e-04 - val_loss: 0.0085 - 131ms/epoch - 13ms/step\n",
      "Epoch 14/113\n",
      "10/10 - 0s - loss: 3.2679e-04 - val_loss: 0.0085 - 134ms/epoch - 13ms/step\n",
      "Epoch 15/113\n",
      "10/10 - 0s - loss: 3.2844e-04 - val_loss: 0.0084 - 133ms/epoch - 13ms/step\n",
      "Epoch 16/113\n",
      "10/10 - 0s - loss: 3.1453e-04 - val_loss: 0.0084 - 135ms/epoch - 13ms/step\n",
      "Epoch 17/113\n",
      "10/10 - 0s - loss: 2.8870e-04 - val_loss: 0.0083 - 134ms/epoch - 13ms/step\n",
      "Epoch 18/113\n",
      "10/10 - 0s - loss: 2.8179e-04 - val_loss: 0.0085 - 150ms/epoch - 15ms/step\n",
      "Epoch 19/113\n",
      "10/10 - 0s - loss: 2.8384e-04 - val_loss: 0.0082 - 147ms/epoch - 15ms/step\n",
      "Epoch 20/113\n",
      "10/10 - 0s - loss: 2.5497e-04 - val_loss: 0.0085 - 133ms/epoch - 13ms/step\n",
      "Epoch 21/113\n",
      "10/10 - 0s - loss: 2.7012e-04 - val_loss: 0.0082 - 136ms/epoch - 14ms/step\n",
      "Epoch 22/113\n",
      "10/10 - 0s - loss: 2.7825e-04 - val_loss: 0.0084 - 129ms/epoch - 13ms/step\n",
      "Epoch 23/113\n",
      "10/10 - 0s - loss: 2.9303e-04 - val_loss: 0.0082 - 188ms/epoch - 19ms/step\n",
      "Epoch 24/113\n",
      "10/10 - 0s - loss: 2.7483e-04 - val_loss: 0.0082 - 134ms/epoch - 13ms/step\n",
      "Epoch 25/113\n",
      "10/10 - 0s - loss: 2.7024e-04 - val_loss: 0.0084 - 129ms/epoch - 13ms/step\n",
      "Epoch 26/113\n",
      "10/10 - 0s - loss: 2.9721e-04 - val_loss: 0.0082 - 132ms/epoch - 13ms/step\n",
      "Epoch 27/113\n",
      "10/10 - 0s - loss: 3.1370e-04 - val_loss: 0.0082 - 131ms/epoch - 13ms/step\n",
      "Epoch 28/113\n",
      "10/10 - 0s - loss: 2.3549e-04 - val_loss: 0.0082 - 144ms/epoch - 14ms/step\n",
      "Epoch 29/113\n",
      "10/10 - 0s - loss: 2.5867e-04 - val_loss: 0.0082 - 137ms/epoch - 14ms/step\n",
      "Epoch 30/113\n",
      "10/10 - 0s - loss: 2.5751e-04 - val_loss: 0.0083 - 138ms/epoch - 14ms/step\n",
      "Epoch 31/113\n",
      "10/10 - 0s - loss: 2.6503e-04 - val_loss: 0.0082 - 133ms/epoch - 13ms/step\n",
      "Epoch 32/113\n",
      "10/10 - 0s - loss: 2.5266e-04 - val_loss: 0.0081 - 130ms/epoch - 13ms/step\n",
      "Epoch 33/113\n",
      "10/10 - 0s - loss: 2.5312e-04 - val_loss: 0.0082 - 131ms/epoch - 13ms/step\n",
      "Epoch 34/113\n",
      "10/10 - 0s - loss: 2.4727e-04 - val_loss: 0.0080 - 145ms/epoch - 14ms/step\n",
      "Epoch 35/113\n",
      "10/10 - 0s - loss: 2.4341e-04 - val_loss: 0.0082 - 131ms/epoch - 13ms/step\n",
      "Epoch 36/113\n",
      "10/10 - 0s - loss: 2.3122e-04 - val_loss: 0.0081 - 131ms/epoch - 13ms/step\n",
      "Epoch 37/113\n",
      "10/10 - 0s - loss: 2.3777e-04 - val_loss: 0.0082 - 131ms/epoch - 13ms/step\n",
      "Epoch 38/113\n",
      "10/10 - 0s - loss: 2.3008e-04 - val_loss: 0.0083 - 132ms/epoch - 13ms/step\n",
      "Epoch 39/113\n",
      "10/10 - 0s - loss: 2.3977e-04 - val_loss: 0.0081 - 130ms/epoch - 13ms/step\n",
      "Epoch 40/113\n",
      "10/10 - 0s - loss: 2.2302e-04 - val_loss: 0.0081 - 130ms/epoch - 13ms/step\n",
      "Epoch 41/113\n",
      "10/10 - 0s - loss: 3.0594e-04 - val_loss: 0.0081 - 143ms/epoch - 14ms/step\n",
      "Epoch 42/113\n",
      "10/10 - 0s - loss: 2.5477e-04 - val_loss: 0.0083 - 133ms/epoch - 13ms/step\n",
      "Epoch 43/113\n",
      "10/10 - 0s - loss: 2.9217e-04 - val_loss: 0.0083 - 152ms/epoch - 15ms/step\n",
      "Epoch 44/113\n",
      "10/10 - 0s - loss: 2.8183e-04 - val_loss: 0.0081 - 135ms/epoch - 13ms/step\n",
      "Epoch 45/113\n",
      "10/10 - 0s - loss: 2.3353e-04 - val_loss: 0.0081 - 134ms/epoch - 13ms/step\n",
      "Epoch 46/113\n",
      "10/10 - 0s - loss: 2.6825e-04 - val_loss: 0.0084 - 131ms/epoch - 13ms/step\n",
      "Epoch 47/113\n",
      "10/10 - 0s - loss: 2.9572e-04 - val_loss: 0.0083 - 145ms/epoch - 15ms/step\n",
      "Epoch 48/113\n",
      "10/10 - 0s - loss: 2.3764e-04 - val_loss: 0.0081 - 132ms/epoch - 13ms/step\n",
      "Epoch 49/113\n",
      "10/10 - 0s - loss: 2.2577e-04 - val_loss: 0.0081 - 134ms/epoch - 13ms/step\n",
      "Epoch 50/113\n",
      "10/10 - 0s - loss: 2.3998e-04 - val_loss: 0.0081 - 132ms/epoch - 13ms/step\n",
      "Epoch 51/113\n",
      "10/10 - 0s - loss: 2.4355e-04 - val_loss: 0.0081 - 136ms/epoch - 14ms/step\n",
      "Epoch 52/113\n",
      "10/10 - 0s - loss: 2.7440e-04 - val_loss: 0.0082 - 131ms/epoch - 13ms/step\n",
      "Epoch 53/113\n",
      "10/10 - 0s - loss: 2.5016e-04 - val_loss: 0.0083 - 135ms/epoch - 14ms/step\n",
      "Epoch 54/113\n",
      "10/10 - 0s - loss: 2.1814e-04 - val_loss: 0.0082 - 174ms/epoch - 17ms/step\n",
      "Epoch 55/113\n",
      "10/10 - 0s - loss: 2.3061e-04 - val_loss: 0.0082 - 150ms/epoch - 15ms/step\n",
      "Epoch 56/113\n",
      "10/10 - 0s - loss: 2.2763e-04 - val_loss: 0.0083 - 134ms/epoch - 13ms/step\n",
      "Epoch 57/113\n",
      "10/10 - 0s - loss: 2.3806e-04 - val_loss: 0.0085 - 137ms/epoch - 14ms/step\n",
      "Epoch 58/113\n",
      "10/10 - 0s - loss: 2.7571e-04 - val_loss: 0.0083 - 150ms/epoch - 15ms/step\n",
      "Epoch 59/113\n",
      "10/10 - 0s - loss: 3.3366e-04 - val_loss: 0.0083 - 160ms/epoch - 16ms/step\n",
      "Epoch 60/113\n",
      "10/10 - 0s - loss: 2.4319e-04 - val_loss: 0.0083 - 168ms/epoch - 17ms/step\n",
      "Epoch 61/113\n",
      "10/10 - 0s - loss: 2.3176e-04 - val_loss: 0.0081 - 143ms/epoch - 14ms/step\n",
      "Epoch 62/113\n",
      "10/10 - 0s - loss: 2.2501e-04 - val_loss: 0.0083 - 147ms/epoch - 15ms/step\n",
      "Epoch 63/113\n",
      "10/10 - 0s - loss: 2.8903e-04 - val_loss: 0.0082 - 138ms/epoch - 14ms/step\n",
      "Epoch 64/113\n",
      "10/10 - 0s - loss: 2.3220e-04 - val_loss: 0.0082 - 132ms/epoch - 13ms/step\n",
      "Epoch 65/113\n",
      "10/10 - 0s - loss: 2.1371e-04 - val_loss: 0.0081 - 131ms/epoch - 13ms/step\n",
      "Epoch 66/113\n",
      "10/10 - 0s - loss: 2.2035e-04 - val_loss: 0.0081 - 176ms/epoch - 18ms/step\n",
      "Epoch 67/113\n",
      "10/10 - 0s - loss: 2.7193e-04 - val_loss: 0.0082 - 140ms/epoch - 14ms/step\n",
      "Epoch 68/113\n",
      "10/10 - 0s - loss: 2.5113e-04 - val_loss: 0.0082 - 132ms/epoch - 13ms/step\n",
      "Epoch 69/113\n",
      "10/10 - 0s - loss: 2.0729e-04 - val_loss: 0.0082 - 129ms/epoch - 13ms/step\n",
      "Epoch 70/113\n",
      "10/10 - 0s - loss: 2.0759e-04 - val_loss: 0.0082 - 135ms/epoch - 13ms/step\n",
      "Epoch 71/113\n",
      "10/10 - 0s - loss: 2.4398e-04 - val_loss: 0.0082 - 145ms/epoch - 15ms/step\n",
      "Epoch 72/113\n",
      "10/10 - 0s - loss: 2.3456e-04 - val_loss: 0.0083 - 156ms/epoch - 16ms/step\n",
      "Epoch 73/113\n",
      "10/10 - 0s - loss: 2.2126e-04 - val_loss: 0.0083 - 140ms/epoch - 14ms/step\n",
      "Epoch 74/113\n",
      "10/10 - 0s - loss: 2.1210e-04 - val_loss: 0.0084 - 138ms/epoch - 14ms/step\n",
      "Epoch 75/113\n",
      "10/10 - 0s - loss: 2.2282e-04 - val_loss: 0.0083 - 143ms/epoch - 14ms/step\n",
      "Epoch 76/113\n",
      "10/10 - 0s - loss: 2.1973e-04 - val_loss: 0.0084 - 143ms/epoch - 14ms/step\n",
      "Epoch 77/113\n",
      "10/10 - 0s - loss: 2.2870e-04 - val_loss: 0.0082 - 165ms/epoch - 16ms/step\n",
      "Epoch 78/113\n",
      "10/10 - 0s - loss: 2.0886e-04 - val_loss: 0.0083 - 147ms/epoch - 15ms/step\n",
      "Epoch 79/113\n",
      "10/10 - 0s - loss: 2.3196e-04 - val_loss: 0.0083 - 135ms/epoch - 14ms/step\n",
      "Epoch 80/113\n",
      "10/10 - 0s - loss: 2.5949e-04 - val_loss: 0.0084 - 142ms/epoch - 14ms/step\n",
      "Epoch 81/113\n",
      "10/10 - 0s - loss: 2.3522e-04 - val_loss: 0.0083 - 134ms/epoch - 13ms/step\n",
      "Epoch 82/113\n",
      "10/10 - 0s - loss: 2.3716e-04 - val_loss: 0.0085 - 132ms/epoch - 13ms/step\n",
      "Epoch 83/113\n",
      "10/10 - 0s - loss: 2.3153e-04 - val_loss: 0.0083 - 151ms/epoch - 15ms/step\n",
      "Epoch 84/113\n",
      "10/10 - 0s - loss: 2.1354e-04 - val_loss: 0.0086 - 147ms/epoch - 15ms/step\n",
      "Epoch 85/113\n",
      "10/10 - 0s - loss: 2.2586e-04 - val_loss: 0.0084 - 142ms/epoch - 14ms/step\n",
      "Epoch 86/113\n",
      "10/10 - 0s - loss: 2.0876e-04 - val_loss: 0.0083 - 132ms/epoch - 13ms/step\n",
      "Epoch 87/113\n",
      "10/10 - 0s - loss: 2.0651e-04 - val_loss: 0.0084 - 166ms/epoch - 17ms/step\n",
      "Epoch 88/113\n",
      "10/10 - 0s - loss: 2.1088e-04 - val_loss: 0.0083 - 137ms/epoch - 14ms/step\n",
      "Epoch 89/113\n",
      "10/10 - 0s - loss: 2.0104e-04 - val_loss: 0.0084 - 144ms/epoch - 14ms/step\n",
      "Epoch 90/113\n",
      "10/10 - 0s - loss: 2.1050e-04 - val_loss: 0.0084 - 164ms/epoch - 16ms/step\n",
      "Epoch 91/113\n",
      "10/10 - 0s - loss: 2.5260e-04 - val_loss: 0.0086 - 131ms/epoch - 13ms/step\n",
      "Epoch 92/113\n",
      "10/10 - 0s - loss: 2.2254e-04 - val_loss: 0.0084 - 134ms/epoch - 13ms/step\n",
      "Epoch 93/113\n",
      "10/10 - 0s - loss: 2.2053e-04 - val_loss: 0.0083 - 133ms/epoch - 13ms/step\n",
      "Epoch 94/113\n",
      "10/10 - 0s - loss: 2.2109e-04 - val_loss: 0.0084 - 130ms/epoch - 13ms/step\n",
      "Epoch 95/113\n",
      "10/10 - 0s - loss: 2.0361e-04 - val_loss: 0.0087 - 131ms/epoch - 13ms/step\n",
      "Epoch 96/113\n",
      "10/10 - 0s - loss: 2.1728e-04 - val_loss: 0.0085 - 142ms/epoch - 14ms/step\n",
      "Epoch 97/113\n",
      "10/10 - 0s - loss: 2.4748e-04 - val_loss: 0.0086 - 130ms/epoch - 13ms/step\n",
      "Epoch 98/113\n",
      "10/10 - 0s - loss: 2.3840e-04 - val_loss: 0.0085 - 130ms/epoch - 13ms/step\n",
      "Epoch 99/113\n",
      "10/10 - 0s - loss: 2.0445e-04 - val_loss: 0.0084 - 128ms/epoch - 13ms/step\n",
      "Epoch 100/113\n",
      "10/10 - 0s - loss: 2.4854e-04 - val_loss: 0.0083 - 130ms/epoch - 13ms/step\n",
      "Epoch 101/113\n",
      "10/10 - 0s - loss: 2.0957e-04 - val_loss: 0.0083 - 131ms/epoch - 13ms/step\n",
      "Epoch 102/113\n",
      "10/10 - 0s - loss: 2.2292e-04 - val_loss: 0.0084 - 146ms/epoch - 15ms/step\n",
      "Epoch 103/113\n",
      "10/10 - 0s - loss: 2.3939e-04 - val_loss: 0.0084 - 136ms/epoch - 14ms/step\n",
      "Epoch 104/113\n",
      "10/10 - 0s - loss: 2.3186e-04 - val_loss: 0.0084 - 131ms/epoch - 13ms/step\n",
      "Epoch 105/113\n",
      "10/10 - 0s - loss: 2.1560e-04 - val_loss: 0.0084 - 130ms/epoch - 13ms/step\n",
      "Epoch 106/113\n",
      "10/10 - 0s - loss: 2.2022e-04 - val_loss: 0.0085 - 131ms/epoch - 13ms/step\n",
      "Epoch 107/113\n",
      "10/10 - 0s - loss: 1.9153e-04 - val_loss: 0.0086 - 131ms/epoch - 13ms/step\n",
      "Epoch 108/113\n",
      "10/10 - 0s - loss: 2.1277e-04 - val_loss: 0.0088 - 144ms/epoch - 14ms/step\n",
      "Epoch 109/113\n",
      "10/10 - 0s - loss: 2.1811e-04 - val_loss: 0.0086 - 131ms/epoch - 13ms/step\n",
      "Epoch 110/113\n",
      "10/10 - 0s - loss: 2.0402e-04 - val_loss: 0.0086 - 185ms/epoch - 19ms/step\n",
      "Epoch 111/113\n",
      "10/10 - 0s - loss: 2.3076e-04 - val_loss: 0.0086 - 141ms/epoch - 14ms/step\n",
      "Epoch 112/113\n",
      "10/10 - 0s - loss: 2.5682e-04 - val_loss: 0.0088 - 137ms/epoch - 14ms/step\n",
      "Epoch 113/113\n",
      "10/10 - 0s - loss: 3.3123e-04 - val_loss: 0.0087 - 134ms/epoch - 13ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m-167.2   \u001b[0m | \u001b[0m113.2    \u001b[0m | \u001b[0m3.718    \u001b[0m | \u001b[0m0.006694 \u001b[0m | \u001b[0m115.5    \u001b[0m |\n",
      "Model: \"sequential_139\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_503 (LSTM)             (None, 1, 94)             37600     \n",
      "                                                                 \n",
      " dropout_364 (Dropout)       (None, 1, 94)             0         \n",
      "                                                                 \n",
      " lstm_504 (LSTM)             (None, 94)                71064     \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 1)                 95        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,759\n",
      "Trainable params: 108,759\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/64\n",
      "10/10 - 4s - loss: 0.0675 - val_loss: 0.0880 - 4s/epoch - 394ms/step\n",
      "Epoch 2/64\n",
      "10/10 - 0s - loss: 0.0671 - val_loss: 0.0876 - 75ms/epoch - 8ms/step\n",
      "Epoch 3/64\n",
      "10/10 - 0s - loss: 0.0668 - val_loss: 0.0871 - 76ms/epoch - 8ms/step\n",
      "Epoch 4/64\n",
      "10/10 - 0s - loss: 0.0664 - val_loss: 0.0867 - 74ms/epoch - 7ms/step\n",
      "Epoch 5/64\n",
      "10/10 - 0s - loss: 0.0660 - val_loss: 0.0863 - 75ms/epoch - 7ms/step\n",
      "Epoch 6/64\n",
      "10/10 - 0s - loss: 0.0656 - val_loss: 0.0859 - 85ms/epoch - 9ms/step\n",
      "Epoch 7/64\n",
      "10/10 - 0s - loss: 0.0653 - val_loss: 0.0854 - 75ms/epoch - 8ms/step\n",
      "Epoch 8/64\n",
      "10/10 - 0s - loss: 0.0649 - val_loss: 0.0850 - 78ms/epoch - 8ms/step\n",
      "Epoch 9/64\n",
      "10/10 - 0s - loss: 0.0646 - val_loss: 0.0846 - 75ms/epoch - 7ms/step\n",
      "Epoch 10/64\n",
      "10/10 - 0s - loss: 0.0641 - val_loss: 0.0842 - 78ms/epoch - 8ms/step\n",
      "Epoch 11/64\n",
      "10/10 - 0s - loss: 0.0638 - val_loss: 0.0837 - 111ms/epoch - 11ms/step\n",
      "Epoch 12/64\n",
      "10/10 - 0s - loss: 0.0634 - val_loss: 0.0833 - 87ms/epoch - 9ms/step\n",
      "Epoch 13/64\n",
      "10/10 - 0s - loss: 0.0630 - val_loss: 0.0829 - 77ms/epoch - 8ms/step\n",
      "Epoch 14/64\n",
      "10/10 - 0s - loss: 0.0626 - val_loss: 0.0825 - 78ms/epoch - 8ms/step\n",
      "Epoch 15/64\n",
      "10/10 - 0s - loss: 0.0623 - val_loss: 0.0820 - 75ms/epoch - 8ms/step\n",
      "Epoch 16/64\n",
      "10/10 - 0s - loss: 0.0618 - val_loss: 0.0816 - 89ms/epoch - 9ms/step\n",
      "Epoch 17/64\n",
      "10/10 - 0s - loss: 0.0615 - val_loss: 0.0812 - 80ms/epoch - 8ms/step\n",
      "Epoch 18/64\n",
      "10/10 - 0s - loss: 0.0611 - val_loss: 0.0808 - 78ms/epoch - 8ms/step\n",
      "Epoch 19/64\n",
      "10/10 - 0s - loss: 0.0607 - val_loss: 0.0803 - 78ms/epoch - 8ms/step\n",
      "Epoch 20/64\n",
      "10/10 - 0s - loss: 0.0603 - val_loss: 0.0799 - 77ms/epoch - 8ms/step\n",
      "Epoch 21/64\n",
      "10/10 - 0s - loss: 0.0600 - val_loss: 0.0795 - 93ms/epoch - 9ms/step\n",
      "Epoch 22/64\n",
      "10/10 - 0s - loss: 0.0596 - val_loss: 0.0790 - 83ms/epoch - 8ms/step\n",
      "Epoch 23/64\n",
      "10/10 - 0s - loss: 0.0591 - val_loss: 0.0786 - 84ms/epoch - 8ms/step\n",
      "Epoch 24/64\n",
      "10/10 - 0s - loss: 0.0588 - val_loss: 0.0782 - 84ms/epoch - 8ms/step\n",
      "Epoch 25/64\n",
      "10/10 - 0s - loss: 0.0584 - val_loss: 0.0777 - 116ms/epoch - 12ms/step\n",
      "Epoch 26/64\n",
      "10/10 - 0s - loss: 0.0580 - val_loss: 0.0773 - 102ms/epoch - 10ms/step\n",
      "Epoch 27/64\n",
      "10/10 - 0s - loss: 0.0577 - val_loss: 0.0769 - 82ms/epoch - 8ms/step\n",
      "Epoch 28/64\n",
      "10/10 - 0s - loss: 0.0572 - val_loss: 0.0764 - 84ms/epoch - 8ms/step\n",
      "Epoch 29/64\n",
      "10/10 - 0s - loss: 0.0569 - val_loss: 0.0760 - 82ms/epoch - 8ms/step\n",
      "Epoch 30/64\n",
      "10/10 - 0s - loss: 0.0565 - val_loss: 0.0755 - 79ms/epoch - 8ms/step\n",
      "Epoch 31/64\n",
      "10/10 - 0s - loss: 0.0561 - val_loss: 0.0751 - 92ms/epoch - 9ms/step\n",
      "Epoch 32/64\n",
      "10/10 - 0s - loss: 0.0556 - val_loss: 0.0747 - 78ms/epoch - 8ms/step\n",
      "Epoch 33/64\n",
      "10/10 - 0s - loss: 0.0553 - val_loss: 0.0742 - 78ms/epoch - 8ms/step\n",
      "Epoch 34/64\n",
      "10/10 - 0s - loss: 0.0548 - val_loss: 0.0738 - 79ms/epoch - 8ms/step\n",
      "Epoch 35/64\n",
      "10/10 - 0s - loss: 0.0545 - val_loss: 0.0733 - 79ms/epoch - 8ms/step\n",
      "Epoch 36/64\n",
      "10/10 - 0s - loss: 0.0540 - val_loss: 0.0729 - 96ms/epoch - 10ms/step\n",
      "Epoch 37/64\n",
      "10/10 - 0s - loss: 0.0537 - val_loss: 0.0724 - 79ms/epoch - 8ms/step\n",
      "Epoch 38/64\n",
      "10/10 - 0s - loss: 0.0533 - val_loss: 0.0720 - 76ms/epoch - 8ms/step\n",
      "Epoch 39/64\n",
      "10/10 - 0s - loss: 0.0529 - val_loss: 0.0715 - 90ms/epoch - 9ms/step\n",
      "Epoch 40/64\n",
      "10/10 - 0s - loss: 0.0525 - val_loss: 0.0710 - 87ms/epoch - 9ms/step\n",
      "Epoch 41/64\n",
      "10/10 - 0s - loss: 0.0521 - val_loss: 0.0706 - 91ms/epoch - 9ms/step\n",
      "Epoch 42/64\n",
      "10/10 - 0s - loss: 0.0517 - val_loss: 0.0701 - 84ms/epoch - 8ms/step\n",
      "Epoch 43/64\n",
      "10/10 - 0s - loss: 0.0513 - val_loss: 0.0697 - 82ms/epoch - 8ms/step\n",
      "Epoch 44/64\n",
      "10/10 - 0s - loss: 0.0508 - val_loss: 0.0692 - 78ms/epoch - 8ms/step\n",
      "Epoch 45/64\n",
      "10/10 - 0s - loss: 0.0504 - val_loss: 0.0687 - 75ms/epoch - 7ms/step\n",
      "Epoch 46/64\n",
      "10/10 - 0s - loss: 0.0500 - val_loss: 0.0683 - 90ms/epoch - 9ms/step\n",
      "Epoch 47/64\n",
      "10/10 - 0s - loss: 0.0496 - val_loss: 0.0678 - 80ms/epoch - 8ms/step\n",
      "Epoch 48/64\n",
      "10/10 - 0s - loss: 0.0493 - val_loss: 0.0674 - 91ms/epoch - 9ms/step\n",
      "Epoch 49/64\n",
      "10/10 - 0s - loss: 0.0489 - val_loss: 0.0669 - 82ms/epoch - 8ms/step\n",
      "Epoch 50/64\n",
      "10/10 - 0s - loss: 0.0484 - val_loss: 0.0664 - 79ms/epoch - 8ms/step\n",
      "Epoch 51/64\n",
      "10/10 - 0s - loss: 0.0481 - val_loss: 0.0659 - 84ms/epoch - 8ms/step\n",
      "Epoch 52/64\n",
      "10/10 - 0s - loss: 0.0477 - val_loss: 0.0655 - 76ms/epoch - 8ms/step\n",
      "Epoch 53/64\n",
      "10/10 - 0s - loss: 0.0471 - val_loss: 0.0650 - 75ms/epoch - 8ms/step\n",
      "Epoch 54/64\n",
      "10/10 - 0s - loss: 0.0467 - val_loss: 0.0645 - 76ms/epoch - 8ms/step\n",
      "Epoch 55/64\n",
      "10/10 - 0s - loss: 0.0464 - val_loss: 0.0641 - 78ms/epoch - 8ms/step\n",
      "Epoch 56/64\n",
      "10/10 - 0s - loss: 0.0461 - val_loss: 0.0636 - 90ms/epoch - 9ms/step\n",
      "Epoch 57/64\n",
      "10/10 - 0s - loss: 0.0457 - val_loss: 0.0631 - 76ms/epoch - 8ms/step\n",
      "Epoch 58/64\n",
      "10/10 - 0s - loss: 0.0452 - val_loss: 0.0626 - 76ms/epoch - 8ms/step\n",
      "Epoch 59/64\n",
      "10/10 - 0s - loss: 0.0446 - val_loss: 0.0622 - 74ms/epoch - 7ms/step\n",
      "Epoch 60/64\n",
      "10/10 - 0s - loss: 0.0443 - val_loss: 0.0617 - 103ms/epoch - 10ms/step\n",
      "Epoch 61/64\n",
      "10/10 - 0s - loss: 0.0439 - val_loss: 0.0612 - 86ms/epoch - 9ms/step\n",
      "Epoch 62/64\n",
      "10/10 - 0s - loss: 0.0434 - val_loss: 0.0607 - 76ms/epoch - 8ms/step\n",
      "Epoch 63/64\n",
      "10/10 - 0s - loss: 0.0430 - val_loss: 0.0602 - 74ms/epoch - 7ms/step\n",
      "Epoch 64/64\n",
      "10/10 - 0s - loss: 0.0427 - val_loss: 0.0597 - 77ms/epoch - 8ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m-437.8   \u001b[0m | \u001b[0m64.98    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1e-05    \u001b[0m | \u001b[0m94.64    \u001b[0m |\n",
      "Model: \"sequential_140\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_505 (LSTM)             (None, 1, 127)            67564     \n",
      "                                                                 \n",
      " dropout_365 (Dropout)       (None, 1, 127)            0         \n",
      "                                                                 \n",
      " lstm_506 (LSTM)             (None, 1, 127)            129540    \n",
      "                                                                 \n",
      " dropout_366 (Dropout)       (None, 1, 127)            0         \n",
      "                                                                 \n",
      " lstm_507 (LSTM)             (None, 1, 127)            129540    \n",
      "                                                                 \n",
      " dropout_367 (Dropout)       (None, 1, 127)            0         \n",
      "                                                                 \n",
      " lstm_508 (LSTM)             (None, 1, 127)            129540    \n",
      "                                                                 \n",
      " dropout_368 (Dropout)       (None, 1, 127)            0         \n",
      "                                                                 \n",
      " lstm_509 (LSTM)             (None, 1, 127)            129540    \n",
      "                                                                 \n",
      " dropout_369 (Dropout)       (None, 1, 127)            0         \n",
      "                                                                 \n",
      " lstm_510 (LSTM)             (None, 127)               129540    \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 1)                 128       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 715,392\n",
      "Trainable params: 715,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10/10 - 13s - loss: 0.0188 - val_loss: 0.0193 - 13s/epoch - 1s/step\n",
      "Epoch 2/50\n",
      "10/10 - 0s - loss: 0.0036 - val_loss: 0.0178 - 196ms/epoch - 20ms/step\n",
      "Epoch 3/50\n",
      "10/10 - 0s - loss: 0.0034 - val_loss: 0.0169 - 194ms/epoch - 19ms/step\n",
      "Epoch 4/50\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0167 - 196ms/epoch - 20ms/step\n",
      "Epoch 5/50\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0127 - 195ms/epoch - 20ms/step\n",
      "Epoch 6/50\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0130 - 203ms/epoch - 20ms/step\n",
      "Epoch 7/50\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0110 - 197ms/epoch - 20ms/step\n",
      "Epoch 8/50\n",
      "10/10 - 0s - loss: 9.4014e-04 - val_loss: 0.0083 - 212ms/epoch - 21ms/step\n",
      "Epoch 9/50\n",
      "10/10 - 0s - loss: 5.7031e-04 - val_loss: 0.0082 - 194ms/epoch - 19ms/step\n",
      "Epoch 10/50\n",
      "10/10 - 0s - loss: 5.1645e-04 - val_loss: 0.0080 - 194ms/epoch - 19ms/step\n",
      "Epoch 11/50\n",
      "10/10 - 0s - loss: 3.7254e-04 - val_loss: 0.0079 - 196ms/epoch - 20ms/step\n",
      "Epoch 12/50\n",
      "10/10 - 0s - loss: 3.3278e-04 - val_loss: 0.0079 - 193ms/epoch - 19ms/step\n",
      "Epoch 13/50\n",
      "10/10 - 0s - loss: 2.9951e-04 - val_loss: 0.0079 - 204ms/epoch - 20ms/step\n",
      "Epoch 14/50\n",
      "10/10 - 0s - loss: 2.8925e-04 - val_loss: 0.0077 - 193ms/epoch - 19ms/step\n",
      "Epoch 15/50\n",
      "10/10 - 0s - loss: 3.3446e-04 - val_loss: 0.0080 - 190ms/epoch - 19ms/step\n",
      "Epoch 16/50\n",
      "10/10 - 0s - loss: 3.2799e-04 - val_loss: 0.0078 - 193ms/epoch - 19ms/step\n",
      "Epoch 17/50\n",
      "10/10 - 0s - loss: 3.3801e-04 - val_loss: 0.0083 - 191ms/epoch - 19ms/step\n",
      "Epoch 18/50\n",
      "10/10 - 0s - loss: 3.1122e-04 - val_loss: 0.0079 - 209ms/epoch - 21ms/step\n",
      "Epoch 19/50\n",
      "10/10 - 0s - loss: 2.7705e-04 - val_loss: 0.0080 - 209ms/epoch - 21ms/step\n",
      "Epoch 20/50\n",
      "10/10 - 0s - loss: 2.9202e-04 - val_loss: 0.0079 - 189ms/epoch - 19ms/step\n",
      "Epoch 21/50\n",
      "10/10 - 0s - loss: 2.6973e-04 - val_loss: 0.0081 - 189ms/epoch - 19ms/step\n",
      "Epoch 22/50\n",
      "10/10 - 0s - loss: 2.9820e-04 - val_loss: 0.0081 - 187ms/epoch - 19ms/step\n",
      "Epoch 23/50\n",
      "10/10 - 0s - loss: 2.9440e-04 - val_loss: 0.0079 - 205ms/epoch - 20ms/step\n",
      "Epoch 24/50\n",
      "10/10 - 0s - loss: 3.1066e-04 - val_loss: 0.0083 - 196ms/epoch - 20ms/step\n",
      "Epoch 25/50\n",
      "10/10 - 0s - loss: 2.7272e-04 - val_loss: 0.0081 - 192ms/epoch - 19ms/step\n",
      "Epoch 26/50\n",
      "10/10 - 0s - loss: 2.6578e-04 - val_loss: 0.0081 - 193ms/epoch - 19ms/step\n",
      "Epoch 27/50\n",
      "10/10 - 0s - loss: 3.0775e-04 - val_loss: 0.0090 - 192ms/epoch - 19ms/step\n",
      "Epoch 28/50\n",
      "10/10 - 0s - loss: 3.8148e-04 - val_loss: 0.0082 - 198ms/epoch - 20ms/step\n",
      "Epoch 29/50\n",
      "10/10 - 0s - loss: 3.2353e-04 - val_loss: 0.0081 - 189ms/epoch - 19ms/step\n",
      "Epoch 30/50\n",
      "10/10 - 0s - loss: 3.1573e-04 - val_loss: 0.0087 - 209ms/epoch - 21ms/step\n",
      "Epoch 31/50\n",
      "10/10 - 0s - loss: 2.8224e-04 - val_loss: 0.0083 - 192ms/epoch - 19ms/step\n",
      "Epoch 32/50\n",
      "10/10 - 0s - loss: 3.1736e-04 - val_loss: 0.0086 - 195ms/epoch - 20ms/step\n",
      "Epoch 33/50\n",
      "10/10 - 0s - loss: 3.2389e-04 - val_loss: 0.0087 - 208ms/epoch - 21ms/step\n",
      "Epoch 34/50\n",
      "10/10 - 0s - loss: 2.9585e-04 - val_loss: 0.0094 - 195ms/epoch - 20ms/step\n",
      "Epoch 35/50\n",
      "10/10 - 0s - loss: 3.3573e-04 - val_loss: 0.0095 - 195ms/epoch - 20ms/step\n",
      "Epoch 36/50\n",
      "10/10 - 0s - loss: 2.4713e-04 - val_loss: 0.0095 - 208ms/epoch - 21ms/step\n",
      "Epoch 37/50\n",
      "10/10 - 0s - loss: 2.4695e-04 - val_loss: 0.0096 - 204ms/epoch - 20ms/step\n",
      "Epoch 38/50\n",
      "10/10 - 0s - loss: 2.7454e-04 - val_loss: 0.0102 - 195ms/epoch - 20ms/step\n",
      "Epoch 39/50\n",
      "10/10 - 0s - loss: 2.7255e-04 - val_loss: 0.0100 - 204ms/epoch - 20ms/step\n",
      "Epoch 40/50\n",
      "10/10 - 0s - loss: 2.7884e-04 - val_loss: 0.0102 - 192ms/epoch - 19ms/step\n",
      "Epoch 41/50\n",
      "10/10 - 0s - loss: 2.7495e-04 - val_loss: 0.0103 - 187ms/epoch - 19ms/step\n",
      "Epoch 42/50\n",
      "10/10 - 0s - loss: 2.9178e-04 - val_loss: 0.0105 - 188ms/epoch - 19ms/step\n",
      "Epoch 43/50\n",
      "10/10 - 0s - loss: 2.6760e-04 - val_loss: 0.0112 - 213ms/epoch - 21ms/step\n",
      "Epoch 44/50\n",
      "10/10 - 0s - loss: 3.0305e-04 - val_loss: 0.0112 - 202ms/epoch - 20ms/step\n",
      "Epoch 45/50\n",
      "10/10 - 0s - loss: 3.1536e-04 - val_loss: 0.0120 - 188ms/epoch - 19ms/step\n",
      "Epoch 46/50\n",
      "10/10 - 0s - loss: 3.1077e-04 - val_loss: 0.0116 - 194ms/epoch - 19ms/step\n",
      "Epoch 47/50\n",
      "10/10 - 0s - loss: 2.5679e-04 - val_loss: 0.0115 - 192ms/epoch - 19ms/step\n",
      "Epoch 48/50\n",
      "10/10 - 0s - loss: 2.3644e-04 - val_loss: 0.0124 - 187ms/epoch - 19ms/step\n",
      "Epoch 49/50\n",
      "10/10 - 0s - loss: 2.5941e-04 - val_loss: 0.0116 - 203ms/epoch - 20ms/step\n",
      "Epoch 50/50\n",
      "10/10 - 0s - loss: 2.5012e-04 - val_loss: 0.0123 - 191ms/epoch - 19ms/step\n",
      "9/9 [==============================] - 1s 4ms/step\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m-198.7   \u001b[0m | \u001b[0m50.0     \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m127.9    \u001b[0m |\n",
      "Model: \"sequential_141\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_511 (LSTM)             (None, 1, 96)             39168     \n",
      "                                                                 \n",
      " dropout_370 (Dropout)       (None, 1, 96)             0         \n",
      "                                                                 \n",
      " lstm_512 (LSTM)             (None, 1, 96)             74112     \n",
      "                                                                 \n",
      " dropout_371 (Dropout)       (None, 1, 96)             0         \n",
      "                                                                 \n",
      " lstm_513 (LSTM)             (None, 1, 96)             74112     \n",
      "                                                                 \n",
      " dropout_372 (Dropout)       (None, 1, 96)             0         \n",
      "                                                                 \n",
      " lstm_514 (LSTM)             (None, 1, 96)             74112     \n",
      "                                                                 \n",
      " dropout_373 (Dropout)       (None, 1, 96)             0         \n",
      "                                                                 \n",
      " lstm_515 (LSTM)             (None, 1, 96)             74112     \n",
      "                                                                 \n",
      " dropout_374 (Dropout)       (None, 1, 96)             0         \n",
      "                                                                 \n",
      " lstm_516 (LSTM)             (None, 96)                74112     \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 1)                 97        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 409,825\n",
      "Trainable params: 409,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/104\n",
      "10/10 - 11s - loss: 0.0205 - val_loss: 0.0184 - 11s/epoch - 1s/step\n",
      "Epoch 2/104\n",
      "10/10 - 0s - loss: 0.0035 - val_loss: 0.0168 - 155ms/epoch - 15ms/step\n",
      "Epoch 3/104\n",
      "10/10 - 0s - loss: 0.0032 - val_loss: 0.0169 - 189ms/epoch - 19ms/step\n",
      "Epoch 4/104\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0125 - 155ms/epoch - 15ms/step\n",
      "Epoch 5/104\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0096 - 179ms/epoch - 18ms/step\n",
      "Epoch 6/104\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0087 - 163ms/epoch - 16ms/step\n",
      "Epoch 7/104\n",
      "10/10 - 0s - loss: 7.2772e-04 - val_loss: 0.0087 - 155ms/epoch - 15ms/step\n",
      "Epoch 8/104\n",
      "10/10 - 0s - loss: 5.3777e-04 - val_loss: 0.0088 - 157ms/epoch - 16ms/step\n",
      "Epoch 9/104\n",
      "10/10 - 0s - loss: 5.2457e-04 - val_loss: 0.0078 - 154ms/epoch - 15ms/step\n",
      "Epoch 10/104\n",
      "10/10 - 0s - loss: 4.1253e-04 - val_loss: 0.0081 - 164ms/epoch - 16ms/step\n",
      "Epoch 11/104\n",
      "10/10 - 0s - loss: 3.8522e-04 - val_loss: 0.0081 - 153ms/epoch - 15ms/step\n",
      "Epoch 12/104\n",
      "10/10 - 0s - loss: 3.5511e-04 - val_loss: 0.0081 - 156ms/epoch - 16ms/step\n",
      "Epoch 13/104\n",
      "10/10 - 0s - loss: 3.3812e-04 - val_loss: 0.0087 - 152ms/epoch - 15ms/step\n",
      "Epoch 14/104\n",
      "10/10 - 0s - loss: 3.8260e-04 - val_loss: 0.0080 - 154ms/epoch - 15ms/step\n",
      "Epoch 15/104\n",
      "10/10 - 0s - loss: 3.2874e-04 - val_loss: 0.0080 - 197ms/epoch - 20ms/step\n",
      "Epoch 16/104\n",
      "10/10 - 0s - loss: 3.3150e-04 - val_loss: 0.0083 - 151ms/epoch - 15ms/step\n",
      "Epoch 17/104\n",
      "10/10 - 0s - loss: 3.2491e-04 - val_loss: 0.0079 - 157ms/epoch - 16ms/step\n",
      "Epoch 18/104\n",
      "10/10 - 0s - loss: 3.2700e-04 - val_loss: 0.0083 - 152ms/epoch - 15ms/step\n",
      "Epoch 19/104\n",
      "10/10 - 0s - loss: 3.4897e-04 - val_loss: 0.0085 - 152ms/epoch - 15ms/step\n",
      "Epoch 20/104\n",
      "10/10 - 0s - loss: 3.1656e-04 - val_loss: 0.0089 - 165ms/epoch - 16ms/step\n",
      "Epoch 21/104\n",
      "10/10 - 0s - loss: 3.1706e-04 - val_loss: 0.0089 - 151ms/epoch - 15ms/step\n",
      "Epoch 22/104\n",
      "10/10 - 0s - loss: 3.0796e-04 - val_loss: 0.0086 - 154ms/epoch - 15ms/step\n",
      "Epoch 23/104\n",
      "10/10 - 0s - loss: 3.0568e-04 - val_loss: 0.0086 - 154ms/epoch - 15ms/step\n",
      "Epoch 24/104\n",
      "10/10 - 0s - loss: 3.0653e-04 - val_loss: 0.0089 - 150ms/epoch - 15ms/step\n",
      "Epoch 25/104\n",
      "10/10 - 0s - loss: 2.6237e-04 - val_loss: 0.0092 - 167ms/epoch - 17ms/step\n",
      "Epoch 26/104\n",
      "10/10 - 0s - loss: 2.9083e-04 - val_loss: 0.0092 - 152ms/epoch - 15ms/step\n",
      "Epoch 27/104\n",
      "10/10 - 0s - loss: 2.8465e-04 - val_loss: 0.0099 - 152ms/epoch - 15ms/step\n",
      "Epoch 28/104\n",
      "10/10 - 0s - loss: 2.6194e-04 - val_loss: 0.0100 - 177ms/epoch - 18ms/step\n",
      "Epoch 29/104\n",
      "10/10 - 0s - loss: 2.6005e-04 - val_loss: 0.0101 - 153ms/epoch - 15ms/step\n",
      "Epoch 30/104\n",
      "10/10 - 0s - loss: 2.7498e-04 - val_loss: 0.0098 - 169ms/epoch - 17ms/step\n",
      "Epoch 31/104\n",
      "10/10 - 0s - loss: 4.0739e-04 - val_loss: 0.0111 - 155ms/epoch - 16ms/step\n",
      "Epoch 32/104\n",
      "10/10 - 0s - loss: 3.2779e-04 - val_loss: 0.0114 - 151ms/epoch - 15ms/step\n",
      "Epoch 33/104\n",
      "10/10 - 0s - loss: 3.0981e-04 - val_loss: 0.0113 - 153ms/epoch - 15ms/step\n",
      "Epoch 34/104\n",
      "10/10 - 0s - loss: 2.5799e-04 - val_loss: 0.0116 - 154ms/epoch - 15ms/step\n",
      "Epoch 35/104\n",
      "10/10 - 0s - loss: 2.8152e-04 - val_loss: 0.0116 - 177ms/epoch - 18ms/step\n",
      "Epoch 36/104\n",
      "10/10 - 0s - loss: 2.6165e-04 - val_loss: 0.0117 - 156ms/epoch - 16ms/step\n",
      "Epoch 37/104\n",
      "10/10 - 0s - loss: 2.8948e-04 - val_loss: 0.0120 - 156ms/epoch - 16ms/step\n",
      "Epoch 38/104\n",
      "10/10 - 0s - loss: 2.4361e-04 - val_loss: 0.0116 - 155ms/epoch - 16ms/step\n",
      "Epoch 39/104\n",
      "10/10 - 0s - loss: 2.4997e-04 - val_loss: 0.0118 - 155ms/epoch - 16ms/step\n",
      "Epoch 40/104\n",
      "10/10 - 0s - loss: 2.5343e-04 - val_loss: 0.0121 - 167ms/epoch - 17ms/step\n",
      "Epoch 41/104\n",
      "10/10 - 0s - loss: 2.3721e-04 - val_loss: 0.0117 - 156ms/epoch - 16ms/step\n",
      "Epoch 42/104\n",
      "10/10 - 0s - loss: 2.8284e-04 - val_loss: 0.0122 - 167ms/epoch - 17ms/step\n",
      "Epoch 43/104\n",
      "10/10 - 0s - loss: 2.6291e-04 - val_loss: 0.0122 - 154ms/epoch - 15ms/step\n",
      "Epoch 44/104\n",
      "10/10 - 0s - loss: 2.7314e-04 - val_loss: 0.0122 - 173ms/epoch - 17ms/step\n",
      "Epoch 45/104\n",
      "10/10 - 0s - loss: 3.0234e-04 - val_loss: 0.0122 - 174ms/epoch - 17ms/step\n",
      "Epoch 46/104\n",
      "10/10 - 0s - loss: 3.2697e-04 - val_loss: 0.0127 - 168ms/epoch - 17ms/step\n",
      "Epoch 47/104\n",
      "10/10 - 0s - loss: 3.7132e-04 - val_loss: 0.0124 - 169ms/epoch - 17ms/step\n",
      "Epoch 48/104\n",
      "10/10 - 0s - loss: 3.3041e-04 - val_loss: 0.0124 - 159ms/epoch - 16ms/step\n",
      "Epoch 49/104\n",
      "10/10 - 0s - loss: 3.0041e-04 - val_loss: 0.0125 - 152ms/epoch - 15ms/step\n",
      "Epoch 50/104\n",
      "10/10 - 0s - loss: 2.9912e-04 - val_loss: 0.0127 - 167ms/epoch - 17ms/step\n",
      "Epoch 51/104\n",
      "10/10 - 0s - loss: 2.6205e-04 - val_loss: 0.0119 - 163ms/epoch - 16ms/step\n",
      "Epoch 52/104\n",
      "10/10 - 0s - loss: 2.3886e-04 - val_loss: 0.0121 - 166ms/epoch - 17ms/step\n",
      "Epoch 53/104\n",
      "10/10 - 0s - loss: 2.3997e-04 - val_loss: 0.0123 - 155ms/epoch - 16ms/step\n",
      "Epoch 54/104\n",
      "10/10 - 0s - loss: 2.6245e-04 - val_loss: 0.0118 - 155ms/epoch - 15ms/step\n",
      "Epoch 55/104\n",
      "10/10 - 0s - loss: 2.7095e-04 - val_loss: 0.0125 - 176ms/epoch - 18ms/step\n",
      "Epoch 56/104\n",
      "10/10 - 0s - loss: 2.6608e-04 - val_loss: 0.0122 - 154ms/epoch - 15ms/step\n",
      "Epoch 57/104\n",
      "10/10 - 0s - loss: 2.4528e-04 - val_loss: 0.0125 - 159ms/epoch - 16ms/step\n",
      "Epoch 58/104\n",
      "10/10 - 0s - loss: 2.3539e-04 - val_loss: 0.0124 - 163ms/epoch - 16ms/step\n",
      "Epoch 59/104\n",
      "10/10 - 0s - loss: 2.5801e-04 - val_loss: 0.0119 - 165ms/epoch - 16ms/step\n",
      "Epoch 60/104\n",
      "10/10 - 0s - loss: 2.4956e-04 - val_loss: 0.0121 - 188ms/epoch - 19ms/step\n",
      "Epoch 61/104\n",
      "10/10 - 0s - loss: 2.4751e-04 - val_loss: 0.0127 - 179ms/epoch - 18ms/step\n",
      "Epoch 62/104\n",
      "10/10 - 0s - loss: 2.5245e-04 - val_loss: 0.0121 - 161ms/epoch - 16ms/step\n",
      "Epoch 63/104\n",
      "10/10 - 0s - loss: 2.7710e-04 - val_loss: 0.0129 - 152ms/epoch - 15ms/step\n",
      "Epoch 64/104\n",
      "10/10 - 0s - loss: 2.3802e-04 - val_loss: 0.0119 - 153ms/epoch - 15ms/step\n",
      "Epoch 65/104\n",
      "10/10 - 0s - loss: 2.4922e-04 - val_loss: 0.0126 - 156ms/epoch - 16ms/step\n",
      "Epoch 66/104\n",
      "10/10 - 0s - loss: 2.6066e-04 - val_loss: 0.0118 - 172ms/epoch - 17ms/step\n",
      "Epoch 67/104\n",
      "10/10 - 0s - loss: 2.7511e-04 - val_loss: 0.0120 - 161ms/epoch - 16ms/step\n",
      "Epoch 68/104\n",
      "10/10 - 0s - loss: 2.4965e-04 - val_loss: 0.0125 - 176ms/epoch - 18ms/step\n",
      "Epoch 69/104\n",
      "10/10 - 0s - loss: 2.2523e-04 - val_loss: 0.0123 - 181ms/epoch - 18ms/step\n",
      "Epoch 70/104\n",
      "10/10 - 0s - loss: 2.5703e-04 - val_loss: 0.0122 - 166ms/epoch - 17ms/step\n",
      "Epoch 71/104\n",
      "10/10 - 0s - loss: 3.4772e-04 - val_loss: 0.0125 - 215ms/epoch - 21ms/step\n",
      "Epoch 72/104\n",
      "10/10 - 0s - loss: 3.1876e-04 - val_loss: 0.0127 - 180ms/epoch - 18ms/step\n",
      "Epoch 73/104\n",
      "10/10 - 0s - loss: 2.4855e-04 - val_loss: 0.0129 - 161ms/epoch - 16ms/step\n",
      "Epoch 74/104\n",
      "10/10 - 0s - loss: 2.2044e-04 - val_loss: 0.0126 - 158ms/epoch - 16ms/step\n",
      "Epoch 75/104\n",
      "10/10 - 0s - loss: 2.3582e-04 - val_loss: 0.0127 - 159ms/epoch - 16ms/step\n",
      "Epoch 76/104\n",
      "10/10 - 0s - loss: 2.6342e-04 - val_loss: 0.0126 - 183ms/epoch - 18ms/step\n",
      "Epoch 77/104\n",
      "10/10 - 0s - loss: 2.4026e-04 - val_loss: 0.0123 - 158ms/epoch - 16ms/step\n",
      "Epoch 78/104\n",
      "10/10 - 0s - loss: 2.5325e-04 - val_loss: 0.0124 - 156ms/epoch - 16ms/step\n",
      "Epoch 79/104\n",
      "10/10 - 0s - loss: 2.3119e-04 - val_loss: 0.0121 - 157ms/epoch - 16ms/step\n",
      "Epoch 80/104\n",
      "10/10 - 0s - loss: 2.5031e-04 - val_loss: 0.0125 - 159ms/epoch - 16ms/step\n",
      "Epoch 81/104\n",
      "10/10 - 0s - loss: 2.7901e-04 - val_loss: 0.0126 - 170ms/epoch - 17ms/step\n",
      "Epoch 82/104\n",
      "10/10 - 0s - loss: 3.0256e-04 - val_loss: 0.0125 - 157ms/epoch - 16ms/step\n",
      "Epoch 83/104\n",
      "10/10 - 0s - loss: 2.7349e-04 - val_loss: 0.0130 - 154ms/epoch - 15ms/step\n",
      "Epoch 84/104\n",
      "10/10 - 0s - loss: 2.5684e-04 - val_loss: 0.0126 - 161ms/epoch - 16ms/step\n",
      "Epoch 85/104\n",
      "10/10 - 0s - loss: 2.4294e-04 - val_loss: 0.0127 - 181ms/epoch - 18ms/step\n",
      "Epoch 86/104\n",
      "10/10 - 0s - loss: 2.6577e-04 - val_loss: 0.0128 - 173ms/epoch - 17ms/step\n",
      "Epoch 87/104\n",
      "10/10 - 0s - loss: 2.5095e-04 - val_loss: 0.0132 - 178ms/epoch - 18ms/step\n",
      "Epoch 88/104\n",
      "10/10 - 0s - loss: 2.4721e-04 - val_loss: 0.0129 - 157ms/epoch - 16ms/step\n",
      "Epoch 89/104\n",
      "10/10 - 0s - loss: 2.3219e-04 - val_loss: 0.0127 - 155ms/epoch - 15ms/step\n",
      "Epoch 90/104\n",
      "10/10 - 0s - loss: 2.3882e-04 - val_loss: 0.0121 - 153ms/epoch - 15ms/step\n",
      "Epoch 91/104\n",
      "10/10 - 0s - loss: 2.3493e-04 - val_loss: 0.0125 - 155ms/epoch - 15ms/step\n",
      "Epoch 92/104\n",
      "10/10 - 0s - loss: 2.8371e-04 - val_loss: 0.0126 - 175ms/epoch - 17ms/step\n",
      "Epoch 93/104\n",
      "10/10 - 0s - loss: 2.7254e-04 - val_loss: 0.0123 - 163ms/epoch - 16ms/step\n",
      "Epoch 94/104\n",
      "10/10 - 0s - loss: 2.2736e-04 - val_loss: 0.0126 - 156ms/epoch - 16ms/step\n",
      "Epoch 95/104\n",
      "10/10 - 0s - loss: 2.4069e-04 - val_loss: 0.0122 - 162ms/epoch - 16ms/step\n",
      "Epoch 96/104\n",
      "10/10 - 0s - loss: 2.5169e-04 - val_loss: 0.0129 - 155ms/epoch - 16ms/step\n",
      "Epoch 97/104\n",
      "10/10 - 0s - loss: 2.3858e-04 - val_loss: 0.0123 - 170ms/epoch - 17ms/step\n",
      "Epoch 98/104\n",
      "10/10 - 0s - loss: 2.6270e-04 - val_loss: 0.0127 - 157ms/epoch - 16ms/step\n",
      "Epoch 99/104\n",
      "10/10 - 0s - loss: 2.6315e-04 - val_loss: 0.0127 - 159ms/epoch - 16ms/step\n",
      "Epoch 100/104\n",
      "10/10 - 0s - loss: 2.2250e-04 - val_loss: 0.0131 - 188ms/epoch - 19ms/step\n",
      "Epoch 101/104\n",
      "10/10 - 0s - loss: 2.4987e-04 - val_loss: 0.0130 - 162ms/epoch - 16ms/step\n",
      "Epoch 102/104\n",
      "10/10 - 0s - loss: 2.2448e-04 - val_loss: 0.0129 - 172ms/epoch - 17ms/step\n",
      "Epoch 103/104\n",
      "10/10 - 0s - loss: 2.4092e-04 - val_loss: 0.0131 - 161ms/epoch - 16ms/step\n",
      "Epoch 104/104\n",
      "10/10 - 0s - loss: 2.2513e-04 - val_loss: 0.0125 - 154ms/epoch - 15ms/step\n",
      "9/9 [==============================] - 1s 3ms/step\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m-199.9   \u001b[0m | \u001b[0m104.9    \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m96.85    \u001b[0m |\n",
      "Model: \"sequential_142\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_517 (LSTM)             (None, 1, 59)             15340     \n",
      "                                                                 \n",
      " dropout_375 (Dropout)       (None, 1, 59)             0         \n",
      "                                                                 \n",
      " lstm_518 (LSTM)             (None, 59)                28084     \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 1)                 60        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,484\n",
      "Trainable params: 43,484\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/180\n",
      "10/10 - 4s - loss: 0.0707 - val_loss: 0.0917 - 4s/epoch - 389ms/step\n",
      "Epoch 2/180\n",
      "10/10 - 0s - loss: 0.0703 - val_loss: 0.0914 - 68ms/epoch - 7ms/step\n",
      "Epoch 3/180\n",
      "10/10 - 0s - loss: 0.0700 - val_loss: 0.0910 - 68ms/epoch - 7ms/step\n",
      "Epoch 4/180\n",
      "10/10 - 0s - loss: 0.0696 - val_loss: 0.0907 - 67ms/epoch - 7ms/step\n",
      "Epoch 5/180\n",
      "10/10 - 0s - loss: 0.0693 - val_loss: 0.0903 - 80ms/epoch - 8ms/step\n",
      "Epoch 6/180\n",
      "10/10 - 0s - loss: 0.0691 - val_loss: 0.0900 - 68ms/epoch - 7ms/step\n",
      "Epoch 7/180\n",
      "10/10 - 0s - loss: 0.0687 - val_loss: 0.0896 - 69ms/epoch - 7ms/step\n",
      "Epoch 8/180\n",
      "10/10 - 0s - loss: 0.0683 - val_loss: 0.0893 - 68ms/epoch - 7ms/step\n",
      "Epoch 9/180\n",
      "10/10 - 0s - loss: 0.0682 - val_loss: 0.0889 - 68ms/epoch - 7ms/step\n",
      "Epoch 10/180\n",
      "10/10 - 0s - loss: 0.0678 - val_loss: 0.0886 - 78ms/epoch - 8ms/step\n",
      "Epoch 11/180\n",
      "10/10 - 0s - loss: 0.0675 - val_loss: 0.0883 - 68ms/epoch - 7ms/step\n",
      "Epoch 12/180\n",
      "10/10 - 0s - loss: 0.0671 - val_loss: 0.0879 - 68ms/epoch - 7ms/step\n",
      "Epoch 13/180\n",
      "10/10 - 0s - loss: 0.0669 - val_loss: 0.0876 - 71ms/epoch - 7ms/step\n",
      "Epoch 14/180\n",
      "10/10 - 0s - loss: 0.0666 - val_loss: 0.0872 - 69ms/epoch - 7ms/step\n",
      "Epoch 15/180\n",
      "10/10 - 0s - loss: 0.0662 - val_loss: 0.0869 - 75ms/epoch - 7ms/step\n",
      "Epoch 16/180\n",
      "10/10 - 0s - loss: 0.0659 - val_loss: 0.0865 - 71ms/epoch - 7ms/step\n",
      "Epoch 17/180\n",
      "10/10 - 0s - loss: 0.0656 - val_loss: 0.0862 - 68ms/epoch - 7ms/step\n",
      "Epoch 18/180\n",
      "10/10 - 0s - loss: 0.0653 - val_loss: 0.0859 - 68ms/epoch - 7ms/step\n",
      "Epoch 19/180\n",
      "10/10 - 0s - loss: 0.0650 - val_loss: 0.0855 - 69ms/epoch - 7ms/step\n",
      "Epoch 20/180\n",
      "10/10 - 0s - loss: 0.0647 - val_loss: 0.0852 - 69ms/epoch - 7ms/step\n",
      "Epoch 21/180\n",
      "10/10 - 0s - loss: 0.0644 - val_loss: 0.0849 - 109ms/epoch - 11ms/step\n",
      "Epoch 22/180\n",
      "10/10 - 0s - loss: 0.0642 - val_loss: 0.0845 - 74ms/epoch - 7ms/step\n",
      "Epoch 23/180\n",
      "10/10 - 0s - loss: 0.0638 - val_loss: 0.0842 - 66ms/epoch - 7ms/step\n",
      "Epoch 24/180\n",
      "10/10 - 0s - loss: 0.0635 - val_loss: 0.0838 - 70ms/epoch - 7ms/step\n",
      "Epoch 25/180\n",
      "10/10 - 0s - loss: 0.0633 - val_loss: 0.0835 - 78ms/epoch - 8ms/step\n",
      "Epoch 26/180\n",
      "10/10 - 0s - loss: 0.0629 - val_loss: 0.0832 - 82ms/epoch - 8ms/step\n",
      "Epoch 27/180\n",
      "10/10 - 0s - loss: 0.0627 - val_loss: 0.0828 - 70ms/epoch - 7ms/step\n",
      "Epoch 28/180\n",
      "10/10 - 0s - loss: 0.0622 - val_loss: 0.0825 - 67ms/epoch - 7ms/step\n",
      "Epoch 29/180\n",
      "10/10 - 0s - loss: 0.0619 - val_loss: 0.0821 - 68ms/epoch - 7ms/step\n",
      "Epoch 30/180\n",
      "10/10 - 0s - loss: 0.0616 - val_loss: 0.0818 - 66ms/epoch - 7ms/step\n",
      "Epoch 31/180\n",
      "10/10 - 0s - loss: 0.0614 - val_loss: 0.0815 - 81ms/epoch - 8ms/step\n",
      "Epoch 32/180\n",
      "10/10 - 0s - loss: 0.0610 - val_loss: 0.0811 - 67ms/epoch - 7ms/step\n",
      "Epoch 33/180\n",
      "10/10 - 0s - loss: 0.0607 - val_loss: 0.0808 - 66ms/epoch - 7ms/step\n",
      "Epoch 34/180\n",
      "10/10 - 0s - loss: 0.0604 - val_loss: 0.0804 - 67ms/epoch - 7ms/step\n",
      "Epoch 35/180\n",
      "10/10 - 0s - loss: 0.0602 - val_loss: 0.0801 - 68ms/epoch - 7ms/step\n",
      "Epoch 36/180\n",
      "10/10 - 0s - loss: 0.0599 - val_loss: 0.0798 - 76ms/epoch - 8ms/step\n",
      "Epoch 37/180\n",
      "10/10 - 0s - loss: 0.0594 - val_loss: 0.0794 - 73ms/epoch - 7ms/step\n",
      "Epoch 38/180\n",
      "10/10 - 0s - loss: 0.0593 - val_loss: 0.0791 - 73ms/epoch - 7ms/step\n",
      "Epoch 39/180\n",
      "10/10 - 0s - loss: 0.0589 - val_loss: 0.0787 - 69ms/epoch - 7ms/step\n",
      "Epoch 40/180\n",
      "10/10 - 0s - loss: 0.0587 - val_loss: 0.0784 - 69ms/epoch - 7ms/step\n",
      "Epoch 41/180\n",
      "10/10 - 0s - loss: 0.0583 - val_loss: 0.0781 - 123ms/epoch - 12ms/step\n",
      "Epoch 42/180\n",
      "10/10 - 0s - loss: 0.0580 - val_loss: 0.0777 - 70ms/epoch - 7ms/step\n",
      "Epoch 43/180\n",
      "10/10 - 0s - loss: 0.0577 - val_loss: 0.0774 - 67ms/epoch - 7ms/step\n",
      "Epoch 44/180\n",
      "10/10 - 0s - loss: 0.0574 - val_loss: 0.0770 - 69ms/epoch - 7ms/step\n",
      "Epoch 45/180\n",
      "10/10 - 0s - loss: 0.0571 - val_loss: 0.0767 - 66ms/epoch - 7ms/step\n",
      "Epoch 46/180\n",
      "10/10 - 0s - loss: 0.0568 - val_loss: 0.0763 - 77ms/epoch - 8ms/step\n",
      "Epoch 47/180\n",
      "10/10 - 0s - loss: 0.0564 - val_loss: 0.0760 - 68ms/epoch - 7ms/step\n",
      "Epoch 48/180\n",
      "10/10 - 0s - loss: 0.0561 - val_loss: 0.0756 - 66ms/epoch - 7ms/step\n",
      "Epoch 49/180\n",
      "10/10 - 0s - loss: 0.0557 - val_loss: 0.0753 - 65ms/epoch - 6ms/step\n",
      "Epoch 50/180\n",
      "10/10 - 0s - loss: 0.0556 - val_loss: 0.0749 - 69ms/epoch - 7ms/step\n",
      "Epoch 51/180\n",
      "10/10 - 0s - loss: 0.0551 - val_loss: 0.0746 - 78ms/epoch - 8ms/step\n",
      "Epoch 52/180\n",
      "10/10 - 0s - loss: 0.0549 - val_loss: 0.0742 - 67ms/epoch - 7ms/step\n",
      "Epoch 53/180\n",
      "10/10 - 0s - loss: 0.0546 - val_loss: 0.0739 - 66ms/epoch - 7ms/step\n",
      "Epoch 54/180\n",
      "10/10 - 0s - loss: 0.0543 - val_loss: 0.0735 - 66ms/epoch - 7ms/step\n",
      "Epoch 55/180\n",
      "10/10 - 0s - loss: 0.0540 - val_loss: 0.0732 - 66ms/epoch - 7ms/step\n",
      "Epoch 56/180\n",
      "10/10 - 0s - loss: 0.0537 - val_loss: 0.0728 - 77ms/epoch - 8ms/step\n",
      "Epoch 57/180\n",
      "10/10 - 0s - loss: 0.0534 - val_loss: 0.0725 - 67ms/epoch - 7ms/step\n",
      "Epoch 58/180\n",
      "10/10 - 0s - loss: 0.0529 - val_loss: 0.0721 - 70ms/epoch - 7ms/step\n",
      "Epoch 59/180\n",
      "10/10 - 0s - loss: 0.0526 - val_loss: 0.0717 - 66ms/epoch - 7ms/step\n",
      "Epoch 60/180\n",
      "10/10 - 0s - loss: 0.0523 - val_loss: 0.0714 - 107ms/epoch - 11ms/step\n",
      "Epoch 61/180\n",
      "10/10 - 0s - loss: 0.0521 - val_loss: 0.0710 - 76ms/epoch - 8ms/step\n",
      "Epoch 62/180\n",
      "10/10 - 0s - loss: 0.0518 - val_loss: 0.0707 - 68ms/epoch - 7ms/step\n",
      "Epoch 63/180\n",
      "10/10 - 0s - loss: 0.0515 - val_loss: 0.0703 - 70ms/epoch - 7ms/step\n",
      "Epoch 64/180\n",
      "10/10 - 0s - loss: 0.0512 - val_loss: 0.0699 - 75ms/epoch - 8ms/step\n",
      "Epoch 65/180\n",
      "10/10 - 0s - loss: 0.0508 - val_loss: 0.0696 - 68ms/epoch - 7ms/step\n",
      "Epoch 66/180\n",
      "10/10 - 0s - loss: 0.0503 - val_loss: 0.0692 - 67ms/epoch - 7ms/step\n",
      "Epoch 67/180\n",
      "10/10 - 0s - loss: 0.0501 - val_loss: 0.0689 - 68ms/epoch - 7ms/step\n",
      "Epoch 68/180\n",
      "10/10 - 0s - loss: 0.0498 - val_loss: 0.0685 - 69ms/epoch - 7ms/step\n",
      "Epoch 69/180\n",
      "10/10 - 0s - loss: 0.0494 - val_loss: 0.0681 - 81ms/epoch - 8ms/step\n",
      "Epoch 70/180\n",
      "10/10 - 0s - loss: 0.0493 - val_loss: 0.0678 - 68ms/epoch - 7ms/step\n",
      "Epoch 71/180\n",
      "10/10 - 0s - loss: 0.0488 - val_loss: 0.0674 - 71ms/epoch - 7ms/step\n",
      "Epoch 72/180\n",
      "10/10 - 0s - loss: 0.0485 - val_loss: 0.0670 - 67ms/epoch - 7ms/step\n",
      "Epoch 73/180\n",
      "10/10 - 0s - loss: 0.0481 - val_loss: 0.0667 - 67ms/epoch - 7ms/step\n",
      "Epoch 74/180\n",
      "10/10 - 0s - loss: 0.0478 - val_loss: 0.0663 - 119ms/epoch - 12ms/step\n",
      "Epoch 75/180\n",
      "10/10 - 0s - loss: 0.0475 - val_loss: 0.0659 - 69ms/epoch - 7ms/step\n",
      "Epoch 76/180\n",
      "10/10 - 0s - loss: 0.0471 - val_loss: 0.0655 - 68ms/epoch - 7ms/step\n",
      "Epoch 77/180\n",
      "10/10 - 0s - loss: 0.0469 - val_loss: 0.0652 - 66ms/epoch - 7ms/step\n",
      "Epoch 78/180\n",
      "10/10 - 0s - loss: 0.0466 - val_loss: 0.0648 - 66ms/epoch - 7ms/step\n",
      "Epoch 79/180\n",
      "10/10 - 0s - loss: 0.0462 - val_loss: 0.0644 - 76ms/epoch - 8ms/step\n",
      "Epoch 80/180\n",
      "10/10 - 0s - loss: 0.0458 - val_loss: 0.0640 - 66ms/epoch - 7ms/step\n",
      "Epoch 81/180\n",
      "10/10 - 0s - loss: 0.0455 - val_loss: 0.0637 - 66ms/epoch - 7ms/step\n",
      "Epoch 82/180\n",
      "10/10 - 0s - loss: 0.0453 - val_loss: 0.0633 - 69ms/epoch - 7ms/step\n",
      "Epoch 83/180\n",
      "10/10 - 0s - loss: 0.0449 - val_loss: 0.0629 - 70ms/epoch - 7ms/step\n",
      "Epoch 84/180\n",
      "10/10 - 0s - loss: 0.0446 - val_loss: 0.0625 - 77ms/epoch - 8ms/step\n",
      "Epoch 85/180\n",
      "10/10 - 0s - loss: 0.0442 - val_loss: 0.0622 - 67ms/epoch - 7ms/step\n",
      "Epoch 86/180\n",
      "10/10 - 0s - loss: 0.0437 - val_loss: 0.0618 - 68ms/epoch - 7ms/step\n",
      "Epoch 87/180\n",
      "10/10 - 0s - loss: 0.0436 - val_loss: 0.0614 - 75ms/epoch - 8ms/step\n",
      "Epoch 88/180\n",
      "10/10 - 0s - loss: 0.0431 - val_loss: 0.0610 - 87ms/epoch - 9ms/step\n",
      "Epoch 89/180\n",
      "10/10 - 0s - loss: 0.0428 - val_loss: 0.0606 - 75ms/epoch - 7ms/step\n",
      "Epoch 90/180\n",
      "10/10 - 0s - loss: 0.0426 - val_loss: 0.0603 - 67ms/epoch - 7ms/step\n",
      "Epoch 91/180\n",
      "10/10 - 0s - loss: 0.0423 - val_loss: 0.0599 - 66ms/epoch - 7ms/step\n",
      "Epoch 92/180\n",
      "10/10 - 0s - loss: 0.0419 - val_loss: 0.0595 - 68ms/epoch - 7ms/step\n",
      "Epoch 93/180\n",
      "10/10 - 0s - loss: 0.0415 - val_loss: 0.0591 - 67ms/epoch - 7ms/step\n",
      "Epoch 94/180\n",
      "10/10 - 0s - loss: 0.0413 - val_loss: 0.0587 - 75ms/epoch - 7ms/step\n",
      "Epoch 95/180\n",
      "10/10 - 0s - loss: 0.0410 - val_loss: 0.0583 - 65ms/epoch - 7ms/step\n",
      "Epoch 96/180\n",
      "10/10 - 0s - loss: 0.0404 - val_loss: 0.0580 - 66ms/epoch - 7ms/step\n",
      "Epoch 97/180\n",
      "10/10 - 0s - loss: 0.0403 - val_loss: 0.0576 - 66ms/epoch - 7ms/step\n",
      "Epoch 98/180\n",
      "10/10 - 0s - loss: 0.0398 - val_loss: 0.0572 - 68ms/epoch - 7ms/step\n",
      "Epoch 99/180\n",
      "10/10 - 0s - loss: 0.0395 - val_loss: 0.0568 - 83ms/epoch - 8ms/step\n",
      "Epoch 100/180\n",
      "10/10 - 0s - loss: 0.0392 - val_loss: 0.0564 - 67ms/epoch - 7ms/step\n",
      "Epoch 101/180\n",
      "10/10 - 0s - loss: 0.0388 - val_loss: 0.0560 - 87ms/epoch - 9ms/step\n",
      "Epoch 102/180\n",
      "10/10 - 0s - loss: 0.0385 - val_loss: 0.0556 - 70ms/epoch - 7ms/step\n",
      "Epoch 103/180\n",
      "10/10 - 0s - loss: 0.0381 - val_loss: 0.0552 - 66ms/epoch - 7ms/step\n",
      "Epoch 104/180\n",
      "10/10 - 0s - loss: 0.0378 - val_loss: 0.0549 - 77ms/epoch - 8ms/step\n",
      "Epoch 105/180\n",
      "10/10 - 0s - loss: 0.0375 - val_loss: 0.0545 - 67ms/epoch - 7ms/step\n",
      "Epoch 106/180\n",
      "10/10 - 0s - loss: 0.0373 - val_loss: 0.0541 - 67ms/epoch - 7ms/step\n",
      "Epoch 107/180\n",
      "10/10 - 0s - loss: 0.0368 - val_loss: 0.0537 - 68ms/epoch - 7ms/step\n",
      "Epoch 108/180\n",
      "10/10 - 0s - loss: 0.0364 - val_loss: 0.0533 - 66ms/epoch - 7ms/step\n",
      "Epoch 109/180\n",
      "10/10 - 0s - loss: 0.0362 - val_loss: 0.0529 - 73ms/epoch - 7ms/step\n",
      "Epoch 110/180\n",
      "10/10 - 0s - loss: 0.0356 - val_loss: 0.0525 - 66ms/epoch - 7ms/step\n",
      "Epoch 111/180\n",
      "10/10 - 0s - loss: 0.0355 - val_loss: 0.0521 - 66ms/epoch - 7ms/step\n",
      "Epoch 112/180\n",
      "10/10 - 0s - loss: 0.0350 - val_loss: 0.0517 - 66ms/epoch - 7ms/step\n",
      "Epoch 113/180\n",
      "10/10 - 0s - loss: 0.0348 - val_loss: 0.0513 - 66ms/epoch - 7ms/step\n",
      "Epoch 114/180\n",
      "10/10 - 0s - loss: 0.0345 - val_loss: 0.0510 - 91ms/epoch - 9ms/step\n",
      "Epoch 115/180\n",
      "10/10 - 0s - loss: 0.0341 - val_loss: 0.0506 - 77ms/epoch - 8ms/step\n",
      "Epoch 116/180\n",
      "10/10 - 0s - loss: 0.0338 - val_loss: 0.0502 - 66ms/epoch - 7ms/step\n",
      "Epoch 117/180\n",
      "10/10 - 0s - loss: 0.0335 - val_loss: 0.0498 - 64ms/epoch - 6ms/step\n",
      "Epoch 118/180\n",
      "10/10 - 0s - loss: 0.0331 - val_loss: 0.0494 - 66ms/epoch - 7ms/step\n",
      "Epoch 119/180\n",
      "10/10 - 0s - loss: 0.0328 - val_loss: 0.0490 - 81ms/epoch - 8ms/step\n",
      "Epoch 120/180\n",
      "10/10 - 0s - loss: 0.0325 - val_loss: 0.0486 - 66ms/epoch - 7ms/step\n",
      "Epoch 121/180\n",
      "10/10 - 0s - loss: 0.0321 - val_loss: 0.0482 - 65ms/epoch - 7ms/step\n",
      "Epoch 122/180\n",
      "10/10 - 0s - loss: 0.0319 - val_loss: 0.0478 - 65ms/epoch - 6ms/step\n",
      "Epoch 123/180\n",
      "10/10 - 0s - loss: 0.0313 - val_loss: 0.0474 - 67ms/epoch - 7ms/step\n",
      "Epoch 124/180\n",
      "10/10 - 0s - loss: 0.0310 - val_loss: 0.0470 - 87ms/epoch - 9ms/step\n",
      "Epoch 125/180\n",
      "10/10 - 0s - loss: 0.0307 - val_loss: 0.0467 - 69ms/epoch - 7ms/step\n",
      "Epoch 126/180\n",
      "10/10 - 0s - loss: 0.0302 - val_loss: 0.0463 - 68ms/epoch - 7ms/step\n",
      "Epoch 127/180\n",
      "10/10 - 0s - loss: 0.0301 - val_loss: 0.0459 - 65ms/epoch - 6ms/step\n",
      "Epoch 128/180\n",
      "10/10 - 0s - loss: 0.0296 - val_loss: 0.0455 - 120ms/epoch - 12ms/step\n",
      "Epoch 129/180\n",
      "10/10 - 0s - loss: 0.0295 - val_loss: 0.0451 - 68ms/epoch - 7ms/step\n",
      "Epoch 130/180\n",
      "10/10 - 0s - loss: 0.0290 - val_loss: 0.0447 - 66ms/epoch - 7ms/step\n",
      "Epoch 131/180\n",
      "10/10 - 0s - loss: 0.0287 - val_loss: 0.0443 - 65ms/epoch - 6ms/step\n",
      "Epoch 132/180\n",
      "10/10 - 0s - loss: 0.0284 - val_loss: 0.0439 - 76ms/epoch - 8ms/step\n",
      "Epoch 133/180\n",
      "10/10 - 0s - loss: 0.0281 - val_loss: 0.0435 - 69ms/epoch - 7ms/step\n",
      "Epoch 134/180\n",
      "10/10 - 0s - loss: 0.0278 - val_loss: 0.0432 - 66ms/epoch - 7ms/step\n",
      "Epoch 135/180\n",
      "10/10 - 0s - loss: 0.0273 - val_loss: 0.0428 - 67ms/epoch - 7ms/step\n",
      "Epoch 136/180\n",
      "10/10 - 0s - loss: 0.0269 - val_loss: 0.0424 - 68ms/epoch - 7ms/step\n",
      "Epoch 137/180\n",
      "10/10 - 0s - loss: 0.0267 - val_loss: 0.0420 - 80ms/epoch - 8ms/step\n",
      "Epoch 138/180\n",
      "10/10 - 0s - loss: 0.0262 - val_loss: 0.0416 - 68ms/epoch - 7ms/step\n",
      "Epoch 139/180\n",
      "10/10 - 0s - loss: 0.0260 - val_loss: 0.0412 - 68ms/epoch - 7ms/step\n",
      "Epoch 140/180\n",
      "10/10 - 0s - loss: 0.0257 - val_loss: 0.0408 - 67ms/epoch - 7ms/step\n",
      "Epoch 141/180\n",
      "10/10 - 0s - loss: 0.0254 - val_loss: 0.0405 - 118ms/epoch - 12ms/step\n",
      "Epoch 142/180\n",
      "10/10 - 0s - loss: 0.0249 - val_loss: 0.0401 - 73ms/epoch - 7ms/step\n",
      "Epoch 143/180\n",
      "10/10 - 0s - loss: 0.0247 - val_loss: 0.0397 - 68ms/epoch - 7ms/step\n",
      "Epoch 144/180\n",
      "10/10 - 0s - loss: 0.0245 - val_loss: 0.0393 - 67ms/epoch - 7ms/step\n",
      "Epoch 145/180\n",
      "10/10 - 0s - loss: 0.0241 - val_loss: 0.0389 - 67ms/epoch - 7ms/step\n",
      "Epoch 146/180\n",
      "10/10 - 0s - loss: 0.0239 - val_loss: 0.0386 - 77ms/epoch - 8ms/step\n",
      "Epoch 147/180\n",
      "10/10 - 0s - loss: 0.0235 - val_loss: 0.0382 - 69ms/epoch - 7ms/step\n",
      "Epoch 148/180\n",
      "10/10 - 0s - loss: 0.0231 - val_loss: 0.0378 - 67ms/epoch - 7ms/step\n",
      "Epoch 149/180\n",
      "10/10 - 0s - loss: 0.0229 - val_loss: 0.0375 - 66ms/epoch - 7ms/step\n",
      "Epoch 150/180\n",
      "10/10 - 0s - loss: 0.0226 - val_loss: 0.0371 - 69ms/epoch - 7ms/step\n",
      "Epoch 151/180\n",
      "10/10 - 0s - loss: 0.0222 - val_loss: 0.0367 - 77ms/epoch - 8ms/step\n",
      "Epoch 152/180\n",
      "10/10 - 0s - loss: 0.0219 - val_loss: 0.0363 - 67ms/epoch - 7ms/step\n",
      "Epoch 153/180\n",
      "10/10 - 0s - loss: 0.0215 - val_loss: 0.0360 - 68ms/epoch - 7ms/step\n",
      "Epoch 154/180\n",
      "10/10 - 0s - loss: 0.0213 - val_loss: 0.0356 - 66ms/epoch - 7ms/step\n",
      "Epoch 155/180\n",
      "10/10 - 0s - loss: 0.0210 - val_loss: 0.0352 - 68ms/epoch - 7ms/step\n",
      "Epoch 156/180\n",
      "10/10 - 0s - loss: 0.0208 - val_loss: 0.0349 - 78ms/epoch - 8ms/step\n",
      "Epoch 157/180\n",
      "10/10 - 0s - loss: 0.0204 - val_loss: 0.0345 - 66ms/epoch - 7ms/step\n",
      "Epoch 158/180\n",
      "10/10 - 0s - loss: 0.0201 - val_loss: 0.0342 - 92ms/epoch - 9ms/step\n",
      "Epoch 159/180\n",
      "10/10 - 0s - loss: 0.0197 - val_loss: 0.0338 - 67ms/epoch - 7ms/step\n",
      "Epoch 160/180\n",
      "10/10 - 0s - loss: 0.0196 - val_loss: 0.0335 - 67ms/epoch - 7ms/step\n",
      "Epoch 161/180\n",
      "10/10 - 0s - loss: 0.0193 - val_loss: 0.0331 - 76ms/epoch - 8ms/step\n",
      "Epoch 162/180\n",
      "10/10 - 0s - loss: 0.0190 - val_loss: 0.0328 - 68ms/epoch - 7ms/step\n",
      "Epoch 163/180\n",
      "10/10 - 0s - loss: 0.0186 - val_loss: 0.0324 - 68ms/epoch - 7ms/step\n",
      "Epoch 164/180\n",
      "10/10 - 0s - loss: 0.0183 - val_loss: 0.0321 - 66ms/epoch - 7ms/step\n",
      "Epoch 165/180\n",
      "10/10 - 0s - loss: 0.0179 - val_loss: 0.0317 - 66ms/epoch - 7ms/step\n",
      "Epoch 166/180\n",
      "10/10 - 0s - loss: 0.0178 - val_loss: 0.0314 - 77ms/epoch - 8ms/step\n",
      "Epoch 167/180\n",
      "10/10 - 0s - loss: 0.0174 - val_loss: 0.0310 - 66ms/epoch - 7ms/step\n",
      "Epoch 168/180\n",
      "10/10 - 0s - loss: 0.0171 - val_loss: 0.0307 - 66ms/epoch - 7ms/step\n",
      "Epoch 169/180\n",
      "10/10 - 0s - loss: 0.0170 - val_loss: 0.0304 - 68ms/epoch - 7ms/step\n",
      "Epoch 170/180\n",
      "10/10 - 0s - loss: 0.0165 - val_loss: 0.0300 - 67ms/epoch - 7ms/step\n",
      "Epoch 171/180\n",
      "10/10 - 0s - loss: 0.0162 - val_loss: 0.0297 - 76ms/epoch - 8ms/step\n",
      "Epoch 172/180\n",
      "10/10 - 0s - loss: 0.0162 - val_loss: 0.0294 - 67ms/epoch - 7ms/step\n",
      "Epoch 173/180\n",
      "10/10 - 0s - loss: 0.0158 - val_loss: 0.0290 - 68ms/epoch - 7ms/step\n",
      "Epoch 174/180\n",
      "10/10 - 0s - loss: 0.0155 - val_loss: 0.0287 - 90ms/epoch - 9ms/step\n",
      "Epoch 175/180\n",
      "10/10 - 0s - loss: 0.0153 - val_loss: 0.0284 - 69ms/epoch - 7ms/step\n",
      "Epoch 176/180\n",
      "10/10 - 0s - loss: 0.0149 - val_loss: 0.0281 - 78ms/epoch - 8ms/step\n",
      "Epoch 177/180\n",
      "10/10 - 0s - loss: 0.0148 - val_loss: 0.0278 - 69ms/epoch - 7ms/step\n",
      "Epoch 178/180\n",
      "10/10 - 0s - loss: 0.0145 - val_loss: 0.0274 - 66ms/epoch - 7ms/step\n",
      "Epoch 179/180\n",
      "10/10 - 0s - loss: 0.0141 - val_loss: 0.0271 - 66ms/epoch - 7ms/step\n",
      "Epoch 180/180\n",
      "10/10 - 0s - loss: 0.0139 - val_loss: 0.0268 - 68ms/epoch - 7ms/step\n",
      "9/9 [==============================] - 1s 1ms/step\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m-293.3   \u001b[0m | \u001b[0m180.9    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.18e-05 \u001b[0m | \u001b[0m59.87    \u001b[0m |\n",
      "Model: \"sequential_143\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_519 (LSTM)             (None, 1, 33)             5148      \n",
      "                                                                 \n",
      " dropout_376 (Dropout)       (None, 1, 33)             0         \n",
      "                                                                 \n",
      " lstm_520 (LSTM)             (None, 1, 33)             8844      \n",
      "                                                                 \n",
      " dropout_377 (Dropout)       (None, 1, 33)             0         \n",
      "                                                                 \n",
      " lstm_521 (LSTM)             (None, 1, 33)             8844      \n",
      "                                                                 \n",
      " dropout_378 (Dropout)       (None, 1, 33)             0         \n",
      "                                                                 \n",
      " lstm_522 (LSTM)             (None, 33)                8844      \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 1)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,714\n",
      "Trainable params: 31,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/132\n",
      "10/10 - 9s - loss: 0.0690 - val_loss: 0.0881 - 9s/epoch - 861ms/step\n",
      "Epoch 2/132\n",
      "10/10 - 0s - loss: 0.0654 - val_loss: 0.0843 - 83ms/epoch - 8ms/step\n",
      "Epoch 3/132\n",
      "10/10 - 0s - loss: 0.0618 - val_loss: 0.0804 - 103ms/epoch - 10ms/step\n",
      "Epoch 4/132\n",
      "10/10 - 0s - loss: 0.0581 - val_loss: 0.0763 - 88ms/epoch - 9ms/step\n",
      "Epoch 5/132\n",
      "10/10 - 0s - loss: 0.0542 - val_loss: 0.0720 - 96ms/epoch - 10ms/step\n",
      "Epoch 6/132\n",
      "10/10 - 0s - loss: 0.0501 - val_loss: 0.0675 - 84ms/epoch - 8ms/step\n",
      "Epoch 7/132\n",
      "10/10 - 0s - loss: 0.0457 - val_loss: 0.0626 - 83ms/epoch - 8ms/step\n",
      "Epoch 8/132\n",
      "10/10 - 0s - loss: 0.0411 - val_loss: 0.0573 - 82ms/epoch - 8ms/step\n",
      "Epoch 9/132\n",
      "10/10 - 0s - loss: 0.0362 - val_loss: 0.0517 - 83ms/epoch - 8ms/step\n",
      "Epoch 10/132\n",
      "10/10 - 0s - loss: 0.0308 - val_loss: 0.0457 - 82ms/epoch - 8ms/step\n",
      "Epoch 11/132\n",
      "10/10 - 0s - loss: 0.0255 - val_loss: 0.0393 - 82ms/epoch - 8ms/step\n",
      "Epoch 12/132\n",
      "10/10 - 0s - loss: 0.0198 - val_loss: 0.0329 - 80ms/epoch - 8ms/step\n",
      "Epoch 13/132\n",
      "10/10 - 0s - loss: 0.0144 - val_loss: 0.0266 - 92ms/epoch - 9ms/step\n",
      "Epoch 14/132\n",
      "10/10 - 0s - loss: 0.0095 - val_loss: 0.0211 - 80ms/epoch - 8ms/step\n",
      "Epoch 15/132\n",
      "10/10 - 0s - loss: 0.0060 - val_loss: 0.0168 - 79ms/epoch - 8ms/step\n",
      "Epoch 16/132\n",
      "10/10 - 0s - loss: 0.0034 - val_loss: 0.0142 - 79ms/epoch - 8ms/step\n",
      "Epoch 17/132\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0130 - 80ms/epoch - 8ms/step\n",
      "Epoch 18/132\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0127 - 96ms/epoch - 10ms/step\n",
      "Epoch 19/132\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0127 - 83ms/epoch - 8ms/step\n",
      "Epoch 20/132\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0128 - 80ms/epoch - 8ms/step\n",
      "Epoch 21/132\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0129 - 80ms/epoch - 8ms/step\n",
      "Epoch 22/132\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0130 - 105ms/epoch - 10ms/step\n",
      "Epoch 23/132\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0128 - 90ms/epoch - 9ms/step\n",
      "Epoch 24/132\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0128 - 81ms/epoch - 8ms/step\n",
      "Epoch 25/132\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0128 - 81ms/epoch - 8ms/step\n",
      "Epoch 26/132\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0128 - 77ms/epoch - 8ms/step\n",
      "Epoch 27/132\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0127 - 78ms/epoch - 8ms/step\n",
      "Epoch 28/132\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0126 - 89ms/epoch - 9ms/step\n",
      "Epoch 29/132\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0126 - 78ms/epoch - 8ms/step\n",
      "Epoch 30/132\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0125 - 78ms/epoch - 8ms/step\n",
      "Epoch 31/132\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0125 - 80ms/epoch - 8ms/step\n",
      "Epoch 32/132\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0124 - 87ms/epoch - 9ms/step\n",
      "Epoch 33/132\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0123 - 78ms/epoch - 8ms/step\n",
      "Epoch 34/132\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0123 - 79ms/epoch - 8ms/step\n",
      "Epoch 35/132\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0123 - 80ms/epoch - 8ms/step\n",
      "Epoch 36/132\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0122 - 77ms/epoch - 8ms/step\n",
      "Epoch 37/132\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0122 - 84ms/epoch - 8ms/step\n",
      "Epoch 38/132\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0122 - 87ms/epoch - 9ms/step\n",
      "Epoch 39/132\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0121 - 112ms/epoch - 11ms/step\n",
      "Epoch 40/132\n",
      "10/10 - 0s - loss: 0.0023 - val_loss: 0.0120 - 82ms/epoch - 8ms/step\n",
      "Epoch 41/132\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0120 - 78ms/epoch - 8ms/step\n",
      "Epoch 42/132\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0119 - 78ms/epoch - 8ms/step\n",
      "Epoch 43/132\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0117 - 76ms/epoch - 8ms/step\n",
      "Epoch 44/132\n",
      "10/10 - 0s - loss: 0.0023 - val_loss: 0.0117 - 91ms/epoch - 9ms/step\n",
      "Epoch 45/132\n",
      "10/10 - 0s - loss: 0.0023 - val_loss: 0.0117 - 85ms/epoch - 9ms/step\n",
      "Epoch 46/132\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0116 - 93ms/epoch - 9ms/step\n",
      "Epoch 47/132\n",
      "10/10 - 0s - loss: 0.0023 - val_loss: 0.0116 - 91ms/epoch - 9ms/step\n",
      "Epoch 48/132\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0114 - 87ms/epoch - 9ms/step\n",
      "Epoch 49/132\n",
      "10/10 - 0s - loss: 0.0023 - val_loss: 0.0114 - 100ms/epoch - 10ms/step\n",
      "Epoch 50/132\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0115 - 83ms/epoch - 8ms/step\n",
      "Epoch 51/132\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0114 - 79ms/epoch - 8ms/step\n",
      "Epoch 52/132\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0113 - 77ms/epoch - 8ms/step\n",
      "Epoch 53/132\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0113 - 111ms/epoch - 11ms/step\n",
      "Epoch 54/132\n",
      "10/10 - 0s - loss: 0.0023 - val_loss: 0.0111 - 80ms/epoch - 8ms/step\n",
      "Epoch 55/132\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0110 - 90ms/epoch - 9ms/step\n",
      "Epoch 56/132\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0109 - 95ms/epoch - 9ms/step\n",
      "Epoch 57/132\n",
      "10/10 - 0s - loss: 0.0021 - val_loss: 0.0109 - 86ms/epoch - 9ms/step\n",
      "Epoch 58/132\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0109 - 81ms/epoch - 8ms/step\n",
      "Epoch 59/132\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0108 - 80ms/epoch - 8ms/step\n",
      "Epoch 60/132\n",
      "10/10 - 0s - loss: 0.0021 - val_loss: 0.0107 - 81ms/epoch - 8ms/step\n",
      "Epoch 61/132\n",
      "10/10 - 0s - loss: 0.0020 - val_loss: 0.0107 - 81ms/epoch - 8ms/step\n",
      "Epoch 62/132\n",
      "10/10 - 0s - loss: 0.0020 - val_loss: 0.0105 - 99ms/epoch - 10ms/step\n",
      "Epoch 63/132\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0105 - 86ms/epoch - 9ms/step\n",
      "Epoch 64/132\n",
      "10/10 - 0s - loss: 0.0020 - val_loss: 0.0105 - 87ms/epoch - 9ms/step\n",
      "Epoch 65/132\n",
      "10/10 - 0s - loss: 0.0020 - val_loss: 0.0104 - 91ms/epoch - 9ms/step\n",
      "Epoch 66/132\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0103 - 112ms/epoch - 11ms/step\n",
      "Epoch 67/132\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0102 - 87ms/epoch - 9ms/step\n",
      "Epoch 68/132\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0102 - 81ms/epoch - 8ms/step\n",
      "Epoch 69/132\n",
      "10/10 - 0s - loss: 0.0020 - val_loss: 0.0101 - 80ms/epoch - 8ms/step\n",
      "Epoch 70/132\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0100 - 82ms/epoch - 8ms/step\n",
      "Epoch 71/132\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0099 - 121ms/epoch - 12ms/step\n",
      "Epoch 72/132\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0099 - 82ms/epoch - 8ms/step\n",
      "Epoch 73/132\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0099 - 78ms/epoch - 8ms/step\n",
      "Epoch 74/132\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0097 - 79ms/epoch - 8ms/step\n",
      "Epoch 75/132\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0097 - 82ms/epoch - 8ms/step\n",
      "Epoch 76/132\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0096 - 106ms/epoch - 11ms/step\n",
      "Epoch 77/132\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0096 - 110ms/epoch - 11ms/step\n",
      "Epoch 78/132\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0095 - 87ms/epoch - 9ms/step\n",
      "Epoch 79/132\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0095 - 79ms/epoch - 8ms/step\n",
      "Epoch 80/132\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0094 - 79ms/epoch - 8ms/step\n",
      "Epoch 81/132\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0093 - 78ms/epoch - 8ms/step\n",
      "Epoch 82/132\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0092 - 99ms/epoch - 10ms/step\n",
      "Epoch 83/132\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0092 - 82ms/epoch - 8ms/step\n",
      "Epoch 84/132\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0091 - 77ms/epoch - 8ms/step\n",
      "Epoch 85/132\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0091 - 77ms/epoch - 8ms/step\n",
      "Epoch 86/132\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0090 - 87ms/epoch - 9ms/step\n",
      "Epoch 87/132\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0090 - 79ms/epoch - 8ms/step\n",
      "Epoch 88/132\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0089 - 79ms/epoch - 8ms/step\n",
      "Epoch 89/132\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0088 - 104ms/epoch - 10ms/step\n",
      "Epoch 90/132\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0089 - 79ms/epoch - 8ms/step\n",
      "Epoch 91/132\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0088 - 81ms/epoch - 8ms/step\n",
      "Epoch 92/132\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0088 - 88ms/epoch - 9ms/step\n",
      "Epoch 93/132\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0087 - 79ms/epoch - 8ms/step\n",
      "Epoch 94/132\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0087 - 79ms/epoch - 8ms/step\n",
      "Epoch 95/132\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0087 - 79ms/epoch - 8ms/step\n",
      "Epoch 96/132\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0087 - 88ms/epoch - 9ms/step\n",
      "Epoch 97/132\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0086 - 81ms/epoch - 8ms/step\n",
      "Epoch 98/132\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0086 - 84ms/epoch - 8ms/step\n",
      "Epoch 99/132\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0086 - 90ms/epoch - 9ms/step\n",
      "Epoch 100/132\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0086 - 88ms/epoch - 9ms/step\n",
      "Epoch 101/132\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0086 - 88ms/epoch - 9ms/step\n",
      "Epoch 102/132\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0086 - 131ms/epoch - 13ms/step\n",
      "Epoch 103/132\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0086 - 85ms/epoch - 9ms/step\n",
      "Epoch 104/132\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0086 - 87ms/epoch - 9ms/step\n",
      "Epoch 105/132\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0086 - 82ms/epoch - 8ms/step\n",
      "Epoch 106/132\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0086 - 81ms/epoch - 8ms/step\n",
      "Epoch 107/132\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0086 - 97ms/epoch - 10ms/step\n",
      "Epoch 108/132\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0086 - 104ms/epoch - 10ms/step\n",
      "Epoch 109/132\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0086 - 86ms/epoch - 9ms/step\n",
      "Epoch 110/132\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0086 - 82ms/epoch - 8ms/step\n",
      "Epoch 111/132\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0086 - 85ms/epoch - 9ms/step\n",
      "Epoch 112/132\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0086 - 130ms/epoch - 13ms/step\n",
      "Epoch 113/132\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0086 - 87ms/epoch - 9ms/step\n",
      "Epoch 114/132\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0086 - 92ms/epoch - 9ms/step\n",
      "Epoch 115/132\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0087 - 91ms/epoch - 9ms/step\n",
      "Epoch 116/132\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0087 - 90ms/epoch - 9ms/step\n",
      "Epoch 117/132\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0087 - 112ms/epoch - 11ms/step\n",
      "Epoch 118/132\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0087 - 98ms/epoch - 10ms/step\n",
      "Epoch 119/132\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0087 - 90ms/epoch - 9ms/step\n",
      "Epoch 120/132\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0087 - 87ms/epoch - 9ms/step\n",
      "Epoch 121/132\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0087 - 86ms/epoch - 9ms/step\n",
      "Epoch 122/132\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0087 - 92ms/epoch - 9ms/step\n",
      "Epoch 123/132\n",
      "10/10 - 0s - loss: 9.7838e-04 - val_loss: 0.0087 - 106ms/epoch - 11ms/step\n",
      "Epoch 124/132\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0088 - 85ms/epoch - 8ms/step\n",
      "Epoch 125/132\n",
      "10/10 - 0s - loss: 9.5885e-04 - val_loss: 0.0088 - 85ms/epoch - 8ms/step\n",
      "Epoch 126/132\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0088 - 82ms/epoch - 8ms/step\n",
      "Epoch 127/132\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0088 - 106ms/epoch - 11ms/step\n",
      "Epoch 128/132\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0088 - 110ms/epoch - 11ms/step\n",
      "Epoch 129/132\n",
      "10/10 - 0s - loss: 8.9808e-04 - val_loss: 0.0089 - 83ms/epoch - 8ms/step\n",
      "Epoch 130/132\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0089 - 93ms/epoch - 9ms/step\n",
      "Epoch 131/132\n",
      "10/10 - 0s - loss: 9.6171e-04 - val_loss: 0.0088 - 82ms/epoch - 8ms/step\n",
      "Epoch 132/132\n",
      "10/10 - 0s - loss: 9.9394e-04 - val_loss: 0.0089 - 90ms/epoch - 9ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m-169.0   \u001b[0m | \u001b[0m132.7    \u001b[0m | \u001b[0m3.94     \u001b[0m | \u001b[0m0.0002301\u001b[0m | \u001b[0m33.87    \u001b[0m |\n",
      "Model: \"sequential_144\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_523 (LSTM)             (None, 1, 118)            58528     \n",
      "                                                                 \n",
      " dropout_379 (Dropout)       (None, 1, 118)            0         \n",
      "                                                                 \n",
      " lstm_524 (LSTM)             (None, 1, 118)            111864    \n",
      "                                                                 \n",
      " dropout_380 (Dropout)       (None, 1, 118)            0         \n",
      "                                                                 \n",
      " lstm_525 (LSTM)             (None, 1, 118)            111864    \n",
      "                                                                 \n",
      " dropout_381 (Dropout)       (None, 1, 118)            0         \n",
      "                                                                 \n",
      " lstm_526 (LSTM)             (None, 1, 118)            111864    \n",
      "                                                                 \n",
      " dropout_382 (Dropout)       (None, 1, 118)            0         \n",
      "                                                                 \n",
      " lstm_527 (LSTM)             (None, 1, 118)            111864    \n",
      "                                                                 \n",
      " dropout_383 (Dropout)       (None, 1, 118)            0         \n",
      "                                                                 \n",
      " lstm_528 (LSTM)             (None, 118)               111864    \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 1)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 617,967\n",
      "Trainable params: 617,967\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/129\n",
      "10/10 - 12s - loss: 0.0201 - val_loss: 0.0203 - 12s/epoch - 1s/step\n",
      "Epoch 2/129\n",
      "10/10 - 0s - loss: 0.0041 - val_loss: 0.0167 - 192ms/epoch - 19ms/step\n",
      "Epoch 3/129\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0165 - 197ms/epoch - 20ms/step\n",
      "Epoch 4/129\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0164 - 197ms/epoch - 20ms/step\n",
      "Epoch 5/129\n",
      "10/10 - 0s - loss: 0.0021 - val_loss: 0.0082 - 199ms/epoch - 20ms/step\n",
      "Epoch 6/129\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0137 - 183ms/epoch - 18ms/step\n",
      "Epoch 7/129\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0112 - 182ms/epoch - 18ms/step\n",
      "Epoch 8/129\n",
      "10/10 - 0s - loss: 9.6145e-04 - val_loss: 0.0092 - 186ms/epoch - 19ms/step\n",
      "Epoch 9/129\n",
      "10/10 - 0s - loss: 9.4949e-04 - val_loss: 0.0079 - 190ms/epoch - 19ms/step\n",
      "Epoch 10/129\n",
      "10/10 - 0s - loss: 5.1420e-04 - val_loss: 0.0082 - 247ms/epoch - 25ms/step\n",
      "Epoch 11/129\n",
      "10/10 - 0s - loss: 4.2715e-04 - val_loss: 0.0080 - 223ms/epoch - 22ms/step\n",
      "Epoch 12/129\n",
      "10/10 - 0s - loss: 3.9783e-04 - val_loss: 0.0079 - 195ms/epoch - 19ms/step\n",
      "Epoch 13/129\n",
      "10/10 - 0s - loss: 4.0173e-04 - val_loss: 0.0081 - 192ms/epoch - 19ms/step\n",
      "Epoch 14/129\n",
      "10/10 - 0s - loss: 3.5477e-04 - val_loss: 0.0078 - 209ms/epoch - 21ms/step\n",
      "Epoch 15/129\n",
      "10/10 - 0s - loss: 3.8416e-04 - val_loss: 0.0081 - 212ms/epoch - 21ms/step\n",
      "Epoch 16/129\n",
      "10/10 - 0s - loss: 3.2089e-04 - val_loss: 0.0079 - 204ms/epoch - 20ms/step\n",
      "Epoch 17/129\n",
      "10/10 - 0s - loss: 2.9704e-04 - val_loss: 0.0082 - 211ms/epoch - 21ms/step\n",
      "Epoch 18/129\n",
      "10/10 - 0s - loss: 3.1125e-04 - val_loss: 0.0080 - 192ms/epoch - 19ms/step\n",
      "Epoch 19/129\n",
      "10/10 - 0s - loss: 3.0731e-04 - val_loss: 0.0079 - 203ms/epoch - 20ms/step\n",
      "Epoch 20/129\n",
      "10/10 - 0s - loss: 2.9666e-04 - val_loss: 0.0080 - 199ms/epoch - 20ms/step\n",
      "Epoch 21/129\n",
      "10/10 - 0s - loss: 2.9025e-04 - val_loss: 0.0082 - 185ms/epoch - 19ms/step\n",
      "Epoch 22/129\n",
      "10/10 - 0s - loss: 2.8921e-04 - val_loss: 0.0083 - 186ms/epoch - 19ms/step\n",
      "Epoch 23/129\n",
      "10/10 - 0s - loss: 2.8063e-04 - val_loss: 0.0085 - 193ms/epoch - 19ms/step\n",
      "Epoch 24/129\n",
      "10/10 - 0s - loss: 3.1359e-04 - val_loss: 0.0080 - 185ms/epoch - 18ms/step\n",
      "Epoch 25/129\n",
      "10/10 - 0s - loss: 2.9209e-04 - val_loss: 0.0085 - 191ms/epoch - 19ms/step\n",
      "Epoch 26/129\n",
      "10/10 - 0s - loss: 2.4191e-04 - val_loss: 0.0084 - 192ms/epoch - 19ms/step\n",
      "Epoch 27/129\n",
      "10/10 - 0s - loss: 2.5350e-04 - val_loss: 0.0083 - 227ms/epoch - 23ms/step\n",
      "Epoch 28/129\n",
      "10/10 - 0s - loss: 3.2574e-04 - val_loss: 0.0089 - 203ms/epoch - 20ms/step\n",
      "Epoch 29/129\n",
      "10/10 - 0s - loss: 3.2965e-04 - val_loss: 0.0093 - 190ms/epoch - 19ms/step\n",
      "Epoch 30/129\n",
      "10/10 - 0s - loss: 3.6006e-04 - val_loss: 0.0092 - 184ms/epoch - 18ms/step\n",
      "Epoch 31/129\n",
      "10/10 - 0s - loss: 3.8840e-04 - val_loss: 0.0101 - 191ms/epoch - 19ms/step\n",
      "Epoch 32/129\n",
      "10/10 - 0s - loss: 3.5017e-04 - val_loss: 0.0097 - 183ms/epoch - 18ms/step\n",
      "Epoch 33/129\n",
      "10/10 - 0s - loss: 3.0550e-04 - val_loss: 0.0101 - 217ms/epoch - 22ms/step\n",
      "Epoch 34/129\n",
      "10/10 - 0s - loss: 2.8529e-04 - val_loss: 0.0106 - 186ms/epoch - 19ms/step\n",
      "Epoch 35/129\n",
      "10/10 - 0s - loss: 2.7760e-04 - val_loss: 0.0109 - 187ms/epoch - 19ms/step\n",
      "Epoch 36/129\n",
      "10/10 - 0s - loss: 2.4447e-04 - val_loss: 0.0108 - 189ms/epoch - 19ms/step\n",
      "Epoch 37/129\n",
      "10/10 - 0s - loss: 2.3314e-04 - val_loss: 0.0109 - 186ms/epoch - 19ms/step\n",
      "Epoch 38/129\n",
      "10/10 - 0s - loss: 2.4159e-04 - val_loss: 0.0111 - 197ms/epoch - 20ms/step\n",
      "Epoch 39/129\n",
      "10/10 - 0s - loss: 2.4691e-04 - val_loss: 0.0117 - 216ms/epoch - 22ms/step\n",
      "Epoch 40/129\n",
      "10/10 - 0s - loss: 2.7057e-04 - val_loss: 0.0119 - 187ms/epoch - 19ms/step\n",
      "Epoch 41/129\n",
      "10/10 - 0s - loss: 2.7967e-04 - val_loss: 0.0112 - 180ms/epoch - 18ms/step\n",
      "Epoch 42/129\n",
      "10/10 - 0s - loss: 2.8038e-04 - val_loss: 0.0121 - 179ms/epoch - 18ms/step\n",
      "Epoch 43/129\n",
      "10/10 - 0s - loss: 2.5520e-04 - val_loss: 0.0117 - 196ms/epoch - 20ms/step\n",
      "Epoch 44/129\n",
      "10/10 - 0s - loss: 2.8459e-04 - val_loss: 0.0119 - 188ms/epoch - 19ms/step\n",
      "Epoch 45/129\n",
      "10/10 - 0s - loss: 2.8262e-04 - val_loss: 0.0122 - 194ms/epoch - 19ms/step\n",
      "Epoch 46/129\n",
      "10/10 - 0s - loss: 3.0491e-04 - val_loss: 0.0128 - 187ms/epoch - 19ms/step\n",
      "Epoch 47/129\n",
      "10/10 - 0s - loss: 3.4929e-04 - val_loss: 0.0119 - 217ms/epoch - 22ms/step\n",
      "Epoch 48/129\n",
      "10/10 - 0s - loss: 2.4251e-04 - val_loss: 0.0124 - 214ms/epoch - 21ms/step\n",
      "Epoch 49/129\n",
      "10/10 - 0s - loss: 2.5266e-04 - val_loss: 0.0123 - 190ms/epoch - 19ms/step\n",
      "Epoch 50/129\n",
      "10/10 - 0s - loss: 2.5635e-04 - val_loss: 0.0120 - 183ms/epoch - 18ms/step\n",
      "Epoch 51/129\n",
      "10/10 - 0s - loss: 2.4686e-04 - val_loss: 0.0120 - 192ms/epoch - 19ms/step\n",
      "Epoch 52/129\n",
      "10/10 - 0s - loss: 2.6964e-04 - val_loss: 0.0129 - 191ms/epoch - 19ms/step\n",
      "Epoch 53/129\n",
      "10/10 - 0s - loss: 2.5214e-04 - val_loss: 0.0118 - 250ms/epoch - 25ms/step\n",
      "Epoch 54/129\n",
      "10/10 - 0s - loss: 2.3166e-04 - val_loss: 0.0123 - 202ms/epoch - 20ms/step\n",
      "Epoch 55/129\n",
      "10/10 - 0s - loss: 2.2916e-04 - val_loss: 0.0124 - 192ms/epoch - 19ms/step\n",
      "Epoch 56/129\n",
      "10/10 - 0s - loss: 2.3388e-04 - val_loss: 0.0119 - 182ms/epoch - 18ms/step\n",
      "Epoch 57/129\n",
      "10/10 - 0s - loss: 2.6882e-04 - val_loss: 0.0118 - 184ms/epoch - 18ms/step\n",
      "Epoch 58/129\n",
      "10/10 - 0s - loss: 2.4942e-04 - val_loss: 0.0130 - 196ms/epoch - 20ms/step\n",
      "Epoch 59/129\n",
      "10/10 - 0s - loss: 2.7712e-04 - val_loss: 0.0121 - 182ms/epoch - 18ms/step\n",
      "Epoch 60/129\n",
      "10/10 - 0s - loss: 2.5423e-04 - val_loss: 0.0123 - 182ms/epoch - 18ms/step\n",
      "Epoch 61/129\n",
      "10/10 - 0s - loss: 2.5735e-04 - val_loss: 0.0128 - 192ms/epoch - 19ms/step\n",
      "Epoch 62/129\n",
      "10/10 - 0s - loss: 2.3660e-04 - val_loss: 0.0126 - 204ms/epoch - 20ms/step\n",
      "Epoch 63/129\n",
      "10/10 - 0s - loss: 2.4643e-04 - val_loss: 0.0130 - 186ms/epoch - 19ms/step\n",
      "Epoch 64/129\n",
      "10/10 - 0s - loss: 2.4910e-04 - val_loss: 0.0124 - 180ms/epoch - 18ms/step\n",
      "Epoch 65/129\n",
      "10/10 - 0s - loss: 3.0465e-04 - val_loss: 0.0128 - 187ms/epoch - 19ms/step\n",
      "Epoch 66/129\n",
      "10/10 - 0s - loss: 2.7203e-04 - val_loss: 0.0132 - 216ms/epoch - 22ms/step\n",
      "Epoch 67/129\n",
      "10/10 - 0s - loss: 2.7715e-04 - val_loss: 0.0130 - 199ms/epoch - 20ms/step\n",
      "Epoch 68/129\n",
      "10/10 - 0s - loss: 3.0565e-04 - val_loss: 0.0137 - 188ms/epoch - 19ms/step\n",
      "Epoch 69/129\n",
      "10/10 - 0s - loss: 3.2559e-04 - val_loss: 0.0130 - 189ms/epoch - 19ms/step\n",
      "Epoch 70/129\n",
      "10/10 - 0s - loss: 2.6702e-04 - val_loss: 0.0129 - 189ms/epoch - 19ms/step\n",
      "Epoch 71/129\n",
      "10/10 - 0s - loss: 2.5591e-04 - val_loss: 0.0131 - 209ms/epoch - 21ms/step\n",
      "Epoch 72/129\n",
      "10/10 - 0s - loss: 2.5687e-04 - val_loss: 0.0132 - 188ms/epoch - 19ms/step\n",
      "Epoch 73/129\n",
      "10/10 - 0s - loss: 2.5464e-04 - val_loss: 0.0129 - 188ms/epoch - 19ms/step\n",
      "Epoch 74/129\n",
      "10/10 - 0s - loss: 2.4216e-04 - val_loss: 0.0129 - 205ms/epoch - 21ms/step\n",
      "Epoch 75/129\n",
      "10/10 - 0s - loss: 2.4161e-04 - val_loss: 0.0131 - 192ms/epoch - 19ms/step\n",
      "Epoch 76/129\n",
      "10/10 - 0s - loss: 3.4234e-04 - val_loss: 0.0131 - 207ms/epoch - 21ms/step\n",
      "Epoch 77/129\n",
      "10/10 - 0s - loss: 2.7689e-04 - val_loss: 0.0129 - 208ms/epoch - 21ms/step\n",
      "Epoch 78/129\n",
      "10/10 - 0s - loss: 2.2692e-04 - val_loss: 0.0130 - 218ms/epoch - 22ms/step\n",
      "Epoch 79/129\n",
      "10/10 - 0s - loss: 2.6704e-04 - val_loss: 0.0130 - 196ms/epoch - 20ms/step\n",
      "Epoch 80/129\n",
      "10/10 - 0s - loss: 2.8162e-04 - val_loss: 0.0134 - 191ms/epoch - 19ms/step\n",
      "Epoch 81/129\n",
      "10/10 - 0s - loss: 2.7626e-04 - val_loss: 0.0131 - 182ms/epoch - 18ms/step\n",
      "Epoch 82/129\n",
      "10/10 - 0s - loss: 2.8355e-04 - val_loss: 0.0133 - 189ms/epoch - 19ms/step\n",
      "Epoch 83/129\n",
      "10/10 - 0s - loss: 2.6576e-04 - val_loss: 0.0132 - 193ms/epoch - 19ms/step\n",
      "Epoch 84/129\n",
      "10/10 - 0s - loss: 2.5141e-04 - val_loss: 0.0128 - 200ms/epoch - 20ms/step\n",
      "Epoch 85/129\n",
      "10/10 - 0s - loss: 2.3538e-04 - val_loss: 0.0131 - 197ms/epoch - 20ms/step\n",
      "Epoch 86/129\n",
      "10/10 - 0s - loss: 2.0907e-04 - val_loss: 0.0127 - 188ms/epoch - 19ms/step\n",
      "Epoch 87/129\n",
      "10/10 - 0s - loss: 2.2500e-04 - val_loss: 0.0126 - 217ms/epoch - 22ms/step\n",
      "Epoch 88/129\n",
      "10/10 - 0s - loss: 2.2570e-04 - val_loss: 0.0134 - 204ms/epoch - 20ms/step\n",
      "Epoch 89/129\n",
      "10/10 - 0s - loss: 3.1469e-04 - val_loss: 0.0128 - 216ms/epoch - 22ms/step\n",
      "Epoch 90/129\n",
      "10/10 - 0s - loss: 2.7549e-04 - val_loss: 0.0134 - 187ms/epoch - 19ms/step\n",
      "Epoch 91/129\n",
      "10/10 - 0s - loss: 2.2926e-04 - val_loss: 0.0134 - 207ms/epoch - 21ms/step\n",
      "Epoch 92/129\n",
      "10/10 - 0s - loss: 2.3433e-04 - val_loss: 0.0132 - 196ms/epoch - 20ms/step\n",
      "Epoch 93/129\n",
      "10/10 - 0s - loss: 2.4150e-04 - val_loss: 0.0136 - 207ms/epoch - 21ms/step\n",
      "Epoch 94/129\n",
      "10/10 - 0s - loss: 2.4356e-04 - val_loss: 0.0132 - 196ms/epoch - 20ms/step\n",
      "Epoch 95/129\n",
      "10/10 - 0s - loss: 2.1268e-04 - val_loss: 0.0134 - 194ms/epoch - 19ms/step\n",
      "Epoch 96/129\n",
      "10/10 - 0s - loss: 2.5140e-04 - val_loss: 0.0133 - 188ms/epoch - 19ms/step\n",
      "Epoch 97/129\n",
      "10/10 - 0s - loss: 2.5202e-04 - val_loss: 0.0137 - 200ms/epoch - 20ms/step\n",
      "Epoch 98/129\n",
      "10/10 - 0s - loss: 2.8725e-04 - val_loss: 0.0132 - 190ms/epoch - 19ms/step\n",
      "Epoch 99/129\n",
      "10/10 - 0s - loss: 2.3911e-04 - val_loss: 0.0133 - 195ms/epoch - 20ms/step\n",
      "Epoch 100/129\n",
      "10/10 - 0s - loss: 2.5227e-04 - val_loss: 0.0133 - 221ms/epoch - 22ms/step\n",
      "Epoch 101/129\n",
      "10/10 - 0s - loss: 2.6640e-04 - val_loss: 0.0136 - 197ms/epoch - 20ms/step\n",
      "Epoch 102/129\n",
      "10/10 - 0s - loss: 2.2052e-04 - val_loss: 0.0132 - 198ms/epoch - 20ms/step\n",
      "Epoch 103/129\n",
      "10/10 - 0s - loss: 2.5187e-04 - val_loss: 0.0136 - 187ms/epoch - 19ms/step\n",
      "Epoch 104/129\n",
      "10/10 - 0s - loss: 3.0459e-04 - val_loss: 0.0133 - 183ms/epoch - 18ms/step\n",
      "Epoch 105/129\n",
      "10/10 - 0s - loss: 2.3847e-04 - val_loss: 0.0133 - 202ms/epoch - 20ms/step\n",
      "Epoch 106/129\n",
      "10/10 - 0s - loss: 2.4711e-04 - val_loss: 0.0133 - 188ms/epoch - 19ms/step\n",
      "Epoch 107/129\n",
      "10/10 - 0s - loss: 2.2202e-04 - val_loss: 0.0130 - 188ms/epoch - 19ms/step\n",
      "Epoch 108/129\n",
      "10/10 - 0s - loss: 2.8122e-04 - val_loss: 0.0129 - 215ms/epoch - 21ms/step\n",
      "Epoch 109/129\n",
      "10/10 - 0s - loss: 2.8861e-04 - val_loss: 0.0134 - 184ms/epoch - 18ms/step\n",
      "Epoch 110/129\n",
      "10/10 - 0s - loss: 2.2904e-04 - val_loss: 0.0129 - 190ms/epoch - 19ms/step\n",
      "Epoch 111/129\n",
      "10/10 - 0s - loss: 2.4003e-04 - val_loss: 0.0133 - 202ms/epoch - 20ms/step\n",
      "Epoch 112/129\n",
      "10/10 - 0s - loss: 2.4811e-04 - val_loss: 0.0131 - 208ms/epoch - 21ms/step\n",
      "Epoch 113/129\n",
      "10/10 - 0s - loss: 2.5849e-04 - val_loss: 0.0137 - 182ms/epoch - 18ms/step\n",
      "Epoch 114/129\n",
      "10/10 - 0s - loss: 2.4958e-04 - val_loss: 0.0135 - 228ms/epoch - 23ms/step\n",
      "Epoch 115/129\n",
      "10/10 - 0s - loss: 2.5706e-04 - val_loss: 0.0137 - 190ms/epoch - 19ms/step\n",
      "Epoch 116/129\n",
      "10/10 - 0s - loss: 2.5015e-04 - val_loss: 0.0135 - 183ms/epoch - 18ms/step\n",
      "Epoch 117/129\n",
      "10/10 - 0s - loss: 2.2017e-04 - val_loss: 0.0136 - 207ms/epoch - 21ms/step\n",
      "Epoch 118/129\n",
      "10/10 - 0s - loss: 2.5152e-04 - val_loss: 0.0134 - 193ms/epoch - 19ms/step\n",
      "Epoch 119/129\n",
      "10/10 - 0s - loss: 2.4403e-04 - val_loss: 0.0133 - 180ms/epoch - 18ms/step\n",
      "Epoch 120/129\n",
      "10/10 - 0s - loss: 2.1074e-04 - val_loss: 0.0134 - 180ms/epoch - 18ms/step\n",
      "Epoch 121/129\n",
      "10/10 - 0s - loss: 2.1804e-04 - val_loss: 0.0132 - 178ms/epoch - 18ms/step\n",
      "Epoch 122/129\n",
      "10/10 - 0s - loss: 2.4400e-04 - val_loss: 0.0136 - 199ms/epoch - 20ms/step\n",
      "Epoch 123/129\n",
      "10/10 - 0s - loss: 2.4685e-04 - val_loss: 0.0130 - 185ms/epoch - 18ms/step\n",
      "Epoch 124/129\n",
      "10/10 - 0s - loss: 2.6545e-04 - val_loss: 0.0132 - 181ms/epoch - 18ms/step\n",
      "Epoch 125/129\n",
      "10/10 - 0s - loss: 3.7625e-04 - val_loss: 0.0131 - 179ms/epoch - 18ms/step\n",
      "Epoch 126/129\n",
      "10/10 - 0s - loss: 3.0889e-04 - val_loss: 0.0135 - 179ms/epoch - 18ms/step\n",
      "Epoch 127/129\n",
      "10/10 - 0s - loss: 2.2885e-04 - val_loss: 0.0125 - 227ms/epoch - 23ms/step\n",
      "Epoch 128/129\n",
      "10/10 - 0s - loss: 2.3452e-04 - val_loss: 0.0128 - 183ms/epoch - 18ms/step\n",
      "Epoch 129/129\n",
      "10/10 - 0s - loss: 2.1070e-04 - val_loss: 0.0130 - 183ms/epoch - 18ms/step\n",
      "9/9 [==============================] - 1s 5ms/step\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m-204.5   \u001b[0m | \u001b[0m129.6    \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m118.9    \u001b[0m |\n",
      "Model: \"sequential_145\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_529 (LSTM)             (None, 1, 88)             33088     \n",
      "                                                                 \n",
      " dropout_384 (Dropout)       (None, 1, 88)             0         \n",
      "                                                                 \n",
      " lstm_530 (LSTM)             (None, 1, 88)             62304     \n",
      "                                                                 \n",
      " dropout_385 (Dropout)       (None, 1, 88)             0         \n",
      "                                                                 \n",
      " lstm_531 (LSTM)             (None, 1, 88)             62304     \n",
      "                                                                 \n",
      " dropout_386 (Dropout)       (None, 1, 88)             0         \n",
      "                                                                 \n",
      " lstm_532 (LSTM)             (None, 1, 88)             62304     \n",
      "                                                                 \n",
      " dropout_387 (Dropout)       (None, 1, 88)             0         \n",
      "                                                                 \n",
      " lstm_533 (LSTM)             (None, 88)                62304     \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 1)                 89        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 282,393\n",
      "Trainable params: 282,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/167\n",
      "10/10 - 11s - loss: 0.0641 - val_loss: 0.0757 - 11s/epoch - 1s/step\n",
      "Epoch 2/167\n",
      "10/10 - 0s - loss: 0.0476 - val_loss: 0.0561 - 132ms/epoch - 13ms/step\n",
      "Epoch 3/167\n",
      "10/10 - 0s - loss: 0.0273 - val_loss: 0.0319 - 134ms/epoch - 13ms/step\n",
      "Epoch 4/167\n",
      "10/10 - 0s - loss: 0.0076 - val_loss: 0.0147 - 155ms/epoch - 16ms/step\n",
      "Epoch 5/167\n",
      "10/10 - 0s - loss: 0.0042 - val_loss: 0.0150 - 173ms/epoch - 17ms/step\n",
      "Epoch 6/167\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0164 - 137ms/epoch - 14ms/step\n",
      "Epoch 7/167\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0157 - 134ms/epoch - 13ms/step\n",
      "Epoch 8/167\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0150 - 147ms/epoch - 15ms/step\n",
      "Epoch 9/167\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0151 - 135ms/epoch - 14ms/step\n",
      "Epoch 10/167\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0151 - 132ms/epoch - 13ms/step\n",
      "Epoch 11/167\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0146 - 146ms/epoch - 15ms/step\n",
      "Epoch 12/167\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0144 - 164ms/epoch - 16ms/step\n",
      "Epoch 13/167\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0139 - 139ms/epoch - 14ms/step\n",
      "Epoch 14/167\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0137 - 140ms/epoch - 14ms/step\n",
      "Epoch 15/167\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0132 - 168ms/epoch - 17ms/step\n",
      "Epoch 16/167\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0128 - 131ms/epoch - 13ms/step\n",
      "Epoch 17/167\n",
      "10/10 - 0s - loss: 0.0021 - val_loss: 0.0121 - 149ms/epoch - 15ms/step\n",
      "Epoch 18/167\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0115 - 134ms/epoch - 13ms/step\n",
      "Epoch 19/167\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0110 - 135ms/epoch - 13ms/step\n",
      "Epoch 20/167\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0103 - 133ms/epoch - 13ms/step\n",
      "Epoch 21/167\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0097 - 147ms/epoch - 15ms/step\n",
      "Epoch 22/167\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0093 - 133ms/epoch - 13ms/step\n",
      "Epoch 23/167\n",
      "10/10 - 0s - loss: 9.5798e-04 - val_loss: 0.0088 - 133ms/epoch - 13ms/step\n",
      "Epoch 24/167\n",
      "10/10 - 0s - loss: 9.9919e-04 - val_loss: 0.0087 - 140ms/epoch - 14ms/step\n",
      "Epoch 25/167\n",
      "10/10 - 0s - loss: 8.4234e-04 - val_loss: 0.0086 - 148ms/epoch - 15ms/step\n",
      "Epoch 26/167\n",
      "10/10 - 0s - loss: 7.4738e-04 - val_loss: 0.0087 - 148ms/epoch - 15ms/step\n",
      "Epoch 27/167\n",
      "10/10 - 0s - loss: 6.7850e-04 - val_loss: 0.0088 - 135ms/epoch - 13ms/step\n",
      "Epoch 28/167\n",
      "10/10 - 0s - loss: 7.3879e-04 - val_loss: 0.0093 - 136ms/epoch - 14ms/step\n",
      "Epoch 29/167\n",
      "10/10 - 0s - loss: 7.4960e-04 - val_loss: 0.0092 - 185ms/epoch - 19ms/step\n",
      "Epoch 30/167\n",
      "10/10 - 0s - loss: 7.4710e-04 - val_loss: 0.0090 - 169ms/epoch - 17ms/step\n",
      "Epoch 31/167\n",
      "10/10 - 0s - loss: 6.4022e-04 - val_loss: 0.0091 - 164ms/epoch - 16ms/step\n",
      "Epoch 32/167\n",
      "10/10 - 0s - loss: 7.0303e-04 - val_loss: 0.0092 - 158ms/epoch - 16ms/step\n",
      "Epoch 33/167\n",
      "10/10 - 0s - loss: 6.7334e-04 - val_loss: 0.0088 - 166ms/epoch - 17ms/step\n",
      "Epoch 34/167\n",
      "10/10 - 0s - loss: 5.8633e-04 - val_loss: 0.0088 - 175ms/epoch - 17ms/step\n",
      "Epoch 35/167\n",
      "10/10 - 0s - loss: 5.9118e-04 - val_loss: 0.0091 - 138ms/epoch - 14ms/step\n",
      "Epoch 36/167\n",
      "10/10 - 0s - loss: 6.1544e-04 - val_loss: 0.0090 - 139ms/epoch - 14ms/step\n",
      "Epoch 37/167\n",
      "10/10 - 0s - loss: 5.6122e-04 - val_loss: 0.0090 - 131ms/epoch - 13ms/step\n",
      "Epoch 38/167\n",
      "10/10 - 0s - loss: 5.3722e-04 - val_loss: 0.0091 - 156ms/epoch - 16ms/step\n",
      "Epoch 39/167\n",
      "10/10 - 0s - loss: 5.5226e-04 - val_loss: 0.0090 - 172ms/epoch - 17ms/step\n",
      "Epoch 40/167\n",
      "10/10 - 0s - loss: 5.6517e-04 - val_loss: 0.0089 - 148ms/epoch - 15ms/step\n",
      "Epoch 41/167\n",
      "10/10 - 0s - loss: 4.7912e-04 - val_loss: 0.0090 - 161ms/epoch - 16ms/step\n",
      "Epoch 42/167\n",
      "10/10 - 0s - loss: 5.5759e-04 - val_loss: 0.0091 - 147ms/epoch - 15ms/step\n",
      "Epoch 43/167\n",
      "10/10 - 0s - loss: 5.3104e-04 - val_loss: 0.0090 - 152ms/epoch - 15ms/step\n",
      "Epoch 44/167\n",
      "10/10 - 0s - loss: 4.6594e-04 - val_loss: 0.0089 - 137ms/epoch - 14ms/step\n",
      "Epoch 45/167\n",
      "10/10 - 0s - loss: 5.1424e-04 - val_loss: 0.0091 - 136ms/epoch - 14ms/step\n",
      "Epoch 46/167\n",
      "10/10 - 0s - loss: 4.6839e-04 - val_loss: 0.0091 - 136ms/epoch - 14ms/step\n",
      "Epoch 47/167\n",
      "10/10 - 0s - loss: 4.9463e-04 - val_loss: 0.0088 - 151ms/epoch - 15ms/step\n",
      "Epoch 48/167\n",
      "10/10 - 0s - loss: 4.1931e-04 - val_loss: 0.0090 - 139ms/epoch - 14ms/step\n",
      "Epoch 49/167\n",
      "10/10 - 0s - loss: 4.4195e-04 - val_loss: 0.0089 - 132ms/epoch - 13ms/step\n",
      "Epoch 50/167\n",
      "10/10 - 0s - loss: 4.3352e-04 - val_loss: 0.0090 - 137ms/epoch - 14ms/step\n",
      "Epoch 51/167\n",
      "10/10 - 0s - loss: 4.2943e-04 - val_loss: 0.0092 - 151ms/epoch - 15ms/step\n",
      "Epoch 52/167\n",
      "10/10 - 0s - loss: 4.1590e-04 - val_loss: 0.0090 - 149ms/epoch - 15ms/step\n",
      "Epoch 53/167\n",
      "10/10 - 0s - loss: 4.2017e-04 - val_loss: 0.0089 - 136ms/epoch - 14ms/step\n",
      "Epoch 54/167\n",
      "10/10 - 0s - loss: 3.8698e-04 - val_loss: 0.0089 - 137ms/epoch - 14ms/step\n",
      "Epoch 55/167\n",
      "10/10 - 0s - loss: 4.2226e-04 - val_loss: 0.0089 - 187ms/epoch - 19ms/step\n",
      "Epoch 56/167\n",
      "10/10 - 0s - loss: 3.8665e-04 - val_loss: 0.0089 - 136ms/epoch - 14ms/step\n",
      "Epoch 57/167\n",
      "10/10 - 0s - loss: 3.9834e-04 - val_loss: 0.0090 - 131ms/epoch - 13ms/step\n",
      "Epoch 58/167\n",
      "10/10 - 0s - loss: 4.1535e-04 - val_loss: 0.0088 - 137ms/epoch - 14ms/step\n",
      "Epoch 59/167\n",
      "10/10 - 0s - loss: 3.8320e-04 - val_loss: 0.0090 - 148ms/epoch - 15ms/step\n",
      "Epoch 60/167\n",
      "10/10 - 0s - loss: 3.9360e-04 - val_loss: 0.0089 - 131ms/epoch - 13ms/step\n",
      "Epoch 61/167\n",
      "10/10 - 0s - loss: 4.0704e-04 - val_loss: 0.0089 - 140ms/epoch - 14ms/step\n",
      "Epoch 62/167\n",
      "10/10 - 0s - loss: 3.5911e-04 - val_loss: 0.0089 - 144ms/epoch - 14ms/step\n",
      "Epoch 63/167\n",
      "10/10 - 0s - loss: 3.5450e-04 - val_loss: 0.0089 - 149ms/epoch - 15ms/step\n",
      "Epoch 64/167\n",
      "10/10 - 0s - loss: 3.7640e-04 - val_loss: 0.0089 - 157ms/epoch - 16ms/step\n",
      "Epoch 65/167\n",
      "10/10 - 0s - loss: 3.7424e-04 - val_loss: 0.0089 - 131ms/epoch - 13ms/step\n",
      "Epoch 66/167\n",
      "10/10 - 0s - loss: 3.3781e-04 - val_loss: 0.0089 - 147ms/epoch - 15ms/step\n",
      "Epoch 67/167\n",
      "10/10 - 0s - loss: 3.8172e-04 - val_loss: 0.0089 - 127ms/epoch - 13ms/step\n",
      "Epoch 68/167\n",
      "10/10 - 0s - loss: 3.5998e-04 - val_loss: 0.0089 - 127ms/epoch - 13ms/step\n",
      "Epoch 69/167\n",
      "10/10 - 0s - loss: 3.6335e-04 - val_loss: 0.0088 - 127ms/epoch - 13ms/step\n",
      "Epoch 70/167\n",
      "10/10 - 0s - loss: 3.5755e-04 - val_loss: 0.0089 - 142ms/epoch - 14ms/step\n",
      "Epoch 71/167\n",
      "10/10 - 0s - loss: 3.6448e-04 - val_loss: 0.0089 - 151ms/epoch - 15ms/step\n",
      "Epoch 72/167\n",
      "10/10 - 0s - loss: 3.4252e-04 - val_loss: 0.0089 - 130ms/epoch - 13ms/step\n",
      "Epoch 73/167\n",
      "10/10 - 0s - loss: 3.8703e-04 - val_loss: 0.0089 - 128ms/epoch - 13ms/step\n",
      "Epoch 74/167\n",
      "10/10 - 0s - loss: 3.2291e-04 - val_loss: 0.0089 - 142ms/epoch - 14ms/step\n",
      "Epoch 75/167\n",
      "10/10 - 0s - loss: 3.2588e-04 - val_loss: 0.0089 - 127ms/epoch - 13ms/step\n",
      "Epoch 76/167\n",
      "10/10 - 0s - loss: 3.5873e-04 - val_loss: 0.0088 - 129ms/epoch - 13ms/step\n",
      "Epoch 77/167\n",
      "10/10 - 0s - loss: 3.3823e-04 - val_loss: 0.0087 - 127ms/epoch - 13ms/step\n",
      "Epoch 78/167\n",
      "10/10 - 0s - loss: 3.2681e-04 - val_loss: 0.0088 - 139ms/epoch - 14ms/step\n",
      "Epoch 79/167\n",
      "10/10 - 0s - loss: 3.3957e-04 - val_loss: 0.0088 - 128ms/epoch - 13ms/step\n",
      "Epoch 80/167\n",
      "10/10 - 0s - loss: 2.8193e-04 - val_loss: 0.0089 - 128ms/epoch - 13ms/step\n",
      "Epoch 81/167\n",
      "10/10 - 0s - loss: 3.1232e-04 - val_loss: 0.0089 - 127ms/epoch - 13ms/step\n",
      "Epoch 82/167\n",
      "10/10 - 0s - loss: 3.1899e-04 - val_loss: 0.0089 - 136ms/epoch - 14ms/step\n",
      "Epoch 83/167\n",
      "10/10 - 0s - loss: 3.1802e-04 - val_loss: 0.0089 - 151ms/epoch - 15ms/step\n",
      "Epoch 84/167\n",
      "10/10 - 0s - loss: 3.1486e-04 - val_loss: 0.0088 - 130ms/epoch - 13ms/step\n",
      "Epoch 85/167\n",
      "10/10 - 0s - loss: 3.1650e-04 - val_loss: 0.0088 - 126ms/epoch - 13ms/step\n",
      "Epoch 86/167\n",
      "10/10 - 0s - loss: 3.2039e-04 - val_loss: 0.0090 - 126ms/epoch - 13ms/step\n",
      "Epoch 87/167\n",
      "10/10 - 0s - loss: 3.1460e-04 - val_loss: 0.0089 - 136ms/epoch - 14ms/step\n",
      "Epoch 88/167\n",
      "10/10 - 0s - loss: 3.2139e-04 - val_loss: 0.0087 - 128ms/epoch - 13ms/step\n",
      "Epoch 89/167\n",
      "10/10 - 0s - loss: 3.2305e-04 - val_loss: 0.0087 - 125ms/epoch - 13ms/step\n",
      "Epoch 90/167\n",
      "10/10 - 0s - loss: 3.1204e-04 - val_loss: 0.0089 - 129ms/epoch - 13ms/step\n",
      "Epoch 91/167\n",
      "10/10 - 0s - loss: 3.1321e-04 - val_loss: 0.0090 - 138ms/epoch - 14ms/step\n",
      "Epoch 92/167\n",
      "10/10 - 0s - loss: 3.1903e-04 - val_loss: 0.0087 - 136ms/epoch - 14ms/step\n",
      "Epoch 93/167\n",
      "10/10 - 0s - loss: 3.2074e-04 - val_loss: 0.0087 - 144ms/epoch - 14ms/step\n",
      "Epoch 94/167\n",
      "10/10 - 0s - loss: 2.9735e-04 - val_loss: 0.0088 - 128ms/epoch - 13ms/step\n",
      "Epoch 95/167\n",
      "10/10 - 0s - loss: 3.0239e-04 - val_loss: 0.0088 - 140ms/epoch - 14ms/step\n",
      "Epoch 96/167\n",
      "10/10 - 0s - loss: 3.1937e-04 - val_loss: 0.0087 - 126ms/epoch - 13ms/step\n",
      "Epoch 97/167\n",
      "10/10 - 0s - loss: 3.3131e-04 - val_loss: 0.0087 - 126ms/epoch - 13ms/step\n",
      "Epoch 98/167\n",
      "10/10 - 0s - loss: 3.2116e-04 - val_loss: 0.0088 - 126ms/epoch - 13ms/step\n",
      "Epoch 99/167\n",
      "10/10 - 0s - loss: 3.0368e-04 - val_loss: 0.0086 - 141ms/epoch - 14ms/step\n",
      "Epoch 100/167\n",
      "10/10 - 0s - loss: 2.9579e-04 - val_loss: 0.0087 - 128ms/epoch - 13ms/step\n",
      "Epoch 101/167\n",
      "10/10 - 0s - loss: 3.0245e-04 - val_loss: 0.0087 - 126ms/epoch - 13ms/step\n",
      "Epoch 102/167\n",
      "10/10 - 0s - loss: 3.0443e-04 - val_loss: 0.0087 - 126ms/epoch - 13ms/step\n",
      "Epoch 103/167\n",
      "10/10 - 0s - loss: 2.7559e-04 - val_loss: 0.0087 - 137ms/epoch - 14ms/step\n",
      "Epoch 104/167\n",
      "10/10 - 0s - loss: 2.9556e-04 - val_loss: 0.0087 - 136ms/epoch - 14ms/step\n",
      "Epoch 105/167\n",
      "10/10 - 0s - loss: 2.8099e-04 - val_loss: 0.0089 - 146ms/epoch - 15ms/step\n",
      "Epoch 106/167\n",
      "10/10 - 0s - loss: 2.7011e-04 - val_loss: 0.0088 - 129ms/epoch - 13ms/step\n",
      "Epoch 107/167\n",
      "10/10 - 0s - loss: 2.9935e-04 - val_loss: 0.0087 - 140ms/epoch - 14ms/step\n",
      "Epoch 108/167\n",
      "10/10 - 0s - loss: 3.0434e-04 - val_loss: 0.0086 - 130ms/epoch - 13ms/step\n",
      "Epoch 109/167\n",
      "10/10 - 0s - loss: 2.8920e-04 - val_loss: 0.0086 - 126ms/epoch - 13ms/step\n",
      "Epoch 110/167\n",
      "10/10 - 0s - loss: 2.9115e-04 - val_loss: 0.0088 - 125ms/epoch - 12ms/step\n",
      "Epoch 111/167\n",
      "10/10 - 0s - loss: 3.0995e-04 - val_loss: 0.0088 - 137ms/epoch - 14ms/step\n",
      "Epoch 112/167\n",
      "10/10 - 0s - loss: 3.0397e-04 - val_loss: 0.0088 - 162ms/epoch - 16ms/step\n",
      "Epoch 113/167\n",
      "10/10 - 0s - loss: 2.8394e-04 - val_loss: 0.0086 - 139ms/epoch - 14ms/step\n",
      "Epoch 114/167\n",
      "10/10 - 0s - loss: 2.9763e-04 - val_loss: 0.0087 - 126ms/epoch - 13ms/step\n",
      "Epoch 115/167\n",
      "10/10 - 0s - loss: 2.8931e-04 - val_loss: 0.0087 - 139ms/epoch - 14ms/step\n",
      "Epoch 116/167\n",
      "10/10 - 0s - loss: 2.5714e-04 - val_loss: 0.0086 - 127ms/epoch - 13ms/step\n",
      "Epoch 117/167\n",
      "10/10 - 0s - loss: 2.6538e-04 - val_loss: 0.0088 - 130ms/epoch - 13ms/step\n",
      "Epoch 118/167\n",
      "10/10 - 0s - loss: 2.8070e-04 - val_loss: 0.0087 - 137ms/epoch - 14ms/step\n",
      "Epoch 119/167\n",
      "10/10 - 0s - loss: 2.7306e-04 - val_loss: 0.0088 - 144ms/epoch - 14ms/step\n",
      "Epoch 120/167\n",
      "10/10 - 0s - loss: 2.5381e-04 - val_loss: 0.0087 - 128ms/epoch - 13ms/step\n",
      "Epoch 121/167\n",
      "10/10 - 0s - loss: 2.8966e-04 - val_loss: 0.0086 - 130ms/epoch - 13ms/step\n",
      "Epoch 122/167\n",
      "10/10 - 0s - loss: 2.7808e-04 - val_loss: 0.0086 - 149ms/epoch - 15ms/step\n",
      "Epoch 123/167\n",
      "10/10 - 0s - loss: 2.9057e-04 - val_loss: 0.0087 - 138ms/epoch - 14ms/step\n",
      "Epoch 124/167\n",
      "10/10 - 0s - loss: 2.9374e-04 - val_loss: 0.0087 - 128ms/epoch - 13ms/step\n",
      "Epoch 125/167\n",
      "10/10 - 0s - loss: 2.6046e-04 - val_loss: 0.0088 - 130ms/epoch - 13ms/step\n",
      "Epoch 126/167\n",
      "10/10 - 0s - loss: 2.9096e-04 - val_loss: 0.0087 - 127ms/epoch - 13ms/step\n",
      "Epoch 127/167\n",
      "10/10 - 0s - loss: 2.8053e-04 - val_loss: 0.0086 - 142ms/epoch - 14ms/step\n",
      "Epoch 128/167\n",
      "10/10 - 0s - loss: 2.7609e-04 - val_loss: 0.0086 - 127ms/epoch - 13ms/step\n",
      "Epoch 129/167\n",
      "10/10 - 0s - loss: 2.5436e-04 - val_loss: 0.0088 - 129ms/epoch - 13ms/step\n",
      "Epoch 130/167\n",
      "10/10 - 0s - loss: 2.7799e-04 - val_loss: 0.0086 - 126ms/epoch - 13ms/step\n",
      "Epoch 131/167\n",
      "10/10 - 0s - loss: 2.6037e-04 - val_loss: 0.0086 - 139ms/epoch - 14ms/step\n",
      "Epoch 132/167\n",
      "10/10 - 0s - loss: 2.6965e-04 - val_loss: 0.0087 - 127ms/epoch - 13ms/step\n",
      "Epoch 133/167\n",
      "10/10 - 0s - loss: 2.4455e-04 - val_loss: 0.0086 - 125ms/epoch - 12ms/step\n",
      "Epoch 134/167\n",
      "10/10 - 0s - loss: 2.7234e-04 - val_loss: 0.0087 - 151ms/epoch - 15ms/step\n",
      "Epoch 135/167\n",
      "10/10 - 0s - loss: 2.7803e-04 - val_loss: 0.0087 - 146ms/epoch - 15ms/step\n",
      "Epoch 136/167\n",
      "10/10 - 0s - loss: 2.5369e-04 - val_loss: 0.0086 - 130ms/epoch - 13ms/step\n",
      "Epoch 137/167\n",
      "10/10 - 0s - loss: 2.7367e-04 - val_loss: 0.0085 - 129ms/epoch - 13ms/step\n",
      "Epoch 138/167\n",
      "10/10 - 0s - loss: 2.6747e-04 - val_loss: 0.0087 - 130ms/epoch - 13ms/step\n",
      "Epoch 139/167\n",
      "10/10 - 0s - loss: 2.8837e-04 - val_loss: 0.0088 - 141ms/epoch - 14ms/step\n",
      "Epoch 140/167\n",
      "10/10 - 0s - loss: 2.4693e-04 - val_loss: 0.0087 - 150ms/epoch - 15ms/step\n",
      "Epoch 141/167\n",
      "10/10 - 0s - loss: 2.6805e-04 - val_loss: 0.0085 - 133ms/epoch - 13ms/step\n",
      "Epoch 142/167\n",
      "10/10 - 0s - loss: 2.4477e-04 - val_loss: 0.0086 - 127ms/epoch - 13ms/step\n",
      "Epoch 143/167\n",
      "10/10 - 0s - loss: 2.5221e-04 - val_loss: 0.0087 - 143ms/epoch - 14ms/step\n",
      "Epoch 144/167\n",
      "10/10 - 0s - loss: 2.7869e-04 - val_loss: 0.0086 - 125ms/epoch - 13ms/step\n",
      "Epoch 145/167\n",
      "10/10 - 0s - loss: 2.6602e-04 - val_loss: 0.0086 - 130ms/epoch - 13ms/step\n",
      "Epoch 146/167\n",
      "10/10 - 0s - loss: 2.4009e-04 - val_loss: 0.0087 - 127ms/epoch - 13ms/step\n",
      "Epoch 147/167\n",
      "10/10 - 0s - loss: 2.3566e-04 - val_loss: 0.0087 - 136ms/epoch - 14ms/step\n",
      "Epoch 148/167\n",
      "10/10 - 0s - loss: 2.5343e-04 - val_loss: 0.0085 - 132ms/epoch - 13ms/step\n",
      "Epoch 149/167\n",
      "10/10 - 0s - loss: 2.4318e-04 - val_loss: 0.0087 - 127ms/epoch - 13ms/step\n",
      "Epoch 150/167\n",
      "10/10 - 0s - loss: 2.4739e-04 - val_loss: 0.0087 - 130ms/epoch - 13ms/step\n",
      "Epoch 151/167\n",
      "10/10 - 0s - loss: 2.3415e-04 - val_loss: 0.0086 - 146ms/epoch - 15ms/step\n",
      "Epoch 152/167\n",
      "10/10 - 0s - loss: 2.4841e-04 - val_loss: 0.0086 - 127ms/epoch - 13ms/step\n",
      "Epoch 153/167\n",
      "10/10 - 0s - loss: 2.6205e-04 - val_loss: 0.0086 - 151ms/epoch - 15ms/step\n",
      "Epoch 154/167\n",
      "10/10 - 0s - loss: 2.7127e-04 - val_loss: 0.0086 - 132ms/epoch - 13ms/step\n",
      "Epoch 155/167\n",
      "10/10 - 0s - loss: 2.6576e-04 - val_loss: 0.0086 - 138ms/epoch - 14ms/step\n",
      "Epoch 156/167\n",
      "10/10 - 0s - loss: 2.7692e-04 - val_loss: 0.0086 - 129ms/epoch - 13ms/step\n",
      "Epoch 157/167\n",
      "10/10 - 0s - loss: 2.4180e-04 - val_loss: 0.0085 - 128ms/epoch - 13ms/step\n",
      "Epoch 158/167\n",
      "10/10 - 0s - loss: 2.6501e-04 - val_loss: 0.0088 - 131ms/epoch - 13ms/step\n",
      "Epoch 159/167\n",
      "10/10 - 0s - loss: 2.4713e-04 - val_loss: 0.0085 - 150ms/epoch - 15ms/step\n",
      "Epoch 160/167\n",
      "10/10 - 0s - loss: 2.4730e-04 - val_loss: 0.0086 - 129ms/epoch - 13ms/step\n",
      "Epoch 161/167\n",
      "10/10 - 0s - loss: 2.3866e-04 - val_loss: 0.0087 - 128ms/epoch - 13ms/step\n",
      "Epoch 162/167\n",
      "10/10 - 0s - loss: 2.4748e-04 - val_loss: 0.0086 - 127ms/epoch - 13ms/step\n",
      "Epoch 163/167\n",
      "10/10 - 0s - loss: 2.4663e-04 - val_loss: 0.0086 - 164ms/epoch - 16ms/step\n",
      "Epoch 164/167\n",
      "10/10 - 0s - loss: 2.5688e-04 - val_loss: 0.0086 - 138ms/epoch - 14ms/step\n",
      "Epoch 165/167\n",
      "10/10 - 0s - loss: 2.4186e-04 - val_loss: 0.0086 - 128ms/epoch - 13ms/step\n",
      "Epoch 166/167\n",
      "10/10 - 0s - loss: 2.4080e-04 - val_loss: 0.0086 - 128ms/epoch - 13ms/step\n",
      "Epoch 167/167\n",
      "10/10 - 0s - loss: 2.2426e-04 - val_loss: 0.0086 - 140ms/epoch - 14ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m-166.3   \u001b[0m | \u001b[0m167.0    \u001b[0m | \u001b[0m4.261    \u001b[0m | \u001b[0m0.0006287\u001b[0m | \u001b[0m88.53    \u001b[0m |\n",
      "Model: \"sequential_146\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_534 (LSTM)             (None, 1, 78)             26208     \n",
      "                                                                 \n",
      " dropout_388 (Dropout)       (None, 1, 78)             0         \n",
      "                                                                 \n",
      " lstm_535 (LSTM)             (None, 78)                48984     \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 1)                 79        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 75,271\n",
      "Trainable params: 75,271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/97\n",
      "10/10 - 4s - loss: 0.0712 - val_loss: 0.0923 - 4s/epoch - 387ms/step\n",
      "Epoch 2/97\n",
      "10/10 - 0s - loss: 0.0707 - val_loss: 0.0919 - 74ms/epoch - 7ms/step\n",
      "Epoch 3/97\n",
      "10/10 - 0s - loss: 0.0704 - val_loss: 0.0916 - 71ms/epoch - 7ms/step\n",
      "Epoch 4/97\n",
      "10/10 - 0s - loss: 0.0701 - val_loss: 0.0912 - 72ms/epoch - 7ms/step\n",
      "Epoch 5/97\n",
      "10/10 - 0s - loss: 0.0698 - val_loss: 0.0908 - 86ms/epoch - 9ms/step\n",
      "Epoch 6/97\n",
      "10/10 - 0s - loss: 0.0695 - val_loss: 0.0905 - 76ms/epoch - 8ms/step\n",
      "Epoch 7/97\n",
      "10/10 - 0s - loss: 0.0692 - val_loss: 0.0901 - 78ms/epoch - 8ms/step\n",
      "Epoch 8/97\n",
      "10/10 - 0s - loss: 0.0688 - val_loss: 0.0898 - 80ms/epoch - 8ms/step\n",
      "Epoch 9/97\n",
      "10/10 - 0s - loss: 0.0685 - val_loss: 0.0894 - 103ms/epoch - 10ms/step\n",
      "Epoch 10/97\n",
      "10/10 - 0s - loss: 0.0682 - val_loss: 0.0891 - 89ms/epoch - 9ms/step\n",
      "Epoch 11/97\n",
      "10/10 - 0s - loss: 0.0679 - val_loss: 0.0887 - 79ms/epoch - 8ms/step\n",
      "Epoch 12/97\n",
      "10/10 - 0s - loss: 0.0676 - val_loss: 0.0884 - 81ms/epoch - 8ms/step\n",
      "Epoch 13/97\n",
      "10/10 - 0s - loss: 0.0673 - val_loss: 0.0880 - 80ms/epoch - 8ms/step\n",
      "Epoch 14/97\n",
      "10/10 - 0s - loss: 0.0669 - val_loss: 0.0877 - 94ms/epoch - 9ms/step\n",
      "Epoch 15/97\n",
      "10/10 - 0s - loss: 0.0666 - val_loss: 0.0873 - 103ms/epoch - 10ms/step\n",
      "Epoch 16/97\n",
      "10/10 - 0s - loss: 0.0664 - val_loss: 0.0870 - 77ms/epoch - 8ms/step\n",
      "Epoch 17/97\n",
      "10/10 - 0s - loss: 0.0660 - val_loss: 0.0866 - 83ms/epoch - 8ms/step\n",
      "Epoch 18/97\n",
      "10/10 - 0s - loss: 0.0657 - val_loss: 0.0863 - 92ms/epoch - 9ms/step\n",
      "Epoch 19/97\n",
      "10/10 - 0s - loss: 0.0654 - val_loss: 0.0859 - 74ms/epoch - 7ms/step\n",
      "Epoch 20/97\n",
      "10/10 - 0s - loss: 0.0650 - val_loss: 0.0856 - 72ms/epoch - 7ms/step\n",
      "Epoch 21/97\n",
      "10/10 - 0s - loss: 0.0648 - val_loss: 0.0852 - 73ms/epoch - 7ms/step\n",
      "Epoch 22/97\n",
      "10/10 - 0s - loss: 0.0644 - val_loss: 0.0849 - 93ms/epoch - 9ms/step\n",
      "Epoch 23/97\n",
      "10/10 - 0s - loss: 0.0642 - val_loss: 0.0845 - 80ms/epoch - 8ms/step\n",
      "Epoch 24/97\n",
      "10/10 - 0s - loss: 0.0638 - val_loss: 0.0842 - 76ms/epoch - 8ms/step\n",
      "Epoch 25/97\n",
      "10/10 - 0s - loss: 0.0635 - val_loss: 0.0838 - 74ms/epoch - 7ms/step\n",
      "Epoch 26/97\n",
      "10/10 - 0s - loss: 0.0632 - val_loss: 0.0835 - 100ms/epoch - 10ms/step\n",
      "Epoch 27/97\n",
      "10/10 - 0s - loss: 0.0629 - val_loss: 0.0831 - 73ms/epoch - 7ms/step\n",
      "Epoch 28/97\n",
      "10/10 - 0s - loss: 0.0626 - val_loss: 0.0828 - 73ms/epoch - 7ms/step\n",
      "Epoch 29/97\n",
      "10/10 - 0s - loss: 0.0622 - val_loss: 0.0824 - 72ms/epoch - 7ms/step\n",
      "Epoch 30/97\n",
      "10/10 - 0s - loss: 0.0620 - val_loss: 0.0821 - 116ms/epoch - 12ms/step\n",
      "Epoch 31/97\n",
      "10/10 - 0s - loss: 0.0616 - val_loss: 0.0817 - 76ms/epoch - 8ms/step\n",
      "Epoch 32/97\n",
      "10/10 - 0s - loss: 0.0613 - val_loss: 0.0814 - 71ms/epoch - 7ms/step\n",
      "Epoch 33/97\n",
      "10/10 - 0s - loss: 0.0609 - val_loss: 0.0810 - 75ms/epoch - 7ms/step\n",
      "Epoch 34/97\n",
      "10/10 - 0s - loss: 0.0606 - val_loss: 0.0807 - 86ms/epoch - 9ms/step\n",
      "Epoch 35/97\n",
      "10/10 - 0s - loss: 0.0604 - val_loss: 0.0803 - 74ms/epoch - 7ms/step\n",
      "Epoch 36/97\n",
      "10/10 - 0s - loss: 0.0600 - val_loss: 0.0800 - 74ms/epoch - 7ms/step\n",
      "Epoch 37/97\n",
      "10/10 - 0s - loss: 0.0597 - val_loss: 0.0796 - 82ms/epoch - 8ms/step\n",
      "Epoch 38/97\n",
      "10/10 - 0s - loss: 0.0593 - val_loss: 0.0792 - 81ms/epoch - 8ms/step\n",
      "Epoch 39/97\n",
      "10/10 - 0s - loss: 0.0591 - val_loss: 0.0789 - 85ms/epoch - 9ms/step\n",
      "Epoch 40/97\n",
      "10/10 - 0s - loss: 0.0587 - val_loss: 0.0785 - 129ms/epoch - 13ms/step\n",
      "Epoch 41/97\n",
      "10/10 - 0s - loss: 0.0585 - val_loss: 0.0782 - 85ms/epoch - 8ms/step\n",
      "Epoch 42/97\n",
      "10/10 - 0s - loss: 0.0581 - val_loss: 0.0778 - 75ms/epoch - 7ms/step\n",
      "Epoch 43/97\n",
      "10/10 - 0s - loss: 0.0578 - val_loss: 0.0774 - 87ms/epoch - 9ms/step\n",
      "Epoch 44/97\n",
      "10/10 - 0s - loss: 0.0575 - val_loss: 0.0771 - 105ms/epoch - 10ms/step\n",
      "Epoch 45/97\n",
      "10/10 - 0s - loss: 0.0572 - val_loss: 0.0767 - 90ms/epoch - 9ms/step\n",
      "Epoch 46/97\n",
      "10/10 - 0s - loss: 0.0568 - val_loss: 0.0764 - 83ms/epoch - 8ms/step\n",
      "Epoch 47/97\n",
      "10/10 - 0s - loss: 0.0565 - val_loss: 0.0760 - 76ms/epoch - 8ms/step\n",
      "Epoch 48/97\n",
      "10/10 - 0s - loss: 0.0562 - val_loss: 0.0756 - 103ms/epoch - 10ms/step\n",
      "Epoch 49/97\n",
      "10/10 - 0s - loss: 0.0559 - val_loss: 0.0753 - 83ms/epoch - 8ms/step\n",
      "Epoch 50/97\n",
      "10/10 - 0s - loss: 0.0555 - val_loss: 0.0749 - 82ms/epoch - 8ms/step\n",
      "Epoch 51/97\n",
      "10/10 - 0s - loss: 0.0552 - val_loss: 0.0745 - 107ms/epoch - 11ms/step\n",
      "Epoch 52/97\n",
      "10/10 - 0s - loss: 0.0550 - val_loss: 0.0742 - 90ms/epoch - 9ms/step\n",
      "Epoch 53/97\n",
      "10/10 - 0s - loss: 0.0546 - val_loss: 0.0738 - 77ms/epoch - 8ms/step\n",
      "Epoch 54/97\n",
      "10/10 - 0s - loss: 0.0542 - val_loss: 0.0734 - 75ms/epoch - 7ms/step\n",
      "Epoch 55/97\n",
      "10/10 - 0s - loss: 0.0539 - val_loss: 0.0731 - 76ms/epoch - 8ms/step\n",
      "Epoch 56/97\n",
      "10/10 - 0s - loss: 0.0536 - val_loss: 0.0727 - 92ms/epoch - 9ms/step\n",
      "Epoch 57/97\n",
      "10/10 - 0s - loss: 0.0532 - val_loss: 0.0723 - 74ms/epoch - 7ms/step\n",
      "Epoch 58/97\n",
      "10/10 - 0s - loss: 0.0529 - val_loss: 0.0719 - 80ms/epoch - 8ms/step\n",
      "Epoch 59/97\n",
      "10/10 - 0s - loss: 0.0526 - val_loss: 0.0716 - 84ms/epoch - 8ms/step\n",
      "Epoch 60/97\n",
      "10/10 - 0s - loss: 0.0523 - val_loss: 0.0712 - 113ms/epoch - 11ms/step\n",
      "Epoch 61/97\n",
      "10/10 - 0s - loss: 0.0519 - val_loss: 0.0708 - 100ms/epoch - 10ms/step\n",
      "Epoch 62/97\n",
      "10/10 - 0s - loss: 0.0516 - val_loss: 0.0705 - 83ms/epoch - 8ms/step\n",
      "Epoch 63/97\n",
      "10/10 - 0s - loss: 0.0513 - val_loss: 0.0701 - 82ms/epoch - 8ms/step\n",
      "Epoch 64/97\n",
      "10/10 - 0s - loss: 0.0510 - val_loss: 0.0697 - 108ms/epoch - 11ms/step\n",
      "Epoch 65/97\n",
      "10/10 - 0s - loss: 0.0506 - val_loss: 0.0693 - 85ms/epoch - 8ms/step\n",
      "Epoch 66/97\n",
      "10/10 - 0s - loss: 0.0502 - val_loss: 0.0689 - 80ms/epoch - 8ms/step\n",
      "Epoch 67/97\n",
      "10/10 - 0s - loss: 0.0499 - val_loss: 0.0686 - 74ms/epoch - 7ms/step\n",
      "Epoch 68/97\n",
      "10/10 - 0s - loss: 0.0496 - val_loss: 0.0682 - 94ms/epoch - 9ms/step\n",
      "Epoch 69/97\n",
      "10/10 - 0s - loss: 0.0493 - val_loss: 0.0678 - 79ms/epoch - 8ms/step\n",
      "Epoch 70/97\n",
      "10/10 - 0s - loss: 0.0489 - val_loss: 0.0674 - 75ms/epoch - 8ms/step\n",
      "Epoch 71/97\n",
      "10/10 - 0s - loss: 0.0486 - val_loss: 0.0670 - 74ms/epoch - 7ms/step\n",
      "Epoch 72/97\n",
      "10/10 - 0s - loss: 0.0483 - val_loss: 0.0666 - 91ms/epoch - 9ms/step\n",
      "Epoch 73/97\n",
      "10/10 - 0s - loss: 0.0479 - val_loss: 0.0663 - 74ms/epoch - 7ms/step\n",
      "Epoch 74/97\n",
      "10/10 - 0s - loss: 0.0476 - val_loss: 0.0659 - 75ms/epoch - 7ms/step\n",
      "Epoch 75/97\n",
      "10/10 - 0s - loss: 0.0472 - val_loss: 0.0655 - 75ms/epoch - 7ms/step\n",
      "Epoch 76/97\n",
      "10/10 - 0s - loss: 0.0469 - val_loss: 0.0651 - 86ms/epoch - 9ms/step\n",
      "Epoch 77/97\n",
      "10/10 - 0s - loss: 0.0466 - val_loss: 0.0647 - 74ms/epoch - 7ms/step\n",
      "Epoch 78/97\n",
      "10/10 - 0s - loss: 0.0462 - val_loss: 0.0643 - 75ms/epoch - 7ms/step\n",
      "Epoch 79/97\n",
      "10/10 - 0s - loss: 0.0458 - val_loss: 0.0639 - 76ms/epoch - 8ms/step\n",
      "Epoch 80/97\n",
      "10/10 - 0s - loss: 0.0455 - val_loss: 0.0635 - 103ms/epoch - 10ms/step\n",
      "Epoch 81/97\n",
      "10/10 - 0s - loss: 0.0451 - val_loss: 0.0631 - 78ms/epoch - 8ms/step\n",
      "Epoch 82/97\n",
      "10/10 - 0s - loss: 0.0448 - val_loss: 0.0628 - 77ms/epoch - 8ms/step\n",
      "Epoch 83/97\n",
      "10/10 - 0s - loss: 0.0445 - val_loss: 0.0624 - 96ms/epoch - 10ms/step\n",
      "Epoch 84/97\n",
      "10/10 - 0s - loss: 0.0441 - val_loss: 0.0620 - 106ms/epoch - 11ms/step\n",
      "Epoch 85/97\n",
      "10/10 - 0s - loss: 0.0438 - val_loss: 0.0616 - 79ms/epoch - 8ms/step\n",
      "Epoch 86/97\n",
      "10/10 - 0s - loss: 0.0434 - val_loss: 0.0612 - 74ms/epoch - 7ms/step\n",
      "Epoch 87/97\n",
      "10/10 - 0s - loss: 0.0431 - val_loss: 0.0608 - 74ms/epoch - 7ms/step\n",
      "Epoch 88/97\n",
      "10/10 - 0s - loss: 0.0428 - val_loss: 0.0604 - 90ms/epoch - 9ms/step\n",
      "Epoch 89/97\n",
      "10/10 - 0s - loss: 0.0424 - val_loss: 0.0600 - 75ms/epoch - 8ms/step\n",
      "Epoch 90/97\n",
      "10/10 - 0s - loss: 0.0421 - val_loss: 0.0596 - 72ms/epoch - 7ms/step\n",
      "Epoch 91/97\n",
      "10/10 - 0s - loss: 0.0416 - val_loss: 0.0592 - 73ms/epoch - 7ms/step\n",
      "Epoch 92/97\n",
      "10/10 - 0s - loss: 0.0413 - val_loss: 0.0588 - 84ms/epoch - 8ms/step\n",
      "Epoch 93/97\n",
      "10/10 - 0s - loss: 0.0410 - val_loss: 0.0584 - 104ms/epoch - 10ms/step\n",
      "Epoch 94/97\n",
      "10/10 - 0s - loss: 0.0407 - val_loss: 0.0580 - 102ms/epoch - 10ms/step\n",
      "Epoch 95/97\n",
      "10/10 - 0s - loss: 0.0403 - val_loss: 0.0576 - 79ms/epoch - 8ms/step\n",
      "Epoch 96/97\n",
      "10/10 - 0s - loss: 0.0399 - val_loss: 0.0572 - 76ms/epoch - 8ms/step\n",
      "Epoch 97/97\n",
      "10/10 - 0s - loss: 0.0396 - val_loss: 0.0568 - 85ms/epoch - 8ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m-426.8   \u001b[0m | \u001b[0m97.17    \u001b[0m | \u001b[0m1.955    \u001b[0m | \u001b[0m1e-05    \u001b[0m | \u001b[0m78.67    \u001b[0m |\n",
      "Model: \"sequential_147\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_536 (LSTM)             (None, 1, 105)            46620     \n",
      "                                                                 \n",
      " dropout_389 (Dropout)       (None, 1, 105)            0         \n",
      "                                                                 \n",
      " lstm_537 (LSTM)             (None, 1, 105)            88620     \n",
      "                                                                 \n",
      " dropout_390 (Dropout)       (None, 1, 105)            0         \n",
      "                                                                 \n",
      " lstm_538 (LSTM)             (None, 1, 105)            88620     \n",
      "                                                                 \n",
      " dropout_391 (Dropout)       (None, 1, 105)            0         \n",
      "                                                                 \n",
      " lstm_539 (LSTM)             (None, 1, 105)            88620     \n",
      "                                                                 \n",
      " dropout_392 (Dropout)       (None, 1, 105)            0         \n",
      "                                                                 \n",
      " lstm_540 (LSTM)             (None, 105)               88620     \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 1)                 106       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 401,206\n",
      "Trainable params: 401,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/91\n",
      "10/10 - 10s - loss: 0.0626 - val_loss: 0.0721 - 10s/epoch - 1s/step\n",
      "Epoch 2/91\n",
      "10/10 - 0s - loss: 0.0420 - val_loss: 0.0462 - 160ms/epoch - 16ms/step\n",
      "Epoch 3/91\n",
      "10/10 - 0s - loss: 0.0165 - val_loss: 0.0175 - 190ms/epoch - 19ms/step\n",
      "Epoch 4/91\n",
      "10/10 - 0s - loss: 0.0044 - val_loss: 0.0154 - 165ms/epoch - 16ms/step\n",
      "Epoch 5/91\n",
      "10/10 - 0s - loss: 0.0033 - val_loss: 0.0167 - 161ms/epoch - 16ms/step\n",
      "Epoch 6/91\n",
      "10/10 - 0s - loss: 0.0032 - val_loss: 0.0159 - 155ms/epoch - 15ms/step\n",
      "Epoch 7/91\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0151 - 158ms/epoch - 16ms/step\n",
      "Epoch 8/91\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0152 - 157ms/epoch - 16ms/step\n",
      "Epoch 9/91\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0151 - 170ms/epoch - 17ms/step\n",
      "Epoch 10/91\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0146 - 158ms/epoch - 16ms/step\n",
      "Epoch 11/91\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0144 - 189ms/epoch - 19ms/step\n",
      "Epoch 12/91\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0140 - 160ms/epoch - 16ms/step\n",
      "Epoch 13/91\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0138 - 169ms/epoch - 17ms/step\n",
      "Epoch 14/91\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0129 - 158ms/epoch - 16ms/step\n",
      "Epoch 15/91\n",
      "10/10 - 0s - loss: 0.0021 - val_loss: 0.0125 - 165ms/epoch - 17ms/step\n",
      "Epoch 16/91\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0119 - 154ms/epoch - 15ms/step\n",
      "Epoch 17/91\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0111 - 167ms/epoch - 17ms/step\n",
      "Epoch 18/91\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0104 - 157ms/epoch - 16ms/step\n",
      "Epoch 19/91\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0097 - 153ms/epoch - 15ms/step\n",
      "Epoch 20/91\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0090 - 158ms/epoch - 16ms/step\n",
      "Epoch 21/91\n",
      "10/10 - 0s - loss: 9.4641e-04 - val_loss: 0.0085 - 172ms/epoch - 17ms/step\n",
      "Epoch 22/91\n",
      "10/10 - 0s - loss: 7.1536e-04 - val_loss: 0.0085 - 154ms/epoch - 15ms/step\n",
      "Epoch 23/91\n",
      "10/10 - 0s - loss: 6.5679e-04 - val_loss: 0.0086 - 181ms/epoch - 18ms/step\n",
      "Epoch 24/91\n",
      "10/10 - 0s - loss: 6.6598e-04 - val_loss: 0.0088 - 158ms/epoch - 16ms/step\n",
      "Epoch 25/91\n",
      "10/10 - 0s - loss: 5.8695e-04 - val_loss: 0.0090 - 173ms/epoch - 17ms/step\n",
      "Epoch 26/91\n",
      "10/10 - 0s - loss: 6.2089e-04 - val_loss: 0.0090 - 153ms/epoch - 15ms/step\n",
      "Epoch 27/91\n",
      "10/10 - 0s - loss: 6.1436e-04 - val_loss: 0.0091 - 154ms/epoch - 15ms/step\n",
      "Epoch 28/91\n",
      "10/10 - 0s - loss: 5.6114e-04 - val_loss: 0.0088 - 155ms/epoch - 16ms/step\n",
      "Epoch 29/91\n",
      "10/10 - 0s - loss: 5.8358e-04 - val_loss: 0.0088 - 172ms/epoch - 17ms/step\n",
      "Epoch 30/91\n",
      "10/10 - 0s - loss: 5.5297e-04 - val_loss: 0.0088 - 150ms/epoch - 15ms/step\n",
      "Epoch 31/91\n",
      "10/10 - 0s - loss: 5.0929e-04 - val_loss: 0.0089 - 176ms/epoch - 18ms/step\n",
      "Epoch 32/91\n",
      "10/10 - 0s - loss: 4.3192e-04 - val_loss: 0.0090 - 157ms/epoch - 16ms/step\n",
      "Epoch 33/91\n",
      "10/10 - 0s - loss: 4.9358e-04 - val_loss: 0.0089 - 169ms/epoch - 17ms/step\n",
      "Epoch 34/91\n",
      "10/10 - 0s - loss: 5.3052e-04 - val_loss: 0.0088 - 154ms/epoch - 15ms/step\n",
      "Epoch 35/91\n",
      "10/10 - 0s - loss: 4.4907e-04 - val_loss: 0.0088 - 157ms/epoch - 16ms/step\n",
      "Epoch 36/91\n",
      "10/10 - 0s - loss: 4.6809e-04 - val_loss: 0.0088 - 155ms/epoch - 15ms/step\n",
      "Epoch 37/91\n",
      "10/10 - 0s - loss: 4.6838e-04 - val_loss: 0.0087 - 173ms/epoch - 17ms/step\n",
      "Epoch 38/91\n",
      "10/10 - 0s - loss: 4.8946e-04 - val_loss: 0.0088 - 153ms/epoch - 15ms/step\n",
      "Epoch 39/91\n",
      "10/10 - 0s - loss: 4.4311e-04 - val_loss: 0.0091 - 157ms/epoch - 16ms/step\n",
      "Epoch 40/91\n",
      "10/10 - 0s - loss: 4.4120e-04 - val_loss: 0.0087 - 156ms/epoch - 16ms/step\n",
      "Epoch 41/91\n",
      "10/10 - 0s - loss: 4.0444e-04 - val_loss: 0.0088 - 172ms/epoch - 17ms/step\n",
      "Epoch 42/91\n",
      "10/10 - 0s - loss: 4.3926e-04 - val_loss: 0.0089 - 178ms/epoch - 18ms/step\n",
      "Epoch 43/91\n",
      "10/10 - 0s - loss: 4.1735e-04 - val_loss: 0.0088 - 150ms/epoch - 15ms/step\n",
      "Epoch 44/91\n",
      "10/10 - 0s - loss: 4.3537e-04 - val_loss: 0.0087 - 152ms/epoch - 15ms/step\n",
      "Epoch 45/91\n",
      "10/10 - 0s - loss: 4.3547e-04 - val_loss: 0.0087 - 172ms/epoch - 17ms/step\n",
      "Epoch 46/91\n",
      "10/10 - 0s - loss: 3.8748e-04 - val_loss: 0.0088 - 152ms/epoch - 15ms/step\n",
      "Epoch 47/91\n",
      "10/10 - 0s - loss: 3.9718e-04 - val_loss: 0.0088 - 162ms/epoch - 16ms/step\n",
      "Epoch 48/91\n",
      "10/10 - 0s - loss: 4.0698e-04 - val_loss: 0.0087 - 152ms/epoch - 15ms/step\n",
      "Epoch 49/91\n",
      "10/10 - 0s - loss: 4.1589e-04 - val_loss: 0.0087 - 166ms/epoch - 17ms/step\n",
      "Epoch 50/91\n",
      "10/10 - 0s - loss: 3.7420e-04 - val_loss: 0.0087 - 156ms/epoch - 16ms/step\n",
      "Epoch 51/91\n",
      "10/10 - 0s - loss: 3.6539e-04 - val_loss: 0.0087 - 160ms/epoch - 16ms/step\n",
      "Epoch 52/91\n",
      "10/10 - 0s - loss: 3.6985e-04 - val_loss: 0.0087 - 182ms/epoch - 18ms/step\n",
      "Epoch 53/91\n",
      "10/10 - 0s - loss: 3.7135e-04 - val_loss: 0.0086 - 167ms/epoch - 17ms/step\n",
      "Epoch 54/91\n",
      "10/10 - 0s - loss: 3.2973e-04 - val_loss: 0.0086 - 160ms/epoch - 16ms/step\n",
      "Epoch 55/91\n",
      "10/10 - 0s - loss: 3.6768e-04 - val_loss: 0.0087 - 153ms/epoch - 15ms/step\n",
      "Epoch 56/91\n",
      "10/10 - 0s - loss: 3.5691e-04 - val_loss: 0.0087 - 154ms/epoch - 15ms/step\n",
      "Epoch 57/91\n",
      "10/10 - 0s - loss: 3.6754e-04 - val_loss: 0.0087 - 172ms/epoch - 17ms/step\n",
      "Epoch 58/91\n",
      "10/10 - 0s - loss: 3.6926e-04 - val_loss: 0.0086 - 158ms/epoch - 16ms/step\n",
      "Epoch 59/91\n",
      "10/10 - 0s - loss: 3.5461e-04 - val_loss: 0.0086 - 152ms/epoch - 15ms/step\n",
      "Epoch 60/91\n",
      "10/10 - 0s - loss: 3.3873e-04 - val_loss: 0.0086 - 152ms/epoch - 15ms/step\n",
      "Epoch 61/91\n",
      "10/10 - 0s - loss: 3.6256e-04 - val_loss: 0.0087 - 210ms/epoch - 21ms/step\n",
      "Epoch 62/91\n",
      "10/10 - 0s - loss: 3.1651e-04 - val_loss: 0.0088 - 158ms/epoch - 16ms/step\n",
      "Epoch 63/91\n",
      "10/10 - 0s - loss: 2.8628e-04 - val_loss: 0.0087 - 157ms/epoch - 16ms/step\n",
      "Epoch 64/91\n",
      "10/10 - 0s - loss: 3.1678e-04 - val_loss: 0.0088 - 151ms/epoch - 15ms/step\n",
      "Epoch 65/91\n",
      "10/10 - 0s - loss: 3.2794e-04 - val_loss: 0.0087 - 177ms/epoch - 18ms/step\n",
      "Epoch 66/91\n",
      "10/10 - 0s - loss: 2.9342e-04 - val_loss: 0.0086 - 183ms/epoch - 18ms/step\n",
      "Epoch 67/91\n",
      "10/10 - 0s - loss: 3.2903e-04 - val_loss: 0.0086 - 170ms/epoch - 17ms/step\n",
      "Epoch 68/91\n",
      "10/10 - 0s - loss: 3.4045e-04 - val_loss: 0.0086 - 165ms/epoch - 17ms/step\n",
      "Epoch 69/91\n",
      "10/10 - 0s - loss: 3.4965e-04 - val_loss: 0.0087 - 178ms/epoch - 18ms/step\n",
      "Epoch 70/91\n",
      "10/10 - 0s - loss: 3.1697e-04 - val_loss: 0.0087 - 161ms/epoch - 16ms/step\n",
      "Epoch 71/91\n",
      "10/10 - 0s - loss: 3.1148e-04 - val_loss: 0.0088 - 167ms/epoch - 17ms/step\n",
      "Epoch 72/91\n",
      "10/10 - 0s - loss: 2.9852e-04 - val_loss: 0.0086 - 152ms/epoch - 15ms/step\n",
      "Epoch 73/91\n",
      "10/10 - 0s - loss: 3.4477e-04 - val_loss: 0.0086 - 154ms/epoch - 15ms/step\n",
      "Epoch 74/91\n",
      "10/10 - 0s - loss: 2.9807e-04 - val_loss: 0.0087 - 168ms/epoch - 17ms/step\n",
      "Epoch 75/91\n",
      "10/10 - 0s - loss: 3.2547e-04 - val_loss: 0.0086 - 156ms/epoch - 16ms/step\n",
      "Epoch 76/91\n",
      "10/10 - 0s - loss: 2.8102e-04 - val_loss: 0.0087 - 165ms/epoch - 16ms/step\n",
      "Epoch 77/91\n",
      "10/10 - 0s - loss: 2.6383e-04 - val_loss: 0.0086 - 185ms/epoch - 18ms/step\n",
      "Epoch 78/91\n",
      "10/10 - 0s - loss: 2.9156e-04 - val_loss: 0.0086 - 168ms/epoch - 17ms/step\n",
      "Epoch 79/91\n",
      "10/10 - 0s - loss: 3.1402e-04 - val_loss: 0.0085 - 156ms/epoch - 16ms/step\n",
      "Epoch 80/91\n",
      "10/10 - 0s - loss: 2.8333e-04 - val_loss: 0.0085 - 151ms/epoch - 15ms/step\n",
      "Epoch 81/91\n",
      "10/10 - 0s - loss: 2.8634e-04 - val_loss: 0.0085 - 157ms/epoch - 16ms/step\n",
      "Epoch 82/91\n",
      "10/10 - 0s - loss: 2.6301e-04 - val_loss: 0.0086 - 161ms/epoch - 16ms/step\n",
      "Epoch 83/91\n",
      "10/10 - 0s - loss: 2.9017e-04 - val_loss: 0.0086 - 166ms/epoch - 17ms/step\n",
      "Epoch 84/91\n",
      "10/10 - 0s - loss: 2.8495e-04 - val_loss: 0.0087 - 171ms/epoch - 17ms/step\n",
      "Epoch 85/91\n",
      "10/10 - 0s - loss: 2.8418e-04 - val_loss: 0.0086 - 188ms/epoch - 19ms/step\n",
      "Epoch 86/91\n",
      "10/10 - 0s - loss: 3.1043e-04 - val_loss: 0.0087 - 160ms/epoch - 16ms/step\n",
      "Epoch 87/91\n",
      "10/10 - 0s - loss: 2.8263e-04 - val_loss: 0.0086 - 170ms/epoch - 17ms/step\n",
      "Epoch 88/91\n",
      "10/10 - 0s - loss: 2.8025e-04 - val_loss: 0.0085 - 157ms/epoch - 16ms/step\n",
      "Epoch 89/91\n",
      "10/10 - 0s - loss: 2.6699e-04 - val_loss: 0.0085 - 162ms/epoch - 16ms/step\n",
      "Epoch 90/91\n",
      "10/10 - 0s - loss: 2.8535e-04 - val_loss: 0.0086 - 149ms/epoch - 15ms/step\n",
      "Epoch 91/91\n",
      "10/10 - 0s - loss: 2.8710e-04 - val_loss: 0.0086 - 167ms/epoch - 17ms/step\n",
      "9/9 [==============================] - 1s 4ms/step\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m-166.1   \u001b[0m | \u001b[0m91.18    \u001b[0m | \u001b[0m4.788    \u001b[0m | \u001b[0m0.0006887\u001b[0m | \u001b[0m105.7    \u001b[0m |\n",
      "Model: \"sequential_148\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_541 (LSTM)             (None, 1, 14)             1120      \n",
      "                                                                 \n",
      " dropout_393 (Dropout)       (None, 1, 14)             0         \n",
      "                                                                 \n",
      " lstm_542 (LSTM)             (None, 1, 14)             1624      \n",
      "                                                                 \n",
      " dropout_394 (Dropout)       (None, 1, 14)             0         \n",
      "                                                                 \n",
      " lstm_543 (LSTM)             (None, 1, 14)             1624      \n",
      "                                                                 \n",
      " dropout_395 (Dropout)       (None, 1, 14)             0         \n",
      "                                                                 \n",
      " lstm_544 (LSTM)             (None, 1, 14)             1624      \n",
      "                                                                 \n",
      " dropout_396 (Dropout)       (None, 1, 14)             0         \n",
      "                                                                 \n",
      " lstm_545 (LSTM)             (None, 1, 14)             1624      \n",
      "                                                                 \n",
      " dropout_397 (Dropout)       (None, 1, 14)             0         \n",
      "                                                                 \n",
      " lstm_546 (LSTM)             (None, 14)                1624      \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 1)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,255\n",
      "Trainable params: 9,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/120\n",
      "10/10 - 18s - loss: 0.0705 - val_loss: 0.0917 - 18s/epoch - 2s/step\n",
      "Epoch 2/120\n",
      "10/10 - 0s - loss: 0.0704 - val_loss: 0.0916 - 119ms/epoch - 12ms/step\n",
      "Epoch 3/120\n",
      "10/10 - 0s - loss: 0.0703 - val_loss: 0.0914 - 130ms/epoch - 13ms/step\n",
      "Epoch 4/120\n",
      "10/10 - 0s - loss: 0.0702 - val_loss: 0.0913 - 146ms/epoch - 15ms/step\n",
      "Epoch 5/120\n",
      "10/10 - 0s - loss: 0.0700 - val_loss: 0.0912 - 131ms/epoch - 13ms/step\n",
      "Epoch 6/120\n",
      "10/10 - 0s - loss: 0.0699 - val_loss: 0.0911 - 136ms/epoch - 14ms/step\n",
      "Epoch 7/120\n",
      "10/10 - 0s - loss: 0.0698 - val_loss: 0.0909 - 121ms/epoch - 12ms/step\n",
      "Epoch 8/120\n",
      "10/10 - 0s - loss: 0.0697 - val_loss: 0.0908 - 138ms/epoch - 14ms/step\n",
      "Epoch 9/120\n",
      "10/10 - 0s - loss: 0.0696 - val_loss: 0.0907 - 132ms/epoch - 13ms/step\n",
      "Epoch 10/120\n",
      "10/10 - 0s - loss: 0.0694 - val_loss: 0.0906 - 117ms/epoch - 12ms/step\n",
      "Epoch 11/120\n",
      "10/10 - 0s - loss: 0.0693 - val_loss: 0.0904 - 116ms/epoch - 12ms/step\n",
      "Epoch 12/120\n",
      "10/10 - 0s - loss: 0.0692 - val_loss: 0.0903 - 126ms/epoch - 13ms/step\n",
      "Epoch 13/120\n",
      "10/10 - 0s - loss: 0.0691 - val_loss: 0.0902 - 98ms/epoch - 10ms/step\n",
      "Epoch 14/120\n",
      "10/10 - 0s - loss: 0.0690 - val_loss: 0.0901 - 103ms/epoch - 10ms/step\n",
      "Epoch 15/120\n",
      "10/10 - 0s - loss: 0.0688 - val_loss: 0.0899 - 94ms/epoch - 9ms/step\n",
      "Epoch 16/120\n",
      "10/10 - 0s - loss: 0.0687 - val_loss: 0.0898 - 109ms/epoch - 11ms/step\n",
      "Epoch 17/120\n",
      "10/10 - 0s - loss: 0.0686 - val_loss: 0.0897 - 94ms/epoch - 9ms/step\n",
      "Epoch 18/120\n",
      "10/10 - 0s - loss: 0.0685 - val_loss: 0.0896 - 96ms/epoch - 10ms/step\n",
      "Epoch 19/120\n",
      "10/10 - 0s - loss: 0.0684 - val_loss: 0.0894 - 100ms/epoch - 10ms/step\n",
      "Epoch 20/120\n",
      "10/10 - 0s - loss: 0.0683 - val_loss: 0.0893 - 108ms/epoch - 11ms/step\n",
      "Epoch 21/120\n",
      "10/10 - 0s - loss: 0.0681 - val_loss: 0.0892 - 125ms/epoch - 13ms/step\n",
      "Epoch 22/120\n",
      "10/10 - 0s - loss: 0.0680 - val_loss: 0.0891 - 98ms/epoch - 10ms/step\n",
      "Epoch 23/120\n",
      "10/10 - 0s - loss: 0.0679 - val_loss: 0.0889 - 95ms/epoch - 9ms/step\n",
      "Epoch 24/120\n",
      "10/10 - 0s - loss: 0.0678 - val_loss: 0.0888 - 105ms/epoch - 10ms/step\n",
      "Epoch 25/120\n",
      "10/10 - 0s - loss: 0.0677 - val_loss: 0.0887 - 119ms/epoch - 12ms/step\n",
      "Epoch 26/120\n",
      "10/10 - 0s - loss: 0.0675 - val_loss: 0.0886 - 96ms/epoch - 10ms/step\n",
      "Epoch 27/120\n",
      "10/10 - 0s - loss: 0.0674 - val_loss: 0.0884 - 93ms/epoch - 9ms/step\n",
      "Epoch 28/120\n",
      "10/10 - 0s - loss: 0.0673 - val_loss: 0.0883 - 105ms/epoch - 10ms/step\n",
      "Epoch 29/120\n",
      "10/10 - 0s - loss: 0.0672 - val_loss: 0.0882 - 95ms/epoch - 9ms/step\n",
      "Epoch 30/120\n",
      "10/10 - 0s - loss: 0.0670 - val_loss: 0.0880 - 94ms/epoch - 9ms/step\n",
      "Epoch 31/120\n",
      "10/10 - 0s - loss: 0.0669 - val_loss: 0.0879 - 92ms/epoch - 9ms/step\n",
      "Epoch 32/120\n",
      "10/10 - 0s - loss: 0.0668 - val_loss: 0.0878 - 110ms/epoch - 11ms/step\n",
      "Epoch 33/120\n",
      "10/10 - 0s - loss: 0.0667 - val_loss: 0.0877 - 96ms/epoch - 10ms/step\n",
      "Epoch 34/120\n",
      "10/10 - 0s - loss: 0.0666 - val_loss: 0.0875 - 96ms/epoch - 10ms/step\n",
      "Epoch 35/120\n",
      "10/10 - 0s - loss: 0.0665 - val_loss: 0.0874 - 98ms/epoch - 10ms/step\n",
      "Epoch 36/120\n",
      "10/10 - 0s - loss: 0.0663 - val_loss: 0.0873 - 150ms/epoch - 15ms/step\n",
      "Epoch 37/120\n",
      "10/10 - 0s - loss: 0.0662 - val_loss: 0.0872 - 95ms/epoch - 9ms/step\n",
      "Epoch 38/120\n",
      "10/10 - 0s - loss: 0.0661 - val_loss: 0.0870 - 101ms/epoch - 10ms/step\n",
      "Epoch 39/120\n",
      "10/10 - 0s - loss: 0.0660 - val_loss: 0.0869 - 101ms/epoch - 10ms/step\n",
      "Epoch 40/120\n",
      "10/10 - 0s - loss: 0.0658 - val_loss: 0.0868 - 114ms/epoch - 11ms/step\n",
      "Epoch 41/120\n",
      "10/10 - 0s - loss: 0.0657 - val_loss: 0.0866 - 103ms/epoch - 10ms/step\n",
      "Epoch 42/120\n",
      "10/10 - 0s - loss: 0.0656 - val_loss: 0.0865 - 107ms/epoch - 11ms/step\n",
      "Epoch 43/120\n",
      "10/10 - 0s - loss: 0.0655 - val_loss: 0.0864 - 100ms/epoch - 10ms/step\n",
      "Epoch 44/120\n",
      "10/10 - 0s - loss: 0.0654 - val_loss: 0.0863 - 95ms/epoch - 9ms/step\n",
      "Epoch 45/120\n",
      "10/10 - 0s - loss: 0.0652 - val_loss: 0.0861 - 115ms/epoch - 11ms/step\n",
      "Epoch 46/120\n",
      "10/10 - 0s - loss: 0.0651 - val_loss: 0.0860 - 97ms/epoch - 10ms/step\n",
      "Epoch 47/120\n",
      "10/10 - 0s - loss: 0.0650 - val_loss: 0.0859 - 101ms/epoch - 10ms/step\n",
      "Epoch 48/120\n",
      "10/10 - 0s - loss: 0.0649 - val_loss: 0.0858 - 115ms/epoch - 12ms/step\n",
      "Epoch 49/120\n",
      "10/10 - 0s - loss: 0.0648 - val_loss: 0.0856 - 116ms/epoch - 12ms/step\n",
      "Epoch 50/120\n",
      "10/10 - 0s - loss: 0.0646 - val_loss: 0.0855 - 107ms/epoch - 11ms/step\n",
      "Epoch 51/120\n",
      "10/10 - 0s - loss: 0.0645 - val_loss: 0.0854 - 93ms/epoch - 9ms/step\n",
      "Epoch 52/120\n",
      "10/10 - 0s - loss: 0.0644 - val_loss: 0.0852 - 110ms/epoch - 11ms/step\n",
      "Epoch 53/120\n",
      "10/10 - 0s - loss: 0.0643 - val_loss: 0.0851 - 93ms/epoch - 9ms/step\n",
      "Epoch 54/120\n",
      "10/10 - 0s - loss: 0.0642 - val_loss: 0.0850 - 103ms/epoch - 10ms/step\n",
      "Epoch 55/120\n",
      "10/10 - 0s - loss: 0.0640 - val_loss: 0.0849 - 111ms/epoch - 11ms/step\n",
      "Epoch 56/120\n",
      "10/10 - 0s - loss: 0.0639 - val_loss: 0.0847 - 94ms/epoch - 9ms/step\n",
      "Epoch 57/120\n",
      "10/10 - 0s - loss: 0.0638 - val_loss: 0.0846 - 96ms/epoch - 10ms/step\n",
      "Epoch 58/120\n",
      "10/10 - 0s - loss: 0.0637 - val_loss: 0.0845 - 98ms/epoch - 10ms/step\n",
      "Epoch 59/120\n",
      "10/10 - 0s - loss: 0.0635 - val_loss: 0.0843 - 98ms/epoch - 10ms/step\n",
      "Epoch 60/120\n",
      "10/10 - 0s - loss: 0.0634 - val_loss: 0.0842 - 120ms/epoch - 12ms/step\n",
      "Epoch 61/120\n",
      "10/10 - 0s - loss: 0.0633 - val_loss: 0.0841 - 118ms/epoch - 12ms/step\n",
      "Epoch 62/120\n",
      "10/10 - 0s - loss: 0.0632 - val_loss: 0.0839 - 109ms/epoch - 11ms/step\n",
      "Epoch 63/120\n",
      "10/10 - 0s - loss: 0.0630 - val_loss: 0.0838 - 109ms/epoch - 11ms/step\n",
      "Epoch 64/120\n",
      "10/10 - 0s - loss: 0.0629 - val_loss: 0.0837 - 112ms/epoch - 11ms/step\n",
      "Epoch 65/120\n",
      "10/10 - 0s - loss: 0.0628 - val_loss: 0.0836 - 105ms/epoch - 11ms/step\n",
      "Epoch 66/120\n",
      "10/10 - 0s - loss: 0.0627 - val_loss: 0.0834 - 97ms/epoch - 10ms/step\n",
      "Epoch 67/120\n",
      "10/10 - 0s - loss: 0.0626 - val_loss: 0.0833 - 99ms/epoch - 10ms/step\n",
      "Epoch 68/120\n",
      "10/10 - 0s - loss: 0.0625 - val_loss: 0.0832 - 109ms/epoch - 11ms/step\n",
      "Epoch 69/120\n",
      "10/10 - 0s - loss: 0.0623 - val_loss: 0.0830 - 93ms/epoch - 9ms/step\n",
      "Epoch 70/120\n",
      "10/10 - 0s - loss: 0.0622 - val_loss: 0.0829 - 100ms/epoch - 10ms/step\n",
      "Epoch 71/120\n",
      "10/10 - 0s - loss: 0.0621 - val_loss: 0.0828 - 135ms/epoch - 13ms/step\n",
      "Epoch 72/120\n",
      "10/10 - 0s - loss: 0.0619 - val_loss: 0.0827 - 118ms/epoch - 12ms/step\n",
      "Epoch 73/120\n",
      "10/10 - 0s - loss: 0.0618 - val_loss: 0.0825 - 102ms/epoch - 10ms/step\n",
      "Epoch 74/120\n",
      "10/10 - 0s - loss: 0.0617 - val_loss: 0.0824 - 100ms/epoch - 10ms/step\n",
      "Epoch 75/120\n",
      "10/10 - 0s - loss: 0.0616 - val_loss: 0.0823 - 96ms/epoch - 10ms/step\n",
      "Epoch 76/120\n",
      "10/10 - 0s - loss: 0.0615 - val_loss: 0.0821 - 157ms/epoch - 16ms/step\n",
      "Epoch 77/120\n",
      "10/10 - 0s - loss: 0.0613 - val_loss: 0.0820 - 101ms/epoch - 10ms/step\n",
      "Epoch 78/120\n",
      "10/10 - 0s - loss: 0.0612 - val_loss: 0.0819 - 97ms/epoch - 10ms/step\n",
      "Epoch 79/120\n",
      "10/10 - 0s - loss: 0.0611 - val_loss: 0.0817 - 98ms/epoch - 10ms/step\n",
      "Epoch 80/120\n",
      "10/10 - 0s - loss: 0.0610 - val_loss: 0.0816 - 111ms/epoch - 11ms/step\n",
      "Epoch 81/120\n",
      "10/10 - 0s - loss: 0.0608 - val_loss: 0.0815 - 94ms/epoch - 9ms/step\n",
      "Epoch 82/120\n",
      "10/10 - 0s - loss: 0.0607 - val_loss: 0.0813 - 93ms/epoch - 9ms/step\n",
      "Epoch 83/120\n",
      "10/10 - 0s - loss: 0.0606 - val_loss: 0.0812 - 95ms/epoch - 9ms/step\n",
      "Epoch 84/120\n",
      "10/10 - 0s - loss: 0.0605 - val_loss: 0.0811 - 95ms/epoch - 10ms/step\n",
      "Epoch 85/120\n",
      "10/10 - 0s - loss: 0.0604 - val_loss: 0.0810 - 109ms/epoch - 11ms/step\n",
      "Epoch 86/120\n",
      "10/10 - 0s - loss: 0.0602 - val_loss: 0.0808 - 94ms/epoch - 9ms/step\n",
      "Epoch 87/120\n",
      "10/10 - 0s - loss: 0.0601 - val_loss: 0.0807 - 94ms/epoch - 9ms/step\n",
      "Epoch 88/120\n",
      "10/10 - 0s - loss: 0.0600 - val_loss: 0.0806 - 92ms/epoch - 9ms/step\n",
      "Epoch 89/120\n",
      "10/10 - 0s - loss: 0.0598 - val_loss: 0.0804 - 129ms/epoch - 13ms/step\n",
      "Epoch 90/120\n",
      "10/10 - 0s - loss: 0.0597 - val_loss: 0.0803 - 104ms/epoch - 10ms/step\n",
      "Epoch 91/120\n",
      "10/10 - 0s - loss: 0.0596 - val_loss: 0.0802 - 92ms/epoch - 9ms/step\n",
      "Epoch 92/120\n",
      "10/10 - 0s - loss: 0.0595 - val_loss: 0.0800 - 94ms/epoch - 9ms/step\n",
      "Epoch 93/120\n",
      "10/10 - 0s - loss: 0.0594 - val_loss: 0.0799 - 108ms/epoch - 11ms/step\n",
      "Epoch 94/120\n",
      "10/10 - 0s - loss: 0.0593 - val_loss: 0.0798 - 102ms/epoch - 10ms/step\n",
      "Epoch 95/120\n",
      "10/10 - 0s - loss: 0.0591 - val_loss: 0.0796 - 108ms/epoch - 11ms/step\n",
      "Epoch 96/120\n",
      "10/10 - 0s - loss: 0.0590 - val_loss: 0.0795 - 119ms/epoch - 12ms/step\n",
      "Epoch 97/120\n",
      "10/10 - 0s - loss: 0.0588 - val_loss: 0.0794 - 128ms/epoch - 13ms/step\n",
      "Epoch 98/120\n",
      "10/10 - 0s - loss: 0.0587 - val_loss: 0.0792 - 100ms/epoch - 10ms/step\n",
      "Epoch 99/120\n",
      "10/10 - 0s - loss: 0.0586 - val_loss: 0.0791 - 113ms/epoch - 11ms/step\n",
      "Epoch 100/120\n",
      "10/10 - 0s - loss: 0.0585 - val_loss: 0.0790 - 98ms/epoch - 10ms/step\n",
      "Epoch 101/120\n",
      "10/10 - 0s - loss: 0.0583 - val_loss: 0.0789 - 94ms/epoch - 9ms/step\n",
      "Epoch 102/120\n",
      "10/10 - 0s - loss: 0.0582 - val_loss: 0.0787 - 98ms/epoch - 10ms/step\n",
      "Epoch 103/120\n",
      "10/10 - 0s - loss: 0.0581 - val_loss: 0.0786 - 111ms/epoch - 11ms/step\n",
      "Epoch 104/120\n",
      "10/10 - 0s - loss: 0.0580 - val_loss: 0.0785 - 94ms/epoch - 9ms/step\n",
      "Epoch 105/120\n",
      "10/10 - 0s - loss: 0.0579 - val_loss: 0.0783 - 122ms/epoch - 12ms/step\n",
      "Epoch 106/120\n",
      "10/10 - 0s - loss: 0.0577 - val_loss: 0.0782 - 126ms/epoch - 13ms/step\n",
      "Epoch 107/120\n",
      "10/10 - 0s - loss: 0.0576 - val_loss: 0.0781 - 100ms/epoch - 10ms/step\n",
      "Epoch 108/120\n",
      "10/10 - 0s - loss: 0.0575 - val_loss: 0.0779 - 97ms/epoch - 10ms/step\n",
      "Epoch 109/120\n",
      "10/10 - 0s - loss: 0.0573 - val_loss: 0.0778 - 96ms/epoch - 10ms/step\n",
      "Epoch 110/120\n",
      "10/10 - 0s - loss: 0.0572 - val_loss: 0.0777 - 114ms/epoch - 11ms/step\n",
      "Epoch 111/120\n",
      "10/10 - 0s - loss: 0.0571 - val_loss: 0.0775 - 96ms/epoch - 10ms/step\n",
      "Epoch 112/120\n",
      "10/10 - 0s - loss: 0.0570 - val_loss: 0.0774 - 95ms/epoch - 10ms/step\n",
      "Epoch 113/120\n",
      "10/10 - 0s - loss: 0.0569 - val_loss: 0.0773 - 95ms/epoch - 9ms/step\n",
      "Epoch 114/120\n",
      "10/10 - 0s - loss: 0.0567 - val_loss: 0.0771 - 113ms/epoch - 11ms/step\n",
      "Epoch 115/120\n",
      "10/10 - 0s - loss: 0.0566 - val_loss: 0.0770 - 129ms/epoch - 13ms/step\n",
      "Epoch 116/120\n",
      "10/10 - 0s - loss: 0.0565 - val_loss: 0.0769 - 106ms/epoch - 11ms/step\n",
      "Epoch 117/120\n",
      "10/10 - 0s - loss: 0.0564 - val_loss: 0.0767 - 93ms/epoch - 9ms/step\n",
      "Epoch 118/120\n",
      "10/10 - 0s - loss: 0.0562 - val_loss: 0.0766 - 109ms/epoch - 11ms/step\n",
      "Epoch 119/120\n",
      "10/10 - 0s - loss: 0.0561 - val_loss: 0.0765 - 94ms/epoch - 9ms/step\n",
      "Epoch 120/120\n",
      "10/10 - 0s - loss: 0.0560 - val_loss: 0.0763 - 91ms/epoch - 9ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m-494.8   \u001b[0m | \u001b[0m120.9    \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m1e-05    \u001b[0m | \u001b[0m14.74    \u001b[0m |\n",
      "Model: \"sequential_149\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_547 (LSTM)             (None, 1, 26)             3328      \n",
      "                                                                 \n",
      " dropout_398 (Dropout)       (None, 1, 26)             0         \n",
      "                                                                 \n",
      " lstm_548 (LSTM)             (None, 1, 26)             5512      \n",
      "                                                                 \n",
      " dropout_399 (Dropout)       (None, 1, 26)             0         \n",
      "                                                                 \n",
      " lstm_549 (LSTM)             (None, 1, 26)             5512      \n",
      "                                                                 \n",
      " dropout_400 (Dropout)       (None, 1, 26)             0         \n",
      "                                                                 \n",
      " lstm_550 (LSTM)             (None, 26)                5512      \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 1)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,891\n",
      "Trainable params: 19,891\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/141\n",
      "10/10 - 8s - loss: 0.0609 - val_loss: 0.0686 - 8s/epoch - 795ms/step\n",
      "Epoch 2/141\n",
      "10/10 - 0s - loss: 0.0388 - val_loss: 0.0444 - 86ms/epoch - 9ms/step\n",
      "Epoch 3/141\n",
      "10/10 - 0s - loss: 0.0171 - val_loss: 0.0221 - 86ms/epoch - 9ms/step\n",
      "Epoch 4/141\n",
      "10/10 - 0s - loss: 0.0041 - val_loss: 0.0151 - 86ms/epoch - 9ms/step\n",
      "Epoch 5/141\n",
      "10/10 - 0s - loss: 0.0043 - val_loss: 0.0151 - 100ms/epoch - 10ms/step\n",
      "Epoch 6/141\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0163 - 113ms/epoch - 11ms/step\n",
      "Epoch 7/141\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0157 - 112ms/epoch - 11ms/step\n",
      "Epoch 8/141\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0152 - 92ms/epoch - 9ms/step\n",
      "Epoch 9/141\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0151 - 86ms/epoch - 9ms/step\n",
      "Epoch 10/141\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0150 - 125ms/epoch - 12ms/step\n",
      "Epoch 11/141\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0149 - 102ms/epoch - 10ms/step\n",
      "Epoch 12/141\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0144 - 96ms/epoch - 10ms/step\n",
      "Epoch 13/141\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0141 - 83ms/epoch - 8ms/step\n",
      "Epoch 14/141\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0139 - 130ms/epoch - 13ms/step\n",
      "Epoch 15/141\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0134 - 84ms/epoch - 8ms/step\n",
      "Epoch 16/141\n",
      "10/10 - 0s - loss: 0.0023 - val_loss: 0.0128 - 91ms/epoch - 9ms/step\n",
      "Epoch 17/141\n",
      "10/10 - 0s - loss: 0.0023 - val_loss: 0.0125 - 99ms/epoch - 10ms/step\n",
      "Epoch 18/141\n",
      "10/10 - 0s - loss: 0.0021 - val_loss: 0.0116 - 82ms/epoch - 8ms/step\n",
      "Epoch 19/141\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0111 - 84ms/epoch - 8ms/step\n",
      "Epoch 20/141\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0102 - 115ms/epoch - 11ms/step\n",
      "Epoch 21/141\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0097 - 116ms/epoch - 12ms/step\n",
      "Epoch 22/141\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0092 - 107ms/epoch - 11ms/step\n",
      "Epoch 23/141\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0090 - 115ms/epoch - 11ms/step\n",
      "Epoch 24/141\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0090 - 93ms/epoch - 9ms/step\n",
      "Epoch 25/141\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0091 - 84ms/epoch - 8ms/step\n",
      "Epoch 26/141\n",
      "10/10 - 0s - loss: 9.7278e-04 - val_loss: 0.0094 - 97ms/epoch - 10ms/step\n",
      "Epoch 27/141\n",
      "10/10 - 0s - loss: 9.3741e-04 - val_loss: 0.0098 - 88ms/epoch - 9ms/step\n",
      "Epoch 28/141\n",
      "10/10 - 0s - loss: 8.7162e-04 - val_loss: 0.0098 - 95ms/epoch - 9ms/step\n",
      "Epoch 29/141\n",
      "10/10 - 0s - loss: 8.5773e-04 - val_loss: 0.0100 - 156ms/epoch - 16ms/step\n",
      "Epoch 30/141\n",
      "10/10 - 0s - loss: 7.7763e-04 - val_loss: 0.0099 - 96ms/epoch - 10ms/step\n",
      "Epoch 31/141\n",
      "10/10 - 0s - loss: 7.2247e-04 - val_loss: 0.0102 - 93ms/epoch - 9ms/step\n",
      "Epoch 32/141\n",
      "10/10 - 0s - loss: 7.0487e-04 - val_loss: 0.0101 - 112ms/epoch - 11ms/step\n",
      "Epoch 33/141\n",
      "10/10 - 0s - loss: 6.9621e-04 - val_loss: 0.0101 - 93ms/epoch - 9ms/step\n",
      "Epoch 34/141\n",
      "10/10 - 0s - loss: 7.1032e-04 - val_loss: 0.0104 - 86ms/epoch - 9ms/step\n",
      "Epoch 35/141\n",
      "10/10 - 0s - loss: 5.9366e-04 - val_loss: 0.0101 - 110ms/epoch - 11ms/step\n",
      "Epoch 36/141\n",
      "10/10 - 0s - loss: 6.8629e-04 - val_loss: 0.0099 - 89ms/epoch - 9ms/step\n",
      "Epoch 37/141\n",
      "10/10 - 0s - loss: 6.2590e-04 - val_loss: 0.0099 - 87ms/epoch - 9ms/step\n",
      "Epoch 38/141\n",
      "10/10 - 0s - loss: 5.9916e-04 - val_loss: 0.0103 - 97ms/epoch - 10ms/step\n",
      "Epoch 39/141\n",
      "10/10 - 0s - loss: 5.7818e-04 - val_loss: 0.0101 - 83ms/epoch - 8ms/step\n",
      "Epoch 40/141\n",
      "10/10 - 0s - loss: 6.3146e-04 - val_loss: 0.0103 - 91ms/epoch - 9ms/step\n",
      "Epoch 41/141\n",
      "10/10 - 0s - loss: 5.3146e-04 - val_loss: 0.0102 - 105ms/epoch - 10ms/step\n",
      "Epoch 42/141\n",
      "10/10 - 0s - loss: 4.7984e-04 - val_loss: 0.0104 - 95ms/epoch - 9ms/step\n",
      "Epoch 43/141\n",
      "10/10 - 0s - loss: 5.0475e-04 - val_loss: 0.0103 - 94ms/epoch - 9ms/step\n",
      "Epoch 44/141\n",
      "10/10 - 0s - loss: 4.7875e-04 - val_loss: 0.0101 - 124ms/epoch - 12ms/step\n",
      "Epoch 45/141\n",
      "10/10 - 0s - loss: 5.1541e-04 - val_loss: 0.0105 - 103ms/epoch - 10ms/step\n",
      "Epoch 46/141\n",
      "10/10 - 0s - loss: 5.1901e-04 - val_loss: 0.0098 - 82ms/epoch - 8ms/step\n",
      "Epoch 47/141\n",
      "10/10 - 0s - loss: 4.8762e-04 - val_loss: 0.0101 - 82ms/epoch - 8ms/step\n",
      "Epoch 48/141\n",
      "10/10 - 0s - loss: 4.0606e-04 - val_loss: 0.0103 - 91ms/epoch - 9ms/step\n",
      "Epoch 49/141\n",
      "10/10 - 0s - loss: 4.3884e-04 - val_loss: 0.0103 - 83ms/epoch - 8ms/step\n",
      "Epoch 50/141\n",
      "10/10 - 0s - loss: 4.5040e-04 - val_loss: 0.0099 - 94ms/epoch - 9ms/step\n",
      "Epoch 51/141\n",
      "10/10 - 0s - loss: 4.3431e-04 - val_loss: 0.0100 - 121ms/epoch - 12ms/step\n",
      "Epoch 52/141\n",
      "10/10 - 0s - loss: 4.0276e-04 - val_loss: 0.0100 - 85ms/epoch - 8ms/step\n",
      "Epoch 53/141\n",
      "10/10 - 0s - loss: 4.3863e-04 - val_loss: 0.0101 - 85ms/epoch - 9ms/step\n",
      "Epoch 54/141\n",
      "10/10 - 0s - loss: 4.0740e-04 - val_loss: 0.0100 - 95ms/epoch - 10ms/step\n",
      "Epoch 55/141\n",
      "10/10 - 0s - loss: 4.1141e-04 - val_loss: 0.0098 - 113ms/epoch - 11ms/step\n",
      "Epoch 56/141\n",
      "10/10 - 0s - loss: 3.9772e-04 - val_loss: 0.0099 - 105ms/epoch - 10ms/step\n",
      "Epoch 57/141\n",
      "10/10 - 0s - loss: 3.7338e-04 - val_loss: 0.0101 - 91ms/epoch - 9ms/step\n",
      "Epoch 58/141\n",
      "10/10 - 0s - loss: 4.3175e-04 - val_loss: 0.0100 - 81ms/epoch - 8ms/step\n",
      "Epoch 59/141\n",
      "10/10 - 0s - loss: 4.5087e-04 - val_loss: 0.0101 - 96ms/epoch - 10ms/step\n",
      "Epoch 60/141\n",
      "10/10 - 0s - loss: 4.2906e-04 - val_loss: 0.0100 - 105ms/epoch - 11ms/step\n",
      "Epoch 61/141\n",
      "10/10 - 0s - loss: 3.9759e-04 - val_loss: 0.0097 - 86ms/epoch - 9ms/step\n",
      "Epoch 62/141\n",
      "10/10 - 0s - loss: 3.6535e-04 - val_loss: 0.0096 - 83ms/epoch - 8ms/step\n",
      "Epoch 63/141\n",
      "10/10 - 0s - loss: 3.8116e-04 - val_loss: 0.0098 - 96ms/epoch - 10ms/step\n",
      "Epoch 64/141\n",
      "10/10 - 0s - loss: 3.8121e-04 - val_loss: 0.0096 - 79ms/epoch - 8ms/step\n",
      "Epoch 65/141\n",
      "10/10 - 0s - loss: 4.0073e-04 - val_loss: 0.0096 - 82ms/epoch - 8ms/step\n",
      "Epoch 66/141\n",
      "10/10 - 0s - loss: 4.3145e-04 - val_loss: 0.0096 - 84ms/epoch - 8ms/step\n",
      "Epoch 67/141\n",
      "10/10 - 0s - loss: 3.7085e-04 - val_loss: 0.0096 - 116ms/epoch - 12ms/step\n",
      "Epoch 68/141\n",
      "10/10 - 0s - loss: 3.9107e-04 - val_loss: 0.0095 - 97ms/epoch - 10ms/step\n",
      "Epoch 69/141\n",
      "10/10 - 0s - loss: 3.8690e-04 - val_loss: 0.0094 - 92ms/epoch - 9ms/step\n",
      "Epoch 70/141\n",
      "10/10 - 0s - loss: 3.6765e-04 - val_loss: 0.0095 - 94ms/epoch - 9ms/step\n",
      "Epoch 71/141\n",
      "10/10 - 0s - loss: 3.6748e-04 - val_loss: 0.0094 - 151ms/epoch - 15ms/step\n",
      "Epoch 72/141\n",
      "10/10 - 0s - loss: 3.4674e-04 - val_loss: 0.0094 - 101ms/epoch - 10ms/step\n",
      "Epoch 73/141\n",
      "10/10 - 0s - loss: 3.6412e-04 - val_loss: 0.0093 - 94ms/epoch - 9ms/step\n",
      "Epoch 74/141\n",
      "10/10 - 0s - loss: 3.2588e-04 - val_loss: 0.0092 - 95ms/epoch - 9ms/step\n",
      "Epoch 75/141\n",
      "10/10 - 0s - loss: 3.5254e-04 - val_loss: 0.0091 - 115ms/epoch - 12ms/step\n",
      "Epoch 76/141\n",
      "10/10 - 0s - loss: 3.7671e-04 - val_loss: 0.0092 - 93ms/epoch - 9ms/step\n",
      "Epoch 77/141\n",
      "10/10 - 0s - loss: 3.5866e-04 - val_loss: 0.0093 - 96ms/epoch - 10ms/step\n",
      "Epoch 78/141\n",
      "10/10 - 0s - loss: 3.5573e-04 - val_loss: 0.0093 - 92ms/epoch - 9ms/step\n",
      "Epoch 79/141\n",
      "10/10 - 0s - loss: 3.6153e-04 - val_loss: 0.0092 - 125ms/epoch - 12ms/step\n",
      "Epoch 80/141\n",
      "10/10 - 0s - loss: 3.8903e-04 - val_loss: 0.0091 - 97ms/epoch - 10ms/step\n",
      "Epoch 81/141\n",
      "10/10 - 0s - loss: 3.3668e-04 - val_loss: 0.0091 - 90ms/epoch - 9ms/step\n",
      "Epoch 82/141\n",
      "10/10 - 0s - loss: 3.4995e-04 - val_loss: 0.0091 - 126ms/epoch - 13ms/step\n",
      "Epoch 83/141\n",
      "10/10 - 0s - loss: 3.4342e-04 - val_loss: 0.0091 - 82ms/epoch - 8ms/step\n",
      "Epoch 84/141\n",
      "10/10 - 0s - loss: 3.3887e-04 - val_loss: 0.0090 - 82ms/epoch - 8ms/step\n",
      "Epoch 85/141\n",
      "10/10 - 0s - loss: 3.6014e-04 - val_loss: 0.0090 - 95ms/epoch - 10ms/step\n",
      "Epoch 86/141\n",
      "10/10 - 0s - loss: 3.8445e-04 - val_loss: 0.0090 - 82ms/epoch - 8ms/step\n",
      "Epoch 87/141\n",
      "10/10 - 0s - loss: 3.4203e-04 - val_loss: 0.0090 - 90ms/epoch - 9ms/step\n",
      "Epoch 88/141\n",
      "10/10 - 0s - loss: 3.5347e-04 - val_loss: 0.0090 - 92ms/epoch - 9ms/step\n",
      "Epoch 89/141\n",
      "10/10 - 0s - loss: 3.4314e-04 - val_loss: 0.0089 - 81ms/epoch - 8ms/step\n",
      "Epoch 90/141\n",
      "10/10 - 0s - loss: 3.1949e-04 - val_loss: 0.0089 - 80ms/epoch - 8ms/step\n",
      "Epoch 91/141\n",
      "10/10 - 0s - loss: 3.4342e-04 - val_loss: 0.0088 - 82ms/epoch - 8ms/step\n",
      "Epoch 92/141\n",
      "10/10 - 0s - loss: 3.4917e-04 - val_loss: 0.0089 - 108ms/epoch - 11ms/step\n",
      "Epoch 93/141\n",
      "10/10 - 0s - loss: 3.5937e-04 - val_loss: 0.0088 - 91ms/epoch - 9ms/step\n",
      "Epoch 94/141\n",
      "10/10 - 0s - loss: 3.8241e-04 - val_loss: 0.0087 - 117ms/epoch - 12ms/step\n",
      "Epoch 95/141\n",
      "10/10 - 0s - loss: 3.8685e-04 - val_loss: 0.0086 - 91ms/epoch - 9ms/step\n",
      "Epoch 96/141\n",
      "10/10 - 0s - loss: 3.3116e-04 - val_loss: 0.0088 - 100ms/epoch - 10ms/step\n",
      "Epoch 97/141\n",
      "10/10 - 0s - loss: 3.4173e-04 - val_loss: 0.0088 - 81ms/epoch - 8ms/step\n",
      "Epoch 98/141\n",
      "10/10 - 0s - loss: 3.5190e-04 - val_loss: 0.0088 - 82ms/epoch - 8ms/step\n",
      "Epoch 99/141\n",
      "10/10 - 0s - loss: 3.4406e-04 - val_loss: 0.0087 - 82ms/epoch - 8ms/step\n",
      "Epoch 100/141\n",
      "10/10 - 0s - loss: 3.5072e-04 - val_loss: 0.0086 - 92ms/epoch - 9ms/step\n",
      "Epoch 101/141\n",
      "10/10 - 0s - loss: 3.1590e-04 - val_loss: 0.0086 - 86ms/epoch - 9ms/step\n",
      "Epoch 102/141\n",
      "10/10 - 0s - loss: 3.3350e-04 - val_loss: 0.0086 - 88ms/epoch - 9ms/step\n",
      "Epoch 103/141\n",
      "10/10 - 0s - loss: 3.4727e-04 - val_loss: 0.0086 - 79ms/epoch - 8ms/step\n",
      "Epoch 104/141\n",
      "10/10 - 0s - loss: 3.3012e-04 - val_loss: 0.0086 - 97ms/epoch - 10ms/step\n",
      "Epoch 105/141\n",
      "10/10 - 0s - loss: 3.2353e-04 - val_loss: 0.0085 - 80ms/epoch - 8ms/step\n",
      "Epoch 106/141\n",
      "10/10 - 0s - loss: 3.2144e-04 - val_loss: 0.0086 - 101ms/epoch - 10ms/step\n",
      "Epoch 107/141\n",
      "10/10 - 0s - loss: 3.2373e-04 - val_loss: 0.0086 - 84ms/epoch - 8ms/step\n",
      "Epoch 108/141\n",
      "10/10 - 0s - loss: 3.6118e-04 - val_loss: 0.0084 - 111ms/epoch - 11ms/step\n",
      "Epoch 109/141\n",
      "10/10 - 0s - loss: 3.1755e-04 - val_loss: 0.0084 - 87ms/epoch - 9ms/step\n",
      "Epoch 110/141\n",
      "10/10 - 0s - loss: 3.4310e-04 - val_loss: 0.0084 - 79ms/epoch - 8ms/step\n",
      "Epoch 111/141\n",
      "10/10 - 0s - loss: 3.2864e-04 - val_loss: 0.0085 - 94ms/epoch - 9ms/step\n",
      "Epoch 112/141\n",
      "10/10 - 0s - loss: 3.4094e-04 - val_loss: 0.0084 - 80ms/epoch - 8ms/step\n",
      "Epoch 113/141\n",
      "10/10 - 0s - loss: 3.4235e-04 - val_loss: 0.0084 - 78ms/epoch - 8ms/step\n",
      "Epoch 114/141\n",
      "10/10 - 0s - loss: 3.2593e-04 - val_loss: 0.0083 - 80ms/epoch - 8ms/step\n",
      "Epoch 115/141\n",
      "10/10 - 0s - loss: 3.2817e-04 - val_loss: 0.0083 - 92ms/epoch - 9ms/step\n",
      "Epoch 116/141\n",
      "10/10 - 0s - loss: 3.0916e-04 - val_loss: 0.0083 - 88ms/epoch - 9ms/step\n",
      "Epoch 117/141\n",
      "10/10 - 0s - loss: 3.0424e-04 - val_loss: 0.0083 - 120ms/epoch - 12ms/step\n",
      "Epoch 118/141\n",
      "10/10 - 0s - loss: 3.2793e-04 - val_loss: 0.0083 - 83ms/epoch - 8ms/step\n",
      "Epoch 119/141\n",
      "10/10 - 0s - loss: 3.2952e-04 - val_loss: 0.0082 - 92ms/epoch - 9ms/step\n",
      "Epoch 120/141\n",
      "10/10 - 0s - loss: 3.3315e-04 - val_loss: 0.0082 - 84ms/epoch - 8ms/step\n",
      "Epoch 121/141\n",
      "10/10 - 0s - loss: 3.5446e-04 - val_loss: 0.0083 - 79ms/epoch - 8ms/step\n",
      "Epoch 122/141\n",
      "10/10 - 0s - loss: 3.2149e-04 - val_loss: 0.0083 - 79ms/epoch - 8ms/step\n",
      "Epoch 123/141\n",
      "10/10 - 0s - loss: 3.2679e-04 - val_loss: 0.0083 - 107ms/epoch - 11ms/step\n",
      "Epoch 124/141\n",
      "10/10 - 0s - loss: 3.2470e-04 - val_loss: 0.0082 - 101ms/epoch - 10ms/step\n",
      "Epoch 125/141\n",
      "10/10 - 0s - loss: 3.4556e-04 - val_loss: 0.0083 - 81ms/epoch - 8ms/step\n",
      "Epoch 126/141\n",
      "10/10 - 0s - loss: 2.9185e-04 - val_loss: 0.0083 - 80ms/epoch - 8ms/step\n",
      "Epoch 127/141\n",
      "10/10 - 0s - loss: 3.3256e-04 - val_loss: 0.0082 - 122ms/epoch - 12ms/step\n",
      "Epoch 128/141\n",
      "10/10 - 0s - loss: 3.1409e-04 - val_loss: 0.0082 - 81ms/epoch - 8ms/step\n",
      "Epoch 129/141\n",
      "10/10 - 0s - loss: 3.0846e-04 - val_loss: 0.0082 - 78ms/epoch - 8ms/step\n",
      "Epoch 130/141\n",
      "10/10 - 0s - loss: 3.0731e-04 - val_loss: 0.0082 - 81ms/epoch - 8ms/step\n",
      "Epoch 131/141\n",
      "10/10 - 0s - loss: 3.0630e-04 - val_loss: 0.0082 - 118ms/epoch - 12ms/step\n",
      "Epoch 132/141\n",
      "10/10 - 0s - loss: 3.1136e-04 - val_loss: 0.0081 - 117ms/epoch - 12ms/step\n",
      "Epoch 133/141\n",
      "10/10 - 0s - loss: 3.1918e-04 - val_loss: 0.0081 - 130ms/epoch - 13ms/step\n",
      "Epoch 134/141\n",
      "10/10 - 0s - loss: 3.2187e-04 - val_loss: 0.0081 - 95ms/epoch - 9ms/step\n",
      "Epoch 135/141\n",
      "10/10 - 0s - loss: 3.1400e-04 - val_loss: 0.0082 - 103ms/epoch - 10ms/step\n",
      "Epoch 136/141\n",
      "10/10 - 0s - loss: 3.0376e-04 - val_loss: 0.0081 - 88ms/epoch - 9ms/step\n",
      "Epoch 137/141\n",
      "10/10 - 0s - loss: 3.2699e-04 - val_loss: 0.0081 - 81ms/epoch - 8ms/step\n",
      "Epoch 138/141\n",
      "10/10 - 0s - loss: 3.1208e-04 - val_loss: 0.0081 - 111ms/epoch - 11ms/step\n",
      "Epoch 139/141\n",
      "10/10 - 0s - loss: 3.1706e-04 - val_loss: 0.0081 - 100ms/epoch - 10ms/step\n",
      "Epoch 140/141\n",
      "10/10 - 0s - loss: 3.0732e-04 - val_loss: 0.0081 - 83ms/epoch - 8ms/step\n",
      "Epoch 141/141\n",
      "10/10 - 0s - loss: 3.0953e-04 - val_loss: 0.0081 - 82ms/epoch - 8ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[95m27       \u001b[0m | \u001b[95m-161.3   \u001b[0m | \u001b[95m141.6    \u001b[0m | \u001b[95m3.989    \u001b[0m | \u001b[95m0.00148  \u001b[0m | \u001b[95m26.19    \u001b[0m |\n",
      "Model: \"sequential_150\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_551 (LSTM)             (None, 1, 89)             33820     \n",
      "                                                                 \n",
      " dropout_401 (Dropout)       (None, 1, 89)             0         \n",
      "                                                                 \n",
      " lstm_552 (LSTM)             (None, 1, 89)             63724     \n",
      "                                                                 \n",
      " dropout_402 (Dropout)       (None, 1, 89)             0         \n",
      "                                                                 \n",
      " lstm_553 (LSTM)             (None, 1, 89)             63724     \n",
      "                                                                 \n",
      " dropout_403 (Dropout)       (None, 1, 89)             0         \n",
      "                                                                 \n",
      " lstm_554 (LSTM)             (None, 1, 89)             63724     \n",
      "                                                                 \n",
      " dropout_404 (Dropout)       (None, 1, 89)             0         \n",
      "                                                                 \n",
      " lstm_555 (LSTM)             (None, 89)                63724     \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 1)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 288,806\n",
      "Trainable params: 288,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/127\n",
      "10/10 - 14s - loss: 0.0617 - val_loss: 0.0694 - 14s/epoch - 1s/step\n",
      "Epoch 2/127\n",
      "10/10 - 0s - loss: 0.0379 - val_loss: 0.0399 - 187ms/epoch - 19ms/step\n",
      "Epoch 3/127\n",
      "10/10 - 0s - loss: 0.0110 - val_loss: 0.0152 - 165ms/epoch - 16ms/step\n",
      "Epoch 4/127\n",
      "10/10 - 0s - loss: 0.0050 - val_loss: 0.0155 - 181ms/epoch - 18ms/step\n",
      "Epoch 5/127\n",
      "10/10 - 0s - loss: 0.0032 - val_loss: 0.0176 - 191ms/epoch - 19ms/step\n",
      "Epoch 6/127\n",
      "10/10 - 0s - loss: 0.0033 - val_loss: 0.0160 - 188ms/epoch - 19ms/step\n",
      "Epoch 7/127\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0157 - 172ms/epoch - 17ms/step\n",
      "Epoch 8/127\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0159 - 214ms/epoch - 21ms/step\n",
      "Epoch 9/127\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0155 - 179ms/epoch - 18ms/step\n",
      "Epoch 10/127\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0154 - 202ms/epoch - 20ms/step\n",
      "Epoch 11/127\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0150 - 197ms/epoch - 20ms/step\n",
      "Epoch 12/127\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0145 - 180ms/epoch - 18ms/step\n",
      "Epoch 13/127\n",
      "10/10 - 0s - loss: 0.0023 - val_loss: 0.0140 - 219ms/epoch - 22ms/step\n",
      "Epoch 14/127\n",
      "10/10 - 0s - loss: 0.0023 - val_loss: 0.0132 - 178ms/epoch - 18ms/step\n",
      "Epoch 15/127\n",
      "10/10 - 0s - loss: 0.0021 - val_loss: 0.0124 - 197ms/epoch - 20ms/step\n",
      "Epoch 16/127\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0114 - 181ms/epoch - 18ms/step\n",
      "Epoch 17/127\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0106 - 185ms/epoch - 18ms/step\n",
      "Epoch 18/127\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0095 - 175ms/epoch - 17ms/step\n",
      "Epoch 19/127\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0087 - 210ms/epoch - 21ms/step\n",
      "Epoch 20/127\n",
      "10/10 - 0s - loss: 8.0325e-04 - val_loss: 0.0084 - 170ms/epoch - 17ms/step\n",
      "Epoch 21/127\n",
      "10/10 - 0s - loss: 7.4858e-04 - val_loss: 0.0086 - 186ms/epoch - 19ms/step\n",
      "Epoch 22/127\n",
      "10/10 - 0s - loss: 6.6604e-04 - val_loss: 0.0090 - 181ms/epoch - 18ms/step\n",
      "Epoch 23/127\n",
      "10/10 - 0s - loss: 6.2704e-04 - val_loss: 0.0093 - 188ms/epoch - 19ms/step\n",
      "Epoch 24/127\n",
      "10/10 - 0s - loss: 6.4534e-04 - val_loss: 0.0093 - 169ms/epoch - 17ms/step\n",
      "Epoch 25/127\n",
      "10/10 - 0s - loss: 5.2608e-04 - val_loss: 0.0089 - 180ms/epoch - 18ms/step\n",
      "Epoch 26/127\n",
      "10/10 - 0s - loss: 4.9531e-04 - val_loss: 0.0088 - 217ms/epoch - 22ms/step\n",
      "Epoch 27/127\n",
      "10/10 - 0s - loss: 5.8690e-04 - val_loss: 0.0089 - 190ms/epoch - 19ms/step\n",
      "Epoch 28/127\n",
      "10/10 - 0s - loss: 5.1137e-04 - val_loss: 0.0090 - 171ms/epoch - 17ms/step\n",
      "Epoch 29/127\n",
      "10/10 - 0s - loss: 5.6911e-04 - val_loss: 0.0088 - 179ms/epoch - 18ms/step\n",
      "Epoch 30/127\n",
      "10/10 - 0s - loss: 4.4973e-04 - val_loss: 0.0090 - 179ms/epoch - 18ms/step\n",
      "Epoch 31/127\n",
      "10/10 - 0s - loss: 4.6900e-04 - val_loss: 0.0089 - 176ms/epoch - 18ms/step\n",
      "Epoch 32/127\n",
      "10/10 - 0s - loss: 4.9953e-04 - val_loss: 0.0090 - 165ms/epoch - 17ms/step\n",
      "Epoch 33/127\n",
      "10/10 - 0s - loss: 4.3951e-04 - val_loss: 0.0090 - 182ms/epoch - 18ms/step\n",
      "Epoch 34/127\n",
      "10/10 - 0s - loss: 5.4206e-04 - val_loss: 0.0087 - 188ms/epoch - 19ms/step\n",
      "Epoch 35/127\n",
      "10/10 - 0s - loss: 4.2685e-04 - val_loss: 0.0087 - 170ms/epoch - 17ms/step\n",
      "Epoch 36/127\n",
      "10/10 - 0s - loss: 4.8407e-04 - val_loss: 0.0087 - 172ms/epoch - 17ms/step\n",
      "Epoch 37/127\n",
      "10/10 - 0s - loss: 4.1271e-04 - val_loss: 0.0089 - 169ms/epoch - 17ms/step\n",
      "Epoch 38/127\n",
      "10/10 - 0s - loss: 4.1119e-04 - val_loss: 0.0089 - 230ms/epoch - 23ms/step\n",
      "Epoch 39/127\n",
      "10/10 - 0s - loss: 4.0575e-04 - val_loss: 0.0088 - 171ms/epoch - 17ms/step\n",
      "Epoch 40/127\n",
      "10/10 - 0s - loss: 4.0458e-04 - val_loss: 0.0087 - 178ms/epoch - 18ms/step\n",
      "Epoch 41/127\n",
      "10/10 - 0s - loss: 3.8438e-04 - val_loss: 0.0087 - 165ms/epoch - 17ms/step\n",
      "Epoch 42/127\n",
      "10/10 - 0s - loss: 4.2046e-04 - val_loss: 0.0087 - 198ms/epoch - 20ms/step\n",
      "Epoch 43/127\n",
      "10/10 - 0s - loss: 3.9845e-04 - val_loss: 0.0088 - 161ms/epoch - 16ms/step\n",
      "Epoch 44/127\n",
      "10/10 - 0s - loss: 3.6934e-04 - val_loss: 0.0089 - 188ms/epoch - 19ms/step\n",
      "Epoch 45/127\n",
      "10/10 - 0s - loss: 4.0820e-04 - val_loss: 0.0088 - 184ms/epoch - 18ms/step\n",
      "Epoch 46/127\n",
      "10/10 - 0s - loss: 4.0679e-04 - val_loss: 0.0086 - 182ms/epoch - 18ms/step\n",
      "Epoch 47/127\n",
      "10/10 - 0s - loss: 3.7943e-04 - val_loss: 0.0086 - 170ms/epoch - 17ms/step\n",
      "Epoch 48/127\n",
      "10/10 - 0s - loss: 3.8132e-04 - val_loss: 0.0089 - 178ms/epoch - 18ms/step\n",
      "Epoch 49/127\n",
      "10/10 - 0s - loss: 3.7604e-04 - val_loss: 0.0090 - 185ms/epoch - 18ms/step\n",
      "Epoch 50/127\n",
      "10/10 - 0s - loss: 3.4173e-04 - val_loss: 0.0088 - 181ms/epoch - 18ms/step\n",
      "Epoch 51/127\n",
      "10/10 - 0s - loss: 3.4678e-04 - val_loss: 0.0088 - 189ms/epoch - 19ms/step\n",
      "Epoch 52/127\n",
      "10/10 - 0s - loss: 3.6728e-04 - val_loss: 0.0088 - 180ms/epoch - 18ms/step\n",
      "Epoch 53/127\n",
      "10/10 - 0s - loss: 3.5680e-04 - val_loss: 0.0087 - 178ms/epoch - 18ms/step\n",
      "Epoch 54/127\n",
      "10/10 - 0s - loss: 3.6310e-04 - val_loss: 0.0085 - 179ms/epoch - 18ms/step\n",
      "Epoch 55/127\n",
      "10/10 - 0s - loss: 3.3915e-04 - val_loss: 0.0085 - 171ms/epoch - 17ms/step\n",
      "Epoch 56/127\n",
      "10/10 - 0s - loss: 3.3018e-04 - val_loss: 0.0085 - 189ms/epoch - 19ms/step\n",
      "Epoch 57/127\n",
      "10/10 - 0s - loss: 3.2913e-04 - val_loss: 0.0087 - 171ms/epoch - 17ms/step\n",
      "Epoch 58/127\n",
      "10/10 - 0s - loss: 3.1791e-04 - val_loss: 0.0087 - 172ms/epoch - 17ms/step\n",
      "Epoch 59/127\n",
      "10/10 - 0s - loss: 3.0333e-04 - val_loss: 0.0086 - 189ms/epoch - 19ms/step\n",
      "Epoch 60/127\n",
      "10/10 - 0s - loss: 3.2518e-04 - val_loss: 0.0087 - 169ms/epoch - 17ms/step\n",
      "Epoch 61/127\n",
      "10/10 - 0s - loss: 3.3498e-04 - val_loss: 0.0086 - 177ms/epoch - 18ms/step\n",
      "Epoch 62/127\n",
      "10/10 - 0s - loss: 3.3917e-04 - val_loss: 0.0086 - 181ms/epoch - 18ms/step\n",
      "Epoch 63/127\n",
      "10/10 - 0s - loss: 3.1345e-04 - val_loss: 0.0085 - 228ms/epoch - 23ms/step\n",
      "Epoch 64/127\n",
      "10/10 - 0s - loss: 3.2952e-04 - val_loss: 0.0085 - 170ms/epoch - 17ms/step\n",
      "Epoch 65/127\n",
      "10/10 - 0s - loss: 3.2448e-04 - val_loss: 0.0086 - 196ms/epoch - 20ms/step\n",
      "Epoch 66/127\n",
      "10/10 - 0s - loss: 3.1198e-04 - val_loss: 0.0086 - 199ms/epoch - 20ms/step\n",
      "Epoch 67/127\n",
      "10/10 - 0s - loss: 2.9868e-04 - val_loss: 0.0086 - 189ms/epoch - 19ms/step\n",
      "Epoch 68/127\n",
      "10/10 - 0s - loss: 3.1232e-04 - val_loss: 0.0086 - 169ms/epoch - 17ms/step\n",
      "Epoch 69/127\n",
      "10/10 - 0s - loss: 3.1799e-04 - val_loss: 0.0086 - 192ms/epoch - 19ms/step\n",
      "Epoch 70/127\n",
      "10/10 - 0s - loss: 3.2018e-04 - val_loss: 0.0087 - 169ms/epoch - 17ms/step\n",
      "Epoch 71/127\n",
      "10/10 - 0s - loss: 2.9847e-04 - val_loss: 0.0086 - 180ms/epoch - 18ms/step\n",
      "Epoch 72/127\n",
      "10/10 - 0s - loss: 3.0291e-04 - val_loss: 0.0086 - 189ms/epoch - 19ms/step\n",
      "Epoch 73/127\n",
      "10/10 - 0s - loss: 3.2691e-04 - val_loss: 0.0087 - 203ms/epoch - 20ms/step\n",
      "Epoch 74/127\n",
      "10/10 - 0s - loss: 3.2404e-04 - val_loss: 0.0086 - 168ms/epoch - 17ms/step\n",
      "Epoch 75/127\n",
      "10/10 - 0s - loss: 2.9932e-04 - val_loss: 0.0086 - 195ms/epoch - 20ms/step\n",
      "Epoch 76/127\n",
      "10/10 - 0s - loss: 2.9027e-04 - val_loss: 0.0086 - 194ms/epoch - 19ms/step\n",
      "Epoch 77/127\n",
      "10/10 - 0s - loss: 2.9065e-04 - val_loss: 0.0085 - 174ms/epoch - 17ms/step\n",
      "Epoch 78/127\n",
      "10/10 - 0s - loss: 2.6062e-04 - val_loss: 0.0085 - 172ms/epoch - 17ms/step\n",
      "Epoch 79/127\n",
      "10/10 - 0s - loss: 2.7134e-04 - val_loss: 0.0086 - 199ms/epoch - 20ms/step\n",
      "Epoch 80/127\n",
      "10/10 - 0s - loss: 3.0084e-04 - val_loss: 0.0086 - 172ms/epoch - 17ms/step\n",
      "Epoch 81/127\n",
      "10/10 - 0s - loss: 2.9772e-04 - val_loss: 0.0085 - 181ms/epoch - 18ms/step\n",
      "Epoch 82/127\n",
      "10/10 - 0s - loss: 2.8545e-04 - val_loss: 0.0085 - 201ms/epoch - 20ms/step\n",
      "Epoch 83/127\n",
      "10/10 - 0s - loss: 2.9625e-04 - val_loss: 0.0085 - 169ms/epoch - 17ms/step\n",
      "Epoch 84/127\n",
      "10/10 - 0s - loss: 2.9668e-04 - val_loss: 0.0086 - 200ms/epoch - 20ms/step\n",
      "Epoch 85/127\n",
      "10/10 - 0s - loss: 2.9398e-04 - val_loss: 0.0085 - 187ms/epoch - 19ms/step\n",
      "Epoch 86/127\n",
      "10/10 - 0s - loss: 2.6709e-04 - val_loss: 0.0086 - 213ms/epoch - 21ms/step\n",
      "Epoch 87/127\n",
      "10/10 - 0s - loss: 2.9151e-04 - val_loss: 0.0086 - 166ms/epoch - 17ms/step\n",
      "Epoch 88/127\n",
      "10/10 - 0s - loss: 2.7486e-04 - val_loss: 0.0085 - 222ms/epoch - 22ms/step\n",
      "Epoch 89/127\n",
      "10/10 - 0s - loss: 2.7260e-04 - val_loss: 0.0085 - 180ms/epoch - 18ms/step\n",
      "Epoch 90/127\n",
      "10/10 - 0s - loss: 3.0255e-04 - val_loss: 0.0085 - 182ms/epoch - 18ms/step\n",
      "Epoch 91/127\n",
      "10/10 - 0s - loss: 2.6820e-04 - val_loss: 0.0086 - 177ms/epoch - 18ms/step\n",
      "Epoch 92/127\n",
      "10/10 - 0s - loss: 2.8617e-04 - val_loss: 0.0086 - 208ms/epoch - 21ms/step\n",
      "Epoch 93/127\n",
      "10/10 - 0s - loss: 2.8253e-04 - val_loss: 0.0085 - 169ms/epoch - 17ms/step\n",
      "Epoch 94/127\n",
      "10/10 - 0s - loss: 2.6537e-04 - val_loss: 0.0085 - 181ms/epoch - 18ms/step\n",
      "Epoch 95/127\n",
      "10/10 - 0s - loss: 2.7034e-04 - val_loss: 0.0085 - 181ms/epoch - 18ms/step\n",
      "Epoch 96/127\n",
      "10/10 - 0s - loss: 2.7834e-04 - val_loss: 0.0085 - 178ms/epoch - 18ms/step\n",
      "Epoch 97/127\n",
      "10/10 - 0s - loss: 2.4697e-04 - val_loss: 0.0085 - 177ms/epoch - 18ms/step\n",
      "Epoch 98/127\n",
      "10/10 - 0s - loss: 2.5828e-04 - val_loss: 0.0086 - 175ms/epoch - 17ms/step\n",
      "Epoch 99/127\n",
      "10/10 - 0s - loss: 2.8206e-04 - val_loss: 0.0085 - 182ms/epoch - 18ms/step\n",
      "Epoch 100/127\n",
      "10/10 - 0s - loss: 2.9942e-04 - val_loss: 0.0085 - 238ms/epoch - 24ms/step\n",
      "Epoch 101/127\n",
      "10/10 - 0s - loss: 2.5492e-04 - val_loss: 0.0085 - 182ms/epoch - 18ms/step\n",
      "Epoch 102/127\n",
      "10/10 - 0s - loss: 2.5854e-04 - val_loss: 0.0085 - 164ms/epoch - 16ms/step\n",
      "Epoch 103/127\n",
      "10/10 - 0s - loss: 2.7405e-04 - val_loss: 0.0085 - 197ms/epoch - 20ms/step\n",
      "Epoch 104/127\n",
      "10/10 - 0s - loss: 2.6056e-04 - val_loss: 0.0085 - 169ms/epoch - 17ms/step\n",
      "Epoch 105/127\n",
      "10/10 - 0s - loss: 2.6799e-04 - val_loss: 0.0086 - 178ms/epoch - 18ms/step\n",
      "Epoch 106/127\n",
      "10/10 - 0s - loss: 2.5704e-04 - val_loss: 0.0085 - 178ms/epoch - 18ms/step\n",
      "Epoch 107/127\n",
      "10/10 - 0s - loss: 2.6165e-04 - val_loss: 0.0085 - 179ms/epoch - 18ms/step\n",
      "Epoch 108/127\n",
      "10/10 - 0s - loss: 2.7531e-04 - val_loss: 0.0085 - 170ms/epoch - 17ms/step\n",
      "Epoch 109/127\n",
      "10/10 - 0s - loss: 2.4291e-04 - val_loss: 0.0084 - 181ms/epoch - 18ms/step\n",
      "Epoch 110/127\n",
      "10/10 - 0s - loss: 2.7054e-04 - val_loss: 0.0085 - 177ms/epoch - 18ms/step\n",
      "Epoch 111/127\n",
      "10/10 - 0s - loss: 2.5049e-04 - val_loss: 0.0085 - 178ms/epoch - 18ms/step\n",
      "Epoch 112/127\n",
      "10/10 - 0s - loss: 2.7763e-04 - val_loss: 0.0085 - 194ms/epoch - 19ms/step\n",
      "Epoch 113/127\n",
      "10/10 - 0s - loss: 2.7950e-04 - val_loss: 0.0084 - 195ms/epoch - 20ms/step\n",
      "Epoch 114/127\n",
      "10/10 - 0s - loss: 2.5523e-04 - val_loss: 0.0086 - 167ms/epoch - 17ms/step\n",
      "Epoch 115/127\n",
      "10/10 - 0s - loss: 2.3956e-04 - val_loss: 0.0085 - 178ms/epoch - 18ms/step\n",
      "Epoch 116/127\n",
      "10/10 - 0s - loss: 2.6372e-04 - val_loss: 0.0085 - 165ms/epoch - 16ms/step\n",
      "Epoch 117/127\n",
      "10/10 - 0s - loss: 2.6833e-04 - val_loss: 0.0086 - 148ms/epoch - 15ms/step\n",
      "Epoch 118/127\n",
      "10/10 - 0s - loss: 2.5610e-04 - val_loss: 0.0084 - 161ms/epoch - 16ms/step\n",
      "Epoch 119/127\n",
      "10/10 - 0s - loss: 2.5872e-04 - val_loss: 0.0085 - 173ms/epoch - 17ms/step\n",
      "Epoch 120/127\n",
      "10/10 - 0s - loss: 2.7290e-04 - val_loss: 0.0084 - 148ms/epoch - 15ms/step\n",
      "Epoch 121/127\n",
      "10/10 - 0s - loss: 2.6130e-04 - val_loss: 0.0085 - 132ms/epoch - 13ms/step\n",
      "Epoch 122/127\n",
      "10/10 - 0s - loss: 2.3424e-04 - val_loss: 0.0086 - 155ms/epoch - 15ms/step\n",
      "Epoch 123/127\n",
      "10/10 - 0s - loss: 2.5930e-04 - val_loss: 0.0084 - 136ms/epoch - 14ms/step\n",
      "Epoch 124/127\n",
      "10/10 - 0s - loss: 2.5556e-04 - val_loss: 0.0085 - 135ms/epoch - 13ms/step\n",
      "Epoch 125/127\n",
      "10/10 - 0s - loss: 2.5786e-04 - val_loss: 0.0085 - 135ms/epoch - 14ms/step\n",
      "Epoch 126/127\n",
      "10/10 - 0s - loss: 2.4322e-04 - val_loss: 0.0085 - 186ms/epoch - 19ms/step\n",
      "Epoch 127/127\n",
      "10/10 - 0s - loss: 2.4412e-04 - val_loss: 0.0086 - 133ms/epoch - 13ms/step\n",
      "9/9 [==============================] - 1s 4ms/step\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m-166.1   \u001b[0m | \u001b[0m127.6    \u001b[0m | \u001b[0m4.23     \u001b[0m | \u001b[0m0.0009292\u001b[0m | \u001b[0m89.27    \u001b[0m |\n",
      "Model: \"sequential_151\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_556 (LSTM)             (None, 1, 40)             7360      \n",
      "                                                                 \n",
      " dropout_405 (Dropout)       (None, 1, 40)             0         \n",
      "                                                                 \n",
      " lstm_557 (LSTM)             (None, 40)                12960     \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 1)                 41        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,361\n",
      "Trainable params: 20,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/119\n",
      "10/10 - 6s - loss: 0.0238 - val_loss: 0.0142 - 6s/epoch - 552ms/step\n",
      "Epoch 2/119\n",
      "10/10 - 0s - loss: 0.0037 - val_loss: 0.0153 - 64ms/epoch - 6ms/step\n",
      "Epoch 3/119\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0131 - 69ms/epoch - 7ms/step\n",
      "Epoch 4/119\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0135 - 92ms/epoch - 9ms/step\n",
      "Epoch 5/119\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0120 - 82ms/epoch - 8ms/step\n",
      "Epoch 6/119\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0113 - 74ms/epoch - 7ms/step\n",
      "Epoch 7/119\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0101 - 86ms/epoch - 9ms/step\n",
      "Epoch 8/119\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0091 - 71ms/epoch - 7ms/step\n",
      "Epoch 9/119\n",
      "10/10 - 0s - loss: 6.8141e-04 - val_loss: 0.0085 - 69ms/epoch - 7ms/step\n",
      "Epoch 10/119\n",
      "10/10 - 0s - loss: 6.0502e-04 - val_loss: 0.0092 - 77ms/epoch - 8ms/step\n",
      "Epoch 11/119\n",
      "10/10 - 0s - loss: 5.4511e-04 - val_loss: 0.0092 - 69ms/epoch - 7ms/step\n",
      "Epoch 12/119\n",
      "10/10 - 0s - loss: 4.1483e-04 - val_loss: 0.0091 - 66ms/epoch - 7ms/step\n",
      "Epoch 13/119\n",
      "10/10 - 0s - loss: 4.3077e-04 - val_loss: 0.0091 - 63ms/epoch - 6ms/step\n",
      "Epoch 14/119\n",
      "10/10 - 0s - loss: 3.7674e-04 - val_loss: 0.0093 - 82ms/epoch - 8ms/step\n",
      "Epoch 15/119\n",
      "10/10 - 0s - loss: 3.7368e-04 - val_loss: 0.0093 - 68ms/epoch - 7ms/step\n",
      "Epoch 16/119\n",
      "10/10 - 0s - loss: 3.5229e-04 - val_loss: 0.0091 - 80ms/epoch - 8ms/step\n",
      "Epoch 17/119\n",
      "10/10 - 0s - loss: 3.2307e-04 - val_loss: 0.0093 - 78ms/epoch - 8ms/step\n",
      "Epoch 18/119\n",
      "10/10 - 0s - loss: 3.3859e-04 - val_loss: 0.0091 - 75ms/epoch - 8ms/step\n",
      "Epoch 19/119\n",
      "10/10 - 0s - loss: 2.9434e-04 - val_loss: 0.0091 - 70ms/epoch - 7ms/step\n",
      "Epoch 20/119\n",
      "10/10 - 0s - loss: 2.9328e-04 - val_loss: 0.0092 - 86ms/epoch - 9ms/step\n",
      "Epoch 21/119\n",
      "10/10 - 0s - loss: 2.7325e-04 - val_loss: 0.0091 - 84ms/epoch - 8ms/step\n",
      "Epoch 22/119\n",
      "10/10 - 0s - loss: 2.9788e-04 - val_loss: 0.0091 - 98ms/epoch - 10ms/step\n",
      "Epoch 23/119\n",
      "10/10 - 0s - loss: 3.0772e-04 - val_loss: 0.0093 - 69ms/epoch - 7ms/step\n",
      "Epoch 24/119\n",
      "10/10 - 0s - loss: 2.8524e-04 - val_loss: 0.0090 - 63ms/epoch - 6ms/step\n",
      "Epoch 25/119\n",
      "10/10 - 0s - loss: 2.5480e-04 - val_loss: 0.0091 - 72ms/epoch - 7ms/step\n",
      "Epoch 26/119\n",
      "10/10 - 0s - loss: 2.6053e-04 - val_loss: 0.0091 - 80ms/epoch - 8ms/step\n",
      "Epoch 27/119\n",
      "10/10 - 0s - loss: 2.5713e-04 - val_loss: 0.0090 - 75ms/epoch - 7ms/step\n",
      "Epoch 28/119\n",
      "10/10 - 0s - loss: 2.3817e-04 - val_loss: 0.0090 - 71ms/epoch - 7ms/step\n",
      "Epoch 29/119\n",
      "10/10 - 0s - loss: 2.5116e-04 - val_loss: 0.0094 - 86ms/epoch - 9ms/step\n",
      "Epoch 30/119\n",
      "10/10 - 0s - loss: 2.6848e-04 - val_loss: 0.0089 - 103ms/epoch - 10ms/step\n",
      "Epoch 31/119\n",
      "10/10 - 0s - loss: 2.6284e-04 - val_loss: 0.0090 - 73ms/epoch - 7ms/step\n",
      "Epoch 32/119\n",
      "10/10 - 0s - loss: 2.4087e-04 - val_loss: 0.0090 - 65ms/epoch - 6ms/step\n",
      "Epoch 33/119\n",
      "10/10 - 0s - loss: 2.4643e-04 - val_loss: 0.0092 - 77ms/epoch - 8ms/step\n",
      "Epoch 34/119\n",
      "10/10 - 0s - loss: 2.3158e-04 - val_loss: 0.0093 - 68ms/epoch - 7ms/step\n",
      "Epoch 35/119\n",
      "10/10 - 0s - loss: 2.2986e-04 - val_loss: 0.0092 - 80ms/epoch - 8ms/step\n",
      "Epoch 36/119\n",
      "10/10 - 0s - loss: 2.2318e-04 - val_loss: 0.0092 - 86ms/epoch - 9ms/step\n",
      "Epoch 37/119\n",
      "10/10 - 0s - loss: 2.2728e-04 - val_loss: 0.0091 - 71ms/epoch - 7ms/step\n",
      "Epoch 38/119\n",
      "10/10 - 0s - loss: 2.2539e-04 - val_loss: 0.0089 - 76ms/epoch - 8ms/step\n",
      "Epoch 39/119\n",
      "10/10 - 0s - loss: 2.3823e-04 - val_loss: 0.0092 - 69ms/epoch - 7ms/step\n",
      "Epoch 40/119\n",
      "10/10 - 0s - loss: 2.1389e-04 - val_loss: 0.0092 - 78ms/epoch - 8ms/step\n",
      "Epoch 41/119\n",
      "10/10 - 0s - loss: 2.3394e-04 - val_loss: 0.0091 - 78ms/epoch - 8ms/step\n",
      "Epoch 42/119\n",
      "10/10 - 0s - loss: 2.4630e-04 - val_loss: 0.0091 - 78ms/epoch - 8ms/step\n",
      "Epoch 43/119\n",
      "10/10 - 0s - loss: 2.2334e-04 - val_loss: 0.0093 - 89ms/epoch - 9ms/step\n",
      "Epoch 44/119\n",
      "10/10 - 0s - loss: 2.1880e-04 - val_loss: 0.0092 - 79ms/epoch - 8ms/step\n",
      "Epoch 45/119\n",
      "10/10 - 0s - loss: 2.2304e-04 - val_loss: 0.0090 - 74ms/epoch - 7ms/step\n",
      "Epoch 46/119\n",
      "10/10 - 0s - loss: 2.2872e-04 - val_loss: 0.0093 - 67ms/epoch - 7ms/step\n",
      "Epoch 47/119\n",
      "10/10 - 0s - loss: 2.2374e-04 - val_loss: 0.0092 - 73ms/epoch - 7ms/step\n",
      "Epoch 48/119\n",
      "10/10 - 0s - loss: 2.1350e-04 - val_loss: 0.0091 - 70ms/epoch - 7ms/step\n",
      "Epoch 49/119\n",
      "10/10 - 0s - loss: 2.4703e-04 - val_loss: 0.0090 - 70ms/epoch - 7ms/step\n",
      "Epoch 50/119\n",
      "10/10 - 0s - loss: 2.9515e-04 - val_loss: 0.0094 - 77ms/epoch - 8ms/step\n",
      "Epoch 51/119\n",
      "10/10 - 0s - loss: 3.2477e-04 - val_loss: 0.0089 - 63ms/epoch - 6ms/step\n",
      "Epoch 52/119\n",
      "10/10 - 0s - loss: 2.4959e-04 - val_loss: 0.0091 - 63ms/epoch - 6ms/step\n",
      "Epoch 53/119\n",
      "10/10 - 0s - loss: 2.7349e-04 - val_loss: 0.0092 - 72ms/epoch - 7ms/step\n",
      "Epoch 54/119\n",
      "10/10 - 0s - loss: 2.2910e-04 - val_loss: 0.0089 - 64ms/epoch - 6ms/step\n",
      "Epoch 55/119\n",
      "10/10 - 0s - loss: 2.3044e-04 - val_loss: 0.0091 - 63ms/epoch - 6ms/step\n",
      "Epoch 56/119\n",
      "10/10 - 0s - loss: 2.2108e-04 - val_loss: 0.0090 - 90ms/epoch - 9ms/step\n",
      "Epoch 57/119\n",
      "10/10 - 0s - loss: 2.2801e-04 - val_loss: 0.0091 - 78ms/epoch - 8ms/step\n",
      "Epoch 58/119\n",
      "10/10 - 0s - loss: 2.0686e-04 - val_loss: 0.0088 - 67ms/epoch - 7ms/step\n",
      "Epoch 59/119\n",
      "10/10 - 0s - loss: 2.4638e-04 - val_loss: 0.0093 - 67ms/epoch - 7ms/step\n",
      "Epoch 60/119\n",
      "10/10 - 0s - loss: 2.3463e-04 - val_loss: 0.0089 - 63ms/epoch - 6ms/step\n",
      "Epoch 61/119\n",
      "10/10 - 0s - loss: 2.5062e-04 - val_loss: 0.0091 - 84ms/epoch - 8ms/step\n",
      "Epoch 62/119\n",
      "10/10 - 0s - loss: 1.9451e-04 - val_loss: 0.0089 - 67ms/epoch - 7ms/step\n",
      "Epoch 63/119\n",
      "10/10 - 0s - loss: 2.0923e-04 - val_loss: 0.0091 - 63ms/epoch - 6ms/step\n",
      "Epoch 64/119\n",
      "10/10 - 0s - loss: 1.9998e-04 - val_loss: 0.0090 - 62ms/epoch - 6ms/step\n",
      "Epoch 65/119\n",
      "10/10 - 0s - loss: 2.0985e-04 - val_loss: 0.0092 - 75ms/epoch - 7ms/step\n",
      "Epoch 66/119\n",
      "10/10 - 0s - loss: 2.0622e-04 - val_loss: 0.0090 - 79ms/epoch - 8ms/step\n",
      "Epoch 67/119\n",
      "10/10 - 0s - loss: 2.2559e-04 - val_loss: 0.0091 - 76ms/epoch - 8ms/step\n",
      "Epoch 68/119\n",
      "10/10 - 0s - loss: 2.1634e-04 - val_loss: 0.0091 - 63ms/epoch - 6ms/step\n",
      "Epoch 69/119\n",
      "10/10 - 0s - loss: 2.0440e-04 - val_loss: 0.0090 - 75ms/epoch - 8ms/step\n",
      "Epoch 70/119\n",
      "10/10 - 0s - loss: 2.2228e-04 - val_loss: 0.0091 - 65ms/epoch - 6ms/step\n",
      "Epoch 71/119\n",
      "10/10 - 0s - loss: 2.1385e-04 - val_loss: 0.0091 - 63ms/epoch - 6ms/step\n",
      "Epoch 72/119\n",
      "10/10 - 0s - loss: 2.0235e-04 - val_loss: 0.0090 - 64ms/epoch - 6ms/step\n",
      "Epoch 73/119\n",
      "10/10 - 0s - loss: 1.9897e-04 - val_loss: 0.0090 - 73ms/epoch - 7ms/step\n",
      "Epoch 74/119\n",
      "10/10 - 0s - loss: 2.0974e-04 - val_loss: 0.0091 - 62ms/epoch - 6ms/step\n",
      "Epoch 75/119\n",
      "10/10 - 0s - loss: 2.0521e-04 - val_loss: 0.0090 - 66ms/epoch - 7ms/step\n",
      "Epoch 76/119\n",
      "10/10 - 0s - loss: 2.0583e-04 - val_loss: 0.0092 - 73ms/epoch - 7ms/step\n",
      "Epoch 77/119\n",
      "10/10 - 0s - loss: 1.9924e-04 - val_loss: 0.0090 - 70ms/epoch - 7ms/step\n",
      "Epoch 78/119\n",
      "10/10 - 0s - loss: 2.2235e-04 - val_loss: 0.0091 - 81ms/epoch - 8ms/step\n",
      "Epoch 79/119\n",
      "10/10 - 0s - loss: 2.3094e-04 - val_loss: 0.0091 - 65ms/epoch - 6ms/step\n",
      "Epoch 80/119\n",
      "10/10 - 0s - loss: 2.9871e-04 - val_loss: 0.0089 - 75ms/epoch - 8ms/step\n",
      "Epoch 81/119\n",
      "10/10 - 0s - loss: 2.4247e-04 - val_loss: 0.0090 - 63ms/epoch - 6ms/step\n",
      "Epoch 82/119\n",
      "10/10 - 0s - loss: 2.1993e-04 - val_loss: 0.0089 - 65ms/epoch - 6ms/step\n",
      "Epoch 83/119\n",
      "10/10 - 0s - loss: 2.1321e-04 - val_loss: 0.0090 - 76ms/epoch - 8ms/step\n",
      "Epoch 84/119\n",
      "10/10 - 0s - loss: 2.3437e-04 - val_loss: 0.0088 - 63ms/epoch - 6ms/step\n",
      "Epoch 85/119\n",
      "10/10 - 0s - loss: 2.1493e-04 - val_loss: 0.0091 - 62ms/epoch - 6ms/step\n",
      "Epoch 86/119\n",
      "10/10 - 0s - loss: 2.3070e-04 - val_loss: 0.0091 - 79ms/epoch - 8ms/step\n",
      "Epoch 87/119\n",
      "10/10 - 0s - loss: 2.5362e-04 - val_loss: 0.0088 - 62ms/epoch - 6ms/step\n",
      "Epoch 88/119\n",
      "10/10 - 0s - loss: 2.3363e-04 - val_loss: 0.0090 - 76ms/epoch - 8ms/step\n",
      "Epoch 89/119\n",
      "10/10 - 0s - loss: 2.0855e-04 - val_loss: 0.0090 - 88ms/epoch - 9ms/step\n",
      "Epoch 90/119\n",
      "10/10 - 0s - loss: 2.1510e-04 - val_loss: 0.0090 - 66ms/epoch - 7ms/step\n",
      "Epoch 91/119\n",
      "10/10 - 0s - loss: 2.0724e-04 - val_loss: 0.0090 - 64ms/epoch - 6ms/step\n",
      "Epoch 92/119\n",
      "10/10 - 0s - loss: 2.1398e-04 - val_loss: 0.0090 - 76ms/epoch - 8ms/step\n",
      "Epoch 93/119\n",
      "10/10 - 0s - loss: 2.1130e-04 - val_loss: 0.0091 - 63ms/epoch - 6ms/step\n",
      "Epoch 94/119\n",
      "10/10 - 0s - loss: 2.0388e-04 - val_loss: 0.0090 - 61ms/epoch - 6ms/step\n",
      "Epoch 95/119\n",
      "10/10 - 0s - loss: 2.1018e-04 - val_loss: 0.0088 - 62ms/epoch - 6ms/step\n",
      "Epoch 96/119\n",
      "10/10 - 0s - loss: 2.0579e-04 - val_loss: 0.0093 - 75ms/epoch - 8ms/step\n",
      "Epoch 97/119\n",
      "10/10 - 0s - loss: 1.9690e-04 - val_loss: 0.0090 - 64ms/epoch - 6ms/step\n",
      "Epoch 98/119\n",
      "10/10 - 0s - loss: 2.0075e-04 - val_loss: 0.0090 - 63ms/epoch - 6ms/step\n",
      "Epoch 99/119\n",
      "10/10 - 0s - loss: 2.0084e-04 - val_loss: 0.0091 - 76ms/epoch - 8ms/step\n",
      "Epoch 100/119\n",
      "10/10 - 0s - loss: 2.0164e-04 - val_loss: 0.0091 - 87ms/epoch - 9ms/step\n",
      "Epoch 101/119\n",
      "10/10 - 0s - loss: 1.9038e-04 - val_loss: 0.0092 - 65ms/epoch - 7ms/step\n",
      "Epoch 102/119\n",
      "10/10 - 0s - loss: 1.8416e-04 - val_loss: 0.0091 - 64ms/epoch - 6ms/step\n",
      "Epoch 103/119\n",
      "10/10 - 0s - loss: 1.8492e-04 - val_loss: 0.0090 - 63ms/epoch - 6ms/step\n",
      "Epoch 104/119\n",
      "10/10 - 0s - loss: 2.0050e-04 - val_loss: 0.0091 - 74ms/epoch - 7ms/step\n",
      "Epoch 105/119\n",
      "10/10 - 0s - loss: 2.0691e-04 - val_loss: 0.0091 - 65ms/epoch - 6ms/step\n",
      "Epoch 106/119\n",
      "10/10 - 0s - loss: 1.9011e-04 - val_loss: 0.0090 - 62ms/epoch - 6ms/step\n",
      "Epoch 107/119\n",
      "10/10 - 0s - loss: 1.8683e-04 - val_loss: 0.0092 - 62ms/epoch - 6ms/step\n",
      "Epoch 108/119\n",
      "10/10 - 0s - loss: 2.2236e-04 - val_loss: 0.0090 - 73ms/epoch - 7ms/step\n",
      "Epoch 109/119\n",
      "10/10 - 0s - loss: 2.2337e-04 - val_loss: 0.0093 - 61ms/epoch - 6ms/step\n",
      "Epoch 110/119\n",
      "10/10 - 0s - loss: 2.6980e-04 - val_loss: 0.0091 - 62ms/epoch - 6ms/step\n",
      "Epoch 111/119\n",
      "10/10 - 0s - loss: 2.5588e-04 - val_loss: 0.0089 - 91ms/epoch - 9ms/step\n",
      "Epoch 112/119\n",
      "10/10 - 0s - loss: 2.3113e-04 - val_loss: 0.0090 - 78ms/epoch - 8ms/step\n",
      "Epoch 113/119\n",
      "10/10 - 0s - loss: 2.1959e-04 - val_loss: 0.0091 - 63ms/epoch - 6ms/step\n",
      "Epoch 114/119\n",
      "10/10 - 0s - loss: 2.1592e-04 - val_loss: 0.0089 - 62ms/epoch - 6ms/step\n",
      "Epoch 115/119\n",
      "10/10 - 0s - loss: 2.0815e-04 - val_loss: 0.0088 - 66ms/epoch - 7ms/step\n",
      "Epoch 116/119\n",
      "10/10 - 0s - loss: 2.1402e-04 - val_loss: 0.0091 - 74ms/epoch - 7ms/step\n",
      "Epoch 117/119\n",
      "10/10 - 0s - loss: 2.0433e-04 - val_loss: 0.0093 - 61ms/epoch - 6ms/step\n",
      "Epoch 118/119\n",
      "10/10 - 0s - loss: 2.3771e-04 - val_loss: 0.0089 - 65ms/epoch - 7ms/step\n",
      "Epoch 119/119\n",
      "10/10 - 0s - loss: 1.8462e-04 - val_loss: 0.0091 - 74ms/epoch - 7ms/step\n",
      "9/9 [==============================] - 1s 1ms/step\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m-170.6   \u001b[0m | \u001b[0m119.8    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m40.42    \u001b[0m |\n",
      "Model: \"sequential_152\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_558 (LSTM)             (None, 1, 14)             1120      \n",
      "                                                                 \n",
      " dropout_406 (Dropout)       (None, 1, 14)             0         \n",
      "                                                                 \n",
      " lstm_559 (LSTM)             (None, 1, 14)             1624      \n",
      "                                                                 \n",
      " dropout_407 (Dropout)       (None, 1, 14)             0         \n",
      "                                                                 \n",
      " lstm_560 (LSTM)             (None, 1, 14)             1624      \n",
      "                                                                 \n",
      " dropout_408 (Dropout)       (None, 1, 14)             0         \n",
      "                                                                 \n",
      " lstm_561 (LSTM)             (None, 1, 14)             1624      \n",
      "                                                                 \n",
      " dropout_409 (Dropout)       (None, 1, 14)             0         \n",
      "                                                                 \n",
      " lstm_562 (LSTM)             (None, 1, 14)             1624      \n",
      "                                                                 \n",
      " dropout_410 (Dropout)       (None, 1, 14)             0         \n",
      "                                                                 \n",
      " lstm_563 (LSTM)             (None, 14)                1624      \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 1)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,255\n",
      "Trainable params: 9,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/146\n",
      "10/10 - 12s - loss: 0.0678 - val_loss: 0.0854 - 12s/epoch - 1s/step\n",
      "Epoch 2/146\n",
      "10/10 - 0s - loss: 0.0617 - val_loss: 0.0789 - 103ms/epoch - 10ms/step\n",
      "Epoch 3/146\n",
      "10/10 - 0s - loss: 0.0557 - val_loss: 0.0724 - 121ms/epoch - 12ms/step\n",
      "Epoch 4/146\n",
      "10/10 - 0s - loss: 0.0495 - val_loss: 0.0659 - 119ms/epoch - 12ms/step\n",
      "Epoch 5/146\n",
      "10/10 - 0s - loss: 0.0434 - val_loss: 0.0593 - 100ms/epoch - 10ms/step\n",
      "Epoch 6/146\n",
      "10/10 - 0s - loss: 0.0373 - val_loss: 0.0527 - 125ms/epoch - 12ms/step\n",
      "Epoch 7/146\n",
      "10/10 - 0s - loss: 0.0310 - val_loss: 0.0460 - 102ms/epoch - 10ms/step\n",
      "Epoch 8/146\n",
      "10/10 - 0s - loss: 0.0248 - val_loss: 0.0394 - 99ms/epoch - 10ms/step\n",
      "Epoch 9/146\n",
      "10/10 - 0s - loss: 0.0192 - val_loss: 0.0330 - 100ms/epoch - 10ms/step\n",
      "Epoch 10/146\n",
      "10/10 - 0s - loss: 0.0138 - val_loss: 0.0272 - 111ms/epoch - 11ms/step\n",
      "Epoch 11/146\n",
      "10/10 - 0s - loss: 0.0091 - val_loss: 0.0222 - 134ms/epoch - 13ms/step\n",
      "Epoch 12/146\n",
      "10/10 - 0s - loss: 0.0058 - val_loss: 0.0187 - 112ms/epoch - 11ms/step\n",
      "Epoch 13/146\n",
      "10/10 - 0s - loss: 0.0040 - val_loss: 0.0169 - 108ms/epoch - 11ms/step\n",
      "Epoch 14/146\n",
      "10/10 - 0s - loss: 0.0038 - val_loss: 0.0164 - 94ms/epoch - 9ms/step\n",
      "Epoch 15/146\n",
      "10/10 - 0s - loss: 0.0038 - val_loss: 0.0164 - 94ms/epoch - 9ms/step\n",
      "Epoch 16/146\n",
      "10/10 - 0s - loss: 0.0037 - val_loss: 0.0165 - 106ms/epoch - 11ms/step\n",
      "Epoch 17/146\n",
      "10/10 - 0s - loss: 0.0035 - val_loss: 0.0165 - 99ms/epoch - 10ms/step\n",
      "Epoch 18/146\n",
      "10/10 - 0s - loss: 0.0036 - val_loss: 0.0166 - 99ms/epoch - 10ms/step\n",
      "Epoch 19/146\n",
      "10/10 - 0s - loss: 0.0034 - val_loss: 0.0166 - 119ms/epoch - 12ms/step\n",
      "Epoch 20/146\n",
      "10/10 - 0s - loss: 0.0036 - val_loss: 0.0165 - 93ms/epoch - 9ms/step\n",
      "Epoch 21/146\n",
      "10/10 - 0s - loss: 0.0036 - val_loss: 0.0165 - 93ms/epoch - 9ms/step\n",
      "Epoch 22/146\n",
      "10/10 - 0s - loss: 0.0035 - val_loss: 0.0165 - 108ms/epoch - 11ms/step\n",
      "Epoch 23/146\n",
      "10/10 - 0s - loss: 0.0037 - val_loss: 0.0164 - 93ms/epoch - 9ms/step\n",
      "Epoch 24/146\n",
      "10/10 - 0s - loss: 0.0033 - val_loss: 0.0164 - 120ms/epoch - 12ms/step\n",
      "Epoch 25/146\n",
      "10/10 - 0s - loss: 0.0034 - val_loss: 0.0164 - 111ms/epoch - 11ms/step\n",
      "Epoch 26/146\n",
      "10/10 - 0s - loss: 0.0036 - val_loss: 0.0164 - 100ms/epoch - 10ms/step\n",
      "Epoch 27/146\n",
      "10/10 - 0s - loss: 0.0033 - val_loss: 0.0164 - 94ms/epoch - 9ms/step\n",
      "Epoch 28/146\n",
      "10/10 - 0s - loss: 0.0035 - val_loss: 0.0164 - 108ms/epoch - 11ms/step\n",
      "Epoch 29/146\n",
      "10/10 - 0s - loss: 0.0033 - val_loss: 0.0162 - 95ms/epoch - 10ms/step\n",
      "Epoch 30/146\n",
      "10/10 - 0s - loss: 0.0034 - val_loss: 0.0162 - 93ms/epoch - 9ms/step\n",
      "Epoch 31/146\n",
      "10/10 - 0s - loss: 0.0036 - val_loss: 0.0162 - 104ms/epoch - 10ms/step\n",
      "Epoch 32/146\n",
      "10/10 - 0s - loss: 0.0032 - val_loss: 0.0162 - 93ms/epoch - 9ms/step\n",
      "Epoch 33/146\n",
      "10/10 - 0s - loss: 0.0035 - val_loss: 0.0161 - 93ms/epoch - 9ms/step\n",
      "Epoch 34/146\n",
      "10/10 - 0s - loss: 0.0035 - val_loss: 0.0160 - 109ms/epoch - 11ms/step\n",
      "Epoch 35/146\n",
      "10/10 - 0s - loss: 0.0033 - val_loss: 0.0160 - 101ms/epoch - 10ms/step\n",
      "Epoch 36/146\n",
      "10/10 - 0s - loss: 0.0032 - val_loss: 0.0159 - 96ms/epoch - 10ms/step\n",
      "Epoch 37/146\n",
      "10/10 - 0s - loss: 0.0032 - val_loss: 0.0157 - 117ms/epoch - 12ms/step\n",
      "Epoch 38/146\n",
      "10/10 - 0s - loss: 0.0034 - val_loss: 0.0157 - 147ms/epoch - 15ms/step\n",
      "Epoch 39/146\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0155 - 101ms/epoch - 10ms/step\n",
      "Epoch 40/146\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0155 - 109ms/epoch - 11ms/step\n",
      "Epoch 41/146\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0154 - 95ms/epoch - 10ms/step\n",
      "Epoch 42/146\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0152 - 103ms/epoch - 10ms/step\n",
      "Epoch 43/146\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0150 - 107ms/epoch - 11ms/step\n",
      "Epoch 44/146\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0149 - 95ms/epoch - 10ms/step\n",
      "Epoch 45/146\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0148 - 94ms/epoch - 9ms/step\n",
      "Epoch 46/146\n",
      "10/10 - 0s - loss: 0.0032 - val_loss: 0.0144 - 111ms/epoch - 11ms/step\n",
      "Epoch 47/146\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0142 - 98ms/epoch - 10ms/step\n",
      "Epoch 48/146\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0140 - 99ms/epoch - 10ms/step\n",
      "Epoch 49/146\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0137 - 123ms/epoch - 12ms/step\n",
      "Epoch 50/146\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0132 - 141ms/epoch - 14ms/step\n",
      "Epoch 51/146\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0131 - 143ms/epoch - 14ms/step\n",
      "Epoch 52/146\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0127 - 169ms/epoch - 17ms/step\n",
      "Epoch 53/146\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0121 - 134ms/epoch - 13ms/step\n",
      "Epoch 54/146\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0119 - 120ms/epoch - 12ms/step\n",
      "Epoch 55/146\n",
      "10/10 - 0s - loss: 0.0023 - val_loss: 0.0114 - 156ms/epoch - 16ms/step\n",
      "Epoch 56/146\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0112 - 120ms/epoch - 12ms/step\n",
      "Epoch 57/146\n",
      "10/10 - 0s - loss: 0.0023 - val_loss: 0.0106 - 133ms/epoch - 13ms/step\n",
      "Epoch 58/146\n",
      "10/10 - 0s - loss: 0.0021 - val_loss: 0.0100 - 139ms/epoch - 14ms/step\n",
      "Epoch 59/146\n",
      "10/10 - 0s - loss: 0.0020 - val_loss: 0.0098 - 136ms/epoch - 14ms/step\n",
      "Epoch 60/146\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0101 - 133ms/epoch - 13ms/step\n",
      "Epoch 61/146\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0093 - 121ms/epoch - 12ms/step\n",
      "Epoch 62/146\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0093 - 156ms/epoch - 16ms/step\n",
      "Epoch 63/146\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0094 - 128ms/epoch - 13ms/step\n",
      "Epoch 64/146\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0091 - 145ms/epoch - 15ms/step\n",
      "Epoch 65/146\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0091 - 139ms/epoch - 14ms/step\n",
      "Epoch 66/146\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0091 - 132ms/epoch - 13ms/step\n",
      "Epoch 67/146\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0090 - 145ms/epoch - 15ms/step\n",
      "Epoch 68/146\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0091 - 138ms/epoch - 14ms/step\n",
      "Epoch 69/146\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0090 - 143ms/epoch - 14ms/step\n",
      "Epoch 70/146\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0090 - 132ms/epoch - 13ms/step\n",
      "Epoch 71/146\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0090 - 118ms/epoch - 12ms/step\n",
      "Epoch 72/146\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0090 - 164ms/epoch - 16ms/step\n",
      "Epoch 73/146\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0090 - 124ms/epoch - 12ms/step\n",
      "Epoch 74/146\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0090 - 156ms/epoch - 16ms/step\n",
      "Epoch 75/146\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0090 - 135ms/epoch - 13ms/step\n",
      "Epoch 76/146\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0090 - 135ms/epoch - 14ms/step\n",
      "Epoch 77/146\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0090 - 133ms/epoch - 13ms/step\n",
      "Epoch 78/146\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0090 - 131ms/epoch - 13ms/step\n",
      "Epoch 79/146\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0090 - 137ms/epoch - 14ms/step\n",
      "Epoch 80/146\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0090 - 136ms/epoch - 14ms/step\n",
      "Epoch 81/146\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0090 - 116ms/epoch - 12ms/step\n",
      "Epoch 82/146\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0090 - 152ms/epoch - 15ms/step\n",
      "Epoch 83/146\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0090 - 147ms/epoch - 15ms/step\n",
      "Epoch 84/146\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0090 - 128ms/epoch - 13ms/step\n",
      "Epoch 85/146\n",
      "10/10 - 0s - loss: 9.8402e-04 - val_loss: 0.0090 - 129ms/epoch - 13ms/step\n",
      "Epoch 86/146\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0091 - 129ms/epoch - 13ms/step\n",
      "Epoch 87/146\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0090 - 132ms/epoch - 13ms/step\n",
      "Epoch 88/146\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0090 - 126ms/epoch - 13ms/step\n",
      "Epoch 89/146\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0090 - 136ms/epoch - 14ms/step\n",
      "Epoch 90/146\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0089 - 126ms/epoch - 13ms/step\n",
      "Epoch 91/146\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0089 - 121ms/epoch - 12ms/step\n",
      "Epoch 92/146\n",
      "10/10 - 0s - loss: 9.9375e-04 - val_loss: 0.0089 - 137ms/epoch - 14ms/step\n",
      "Epoch 93/146\n",
      "10/10 - 0s - loss: 8.7446e-04 - val_loss: 0.0089 - 130ms/epoch - 13ms/step\n",
      "Epoch 94/146\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0088 - 144ms/epoch - 14ms/step\n",
      "Epoch 95/146\n",
      "10/10 - 0s - loss: 9.3928e-04 - val_loss: 0.0088 - 140ms/epoch - 14ms/step\n",
      "Epoch 96/146\n",
      "10/10 - 0s - loss: 9.6901e-04 - val_loss: 0.0088 - 121ms/epoch - 12ms/step\n",
      "Epoch 97/146\n",
      "10/10 - 0s - loss: 9.7004e-04 - val_loss: 0.0088 - 126ms/epoch - 13ms/step\n",
      "Epoch 98/146\n",
      "10/10 - 0s - loss: 8.3017e-04 - val_loss: 0.0088 - 131ms/epoch - 13ms/step\n",
      "Epoch 99/146\n",
      "10/10 - 0s - loss: 9.1282e-04 - val_loss: 0.0087 - 129ms/epoch - 13ms/step\n",
      "Epoch 100/146\n",
      "10/10 - 0s - loss: 8.4390e-04 - val_loss: 0.0088 - 135ms/epoch - 13ms/step\n",
      "Epoch 101/146\n",
      "10/10 - 0s - loss: 8.9104e-04 - val_loss: 0.0087 - 129ms/epoch - 13ms/step\n",
      "Epoch 102/146\n",
      "10/10 - 0s - loss: 9.3359e-04 - val_loss: 0.0087 - 136ms/epoch - 14ms/step\n",
      "Epoch 103/146\n",
      "10/10 - 0s - loss: 9.0620e-04 - val_loss: 0.0087 - 132ms/epoch - 13ms/step\n",
      "Epoch 104/146\n",
      "10/10 - 0s - loss: 9.2004e-04 - val_loss: 0.0086 - 143ms/epoch - 14ms/step\n",
      "Epoch 105/146\n",
      "10/10 - 0s - loss: 8.0238e-04 - val_loss: 0.0086 - 146ms/epoch - 15ms/step\n",
      "Epoch 106/146\n",
      "10/10 - 0s - loss: 8.3041e-04 - val_loss: 0.0086 - 124ms/epoch - 12ms/step\n",
      "Epoch 107/146\n",
      "10/10 - 0s - loss: 8.2478e-04 - val_loss: 0.0086 - 119ms/epoch - 12ms/step\n",
      "Epoch 108/146\n",
      "10/10 - 0s - loss: 8.5015e-04 - val_loss: 0.0085 - 128ms/epoch - 13ms/step\n",
      "Epoch 109/146\n",
      "10/10 - 0s - loss: 9.1050e-04 - val_loss: 0.0085 - 138ms/epoch - 14ms/step\n",
      "Epoch 110/146\n",
      "10/10 - 0s - loss: 8.7443e-04 - val_loss: 0.0085 - 132ms/epoch - 13ms/step\n",
      "Epoch 111/146\n",
      "10/10 - 0s - loss: 7.9549e-04 - val_loss: 0.0085 - 135ms/epoch - 13ms/step\n",
      "Epoch 112/146\n",
      "10/10 - 0s - loss: 8.4535e-04 - val_loss: 0.0085 - 139ms/epoch - 14ms/step\n",
      "Epoch 113/146\n",
      "10/10 - 0s - loss: 7.5015e-04 - val_loss: 0.0084 - 133ms/epoch - 13ms/step\n",
      "Epoch 114/146\n",
      "10/10 - 0s - loss: 7.5864e-04 - val_loss: 0.0084 - 146ms/epoch - 15ms/step\n",
      "Epoch 115/146\n",
      "10/10 - 0s - loss: 7.5576e-04 - val_loss: 0.0084 - 148ms/epoch - 15ms/step\n",
      "Epoch 116/146\n",
      "10/10 - 0s - loss: 8.2298e-04 - val_loss: 0.0084 - 133ms/epoch - 13ms/step\n",
      "Epoch 117/146\n",
      "10/10 - 0s - loss: 9.7724e-04 - val_loss: 0.0084 - 122ms/epoch - 12ms/step\n",
      "Epoch 118/146\n",
      "10/10 - 0s - loss: 7.2473e-04 - val_loss: 0.0084 - 130ms/epoch - 13ms/step\n",
      "Epoch 119/146\n",
      "10/10 - 0s - loss: 8.1045e-04 - val_loss: 0.0083 - 133ms/epoch - 13ms/step\n",
      "Epoch 120/146\n",
      "10/10 - 0s - loss: 7.4387e-04 - val_loss: 0.0083 - 127ms/epoch - 13ms/step\n",
      "Epoch 121/146\n",
      "10/10 - 0s - loss: 7.4330e-04 - val_loss: 0.0083 - 131ms/epoch - 13ms/step\n",
      "Epoch 122/146\n",
      "10/10 - 0s - loss: 7.5253e-04 - val_loss: 0.0083 - 135ms/epoch - 13ms/step\n",
      "Epoch 123/146\n",
      "10/10 - 0s - loss: 7.4033e-04 - val_loss: 0.0083 - 129ms/epoch - 13ms/step\n",
      "Epoch 124/146\n",
      "10/10 - 0s - loss: 7.4271e-04 - val_loss: 0.0083 - 133ms/epoch - 13ms/step\n",
      "Epoch 125/146\n",
      "10/10 - 0s - loss: 7.5251e-04 - val_loss: 0.0082 - 166ms/epoch - 17ms/step\n",
      "Epoch 126/146\n",
      "10/10 - 0s - loss: 7.8786e-04 - val_loss: 0.0082 - 135ms/epoch - 13ms/step\n",
      "Epoch 127/146\n",
      "10/10 - 0s - loss: 7.4968e-04 - val_loss: 0.0082 - 118ms/epoch - 12ms/step\n",
      "Epoch 128/146\n",
      "10/10 - 0s - loss: 6.7913e-04 - val_loss: 0.0082 - 150ms/epoch - 15ms/step\n",
      "Epoch 129/146\n",
      "10/10 - 0s - loss: 7.4971e-04 - val_loss: 0.0082 - 122ms/epoch - 12ms/step\n",
      "Epoch 130/146\n",
      "10/10 - 0s - loss: 7.2715e-04 - val_loss: 0.0082 - 127ms/epoch - 13ms/step\n",
      "Epoch 131/146\n",
      "10/10 - 0s - loss: 7.2191e-04 - val_loss: 0.0082 - 133ms/epoch - 13ms/step\n",
      "Epoch 132/146\n",
      "10/10 - 0s - loss: 7.7045e-04 - val_loss: 0.0082 - 131ms/epoch - 13ms/step\n",
      "Epoch 133/146\n",
      "10/10 - 0s - loss: 7.6649e-04 - val_loss: 0.0082 - 131ms/epoch - 13ms/step\n",
      "Epoch 134/146\n",
      "10/10 - 0s - loss: 6.6625e-04 - val_loss: 0.0081 - 125ms/epoch - 12ms/step\n",
      "Epoch 135/146\n",
      "10/10 - 0s - loss: 6.9525e-04 - val_loss: 0.0081 - 138ms/epoch - 14ms/step\n",
      "Epoch 136/146\n",
      "10/10 - 0s - loss: 7.5946e-04 - val_loss: 0.0081 - 130ms/epoch - 13ms/step\n",
      "Epoch 137/146\n",
      "10/10 - 0s - loss: 7.0637e-04 - val_loss: 0.0081 - 118ms/epoch - 12ms/step\n",
      "Epoch 138/146\n",
      "10/10 - 0s - loss: 6.6780e-04 - val_loss: 0.0082 - 145ms/epoch - 14ms/step\n",
      "Epoch 139/146\n",
      "10/10 - 0s - loss: 6.6683e-04 - val_loss: 0.0082 - 128ms/epoch - 13ms/step\n",
      "Epoch 140/146\n",
      "10/10 - 0s - loss: 7.4294e-04 - val_loss: 0.0082 - 150ms/epoch - 15ms/step\n",
      "Epoch 141/146\n",
      "10/10 - 0s - loss: 6.5234e-04 - val_loss: 0.0081 - 128ms/epoch - 13ms/step\n",
      "Epoch 142/146\n",
      "10/10 - 0s - loss: 6.6588e-04 - val_loss: 0.0081 - 132ms/epoch - 13ms/step\n",
      "Epoch 143/146\n",
      "10/10 - 0s - loss: 6.2931e-04 - val_loss: 0.0081 - 126ms/epoch - 13ms/step\n",
      "Epoch 144/146\n",
      "10/10 - 0s - loss: 6.5600e-04 - val_loss: 0.0081 - 132ms/epoch - 13ms/step\n",
      "Epoch 145/146\n",
      "10/10 - 0s - loss: 6.7698e-04 - val_loss: 0.0081 - 130ms/epoch - 13ms/step\n",
      "Epoch 146/146\n",
      "10/10 - 0s - loss: 7.1126e-04 - val_loss: 0.0081 - 132ms/epoch - 13ms/step\n",
      "9/9 [==============================] - 2s 3ms/step\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m-161.4   \u001b[0m | \u001b[0m146.4    \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m0.0005373\u001b[0m | \u001b[0m14.25    \u001b[0m |\n",
      "Model: \"sequential_153\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_564 (LSTM)             (None, 1, 36)             6048      \n",
      "                                                                 \n",
      " dropout_411 (Dropout)       (None, 1, 36)             0         \n",
      "                                                                 \n",
      " lstm_565 (LSTM)             (None, 36)                10512     \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 1)                 37        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,597\n",
      "Trainable params: 16,597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/106\n",
      "10/10 - 6s - loss: 0.0231 - val_loss: 0.0148 - 6s/epoch - 588ms/step\n",
      "Epoch 2/106\n",
      "10/10 - 0s - loss: 0.0043 - val_loss: 0.0156 - 78ms/epoch - 8ms/step\n",
      "Epoch 3/106\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0129 - 102ms/epoch - 10ms/step\n",
      "Epoch 4/106\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0135 - 92ms/epoch - 9ms/step\n",
      "Epoch 5/106\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0121 - 92ms/epoch - 9ms/step\n",
      "Epoch 6/106\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0115 - 88ms/epoch - 9ms/step\n",
      "Epoch 7/106\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0105 - 91ms/epoch - 9ms/step\n",
      "Epoch 8/106\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0093 - 98ms/epoch - 10ms/step\n",
      "Epoch 9/106\n",
      "10/10 - 0s - loss: 8.5461e-04 - val_loss: 0.0085 - 87ms/epoch - 9ms/step\n",
      "Epoch 10/106\n",
      "10/10 - 0s - loss: 5.9506e-04 - val_loss: 0.0084 - 125ms/epoch - 12ms/step\n",
      "Epoch 11/106\n",
      "10/10 - 0s - loss: 5.0402e-04 - val_loss: 0.0086 - 97ms/epoch - 10ms/step\n",
      "Epoch 12/106\n",
      "10/10 - 0s - loss: 4.8007e-04 - val_loss: 0.0087 - 93ms/epoch - 9ms/step\n",
      "Epoch 13/106\n",
      "10/10 - 0s - loss: 3.8658e-04 - val_loss: 0.0087 - 88ms/epoch - 9ms/step\n",
      "Epoch 14/106\n",
      "10/10 - 0s - loss: 3.7679e-04 - val_loss: 0.0086 - 89ms/epoch - 9ms/step\n",
      "Epoch 15/106\n",
      "10/10 - 0s - loss: 3.1111e-04 - val_loss: 0.0088 - 94ms/epoch - 9ms/step\n",
      "Epoch 16/106\n",
      "10/10 - 0s - loss: 3.4568e-04 - val_loss: 0.0089 - 103ms/epoch - 10ms/step\n",
      "Epoch 17/106\n",
      "10/10 - 0s - loss: 3.3241e-04 - val_loss: 0.0089 - 84ms/epoch - 8ms/step\n",
      "Epoch 18/106\n",
      "10/10 - 0s - loss: 3.0103e-04 - val_loss: 0.0088 - 92ms/epoch - 9ms/step\n",
      "Epoch 19/106\n",
      "10/10 - 0s - loss: 3.0743e-04 - val_loss: 0.0087 - 103ms/epoch - 10ms/step\n",
      "Epoch 20/106\n",
      "10/10 - 0s - loss: 3.1209e-04 - val_loss: 0.0089 - 85ms/epoch - 8ms/step\n",
      "Epoch 21/106\n",
      "10/10 - 0s - loss: 2.6408e-04 - val_loss: 0.0089 - 89ms/epoch - 9ms/step\n",
      "Epoch 22/106\n",
      "10/10 - 0s - loss: 3.0075e-04 - val_loss: 0.0087 - 97ms/epoch - 10ms/step\n",
      "Epoch 23/106\n",
      "10/10 - 0s - loss: 2.9904e-04 - val_loss: 0.0088 - 116ms/epoch - 12ms/step\n",
      "Epoch 24/106\n",
      "10/10 - 0s - loss: 2.6913e-04 - val_loss: 0.0091 - 79ms/epoch - 8ms/step\n",
      "Epoch 25/106\n",
      "10/10 - 0s - loss: 2.7465e-04 - val_loss: 0.0088 - 104ms/epoch - 10ms/step\n",
      "Epoch 26/106\n",
      "10/10 - 0s - loss: 2.5757e-04 - val_loss: 0.0088 - 81ms/epoch - 8ms/step\n",
      "Epoch 27/106\n",
      "10/10 - 0s - loss: 2.5510e-04 - val_loss: 0.0089 - 84ms/epoch - 8ms/step\n",
      "Epoch 28/106\n",
      "10/10 - 0s - loss: 2.4492e-04 - val_loss: 0.0089 - 69ms/epoch - 7ms/step\n",
      "Epoch 29/106\n",
      "10/10 - 0s - loss: 2.3625e-04 - val_loss: 0.0089 - 66ms/epoch - 7ms/step\n",
      "Epoch 30/106\n",
      "10/10 - 0s - loss: 2.2847e-04 - val_loss: 0.0088 - 85ms/epoch - 8ms/step\n",
      "Epoch 31/106\n",
      "10/10 - 0s - loss: 2.3434e-04 - val_loss: 0.0090 - 65ms/epoch - 6ms/step\n",
      "Epoch 32/106\n",
      "10/10 - 0s - loss: 2.2728e-04 - val_loss: 0.0090 - 65ms/epoch - 6ms/step\n",
      "Epoch 33/106\n",
      "10/10 - 0s - loss: 2.2216e-04 - val_loss: 0.0090 - 65ms/epoch - 6ms/step\n",
      "Epoch 34/106\n",
      "10/10 - 0s - loss: 2.1782e-04 - val_loss: 0.0090 - 83ms/epoch - 8ms/step\n",
      "Epoch 35/106\n",
      "10/10 - 0s - loss: 2.3392e-04 - val_loss: 0.0091 - 68ms/epoch - 7ms/step\n",
      "Epoch 36/106\n",
      "10/10 - 0s - loss: 2.2509e-04 - val_loss: 0.0088 - 93ms/epoch - 9ms/step\n",
      "Epoch 37/106\n",
      "10/10 - 0s - loss: 2.3877e-04 - val_loss: 0.0090 - 74ms/epoch - 7ms/step\n",
      "Epoch 38/106\n",
      "10/10 - 0s - loss: 2.3225e-04 - val_loss: 0.0090 - 79ms/epoch - 8ms/step\n",
      "Epoch 39/106\n",
      "10/10 - 0s - loss: 2.2892e-04 - val_loss: 0.0091 - 65ms/epoch - 7ms/step\n",
      "Epoch 40/106\n",
      "10/10 - 0s - loss: 2.4453e-04 - val_loss: 0.0088 - 64ms/epoch - 6ms/step\n",
      "Epoch 41/106\n",
      "10/10 - 0s - loss: 2.1883e-04 - val_loss: 0.0091 - 64ms/epoch - 6ms/step\n",
      "Epoch 42/106\n",
      "10/10 - 0s - loss: 2.1378e-04 - val_loss: 0.0091 - 81ms/epoch - 8ms/step\n",
      "Epoch 43/106\n",
      "10/10 - 0s - loss: 2.0828e-04 - val_loss: 0.0092 - 72ms/epoch - 7ms/step\n",
      "Epoch 44/106\n",
      "10/10 - 0s - loss: 2.2852e-04 - val_loss: 0.0089 - 64ms/epoch - 6ms/step\n",
      "Epoch 45/106\n",
      "10/10 - 0s - loss: 2.1740e-04 - val_loss: 0.0089 - 64ms/epoch - 6ms/step\n",
      "Epoch 46/106\n",
      "10/10 - 0s - loss: 2.4598e-04 - val_loss: 0.0094 - 76ms/epoch - 8ms/step\n",
      "Epoch 47/106\n",
      "10/10 - 0s - loss: 2.5007e-04 - val_loss: 0.0090 - 97ms/epoch - 10ms/step\n",
      "Epoch 48/106\n",
      "10/10 - 0s - loss: 2.0076e-04 - val_loss: 0.0090 - 66ms/epoch - 7ms/step\n",
      "Epoch 49/106\n",
      "10/10 - 0s - loss: 2.1638e-04 - val_loss: 0.0092 - 64ms/epoch - 6ms/step\n",
      "Epoch 50/106\n",
      "10/10 - 0s - loss: 2.0363e-04 - val_loss: 0.0091 - 76ms/epoch - 8ms/step\n",
      "Epoch 51/106\n",
      "10/10 - 0s - loss: 1.9633e-04 - val_loss: 0.0092 - 66ms/epoch - 7ms/step\n",
      "Epoch 52/106\n",
      "10/10 - 0s - loss: 2.0092e-04 - val_loss: 0.0090 - 63ms/epoch - 6ms/step\n",
      "Epoch 53/106\n",
      "10/10 - 0s - loss: 2.2228e-04 - val_loss: 0.0091 - 63ms/epoch - 6ms/step\n",
      "Epoch 54/106\n",
      "10/10 - 0s - loss: 2.0416e-04 - val_loss: 0.0091 - 80ms/epoch - 8ms/step\n",
      "Epoch 55/106\n",
      "10/10 - 0s - loss: 2.4104e-04 - val_loss: 0.0091 - 65ms/epoch - 7ms/step\n",
      "Epoch 56/106\n",
      "10/10 - 0s - loss: 2.1484e-04 - val_loss: 0.0089 - 65ms/epoch - 6ms/step\n",
      "Epoch 57/106\n",
      "10/10 - 0s - loss: 2.0845e-04 - val_loss: 0.0092 - 63ms/epoch - 6ms/step\n",
      "Epoch 58/106\n",
      "10/10 - 0s - loss: 2.2084e-04 - val_loss: 0.0092 - 101ms/epoch - 10ms/step\n",
      "Epoch 59/106\n",
      "10/10 - 0s - loss: 2.1182e-04 - val_loss: 0.0091 - 76ms/epoch - 8ms/step\n",
      "Epoch 60/106\n",
      "10/10 - 0s - loss: 2.0879e-04 - val_loss: 0.0090 - 67ms/epoch - 7ms/step\n",
      "Epoch 61/106\n",
      "10/10 - 0s - loss: 1.9996e-04 - val_loss: 0.0092 - 64ms/epoch - 6ms/step\n",
      "Epoch 62/106\n",
      "10/10 - 0s - loss: 1.9720e-04 - val_loss: 0.0092 - 78ms/epoch - 8ms/step\n",
      "Epoch 63/106\n",
      "10/10 - 0s - loss: 1.9540e-04 - val_loss: 0.0090 - 64ms/epoch - 6ms/step\n",
      "Epoch 64/106\n",
      "10/10 - 0s - loss: 1.9728e-04 - val_loss: 0.0090 - 68ms/epoch - 7ms/step\n",
      "Epoch 65/106\n",
      "10/10 - 0s - loss: 1.9466e-04 - val_loss: 0.0091 - 82ms/epoch - 8ms/step\n",
      "Epoch 66/106\n",
      "10/10 - 0s - loss: 2.1488e-04 - val_loss: 0.0092 - 75ms/epoch - 7ms/step\n",
      "Epoch 67/106\n",
      "10/10 - 0s - loss: 2.1108e-04 - val_loss: 0.0090 - 68ms/epoch - 7ms/step\n",
      "Epoch 68/106\n",
      "10/10 - 0s - loss: 2.3976e-04 - val_loss: 0.0092 - 62ms/epoch - 6ms/step\n",
      "Epoch 69/106\n",
      "10/10 - 0s - loss: 2.1214e-04 - val_loss: 0.0091 - 65ms/epoch - 6ms/step\n",
      "Epoch 70/106\n",
      "10/10 - 0s - loss: 2.2080e-04 - val_loss: 0.0090 - 102ms/epoch - 10ms/step\n",
      "Epoch 71/106\n",
      "10/10 - 0s - loss: 2.0788e-04 - val_loss: 0.0090 - 75ms/epoch - 7ms/step\n",
      "Epoch 72/106\n",
      "10/10 - 0s - loss: 1.9090e-04 - val_loss: 0.0092 - 63ms/epoch - 6ms/step\n",
      "Epoch 73/106\n",
      "10/10 - 0s - loss: 1.9043e-04 - val_loss: 0.0092 - 68ms/epoch - 7ms/step\n",
      "Epoch 74/106\n",
      "10/10 - 0s - loss: 2.0417e-04 - val_loss: 0.0093 - 84ms/epoch - 8ms/step\n",
      "Epoch 75/106\n",
      "10/10 - 0s - loss: 1.9078e-04 - val_loss: 0.0092 - 64ms/epoch - 6ms/step\n",
      "Epoch 76/106\n",
      "10/10 - 0s - loss: 1.9943e-04 - val_loss: 0.0092 - 62ms/epoch - 6ms/step\n",
      "Epoch 77/106\n",
      "10/10 - 0s - loss: 1.9884e-04 - val_loss: 0.0092 - 62ms/epoch - 6ms/step\n",
      "Epoch 78/106\n",
      "10/10 - 0s - loss: 2.3764e-04 - val_loss: 0.0090 - 74ms/epoch - 7ms/step\n",
      "Epoch 79/106\n",
      "10/10 - 0s - loss: 2.2889e-04 - val_loss: 0.0094 - 65ms/epoch - 6ms/step\n",
      "Epoch 80/106\n",
      "10/10 - 0s - loss: 2.6661e-04 - val_loss: 0.0091 - 84ms/epoch - 8ms/step\n",
      "Epoch 81/106\n",
      "10/10 - 0s - loss: 2.3855e-04 - val_loss: 0.0091 - 72ms/epoch - 7ms/step\n",
      "Epoch 82/106\n",
      "10/10 - 0s - loss: 2.7628e-04 - val_loss: 0.0094 - 79ms/epoch - 8ms/step\n",
      "Epoch 83/106\n",
      "10/10 - 0s - loss: 2.2975e-04 - val_loss: 0.0090 - 65ms/epoch - 7ms/step\n",
      "Epoch 84/106\n",
      "10/10 - 0s - loss: 1.9438e-04 - val_loss: 0.0090 - 62ms/epoch - 6ms/step\n",
      "Epoch 85/106\n",
      "10/10 - 0s - loss: 1.9738e-04 - val_loss: 0.0089 - 63ms/epoch - 6ms/step\n",
      "Epoch 86/106\n",
      "10/10 - 0s - loss: 1.9584e-04 - val_loss: 0.0092 - 82ms/epoch - 8ms/step\n",
      "Epoch 87/106\n",
      "10/10 - 0s - loss: 2.2773e-04 - val_loss: 0.0093 - 75ms/epoch - 7ms/step\n",
      "Epoch 88/106\n",
      "10/10 - 0s - loss: 2.4163e-04 - val_loss: 0.0091 - 64ms/epoch - 6ms/step\n",
      "Epoch 89/106\n",
      "10/10 - 0s - loss: 2.5261e-04 - val_loss: 0.0091 - 64ms/epoch - 6ms/step\n",
      "Epoch 90/106\n",
      "10/10 - 0s - loss: 2.0599e-04 - val_loss: 0.0091 - 75ms/epoch - 7ms/step\n",
      "Epoch 91/106\n",
      "10/10 - 0s - loss: 1.9612e-04 - val_loss: 0.0091 - 67ms/epoch - 7ms/step\n",
      "Epoch 92/106\n",
      "10/10 - 0s - loss: 1.9935e-04 - val_loss: 0.0092 - 75ms/epoch - 8ms/step\n",
      "Epoch 93/106\n",
      "10/10 - 0s - loss: 1.9095e-04 - val_loss: 0.0091 - 77ms/epoch - 8ms/step\n",
      "Epoch 94/106\n",
      "10/10 - 0s - loss: 2.2486e-04 - val_loss: 0.0091 - 75ms/epoch - 8ms/step\n",
      "Epoch 95/106\n",
      "10/10 - 0s - loss: 2.2175e-04 - val_loss: 0.0092 - 70ms/epoch - 7ms/step\n",
      "Epoch 96/106\n",
      "10/10 - 0s - loss: 2.2858e-04 - val_loss: 0.0091 - 70ms/epoch - 7ms/step\n",
      "Epoch 97/106\n",
      "10/10 - 0s - loss: 2.0582e-04 - val_loss: 0.0092 - 88ms/epoch - 9ms/step\n",
      "Epoch 98/106\n",
      "10/10 - 0s - loss: 1.9087e-04 - val_loss: 0.0092 - 78ms/epoch - 8ms/step\n",
      "Epoch 99/106\n",
      "10/10 - 0s - loss: 1.9832e-04 - val_loss: 0.0092 - 95ms/epoch - 10ms/step\n",
      "Epoch 100/106\n",
      "10/10 - 0s - loss: 2.0483e-04 - val_loss: 0.0092 - 101ms/epoch - 10ms/step\n",
      "Epoch 101/106\n",
      "10/10 - 0s - loss: 2.1571e-04 - val_loss: 0.0091 - 107ms/epoch - 11ms/step\n",
      "Epoch 102/106\n",
      "10/10 - 0s - loss: 2.0069e-04 - val_loss: 0.0091 - 87ms/epoch - 9ms/step\n",
      "Epoch 103/106\n",
      "10/10 - 0s - loss: 1.8827e-04 - val_loss: 0.0094 - 112ms/epoch - 11ms/step\n",
      "Epoch 104/106\n",
      "10/10 - 0s - loss: 1.9209e-04 - val_loss: 0.0092 - 84ms/epoch - 8ms/step\n",
      "Epoch 105/106\n",
      "10/10 - 0s - loss: 2.0488e-04 - val_loss: 0.0091 - 76ms/epoch - 8ms/step\n",
      "Epoch 106/106\n",
      "10/10 - 0s - loss: 2.0145e-04 - val_loss: 0.0093 - 73ms/epoch - 7ms/step\n",
      "9/9 [==============================] - 1s 1ms/step\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m-173.0   \u001b[0m | \u001b[0m106.2    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.009326 \u001b[0m | \u001b[0m36.53    \u001b[0m |\n",
      "Model: \"sequential_154\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_566 (LSTM)             (None, 1, 87)             32364     \n",
      "                                                                 \n",
      " dropout_412 (Dropout)       (None, 1, 87)             0         \n",
      "                                                                 \n",
      " lstm_567 (LSTM)             (None, 87)                60900     \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 1)                 88        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,352\n",
      "Trainable params: 93,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/180\n",
      "10/10 - 4s - loss: 0.0248 - val_loss: 0.0170 - 4s/epoch - 401ms/step\n",
      "Epoch 2/180\n",
      "10/10 - 0s - loss: 0.0044 - val_loss: 0.0157 - 74ms/epoch - 7ms/step\n",
      "Epoch 3/180\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0111 - 90ms/epoch - 9ms/step\n",
      "Epoch 4/180\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0119 - 97ms/epoch - 10ms/step\n",
      "Epoch 5/180\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0103 - 80ms/epoch - 8ms/step\n",
      "Epoch 6/180\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0102 - 86ms/epoch - 9ms/step\n",
      "Epoch 7/180\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0095 - 76ms/epoch - 8ms/step\n",
      "Epoch 8/180\n",
      "10/10 - 0s - loss: 8.8650e-04 - val_loss: 0.0089 - 76ms/epoch - 8ms/step\n",
      "Epoch 9/180\n",
      "10/10 - 0s - loss: 7.5309e-04 - val_loss: 0.0085 - 88ms/epoch - 9ms/step\n",
      "Epoch 10/180\n",
      "10/10 - 0s - loss: 6.0837e-04 - val_loss: 0.0084 - 80ms/epoch - 8ms/step\n",
      "Epoch 11/180\n",
      "10/10 - 0s - loss: 4.8961e-04 - val_loss: 0.0082 - 77ms/epoch - 8ms/step\n",
      "Epoch 12/180\n",
      "10/10 - 0s - loss: 4.4181e-04 - val_loss: 0.0083 - 87ms/epoch - 9ms/step\n",
      "Epoch 13/180\n",
      "10/10 - 0s - loss: 3.8616e-04 - val_loss: 0.0084 - 75ms/epoch - 7ms/step\n",
      "Epoch 14/180\n",
      "10/10 - 0s - loss: 3.7046e-04 - val_loss: 0.0084 - 75ms/epoch - 7ms/step\n",
      "Epoch 15/180\n",
      "10/10 - 0s - loss: 3.8262e-04 - val_loss: 0.0084 - 84ms/epoch - 8ms/step\n",
      "Epoch 16/180\n",
      "10/10 - 0s - loss: 3.3453e-04 - val_loss: 0.0085 - 75ms/epoch - 7ms/step\n",
      "Epoch 17/180\n",
      "10/10 - 0s - loss: 3.3594e-04 - val_loss: 0.0084 - 75ms/epoch - 7ms/step\n",
      "Epoch 18/180\n",
      "10/10 - 0s - loss: 3.4437e-04 - val_loss: 0.0084 - 124ms/epoch - 12ms/step\n",
      "Epoch 19/180\n",
      "10/10 - 0s - loss: 3.1584e-04 - val_loss: 0.0084 - 80ms/epoch - 8ms/step\n",
      "Epoch 20/180\n",
      "10/10 - 0s - loss: 3.2585e-04 - val_loss: 0.0084 - 82ms/epoch - 8ms/step\n",
      "Epoch 21/180\n",
      "10/10 - 0s - loss: 2.9920e-04 - val_loss: 0.0084 - 110ms/epoch - 11ms/step\n",
      "Epoch 22/180\n",
      "10/10 - 0s - loss: 2.9385e-04 - val_loss: 0.0084 - 76ms/epoch - 8ms/step\n",
      "Epoch 23/180\n",
      "10/10 - 0s - loss: 3.0020e-04 - val_loss: 0.0084 - 75ms/epoch - 7ms/step\n",
      "Epoch 24/180\n",
      "10/10 - 0s - loss: 2.7603e-04 - val_loss: 0.0084 - 76ms/epoch - 8ms/step\n",
      "Epoch 25/180\n",
      "10/10 - 0s - loss: 2.8554e-04 - val_loss: 0.0084 - 92ms/epoch - 9ms/step\n",
      "Epoch 26/180\n",
      "10/10 - 0s - loss: 2.9739e-04 - val_loss: 0.0085 - 75ms/epoch - 8ms/step\n",
      "Epoch 27/180\n",
      "10/10 - 0s - loss: 2.7970e-04 - val_loss: 0.0085 - 77ms/epoch - 8ms/step\n",
      "Epoch 28/180\n",
      "10/10 - 0s - loss: 2.7185e-04 - val_loss: 0.0084 - 94ms/epoch - 9ms/step\n",
      "Epoch 29/180\n",
      "10/10 - 0s - loss: 2.8716e-04 - val_loss: 0.0083 - 79ms/epoch - 8ms/step\n",
      "Epoch 30/180\n",
      "10/10 - 0s - loss: 2.6617e-04 - val_loss: 0.0084 - 77ms/epoch - 8ms/step\n",
      "Epoch 31/180\n",
      "10/10 - 0s - loss: 2.5427e-04 - val_loss: 0.0085 - 80ms/epoch - 8ms/step\n",
      "Epoch 32/180\n",
      "10/10 - 0s - loss: 2.7089e-04 - val_loss: 0.0084 - 91ms/epoch - 9ms/step\n",
      "Epoch 33/180\n",
      "10/10 - 0s - loss: 2.7105e-04 - val_loss: 0.0084 - 93ms/epoch - 9ms/step\n",
      "Epoch 34/180\n",
      "10/10 - 0s - loss: 2.4399e-04 - val_loss: 0.0084 - 110ms/epoch - 11ms/step\n",
      "Epoch 35/180\n",
      "10/10 - 0s - loss: 2.4172e-04 - val_loss: 0.0084 - 92ms/epoch - 9ms/step\n",
      "Epoch 36/180\n",
      "10/10 - 0s - loss: 2.4623e-04 - val_loss: 0.0084 - 77ms/epoch - 8ms/step\n",
      "Epoch 37/180\n",
      "10/10 - 0s - loss: 2.4870e-04 - val_loss: 0.0084 - 77ms/epoch - 8ms/step\n",
      "Epoch 38/180\n",
      "10/10 - 0s - loss: 2.4704e-04 - val_loss: 0.0084 - 91ms/epoch - 9ms/step\n",
      "Epoch 39/180\n",
      "10/10 - 0s - loss: 2.4255e-04 - val_loss: 0.0084 - 75ms/epoch - 7ms/step\n",
      "Epoch 40/180\n",
      "10/10 - 0s - loss: 2.2224e-04 - val_loss: 0.0085 - 77ms/epoch - 8ms/step\n",
      "Epoch 41/180\n",
      "10/10 - 0s - loss: 2.3220e-04 - val_loss: 0.0084 - 95ms/epoch - 10ms/step\n",
      "Epoch 42/180\n",
      "10/10 - 0s - loss: 2.3302e-04 - val_loss: 0.0085 - 86ms/epoch - 9ms/step\n",
      "Epoch 43/180\n",
      "10/10 - 0s - loss: 2.3538e-04 - val_loss: 0.0084 - 76ms/epoch - 8ms/step\n",
      "Epoch 44/180\n",
      "10/10 - 0s - loss: 2.1951e-04 - val_loss: 0.0084 - 77ms/epoch - 8ms/step\n",
      "Epoch 45/180\n",
      "10/10 - 0s - loss: 2.2317e-04 - val_loss: 0.0085 - 89ms/epoch - 9ms/step\n",
      "Epoch 46/180\n",
      "10/10 - 0s - loss: 2.1873e-04 - val_loss: 0.0085 - 80ms/epoch - 8ms/step\n",
      "Epoch 47/180\n",
      "10/10 - 0s - loss: 2.1785e-04 - val_loss: 0.0085 - 75ms/epoch - 8ms/step\n",
      "Epoch 48/180\n",
      "10/10 - 0s - loss: 2.0885e-04 - val_loss: 0.0086 - 117ms/epoch - 12ms/step\n",
      "Epoch 49/180\n",
      "10/10 - 0s - loss: 2.1671e-04 - val_loss: 0.0085 - 78ms/epoch - 8ms/step\n",
      "Epoch 50/180\n",
      "10/10 - 0s - loss: 2.5414e-04 - val_loss: 0.0085 - 77ms/epoch - 8ms/step\n",
      "Epoch 51/180\n",
      "10/10 - 0s - loss: 2.1616e-04 - val_loss: 0.0086 - 91ms/epoch - 9ms/step\n",
      "Epoch 52/180\n",
      "10/10 - 0s - loss: 1.9760e-04 - val_loss: 0.0086 - 77ms/epoch - 8ms/step\n",
      "Epoch 53/180\n",
      "10/10 - 0s - loss: 2.1545e-04 - val_loss: 0.0087 - 82ms/epoch - 8ms/step\n",
      "Epoch 54/180\n",
      "10/10 - 0s - loss: 2.0867e-04 - val_loss: 0.0086 - 91ms/epoch - 9ms/step\n",
      "Epoch 55/180\n",
      "10/10 - 0s - loss: 1.9950e-04 - val_loss: 0.0086 - 77ms/epoch - 8ms/step\n",
      "Epoch 56/180\n",
      "10/10 - 0s - loss: 1.8563e-04 - val_loss: 0.0087 - 91ms/epoch - 9ms/step\n",
      "Epoch 57/180\n",
      "10/10 - 0s - loss: 1.8957e-04 - val_loss: 0.0086 - 94ms/epoch - 9ms/step\n",
      "Epoch 58/180\n",
      "10/10 - 0s - loss: 1.9204e-04 - val_loss: 0.0088 - 79ms/epoch - 8ms/step\n",
      "Epoch 59/180\n",
      "10/10 - 0s - loss: 2.2445e-04 - val_loss: 0.0086 - 76ms/epoch - 8ms/step\n",
      "Epoch 60/180\n",
      "10/10 - 0s - loss: 1.9035e-04 - val_loss: 0.0087 - 91ms/epoch - 9ms/step\n",
      "Epoch 61/180\n",
      "10/10 - 0s - loss: 1.8595e-04 - val_loss: 0.0088 - 80ms/epoch - 8ms/step\n",
      "Epoch 62/180\n",
      "10/10 - 0s - loss: 1.8574e-04 - val_loss: 0.0089 - 78ms/epoch - 8ms/step\n",
      "Epoch 63/180\n",
      "10/10 - 0s - loss: 2.2436e-04 - val_loss: 0.0087 - 93ms/epoch - 9ms/step\n",
      "Epoch 64/180\n",
      "10/10 - 0s - loss: 2.0663e-04 - val_loss: 0.0088 - 109ms/epoch - 11ms/step\n",
      "Epoch 65/180\n",
      "10/10 - 0s - loss: 1.9329e-04 - val_loss: 0.0088 - 87ms/epoch - 9ms/step\n",
      "Epoch 66/180\n",
      "10/10 - 0s - loss: 1.9310e-04 - val_loss: 0.0088 - 97ms/epoch - 10ms/step\n",
      "Epoch 67/180\n",
      "10/10 - 0s - loss: 1.8949e-04 - val_loss: 0.0089 - 80ms/epoch - 8ms/step\n",
      "Epoch 68/180\n",
      "10/10 - 0s - loss: 1.7804e-04 - val_loss: 0.0089 - 77ms/epoch - 8ms/step\n",
      "Epoch 69/180\n",
      "10/10 - 0s - loss: 1.7429e-04 - val_loss: 0.0089 - 90ms/epoch - 9ms/step\n",
      "Epoch 70/180\n",
      "10/10 - 0s - loss: 1.8095e-04 - val_loss: 0.0089 - 79ms/epoch - 8ms/step\n",
      "Epoch 71/180\n",
      "10/10 - 0s - loss: 1.8821e-04 - val_loss: 0.0090 - 80ms/epoch - 8ms/step\n",
      "Epoch 72/180\n",
      "10/10 - 0s - loss: 2.1280e-04 - val_loss: 0.0089 - 93ms/epoch - 9ms/step\n",
      "Epoch 73/180\n",
      "10/10 - 0s - loss: 2.2024e-04 - val_loss: 0.0091 - 76ms/epoch - 8ms/step\n",
      "Epoch 74/180\n",
      "10/10 - 0s - loss: 1.9726e-04 - val_loss: 0.0090 - 78ms/epoch - 8ms/step\n",
      "Epoch 75/180\n",
      "10/10 - 0s - loss: 1.7957e-04 - val_loss: 0.0089 - 88ms/epoch - 9ms/step\n",
      "Epoch 76/180\n",
      "10/10 - 0s - loss: 1.8250e-04 - val_loss: 0.0091 - 78ms/epoch - 8ms/step\n",
      "Epoch 77/180\n",
      "10/10 - 0s - loss: 1.9113e-04 - val_loss: 0.0090 - 99ms/epoch - 10ms/step\n",
      "Epoch 78/180\n",
      "10/10 - 0s - loss: 1.7591e-04 - val_loss: 0.0090 - 88ms/epoch - 9ms/step\n",
      "Epoch 79/180\n",
      "10/10 - 0s - loss: 1.7320e-04 - val_loss: 0.0091 - 74ms/epoch - 7ms/step\n",
      "Epoch 80/180\n",
      "10/10 - 0s - loss: 1.7447e-04 - val_loss: 0.0091 - 74ms/epoch - 7ms/step\n",
      "Epoch 81/180\n",
      "10/10 - 0s - loss: 1.8101e-04 - val_loss: 0.0091 - 83ms/epoch - 8ms/step\n",
      "Epoch 82/180\n",
      "10/10 - 0s - loss: 1.7687e-04 - val_loss: 0.0090 - 74ms/epoch - 7ms/step\n",
      "Epoch 83/180\n",
      "10/10 - 0s - loss: 1.7869e-04 - val_loss: 0.0091 - 77ms/epoch - 8ms/step\n",
      "Epoch 84/180\n",
      "10/10 - 0s - loss: 1.7568e-04 - val_loss: 0.0091 - 92ms/epoch - 9ms/step\n",
      "Epoch 85/180\n",
      "10/10 - 0s - loss: 1.7418e-04 - val_loss: 0.0091 - 73ms/epoch - 7ms/step\n",
      "Epoch 86/180\n",
      "10/10 - 0s - loss: 1.8271e-04 - val_loss: 0.0093 - 79ms/epoch - 8ms/step\n",
      "Epoch 87/180\n",
      "10/10 - 0s - loss: 1.9131e-04 - val_loss: 0.0091 - 89ms/epoch - 9ms/step\n",
      "Epoch 88/180\n",
      "10/10 - 0s - loss: 2.0127e-04 - val_loss: 0.0092 - 75ms/epoch - 7ms/step\n",
      "Epoch 89/180\n",
      "10/10 - 0s - loss: 2.0530e-04 - val_loss: 0.0091 - 76ms/epoch - 8ms/step\n",
      "Epoch 90/180\n",
      "10/10 - 0s - loss: 2.0817e-04 - val_loss: 0.0091 - 99ms/epoch - 10ms/step\n",
      "Epoch 91/180\n",
      "10/10 - 0s - loss: 2.2824e-04 - val_loss: 0.0092 - 80ms/epoch - 8ms/step\n",
      "Epoch 92/180\n",
      "10/10 - 0s - loss: 1.8203e-04 - val_loss: 0.0092 - 79ms/epoch - 8ms/step\n",
      "Epoch 93/180\n",
      "10/10 - 0s - loss: 1.8736e-04 - val_loss: 0.0091 - 133ms/epoch - 13ms/step\n",
      "Epoch 94/180\n",
      "10/10 - 0s - loss: 1.7717e-04 - val_loss: 0.0092 - 81ms/epoch - 8ms/step\n",
      "Epoch 95/180\n",
      "10/10 - 0s - loss: 1.7241e-04 - val_loss: 0.0092 - 77ms/epoch - 8ms/step\n",
      "Epoch 96/180\n",
      "10/10 - 0s - loss: 1.6430e-04 - val_loss: 0.0092 - 95ms/epoch - 9ms/step\n",
      "Epoch 97/180\n",
      "10/10 - 0s - loss: 1.7549e-04 - val_loss: 0.0091 - 82ms/epoch - 8ms/step\n",
      "Epoch 98/180\n",
      "10/10 - 0s - loss: 1.7920e-04 - val_loss: 0.0093 - 87ms/epoch - 9ms/step\n",
      "Epoch 99/180\n",
      "10/10 - 0s - loss: 1.7782e-04 - val_loss: 0.0093 - 94ms/epoch - 9ms/step\n",
      "Epoch 100/180\n",
      "10/10 - 0s - loss: 2.1005e-04 - val_loss: 0.0095 - 77ms/epoch - 8ms/step\n",
      "Epoch 101/180\n",
      "10/10 - 0s - loss: 2.5183e-04 - val_loss: 0.0091 - 80ms/epoch - 8ms/step\n",
      "Epoch 102/180\n",
      "10/10 - 0s - loss: 2.5017e-04 - val_loss: 0.0091 - 90ms/epoch - 9ms/step\n",
      "Epoch 103/180\n",
      "10/10 - 0s - loss: 2.0767e-04 - val_loss: 0.0093 - 79ms/epoch - 8ms/step\n",
      "Epoch 104/180\n",
      "10/10 - 0s - loss: 2.1864e-04 - val_loss: 0.0091 - 96ms/epoch - 10ms/step\n",
      "Epoch 105/180\n",
      "10/10 - 0s - loss: 1.8896e-04 - val_loss: 0.0092 - 103ms/epoch - 10ms/step\n",
      "Epoch 106/180\n",
      "10/10 - 0s - loss: 1.7342e-04 - val_loss: 0.0092 - 81ms/epoch - 8ms/step\n",
      "Epoch 107/180\n",
      "10/10 - 0s - loss: 1.7310e-04 - val_loss: 0.0091 - 77ms/epoch - 8ms/step\n",
      "Epoch 108/180\n",
      "10/10 - 0s - loss: 1.7930e-04 - val_loss: 0.0092 - 107ms/epoch - 11ms/step\n",
      "Epoch 109/180\n",
      "10/10 - 0s - loss: 1.8556e-04 - val_loss: 0.0093 - 81ms/epoch - 8ms/step\n",
      "Epoch 110/180\n",
      "10/10 - 0s - loss: 1.9259e-04 - val_loss: 0.0092 - 76ms/epoch - 8ms/step\n",
      "Epoch 111/180\n",
      "10/10 - 0s - loss: 2.1080e-04 - val_loss: 0.0091 - 86ms/epoch - 9ms/step\n",
      "Epoch 112/180\n",
      "10/10 - 0s - loss: 1.8622e-04 - val_loss: 0.0093 - 78ms/epoch - 8ms/step\n",
      "Epoch 113/180\n",
      "10/10 - 0s - loss: 1.8997e-04 - val_loss: 0.0092 - 75ms/epoch - 7ms/step\n",
      "Epoch 114/180\n",
      "10/10 - 0s - loss: 2.1398e-04 - val_loss: 0.0092 - 83ms/epoch - 8ms/step\n",
      "Epoch 115/180\n",
      "10/10 - 0s - loss: 2.1353e-04 - val_loss: 0.0092 - 74ms/epoch - 7ms/step\n",
      "Epoch 116/180\n",
      "10/10 - 0s - loss: 1.8908e-04 - val_loss: 0.0094 - 81ms/epoch - 8ms/step\n",
      "Epoch 117/180\n",
      "10/10 - 0s - loss: 1.9702e-04 - val_loss: 0.0092 - 83ms/epoch - 8ms/step\n",
      "Epoch 118/180\n",
      "10/10 - 0s - loss: 1.8395e-04 - val_loss: 0.0091 - 75ms/epoch - 8ms/step\n",
      "Epoch 119/180\n",
      "10/10 - 0s - loss: 2.0618e-04 - val_loss: 0.0094 - 102ms/epoch - 10ms/step\n",
      "Epoch 120/180\n",
      "10/10 - 0s - loss: 1.8052e-04 - val_loss: 0.0094 - 88ms/epoch - 9ms/step\n",
      "Epoch 121/180\n",
      "10/10 - 0s - loss: 1.9830e-04 - val_loss: 0.0092 - 79ms/epoch - 8ms/step\n",
      "Epoch 122/180\n",
      "10/10 - 0s - loss: 2.0110e-04 - val_loss: 0.0092 - 78ms/epoch - 8ms/step\n",
      "Epoch 123/180\n",
      "10/10 - 0s - loss: 1.6946e-04 - val_loss: 0.0093 - 89ms/epoch - 9ms/step\n",
      "Epoch 124/180\n",
      "10/10 - 0s - loss: 1.7154e-04 - val_loss: 0.0094 - 78ms/epoch - 8ms/step\n",
      "Epoch 125/180\n",
      "10/10 - 0s - loss: 1.6741e-04 - val_loss: 0.0093 - 78ms/epoch - 8ms/step\n",
      "Epoch 126/180\n",
      "10/10 - 0s - loss: 1.7144e-04 - val_loss: 0.0092 - 88ms/epoch - 9ms/step\n",
      "Epoch 127/180\n",
      "10/10 - 0s - loss: 1.8188e-04 - val_loss: 0.0095 - 76ms/epoch - 8ms/step\n",
      "Epoch 128/180\n",
      "10/10 - 0s - loss: 1.5941e-04 - val_loss: 0.0094 - 82ms/epoch - 8ms/step\n",
      "Epoch 129/180\n",
      "10/10 - 0s - loss: 1.6694e-04 - val_loss: 0.0094 - 91ms/epoch - 9ms/step\n",
      "Epoch 130/180\n",
      "10/10 - 0s - loss: 1.6478e-04 - val_loss: 0.0095 - 76ms/epoch - 8ms/step\n",
      "Epoch 131/180\n",
      "10/10 - 0s - loss: 1.7787e-04 - val_loss: 0.0095 - 109ms/epoch - 11ms/step\n",
      "Epoch 132/180\n",
      "10/10 - 0s - loss: 1.7529e-04 - val_loss: 0.0094 - 104ms/epoch - 10ms/step\n",
      "Epoch 133/180\n",
      "10/10 - 0s - loss: 1.8580e-04 - val_loss: 0.0095 - 77ms/epoch - 8ms/step\n",
      "Epoch 134/180\n",
      "10/10 - 0s - loss: 1.7811e-04 - val_loss: 0.0095 - 77ms/epoch - 8ms/step\n",
      "Epoch 135/180\n",
      "10/10 - 0s - loss: 1.8932e-04 - val_loss: 0.0095 - 93ms/epoch - 9ms/step\n",
      "Epoch 136/180\n",
      "10/10 - 0s - loss: 1.7461e-04 - val_loss: 0.0096 - 77ms/epoch - 8ms/step\n",
      "Epoch 137/180\n",
      "10/10 - 0s - loss: 1.6927e-04 - val_loss: 0.0096 - 77ms/epoch - 8ms/step\n",
      "Epoch 138/180\n",
      "10/10 - 0s - loss: 1.6487e-04 - val_loss: 0.0095 - 91ms/epoch - 9ms/step\n",
      "Epoch 139/180\n",
      "10/10 - 0s - loss: 1.8597e-04 - val_loss: 0.0096 - 93ms/epoch - 9ms/step\n",
      "Epoch 140/180\n",
      "10/10 - 0s - loss: 1.9339e-04 - val_loss: 0.0096 - 79ms/epoch - 8ms/step\n",
      "Epoch 141/180\n",
      "10/10 - 0s - loss: 2.0890e-04 - val_loss: 0.0094 - 88ms/epoch - 9ms/step\n",
      "Epoch 142/180\n",
      "10/10 - 0s - loss: 1.7915e-04 - val_loss: 0.0096 - 110ms/epoch - 11ms/step\n",
      "Epoch 143/180\n",
      "10/10 - 0s - loss: 1.7888e-04 - val_loss: 0.0097 - 83ms/epoch - 8ms/step\n",
      "Epoch 144/180\n",
      "10/10 - 0s - loss: 1.9553e-04 - val_loss: 0.0094 - 90ms/epoch - 9ms/step\n",
      "Epoch 145/180\n",
      "10/10 - 0s - loss: 2.1146e-04 - val_loss: 0.0094 - 80ms/epoch - 8ms/step\n",
      "Epoch 146/180\n",
      "10/10 - 0s - loss: 1.8913e-04 - val_loss: 0.0096 - 77ms/epoch - 8ms/step\n",
      "Epoch 147/180\n",
      "10/10 - 0s - loss: 1.6459e-04 - val_loss: 0.0095 - 87ms/epoch - 9ms/step\n",
      "Epoch 148/180\n",
      "10/10 - 0s - loss: 1.6851e-04 - val_loss: 0.0097 - 83ms/epoch - 8ms/step\n",
      "Epoch 149/180\n",
      "10/10 - 0s - loss: 1.9262e-04 - val_loss: 0.0095 - 81ms/epoch - 8ms/step\n",
      "Epoch 150/180\n",
      "10/10 - 0s - loss: 1.7316e-04 - val_loss: 0.0095 - 85ms/epoch - 8ms/step\n",
      "Epoch 151/180\n",
      "10/10 - 0s - loss: 1.9973e-04 - val_loss: 0.0096 - 73ms/epoch - 7ms/step\n",
      "Epoch 152/180\n",
      "10/10 - 0s - loss: 1.9858e-04 - val_loss: 0.0098 - 76ms/epoch - 8ms/step\n",
      "Epoch 153/180\n",
      "10/10 - 0s - loss: 2.0020e-04 - val_loss: 0.0094 - 132ms/epoch - 13ms/step\n",
      "Epoch 154/180\n",
      "10/10 - 0s - loss: 1.7028e-04 - val_loss: 0.0097 - 81ms/epoch - 8ms/step\n",
      "Epoch 155/180\n",
      "10/10 - 0s - loss: 1.6266e-04 - val_loss: 0.0098 - 85ms/epoch - 8ms/step\n",
      "Epoch 156/180\n",
      "10/10 - 0s - loss: 1.7731e-04 - val_loss: 0.0095 - 92ms/epoch - 9ms/step\n",
      "Epoch 157/180\n",
      "10/10 - 0s - loss: 1.7687e-04 - val_loss: 0.0097 - 78ms/epoch - 8ms/step\n",
      "Epoch 158/180\n",
      "10/10 - 0s - loss: 2.0444e-04 - val_loss: 0.0094 - 77ms/epoch - 8ms/step\n",
      "Epoch 159/180\n",
      "10/10 - 0s - loss: 1.7128e-04 - val_loss: 0.0096 - 91ms/epoch - 9ms/step\n",
      "Epoch 160/180\n",
      "10/10 - 0s - loss: 1.7822e-04 - val_loss: 0.0099 - 78ms/epoch - 8ms/step\n",
      "Epoch 161/180\n",
      "10/10 - 0s - loss: 1.7321e-04 - val_loss: 0.0095 - 81ms/epoch - 8ms/step\n",
      "Epoch 162/180\n",
      "10/10 - 0s - loss: 1.6232e-04 - val_loss: 0.0097 - 90ms/epoch - 9ms/step\n",
      "Epoch 163/180\n",
      "10/10 - 0s - loss: 1.5955e-04 - val_loss: 0.0098 - 79ms/epoch - 8ms/step\n",
      "Epoch 164/180\n",
      "10/10 - 0s - loss: 1.5997e-04 - val_loss: 0.0098 - 92ms/epoch - 9ms/step\n",
      "Epoch 165/180\n",
      "10/10 - 0s - loss: 1.6983e-04 - val_loss: 0.0097 - 95ms/epoch - 9ms/step\n",
      "Epoch 166/180\n",
      "10/10 - 0s - loss: 1.6076e-04 - val_loss: 0.0098 - 77ms/epoch - 8ms/step\n",
      "Epoch 167/180\n",
      "10/10 - 0s - loss: 1.9235e-04 - val_loss: 0.0099 - 113ms/epoch - 11ms/step\n",
      "Epoch 168/180\n",
      "10/10 - 0s - loss: 1.8200e-04 - val_loss: 0.0097 - 92ms/epoch - 9ms/step\n",
      "Epoch 169/180\n",
      "10/10 - 0s - loss: 1.8873e-04 - val_loss: 0.0096 - 77ms/epoch - 8ms/step\n",
      "Epoch 170/180\n",
      "10/10 - 0s - loss: 1.7004e-04 - val_loss: 0.0098 - 77ms/epoch - 8ms/step\n",
      "Epoch 171/180\n",
      "10/10 - 0s - loss: 1.7107e-04 - val_loss: 0.0098 - 88ms/epoch - 9ms/step\n",
      "Epoch 172/180\n",
      "10/10 - 0s - loss: 1.7481e-04 - val_loss: 0.0099 - 80ms/epoch - 8ms/step\n",
      "Epoch 173/180\n",
      "10/10 - 0s - loss: 1.9291e-04 - val_loss: 0.0098 - 81ms/epoch - 8ms/step\n",
      "Epoch 174/180\n",
      "10/10 - 0s - loss: 1.9232e-04 - val_loss: 0.0097 - 97ms/epoch - 10ms/step\n",
      "Epoch 175/180\n",
      "10/10 - 0s - loss: 1.7716e-04 - val_loss: 0.0097 - 78ms/epoch - 8ms/step\n",
      "Epoch 176/180\n",
      "10/10 - 0s - loss: 1.8007e-04 - val_loss: 0.0097 - 77ms/epoch - 8ms/step\n",
      "Epoch 177/180\n",
      "10/10 - 0s - loss: 1.7022e-04 - val_loss: 0.0098 - 93ms/epoch - 9ms/step\n",
      "Epoch 178/180\n",
      "10/10 - 0s - loss: 1.7307e-04 - val_loss: 0.0097 - 105ms/epoch - 10ms/step\n",
      "Epoch 179/180\n",
      "10/10 - 0s - loss: 1.7281e-04 - val_loss: 0.0099 - 78ms/epoch - 8ms/step\n",
      "Epoch 180/180\n",
      "10/10 - 0s - loss: 1.6286e-04 - val_loss: 0.0097 - 89ms/epoch - 9ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m-176.7   \u001b[0m | \u001b[0m181.0    \u001b[0m | \u001b[0m1.17     \u001b[0m | \u001b[0m0.00452  \u001b[0m | \u001b[0m87.43    \u001b[0m |\n",
      "Model: \"sequential_155\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_568 (LSTM)             (None, 1, 121)            61468     \n",
      "                                                                 \n",
      " dropout_413 (Dropout)       (None, 1, 121)            0         \n",
      "                                                                 \n",
      " lstm_569 (LSTM)             (None, 1, 121)            117612    \n",
      "                                                                 \n",
      " dropout_414 (Dropout)       (None, 1, 121)            0         \n",
      "                                                                 \n",
      " lstm_570 (LSTM)             (None, 1, 121)            117612    \n",
      "                                                                 \n",
      " dropout_415 (Dropout)       (None, 1, 121)            0         \n",
      "                                                                 \n",
      " lstm_571 (LSTM)             (None, 1, 121)            117612    \n",
      "                                                                 \n",
      " dropout_416 (Dropout)       (None, 1, 121)            0         \n",
      "                                                                 \n",
      " lstm_572 (LSTM)             (None, 1, 121)            117612    \n",
      "                                                                 \n",
      " dropout_417 (Dropout)       (None, 1, 121)            0         \n",
      "                                                                 \n",
      " lstm_573 (LSTM)             (None, 121)               117612    \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 1)                 122       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 649,650\n",
      "Trainable params: 649,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/83\n",
      "10/10 - 13s - loss: 0.0223 - val_loss: 0.0174 - 13s/epoch - 1s/step\n",
      "Epoch 2/83\n",
      "10/10 - 0s - loss: 0.0036 - val_loss: 0.0168 - 182ms/epoch - 18ms/step\n",
      "Epoch 3/83\n",
      "10/10 - 0s - loss: 0.0032 - val_loss: 0.0170 - 197ms/epoch - 20ms/step\n",
      "Epoch 4/83\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0167 - 196ms/epoch - 20ms/step\n",
      "Epoch 5/83\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0159 - 186ms/epoch - 19ms/step\n",
      "Epoch 6/83\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0104 - 188ms/epoch - 19ms/step\n",
      "Epoch 7/83\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0086 - 185ms/epoch - 18ms/step\n",
      "Epoch 8/83\n",
      "10/10 - 0s - loss: 6.8262e-04 - val_loss: 0.0087 - 185ms/epoch - 18ms/step\n",
      "Epoch 9/83\n",
      "10/10 - 0s - loss: 6.8948e-04 - val_loss: 0.0084 - 198ms/epoch - 20ms/step\n",
      "Epoch 10/83\n",
      "10/10 - 0s - loss: 5.4656e-04 - val_loss: 0.0079 - 186ms/epoch - 19ms/step\n",
      "Epoch 11/83\n",
      "10/10 - 0s - loss: 3.9307e-04 - val_loss: 0.0080 - 182ms/epoch - 18ms/step\n",
      "Epoch 12/83\n",
      "10/10 - 0s - loss: 3.6557e-04 - val_loss: 0.0079 - 201ms/epoch - 20ms/step\n",
      "Epoch 13/83\n",
      "10/10 - 0s - loss: 3.1155e-04 - val_loss: 0.0079 - 207ms/epoch - 21ms/step\n",
      "Epoch 14/83\n",
      "10/10 - 0s - loss: 3.2028e-04 - val_loss: 0.0078 - 187ms/epoch - 19ms/step\n",
      "Epoch 15/83\n",
      "10/10 - 0s - loss: 3.0254e-04 - val_loss: 0.0080 - 194ms/epoch - 19ms/step\n",
      "Epoch 16/83\n",
      "10/10 - 0s - loss: 2.8536e-04 - val_loss: 0.0080 - 180ms/epoch - 18ms/step\n",
      "Epoch 17/83\n",
      "10/10 - 0s - loss: 2.7485e-04 - val_loss: 0.0079 - 192ms/epoch - 19ms/step\n",
      "Epoch 18/83\n",
      "10/10 - 0s - loss: 2.7719e-04 - val_loss: 0.0079 - 216ms/epoch - 22ms/step\n",
      "Epoch 19/83\n",
      "10/10 - 0s - loss: 2.6189e-04 - val_loss: 0.0081 - 195ms/epoch - 19ms/step\n",
      "Epoch 20/83\n",
      "10/10 - 0s - loss: 3.0552e-04 - val_loss: 0.0079 - 194ms/epoch - 19ms/step\n",
      "Epoch 21/83\n",
      "10/10 - 0s - loss: 2.9865e-04 - val_loss: 0.0079 - 209ms/epoch - 21ms/step\n",
      "Epoch 22/83\n",
      "10/10 - 0s - loss: 3.0233e-04 - val_loss: 0.0081 - 198ms/epoch - 20ms/step\n",
      "Epoch 23/83\n",
      "10/10 - 0s - loss: 3.2362e-04 - val_loss: 0.0079 - 196ms/epoch - 20ms/step\n",
      "Epoch 24/83\n",
      "10/10 - 0s - loss: 3.0686e-04 - val_loss: 0.0079 - 195ms/epoch - 19ms/step\n",
      "Epoch 25/83\n",
      "10/10 - 0s - loss: 2.7310e-04 - val_loss: 0.0078 - 178ms/epoch - 18ms/step\n",
      "Epoch 26/83\n",
      "10/10 - 0s - loss: 3.4149e-04 - val_loss: 0.0079 - 182ms/epoch - 18ms/step\n",
      "Epoch 27/83\n",
      "10/10 - 0s - loss: 2.9686e-04 - val_loss: 0.0081 - 197ms/epoch - 20ms/step\n",
      "Epoch 28/83\n",
      "10/10 - 0s - loss: 2.6379e-04 - val_loss: 0.0080 - 208ms/epoch - 21ms/step\n",
      "Epoch 29/83\n",
      "10/10 - 0s - loss: 2.6561e-04 - val_loss: 0.0082 - 179ms/epoch - 18ms/step\n",
      "Epoch 30/83\n",
      "10/10 - 0s - loss: 2.9733e-04 - val_loss: 0.0079 - 197ms/epoch - 20ms/step\n",
      "Epoch 31/83\n",
      "10/10 - 0s - loss: 3.3772e-04 - val_loss: 0.0083 - 183ms/epoch - 18ms/step\n",
      "Epoch 32/83\n",
      "10/10 - 0s - loss: 2.5606e-04 - val_loss: 0.0081 - 189ms/epoch - 19ms/step\n",
      "Epoch 33/83\n",
      "10/10 - 0s - loss: 2.7233e-04 - val_loss: 0.0086 - 198ms/epoch - 20ms/step\n",
      "Epoch 34/83\n",
      "10/10 - 0s - loss: 2.9371e-04 - val_loss: 0.0084 - 183ms/epoch - 18ms/step\n",
      "Epoch 35/83\n",
      "10/10 - 0s - loss: 2.6197e-04 - val_loss: 0.0084 - 180ms/epoch - 18ms/step\n",
      "Epoch 36/83\n",
      "10/10 - 0s - loss: 2.6684e-04 - val_loss: 0.0085 - 215ms/epoch - 21ms/step\n",
      "Epoch 37/83\n",
      "10/10 - 0s - loss: 2.6201e-04 - val_loss: 0.0081 - 183ms/epoch - 18ms/step\n",
      "Epoch 38/83\n",
      "10/10 - 0s - loss: 2.7425e-04 - val_loss: 0.0082 - 189ms/epoch - 19ms/step\n",
      "Epoch 39/83\n",
      "10/10 - 0s - loss: 3.4159e-04 - val_loss: 0.0097 - 200ms/epoch - 20ms/step\n",
      "Epoch 40/83\n",
      "10/10 - 0s - loss: 3.2802e-04 - val_loss: 0.0090 - 201ms/epoch - 20ms/step\n",
      "Epoch 41/83\n",
      "10/10 - 0s - loss: 2.8457e-04 - val_loss: 0.0086 - 222ms/epoch - 22ms/step\n",
      "Epoch 42/83\n",
      "10/10 - 0s - loss: 2.7292e-04 - val_loss: 0.0086 - 185ms/epoch - 18ms/step\n",
      "Epoch 43/83\n",
      "10/10 - 0s - loss: 2.4928e-04 - val_loss: 0.0094 - 228ms/epoch - 23ms/step\n",
      "Epoch 44/83\n",
      "10/10 - 0s - loss: 2.8872e-04 - val_loss: 0.0093 - 191ms/epoch - 19ms/step\n",
      "Epoch 45/83\n",
      "10/10 - 0s - loss: 3.6118e-04 - val_loss: 0.0100 - 192ms/epoch - 19ms/step\n",
      "Epoch 46/83\n",
      "10/10 - 0s - loss: 3.1646e-04 - val_loss: 0.0098 - 208ms/epoch - 21ms/step\n",
      "Epoch 47/83\n",
      "10/10 - 0s - loss: 2.8476e-04 - val_loss: 0.0101 - 186ms/epoch - 19ms/step\n",
      "Epoch 48/83\n",
      "10/10 - 0s - loss: 2.9541e-04 - val_loss: 0.0105 - 194ms/epoch - 19ms/step\n",
      "Epoch 49/83\n",
      "10/10 - 0s - loss: 3.1881e-04 - val_loss: 0.0106 - 203ms/epoch - 20ms/step\n",
      "Epoch 50/83\n",
      "10/10 - 0s - loss: 2.6461e-04 - val_loss: 0.0105 - 184ms/epoch - 18ms/step\n",
      "Epoch 51/83\n",
      "10/10 - 0s - loss: 2.4322e-04 - val_loss: 0.0107 - 191ms/epoch - 19ms/step\n",
      "Epoch 52/83\n",
      "10/10 - 0s - loss: 2.4765e-04 - val_loss: 0.0112 - 187ms/epoch - 19ms/step\n",
      "Epoch 53/83\n",
      "10/10 - 0s - loss: 2.6458e-04 - val_loss: 0.0114 - 229ms/epoch - 23ms/step\n",
      "Epoch 54/83\n",
      "10/10 - 0s - loss: 2.4257e-04 - val_loss: 0.0119 - 195ms/epoch - 19ms/step\n",
      "Epoch 55/83\n",
      "10/10 - 0s - loss: 2.5414e-04 - val_loss: 0.0112 - 203ms/epoch - 20ms/step\n",
      "Epoch 56/83\n",
      "10/10 - 0s - loss: 2.4519e-04 - val_loss: 0.0114 - 205ms/epoch - 20ms/step\n",
      "Epoch 57/83\n",
      "10/10 - 0s - loss: 2.8593e-04 - val_loss: 0.0115 - 189ms/epoch - 19ms/step\n",
      "Epoch 58/83\n",
      "10/10 - 0s - loss: 2.6123e-04 - val_loss: 0.0120 - 189ms/epoch - 19ms/step\n",
      "Epoch 59/83\n",
      "10/10 - 0s - loss: 2.3575e-04 - val_loss: 0.0122 - 206ms/epoch - 21ms/step\n",
      "Epoch 60/83\n",
      "10/10 - 0s - loss: 2.3097e-04 - val_loss: 0.0123 - 183ms/epoch - 18ms/step\n",
      "Epoch 61/83\n",
      "10/10 - 0s - loss: 2.4465e-04 - val_loss: 0.0119 - 200ms/epoch - 20ms/step\n",
      "Epoch 62/83\n",
      "10/10 - 0s - loss: 2.4546e-04 - val_loss: 0.0122 - 186ms/epoch - 19ms/step\n",
      "Epoch 63/83\n",
      "10/10 - 0s - loss: 2.2071e-04 - val_loss: 0.0123 - 204ms/epoch - 20ms/step\n",
      "Epoch 64/83\n",
      "10/10 - 0s - loss: 2.6075e-04 - val_loss: 0.0123 - 193ms/epoch - 19ms/step\n",
      "Epoch 65/83\n",
      "10/10 - 0s - loss: 2.5685e-04 - val_loss: 0.0123 - 201ms/epoch - 20ms/step\n",
      "Epoch 66/83\n",
      "10/10 - 0s - loss: 2.5959e-04 - val_loss: 0.0125 - 209ms/epoch - 21ms/step\n",
      "Epoch 67/83\n",
      "10/10 - 0s - loss: 2.3067e-04 - val_loss: 0.0122 - 194ms/epoch - 19ms/step\n",
      "Epoch 68/83\n",
      "10/10 - 0s - loss: 2.4776e-04 - val_loss: 0.0124 - 197ms/epoch - 20ms/step\n",
      "Epoch 69/83\n",
      "10/10 - 0s - loss: 2.2102e-04 - val_loss: 0.0128 - 190ms/epoch - 19ms/step\n",
      "Epoch 70/83\n",
      "10/10 - 0s - loss: 2.3981e-04 - val_loss: 0.0125 - 190ms/epoch - 19ms/step\n",
      "Epoch 71/83\n",
      "10/10 - 0s - loss: 2.3772e-04 - val_loss: 0.0127 - 184ms/epoch - 18ms/step\n",
      "Epoch 72/83\n",
      "10/10 - 0s - loss: 2.3896e-04 - val_loss: 0.0127 - 198ms/epoch - 20ms/step\n",
      "Epoch 73/83\n",
      "10/10 - 0s - loss: 2.3071e-04 - val_loss: 0.0128 - 179ms/epoch - 18ms/step\n",
      "Epoch 74/83\n",
      "10/10 - 0s - loss: 2.5268e-04 - val_loss: 0.0128 - 181ms/epoch - 18ms/step\n",
      "Epoch 75/83\n",
      "10/10 - 0s - loss: 2.6205e-04 - val_loss: 0.0126 - 199ms/epoch - 20ms/step\n",
      "Epoch 76/83\n",
      "10/10 - 0s - loss: 2.6267e-04 - val_loss: 0.0127 - 191ms/epoch - 19ms/step\n",
      "Epoch 77/83\n",
      "10/10 - 0s - loss: 2.2581e-04 - val_loss: 0.0128 - 193ms/epoch - 19ms/step\n",
      "Epoch 78/83\n",
      "10/10 - 0s - loss: 2.3970e-04 - val_loss: 0.0127 - 231ms/epoch - 23ms/step\n",
      "Epoch 79/83\n",
      "10/10 - 0s - loss: 2.7743e-04 - val_loss: 0.0130 - 207ms/epoch - 21ms/step\n",
      "Epoch 80/83\n",
      "10/10 - 0s - loss: 2.4303e-04 - val_loss: 0.0126 - 201ms/epoch - 20ms/step\n",
      "Epoch 81/83\n",
      "10/10 - 0s - loss: 2.3551e-04 - val_loss: 0.0131 - 191ms/epoch - 19ms/step\n",
      "Epoch 82/83\n",
      "10/10 - 0s - loss: 2.2832e-04 - val_loss: 0.0128 - 205ms/epoch - 20ms/step\n",
      "Epoch 83/83\n",
      "10/10 - 0s - loss: 2.4122e-04 - val_loss: 0.0132 - 182ms/epoch - 18ms/step\n",
      "9/9 [==============================] - 1s 3ms/step\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m-206.1   \u001b[0m | \u001b[0m83.84    \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m0.006808 \u001b[0m | \u001b[0m121.4    \u001b[0m |\n",
      "Model: \"sequential_156\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_574 (LSTM)             (None, 1, 100)            42400     \n",
      "                                                                 \n",
      " dropout_418 (Dropout)       (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_575 (LSTM)             (None, 1, 100)            80400     \n",
      "                                                                 \n",
      " dropout_419 (Dropout)       (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_576 (LSTM)             (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 203,301\n",
      "Trainable params: 203,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/154\n",
      "10/10 - 6s - loss: 0.0273 - val_loss: 0.0149 - 6s/epoch - 607ms/step\n",
      "Epoch 2/154\n",
      "10/10 - 0s - loss: 0.0045 - val_loss: 0.0173 - 105ms/epoch - 10ms/step\n",
      "Epoch 3/154\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0143 - 106ms/epoch - 11ms/step\n",
      "Epoch 4/154\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0155 - 115ms/epoch - 12ms/step\n",
      "Epoch 5/154\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0136 - 100ms/epoch - 10ms/step\n",
      "Epoch 6/154\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0133 - 101ms/epoch - 10ms/step\n",
      "Epoch 7/154\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0115 - 113ms/epoch - 11ms/step\n",
      "Epoch 8/154\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0096 - 100ms/epoch - 10ms/step\n",
      "Epoch 9/154\n",
      "10/10 - 0s - loss: 8.1004e-04 - val_loss: 0.0084 - 105ms/epoch - 11ms/step\n",
      "Epoch 10/154\n",
      "10/10 - 0s - loss: 4.9564e-04 - val_loss: 0.0091 - 100ms/epoch - 10ms/step\n",
      "Epoch 11/154\n",
      "10/10 - 0s - loss: 4.9712e-04 - val_loss: 0.0086 - 111ms/epoch - 11ms/step\n",
      "Epoch 12/154\n",
      "10/10 - 0s - loss: 3.9859e-04 - val_loss: 0.0083 - 99ms/epoch - 10ms/step\n",
      "Epoch 13/154\n",
      "10/10 - 0s - loss: 4.1615e-04 - val_loss: 0.0084 - 100ms/epoch - 10ms/step\n",
      "Epoch 14/154\n",
      "10/10 - 0s - loss: 3.6421e-04 - val_loss: 0.0085 - 149ms/epoch - 15ms/step\n",
      "Epoch 15/154\n",
      "10/10 - 0s - loss: 3.4873e-04 - val_loss: 0.0086 - 99ms/epoch - 10ms/step\n",
      "Epoch 16/154\n",
      "10/10 - 0s - loss: 3.4737e-04 - val_loss: 0.0085 - 100ms/epoch - 10ms/step\n",
      "Epoch 17/154\n",
      "10/10 - 0s - loss: 3.3093e-04 - val_loss: 0.0084 - 98ms/epoch - 10ms/step\n",
      "Epoch 18/154\n",
      "10/10 - 0s - loss: 3.1743e-04 - val_loss: 0.0084 - 111ms/epoch - 11ms/step\n",
      "Epoch 19/154\n",
      "10/10 - 0s - loss: 3.0160e-04 - val_loss: 0.0085 - 98ms/epoch - 10ms/step\n",
      "Epoch 20/154\n",
      "10/10 - 0s - loss: 2.9077e-04 - val_loss: 0.0084 - 100ms/epoch - 10ms/step\n",
      "Epoch 21/154\n",
      "10/10 - 0s - loss: 3.0222e-04 - val_loss: 0.0085 - 101ms/epoch - 10ms/step\n",
      "Epoch 22/154\n",
      "10/10 - 0s - loss: 2.6197e-04 - val_loss: 0.0084 - 110ms/epoch - 11ms/step\n",
      "Epoch 23/154\n",
      "10/10 - 0s - loss: 3.0105e-04 - val_loss: 0.0084 - 102ms/epoch - 10ms/step\n",
      "Epoch 24/154\n",
      "10/10 - 0s - loss: 2.9203e-04 - val_loss: 0.0086 - 99ms/epoch - 10ms/step\n",
      "Epoch 25/154\n",
      "10/10 - 0s - loss: 3.0957e-04 - val_loss: 0.0083 - 109ms/epoch - 11ms/step\n",
      "Epoch 26/154\n",
      "10/10 - 0s - loss: 2.3927e-04 - val_loss: 0.0084 - 101ms/epoch - 10ms/step\n",
      "Epoch 27/154\n",
      "10/10 - 0s - loss: 2.5744e-04 - val_loss: 0.0085 - 108ms/epoch - 11ms/step\n",
      "Epoch 28/154\n",
      "10/10 - 0s - loss: 2.5653e-04 - val_loss: 0.0086 - 122ms/epoch - 12ms/step\n",
      "Epoch 29/154\n",
      "10/10 - 0s - loss: 2.8066e-04 - val_loss: 0.0084 - 113ms/epoch - 11ms/step\n",
      "Epoch 30/154\n",
      "10/10 - 0s - loss: 2.3603e-04 - val_loss: 0.0084 - 98ms/epoch - 10ms/step\n",
      "Epoch 31/154\n",
      "10/10 - 0s - loss: 2.4370e-04 - val_loss: 0.0085 - 99ms/epoch - 10ms/step\n",
      "Epoch 32/154\n",
      "10/10 - 0s - loss: 2.6085e-04 - val_loss: 0.0084 - 112ms/epoch - 11ms/step\n",
      "Epoch 33/154\n",
      "10/10 - 0s - loss: 2.4374e-04 - val_loss: 0.0087 - 104ms/epoch - 10ms/step\n",
      "Epoch 34/154\n",
      "10/10 - 0s - loss: 2.5399e-04 - val_loss: 0.0084 - 101ms/epoch - 10ms/step\n",
      "Epoch 35/154\n",
      "10/10 - 0s - loss: 2.1962e-04 - val_loss: 0.0086 - 105ms/epoch - 11ms/step\n",
      "Epoch 36/154\n",
      "10/10 - 0s - loss: 2.2703e-04 - val_loss: 0.0085 - 114ms/epoch - 11ms/step\n",
      "Epoch 37/154\n",
      "10/10 - 0s - loss: 2.1412e-04 - val_loss: 0.0085 - 148ms/epoch - 15ms/step\n",
      "Epoch 38/154\n",
      "10/10 - 0s - loss: 2.1203e-04 - val_loss: 0.0085 - 107ms/epoch - 11ms/step\n",
      "Epoch 39/154\n",
      "10/10 - 0s - loss: 2.2262e-04 - val_loss: 0.0086 - 113ms/epoch - 11ms/step\n",
      "Epoch 40/154\n",
      "10/10 - 0s - loss: 2.2115e-04 - val_loss: 0.0086 - 106ms/epoch - 11ms/step\n",
      "Epoch 41/154\n",
      "10/10 - 0s - loss: 2.2631e-04 - val_loss: 0.0085 - 120ms/epoch - 12ms/step\n",
      "Epoch 42/154\n",
      "10/10 - 0s - loss: 2.3155e-04 - val_loss: 0.0086 - 101ms/epoch - 10ms/step\n",
      "Epoch 43/154\n",
      "10/10 - 0s - loss: 2.3446e-04 - val_loss: 0.0086 - 119ms/epoch - 12ms/step\n",
      "Epoch 44/154\n",
      "10/10 - 0s - loss: 1.9898e-04 - val_loss: 0.0087 - 110ms/epoch - 11ms/step\n",
      "Epoch 45/154\n",
      "10/10 - 0s - loss: 2.0370e-04 - val_loss: 0.0087 - 98ms/epoch - 10ms/step\n",
      "Epoch 46/154\n",
      "10/10 - 0s - loss: 2.6586e-04 - val_loss: 0.0085 - 114ms/epoch - 11ms/step\n",
      "Epoch 47/154\n",
      "10/10 - 0s - loss: 2.2025e-04 - val_loss: 0.0087 - 104ms/epoch - 10ms/step\n",
      "Epoch 48/154\n",
      "10/10 - 0s - loss: 2.2210e-04 - val_loss: 0.0088 - 118ms/epoch - 12ms/step\n",
      "Epoch 49/154\n",
      "10/10 - 0s - loss: 2.6644e-04 - val_loss: 0.0085 - 127ms/epoch - 13ms/step\n",
      "Epoch 50/154\n",
      "10/10 - 0s - loss: 2.3416e-04 - val_loss: 0.0088 - 102ms/epoch - 10ms/step\n",
      "Epoch 51/154\n",
      "10/10 - 0s - loss: 2.3785e-04 - val_loss: 0.0087 - 104ms/epoch - 10ms/step\n",
      "Epoch 52/154\n",
      "10/10 - 0s - loss: 2.4488e-04 - val_loss: 0.0086 - 112ms/epoch - 11ms/step\n",
      "Epoch 53/154\n",
      "10/10 - 0s - loss: 2.2229e-04 - val_loss: 0.0087 - 138ms/epoch - 14ms/step\n",
      "Epoch 54/154\n",
      "10/10 - 0s - loss: 2.0502e-04 - val_loss: 0.0088 - 104ms/epoch - 10ms/step\n",
      "Epoch 55/154\n",
      "10/10 - 0s - loss: 2.2664e-04 - val_loss: 0.0086 - 118ms/epoch - 12ms/step\n",
      "Epoch 56/154\n",
      "10/10 - 0s - loss: 2.5809e-04 - val_loss: 0.0089 - 103ms/epoch - 10ms/step\n",
      "Epoch 57/154\n",
      "10/10 - 0s - loss: 2.9556e-04 - val_loss: 0.0086 - 102ms/epoch - 10ms/step\n",
      "Epoch 58/154\n",
      "10/10 - 0s - loss: 2.5091e-04 - val_loss: 0.0087 - 117ms/epoch - 12ms/step\n",
      "Epoch 59/154\n",
      "10/10 - 0s - loss: 2.2382e-04 - val_loss: 0.0088 - 104ms/epoch - 10ms/step\n",
      "Epoch 60/154\n",
      "10/10 - 0s - loss: 2.3692e-04 - val_loss: 0.0087 - 103ms/epoch - 10ms/step\n",
      "Epoch 61/154\n",
      "10/10 - 0s - loss: 1.8777e-04 - val_loss: 0.0089 - 100ms/epoch - 10ms/step\n",
      "Epoch 62/154\n",
      "10/10 - 0s - loss: 2.0535e-04 - val_loss: 0.0088 - 109ms/epoch - 11ms/step\n",
      "Epoch 63/154\n",
      "10/10 - 0s - loss: 2.0160e-04 - val_loss: 0.0087 - 112ms/epoch - 11ms/step\n",
      "Epoch 64/154\n",
      "10/10 - 0s - loss: 1.9393e-04 - val_loss: 0.0088 - 104ms/epoch - 10ms/step\n",
      "Epoch 65/154\n",
      "10/10 - 0s - loss: 1.9735e-04 - val_loss: 0.0089 - 117ms/epoch - 12ms/step\n",
      "Epoch 66/154\n",
      "10/10 - 0s - loss: 1.9166e-04 - val_loss: 0.0087 - 101ms/epoch - 10ms/step\n",
      "Epoch 67/154\n",
      "10/10 - 0s - loss: 2.0886e-04 - val_loss: 0.0089 - 105ms/epoch - 10ms/step\n",
      "Epoch 68/154\n",
      "10/10 - 0s - loss: 2.2858e-04 - val_loss: 0.0088 - 105ms/epoch - 10ms/step\n",
      "Epoch 69/154\n",
      "10/10 - 0s - loss: 1.8749e-04 - val_loss: 0.0088 - 162ms/epoch - 16ms/step\n",
      "Epoch 70/154\n",
      "10/10 - 0s - loss: 1.9300e-04 - val_loss: 0.0089 - 99ms/epoch - 10ms/step\n",
      "Epoch 71/154\n",
      "10/10 - 0s - loss: 1.9655e-04 - val_loss: 0.0089 - 98ms/epoch - 10ms/step\n",
      "Epoch 72/154\n",
      "10/10 - 0s - loss: 2.0145e-04 - val_loss: 0.0088 - 111ms/epoch - 11ms/step\n",
      "Epoch 73/154\n",
      "10/10 - 0s - loss: 1.9679e-04 - val_loss: 0.0088 - 99ms/epoch - 10ms/step\n",
      "Epoch 74/154\n",
      "10/10 - 0s - loss: 2.0053e-04 - val_loss: 0.0088 - 102ms/epoch - 10ms/step\n",
      "Epoch 75/154\n",
      "10/10 - 0s - loss: 1.9137e-04 - val_loss: 0.0090 - 98ms/epoch - 10ms/step\n",
      "Epoch 76/154\n",
      "10/10 - 0s - loss: 2.5317e-04 - val_loss: 0.0089 - 118ms/epoch - 12ms/step\n",
      "Epoch 77/154\n",
      "10/10 - 0s - loss: 2.1050e-04 - val_loss: 0.0088 - 125ms/epoch - 12ms/step\n",
      "Epoch 78/154\n",
      "10/10 - 0s - loss: 2.3309e-04 - val_loss: 0.0089 - 107ms/epoch - 11ms/step\n",
      "Epoch 79/154\n",
      "10/10 - 0s - loss: 1.9900e-04 - val_loss: 0.0090 - 129ms/epoch - 13ms/step\n",
      "Epoch 80/154\n",
      "10/10 - 0s - loss: 1.8738e-04 - val_loss: 0.0090 - 164ms/epoch - 16ms/step\n",
      "Epoch 81/154\n",
      "10/10 - 0s - loss: 1.8486e-04 - val_loss: 0.0090 - 134ms/epoch - 13ms/step\n",
      "Epoch 82/154\n",
      "10/10 - 0s - loss: 2.0609e-04 - val_loss: 0.0088 - 129ms/epoch - 13ms/step\n",
      "Epoch 83/154\n",
      "10/10 - 0s - loss: 1.9472e-04 - val_loss: 0.0091 - 104ms/epoch - 10ms/step\n",
      "Epoch 84/154\n",
      "10/10 - 0s - loss: 2.0636e-04 - val_loss: 0.0088 - 101ms/epoch - 10ms/step\n",
      "Epoch 85/154\n",
      "10/10 - 0s - loss: 1.9341e-04 - val_loss: 0.0092 - 113ms/epoch - 11ms/step\n",
      "Epoch 86/154\n",
      "10/10 - 0s - loss: 1.8231e-04 - val_loss: 0.0089 - 100ms/epoch - 10ms/step\n",
      "Epoch 87/154\n",
      "10/10 - 0s - loss: 1.7990e-04 - val_loss: 0.0091 - 102ms/epoch - 10ms/step\n",
      "Epoch 88/154\n",
      "10/10 - 0s - loss: 2.0915e-04 - val_loss: 0.0090 - 123ms/epoch - 12ms/step\n",
      "Epoch 89/154\n",
      "10/10 - 0s - loss: 2.0085e-04 - val_loss: 0.0090 - 103ms/epoch - 10ms/step\n",
      "Epoch 90/154\n",
      "10/10 - 0s - loss: 1.9868e-04 - val_loss: 0.0092 - 158ms/epoch - 16ms/step\n",
      "Epoch 91/154\n",
      "10/10 - 0s - loss: 2.2891e-04 - val_loss: 0.0089 - 124ms/epoch - 12ms/step\n",
      "Epoch 92/154\n",
      "10/10 - 0s - loss: 1.8088e-04 - val_loss: 0.0091 - 110ms/epoch - 11ms/step\n",
      "Epoch 93/154\n",
      "10/10 - 0s - loss: 1.9884e-04 - val_loss: 0.0090 - 102ms/epoch - 10ms/step\n",
      "Epoch 94/154\n",
      "10/10 - 0s - loss: 1.9011e-04 - val_loss: 0.0091 - 116ms/epoch - 12ms/step\n",
      "Epoch 95/154\n",
      "10/10 - 0s - loss: 1.9550e-04 - val_loss: 0.0089 - 99ms/epoch - 10ms/step\n",
      "Epoch 96/154\n",
      "10/10 - 0s - loss: 1.8322e-04 - val_loss: 0.0092 - 99ms/epoch - 10ms/step\n",
      "Epoch 97/154\n",
      "10/10 - 0s - loss: 1.9443e-04 - val_loss: 0.0090 - 117ms/epoch - 12ms/step\n",
      "Epoch 98/154\n",
      "10/10 - 0s - loss: 2.4962e-04 - val_loss: 0.0090 - 105ms/epoch - 11ms/step\n",
      "Epoch 99/154\n",
      "10/10 - 0s - loss: 2.2698e-04 - val_loss: 0.0092 - 103ms/epoch - 10ms/step\n",
      "Epoch 100/154\n",
      "10/10 - 0s - loss: 1.9918e-04 - val_loss: 0.0091 - 135ms/epoch - 14ms/step\n",
      "Epoch 101/154\n",
      "10/10 - 0s - loss: 2.0443e-04 - val_loss: 0.0091 - 112ms/epoch - 11ms/step\n",
      "Epoch 102/154\n",
      "10/10 - 0s - loss: 2.1164e-04 - val_loss: 0.0090 - 119ms/epoch - 12ms/step\n",
      "Epoch 103/154\n",
      "10/10 - 0s - loss: 1.9215e-04 - val_loss: 0.0090 - 119ms/epoch - 12ms/step\n",
      "Epoch 104/154\n",
      "10/10 - 0s - loss: 2.1121e-04 - val_loss: 0.0090 - 104ms/epoch - 10ms/step\n",
      "Epoch 105/154\n",
      "10/10 - 0s - loss: 1.9995e-04 - val_loss: 0.0090 - 111ms/epoch - 11ms/step\n",
      "Epoch 106/154\n",
      "10/10 - 0s - loss: 2.0753e-04 - val_loss: 0.0089 - 119ms/epoch - 12ms/step\n",
      "Epoch 107/154\n",
      "10/10 - 0s - loss: 2.1716e-04 - val_loss: 0.0092 - 99ms/epoch - 10ms/step\n",
      "Epoch 108/154\n",
      "10/10 - 0s - loss: 1.9279e-04 - val_loss: 0.0091 - 105ms/epoch - 10ms/step\n",
      "Epoch 109/154\n",
      "10/10 - 0s - loss: 2.0201e-04 - val_loss: 0.0090 - 100ms/epoch - 10ms/step\n",
      "Epoch 110/154\n",
      "10/10 - 0s - loss: 1.8559e-04 - val_loss: 0.0090 - 113ms/epoch - 11ms/step\n",
      "Epoch 111/154\n",
      "10/10 - 0s - loss: 1.8539e-04 - val_loss: 0.0091 - 100ms/epoch - 10ms/step\n",
      "Epoch 112/154\n",
      "10/10 - 0s - loss: 1.8573e-04 - val_loss: 0.0089 - 100ms/epoch - 10ms/step\n",
      "Epoch 113/154\n",
      "10/10 - 0s - loss: 1.9426e-04 - val_loss: 0.0091 - 110ms/epoch - 11ms/step\n",
      "Epoch 114/154\n",
      "10/10 - 0s - loss: 2.0446e-04 - val_loss: 0.0092 - 99ms/epoch - 10ms/step\n",
      "Epoch 115/154\n",
      "10/10 - 0s - loss: 2.0525e-04 - val_loss: 0.0090 - 99ms/epoch - 10ms/step\n",
      "Epoch 116/154\n",
      "10/10 - 0s - loss: 1.7950e-04 - val_loss: 0.0093 - 107ms/epoch - 11ms/step\n",
      "Epoch 117/154\n",
      "10/10 - 0s - loss: 1.9120e-04 - val_loss: 0.0091 - 127ms/epoch - 13ms/step\n",
      "Epoch 118/154\n",
      "10/10 - 0s - loss: 1.8271e-04 - val_loss: 0.0092 - 100ms/epoch - 10ms/step\n",
      "Epoch 119/154\n",
      "10/10 - 0s - loss: 1.9383e-04 - val_loss: 0.0094 - 98ms/epoch - 10ms/step\n",
      "Epoch 120/154\n",
      "10/10 - 0s - loss: 1.9519e-04 - val_loss: 0.0092 - 111ms/epoch - 11ms/step\n",
      "Epoch 121/154\n",
      "10/10 - 0s - loss: 1.8029e-04 - val_loss: 0.0092 - 99ms/epoch - 10ms/step\n",
      "Epoch 122/154\n",
      "10/10 - 0s - loss: 1.8103e-04 - val_loss: 0.0093 - 98ms/epoch - 10ms/step\n",
      "Epoch 123/154\n",
      "10/10 - 0s - loss: 1.8609e-04 - val_loss: 0.0092 - 112ms/epoch - 11ms/step\n",
      "Epoch 124/154\n",
      "10/10 - 0s - loss: 1.8985e-04 - val_loss: 0.0093 - 99ms/epoch - 10ms/step\n",
      "Epoch 125/154\n",
      "10/10 - 0s - loss: 1.8682e-04 - val_loss: 0.0094 - 99ms/epoch - 10ms/step\n",
      "Epoch 126/154\n",
      "10/10 - 0s - loss: 1.9900e-04 - val_loss: 0.0091 - 111ms/epoch - 11ms/step\n",
      "Epoch 127/154\n",
      "10/10 - 0s - loss: 1.9604e-04 - val_loss: 0.0094 - 101ms/epoch - 10ms/step\n",
      "Epoch 128/154\n",
      "10/10 - 0s - loss: 1.8849e-04 - val_loss: 0.0094 - 103ms/epoch - 10ms/step\n",
      "Epoch 129/154\n",
      "10/10 - 0s - loss: 2.0490e-04 - val_loss: 0.0092 - 148ms/epoch - 15ms/step\n",
      "Epoch 130/154\n",
      "10/10 - 0s - loss: 1.8336e-04 - val_loss: 0.0094 - 119ms/epoch - 12ms/step\n",
      "Epoch 131/154\n",
      "10/10 - 0s - loss: 1.8059e-04 - val_loss: 0.0094 - 104ms/epoch - 10ms/step\n",
      "Epoch 132/154\n",
      "10/10 - 0s - loss: 1.8978e-04 - val_loss: 0.0093 - 98ms/epoch - 10ms/step\n",
      "Epoch 133/154\n",
      "10/10 - 0s - loss: 1.8036e-04 - val_loss: 0.0093 - 113ms/epoch - 11ms/step\n",
      "Epoch 134/154\n",
      "10/10 - 0s - loss: 2.0456e-04 - val_loss: 0.0094 - 100ms/epoch - 10ms/step\n",
      "Epoch 135/154\n",
      "10/10 - 0s - loss: 1.9777e-04 - val_loss: 0.0096 - 99ms/epoch - 10ms/step\n",
      "Epoch 136/154\n",
      "10/10 - 0s - loss: 2.1636e-04 - val_loss: 0.0095 - 117ms/epoch - 12ms/step\n",
      "Epoch 137/154\n",
      "10/10 - 0s - loss: 1.9521e-04 - val_loss: 0.0093 - 108ms/epoch - 11ms/step\n",
      "Epoch 138/154\n",
      "10/10 - 0s - loss: 2.0922e-04 - val_loss: 0.0093 - 100ms/epoch - 10ms/step\n",
      "Epoch 139/154\n",
      "10/10 - 0s - loss: 2.1016e-04 - val_loss: 0.0094 - 115ms/epoch - 12ms/step\n",
      "Epoch 140/154\n",
      "10/10 - 0s - loss: 2.0051e-04 - val_loss: 0.0093 - 126ms/epoch - 13ms/step\n",
      "Epoch 141/154\n",
      "10/10 - 0s - loss: 2.4490e-04 - val_loss: 0.0093 - 99ms/epoch - 10ms/step\n",
      "Epoch 142/154\n",
      "10/10 - 0s - loss: 2.9316e-04 - val_loss: 0.0090 - 105ms/epoch - 11ms/step\n",
      "Epoch 143/154\n",
      "10/10 - 0s - loss: 2.6406e-04 - val_loss: 0.0095 - 99ms/epoch - 10ms/step\n",
      "Epoch 144/154\n",
      "10/10 - 0s - loss: 2.2715e-04 - val_loss: 0.0091 - 98ms/epoch - 10ms/step\n",
      "Epoch 145/154\n",
      "10/10 - 0s - loss: 2.1131e-04 - val_loss: 0.0096 - 111ms/epoch - 11ms/step\n",
      "Epoch 146/154\n",
      "10/10 - 0s - loss: 2.4351e-04 - val_loss: 0.0089 - 99ms/epoch - 10ms/step\n",
      "Epoch 147/154\n",
      "10/10 - 0s - loss: 1.9227e-04 - val_loss: 0.0091 - 98ms/epoch - 10ms/step\n",
      "Epoch 148/154\n",
      "10/10 - 0s - loss: 1.9335e-04 - val_loss: 0.0094 - 111ms/epoch - 11ms/step\n",
      "Epoch 149/154\n",
      "10/10 - 0s - loss: 2.0474e-04 - val_loss: 0.0090 - 101ms/epoch - 10ms/step\n",
      "Epoch 150/154\n",
      "10/10 - 0s - loss: 2.0672e-04 - val_loss: 0.0093 - 101ms/epoch - 10ms/step\n",
      "Epoch 151/154\n",
      "10/10 - 0s - loss: 1.9128e-04 - val_loss: 0.0092 - 156ms/epoch - 16ms/step\n",
      "Epoch 152/154\n",
      "10/10 - 0s - loss: 1.8804e-04 - val_loss: 0.0092 - 100ms/epoch - 10ms/step\n",
      "Epoch 153/154\n",
      "10/10 - 0s - loss: 1.9594e-04 - val_loss: 0.0091 - 117ms/epoch - 12ms/step\n",
      "Epoch 154/154\n",
      "10/10 - 0s - loss: 2.0391e-04 - val_loss: 0.0094 - 131ms/epoch - 13ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m-173.7   \u001b[0m | \u001b[0m154.9    \u001b[0m | \u001b[0m2.341    \u001b[0m | \u001b[0m0.004621 \u001b[0m | \u001b[0m100.2    \u001b[0m |\n",
      "Model: \"sequential_157\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_577 (LSTM)             (None, 1, 105)            46620     \n",
      "                                                                 \n",
      " dropout_420 (Dropout)       (None, 1, 105)            0         \n",
      "                                                                 \n",
      " lstm_578 (LSTM)             (None, 105)               88620     \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 1)                 106       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 135,346\n",
      "Trainable params: 135,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/141\n",
      "10/10 - 4s - loss: 0.0712 - val_loss: 0.0923 - 4s/epoch - 420ms/step\n",
      "Epoch 2/141\n",
      "10/10 - 0s - loss: 0.0707 - val_loss: 0.0918 - 107ms/epoch - 11ms/step\n",
      "Epoch 3/141\n",
      "10/10 - 0s - loss: 0.0703 - val_loss: 0.0913 - 85ms/epoch - 8ms/step\n",
      "Epoch 4/141\n",
      "10/10 - 0s - loss: 0.0698 - val_loss: 0.0908 - 89ms/epoch - 9ms/step\n",
      "Epoch 5/141\n",
      "10/10 - 0s - loss: 0.0693 - val_loss: 0.0903 - 105ms/epoch - 11ms/step\n",
      "Epoch 6/141\n",
      "10/10 - 0s - loss: 0.0688 - val_loss: 0.0898 - 86ms/epoch - 9ms/step\n",
      "Epoch 7/141\n",
      "10/10 - 0s - loss: 0.0684 - val_loss: 0.0893 - 89ms/epoch - 9ms/step\n",
      "Epoch 8/141\n",
      "10/10 - 0s - loss: 0.0680 - val_loss: 0.0888 - 139ms/epoch - 14ms/step\n",
      "Epoch 9/141\n",
      "10/10 - 0s - loss: 0.0676 - val_loss: 0.0883 - 93ms/epoch - 9ms/step\n",
      "Epoch 10/141\n",
      "10/10 - 0s - loss: 0.0671 - val_loss: 0.0878 - 100ms/epoch - 10ms/step\n",
      "Epoch 11/141\n",
      "10/10 - 0s - loss: 0.0667 - val_loss: 0.0873 - 102ms/epoch - 10ms/step\n",
      "Epoch 12/141\n",
      "10/10 - 0s - loss: 0.0662 - val_loss: 0.0868 - 89ms/epoch - 9ms/step\n",
      "Epoch 13/141\n",
      "10/10 - 0s - loss: 0.0658 - val_loss: 0.0863 - 84ms/epoch - 8ms/step\n",
      "Epoch 14/141\n",
      "10/10 - 0s - loss: 0.0654 - val_loss: 0.0858 - 99ms/epoch - 10ms/step\n",
      "Epoch 15/141\n",
      "10/10 - 0s - loss: 0.0649 - val_loss: 0.0853 - 87ms/epoch - 9ms/step\n",
      "Epoch 16/141\n",
      "10/10 - 0s - loss: 0.0645 - val_loss: 0.0848 - 86ms/epoch - 9ms/step\n",
      "Epoch 17/141\n",
      "10/10 - 0s - loss: 0.0640 - val_loss: 0.0843 - 99ms/epoch - 10ms/step\n",
      "Epoch 18/141\n",
      "10/10 - 0s - loss: 0.0636 - val_loss: 0.0838 - 111ms/epoch - 11ms/step\n",
      "Epoch 19/141\n",
      "10/10 - 0s - loss: 0.0632 - val_loss: 0.0833 - 124ms/epoch - 12ms/step\n",
      "Epoch 20/141\n",
      "10/10 - 0s - loss: 0.0628 - val_loss: 0.0828 - 105ms/epoch - 11ms/step\n",
      "Epoch 21/141\n",
      "10/10 - 0s - loss: 0.0623 - val_loss: 0.0823 - 83ms/epoch - 8ms/step\n",
      "Epoch 22/141\n",
      "10/10 - 0s - loss: 0.0619 - val_loss: 0.0818 - 89ms/epoch - 9ms/step\n",
      "Epoch 23/141\n",
      "10/10 - 0s - loss: 0.0614 - val_loss: 0.0813 - 108ms/epoch - 11ms/step\n",
      "Epoch 24/141\n",
      "10/10 - 0s - loss: 0.0610 - val_loss: 0.0809 - 88ms/epoch - 9ms/step\n",
      "Epoch 25/141\n",
      "10/10 - 0s - loss: 0.0605 - val_loss: 0.0804 - 107ms/epoch - 11ms/step\n",
      "Epoch 26/141\n",
      "10/10 - 0s - loss: 0.0601 - val_loss: 0.0799 - 102ms/epoch - 10ms/step\n",
      "Epoch 27/141\n",
      "10/10 - 0s - loss: 0.0596 - val_loss: 0.0794 - 87ms/epoch - 9ms/step\n",
      "Epoch 28/141\n",
      "10/10 - 0s - loss: 0.0593 - val_loss: 0.0789 - 85ms/epoch - 8ms/step\n",
      "Epoch 29/141\n",
      "10/10 - 0s - loss: 0.0588 - val_loss: 0.0784 - 139ms/epoch - 14ms/step\n",
      "Epoch 30/141\n",
      "10/10 - 0s - loss: 0.0583 - val_loss: 0.0779 - 89ms/epoch - 9ms/step\n",
      "Epoch 31/141\n",
      "10/10 - 0s - loss: 0.0579 - val_loss: 0.0774 - 87ms/epoch - 9ms/step\n",
      "Epoch 32/141\n",
      "10/10 - 0s - loss: 0.0575 - val_loss: 0.0769 - 104ms/epoch - 10ms/step\n",
      "Epoch 33/141\n",
      "10/10 - 0s - loss: 0.0571 - val_loss: 0.0764 - 90ms/epoch - 9ms/step\n",
      "Epoch 34/141\n",
      "10/10 - 0s - loss: 0.0567 - val_loss: 0.0759 - 88ms/epoch - 9ms/step\n",
      "Epoch 35/141\n",
      "10/10 - 0s - loss: 0.0562 - val_loss: 0.0754 - 120ms/epoch - 12ms/step\n",
      "Epoch 36/141\n",
      "10/10 - 0s - loss: 0.0557 - val_loss: 0.0749 - 94ms/epoch - 9ms/step\n",
      "Epoch 37/141\n",
      "10/10 - 0s - loss: 0.0553 - val_loss: 0.0744 - 91ms/epoch - 9ms/step\n",
      "Epoch 38/141\n",
      "10/10 - 0s - loss: 0.0549 - val_loss: 0.0739 - 118ms/epoch - 12ms/step\n",
      "Epoch 39/141\n",
      "10/10 - 0s - loss: 0.0545 - val_loss: 0.0734 - 94ms/epoch - 9ms/step\n",
      "Epoch 40/141\n",
      "10/10 - 0s - loss: 0.0540 - val_loss: 0.0729 - 90ms/epoch - 9ms/step\n",
      "Epoch 41/141\n",
      "10/10 - 0s - loss: 0.0536 - val_loss: 0.0724 - 109ms/epoch - 11ms/step\n",
      "Epoch 42/141\n",
      "10/10 - 0s - loss: 0.0531 - val_loss: 0.0719 - 94ms/epoch - 9ms/step\n",
      "Epoch 43/141\n",
      "10/10 - 0s - loss: 0.0526 - val_loss: 0.0714 - 86ms/epoch - 9ms/step\n",
      "Epoch 44/141\n",
      "10/10 - 0s - loss: 0.0522 - val_loss: 0.0709 - 99ms/epoch - 10ms/step\n",
      "Epoch 45/141\n",
      "10/10 - 0s - loss: 0.0518 - val_loss: 0.0704 - 88ms/epoch - 9ms/step\n",
      "Epoch 46/141\n",
      "10/10 - 0s - loss: 0.0514 - val_loss: 0.0699 - 85ms/epoch - 8ms/step\n",
      "Epoch 47/141\n",
      "10/10 - 0s - loss: 0.0509 - val_loss: 0.0694 - 97ms/epoch - 10ms/step\n",
      "Epoch 48/141\n",
      "10/10 - 0s - loss: 0.0505 - val_loss: 0.0689 - 83ms/epoch - 8ms/step\n",
      "Epoch 49/141\n",
      "10/10 - 0s - loss: 0.0500 - val_loss: 0.0684 - 105ms/epoch - 10ms/step\n",
      "Epoch 50/141\n",
      "10/10 - 0s - loss: 0.0497 - val_loss: 0.0679 - 100ms/epoch - 10ms/step\n",
      "Epoch 51/141\n",
      "10/10 - 0s - loss: 0.0491 - val_loss: 0.0674 - 84ms/epoch - 8ms/step\n",
      "Epoch 52/141\n",
      "10/10 - 0s - loss: 0.0487 - val_loss: 0.0669 - 84ms/epoch - 8ms/step\n",
      "Epoch 53/141\n",
      "10/10 - 0s - loss: 0.0482 - val_loss: 0.0664 - 94ms/epoch - 9ms/step\n",
      "Epoch 54/141\n",
      "10/10 - 0s - loss: 0.0479 - val_loss: 0.0658 - 85ms/epoch - 9ms/step\n",
      "Epoch 55/141\n",
      "10/10 - 0s - loss: 0.0474 - val_loss: 0.0653 - 84ms/epoch - 8ms/step\n",
      "Epoch 56/141\n",
      "10/10 - 0s - loss: 0.0469 - val_loss: 0.0648 - 96ms/epoch - 10ms/step\n",
      "Epoch 57/141\n",
      "10/10 - 0s - loss: 0.0464 - val_loss: 0.0643 - 85ms/epoch - 9ms/step\n",
      "Epoch 58/141\n",
      "10/10 - 0s - loss: 0.0460 - val_loss: 0.0638 - 85ms/epoch - 8ms/step\n",
      "Epoch 59/141\n",
      "10/10 - 0s - loss: 0.0455 - val_loss: 0.0633 - 96ms/epoch - 10ms/step\n",
      "Epoch 60/141\n",
      "10/10 - 0s - loss: 0.0451 - val_loss: 0.0628 - 82ms/epoch - 8ms/step\n",
      "Epoch 61/141\n",
      "10/10 - 0s - loss: 0.0446 - val_loss: 0.0622 - 82ms/epoch - 8ms/step\n",
      "Epoch 62/141\n",
      "10/10 - 0s - loss: 0.0442 - val_loss: 0.0617 - 137ms/epoch - 14ms/step\n",
      "Epoch 63/141\n",
      "10/10 - 0s - loss: 0.0437 - val_loss: 0.0612 - 99ms/epoch - 10ms/step\n",
      "Epoch 64/141\n",
      "10/10 - 0s - loss: 0.0432 - val_loss: 0.0607 - 90ms/epoch - 9ms/step\n",
      "Epoch 65/141\n",
      "10/10 - 0s - loss: 0.0428 - val_loss: 0.0602 - 104ms/epoch - 10ms/step\n",
      "Epoch 66/141\n",
      "10/10 - 0s - loss: 0.0423 - val_loss: 0.0596 - 87ms/epoch - 9ms/step\n",
      "Epoch 67/141\n",
      "10/10 - 0s - loss: 0.0418 - val_loss: 0.0591 - 85ms/epoch - 8ms/step\n",
      "Epoch 68/141\n",
      "10/10 - 0s - loss: 0.0415 - val_loss: 0.0586 - 100ms/epoch - 10ms/step\n",
      "Epoch 69/141\n",
      "10/10 - 0s - loss: 0.0410 - val_loss: 0.0581 - 86ms/epoch - 9ms/step\n",
      "Epoch 70/141\n",
      "10/10 - 0s - loss: 0.0406 - val_loss: 0.0576 - 85ms/epoch - 8ms/step\n",
      "Epoch 71/141\n",
      "10/10 - 0s - loss: 0.0402 - val_loss: 0.0570 - 93ms/epoch - 9ms/step\n",
      "Epoch 72/141\n",
      "10/10 - 0s - loss: 0.0396 - val_loss: 0.0565 - 83ms/epoch - 8ms/step\n",
      "Epoch 73/141\n",
      "10/10 - 0s - loss: 0.0392 - val_loss: 0.0560 - 80ms/epoch - 8ms/step\n",
      "Epoch 74/141\n",
      "10/10 - 0s - loss: 0.0388 - val_loss: 0.0555 - 90ms/epoch - 9ms/step\n",
      "Epoch 75/141\n",
      "10/10 - 0s - loss: 0.0383 - val_loss: 0.0549 - 108ms/epoch - 11ms/step\n",
      "Epoch 76/141\n",
      "10/10 - 0s - loss: 0.0378 - val_loss: 0.0544 - 90ms/epoch - 9ms/step\n",
      "Epoch 77/141\n",
      "10/10 - 0s - loss: 0.0375 - val_loss: 0.0539 - 92ms/epoch - 9ms/step\n",
      "Epoch 78/141\n",
      "10/10 - 0s - loss: 0.0370 - val_loss: 0.0534 - 84ms/epoch - 8ms/step\n",
      "Epoch 79/141\n",
      "10/10 - 0s - loss: 0.0365 - val_loss: 0.0529 - 82ms/epoch - 8ms/step\n",
      "Epoch 80/141\n",
      "10/10 - 0s - loss: 0.0361 - val_loss: 0.0523 - 95ms/epoch - 10ms/step\n",
      "Epoch 81/141\n",
      "10/10 - 0s - loss: 0.0356 - val_loss: 0.0518 - 82ms/epoch - 8ms/step\n",
      "Epoch 82/141\n",
      "10/10 - 0s - loss: 0.0352 - val_loss: 0.0513 - 84ms/epoch - 8ms/step\n",
      "Epoch 83/141\n",
      "10/10 - 0s - loss: 0.0347 - val_loss: 0.0508 - 88ms/epoch - 9ms/step\n",
      "Epoch 84/141\n",
      "10/10 - 0s - loss: 0.0342 - val_loss: 0.0502 - 98ms/epoch - 10ms/step\n",
      "Epoch 85/141\n",
      "10/10 - 0s - loss: 0.0338 - val_loss: 0.0497 - 116ms/epoch - 12ms/step\n",
      "Epoch 86/141\n",
      "10/10 - 0s - loss: 0.0333 - val_loss: 0.0492 - 92ms/epoch - 9ms/step\n",
      "Epoch 87/141\n",
      "10/10 - 0s - loss: 0.0329 - val_loss: 0.0487 - 84ms/epoch - 8ms/step\n",
      "Epoch 88/141\n",
      "10/10 - 0s - loss: 0.0323 - val_loss: 0.0481 - 96ms/epoch - 10ms/step\n",
      "Epoch 89/141\n",
      "10/10 - 0s - loss: 0.0320 - val_loss: 0.0476 - 82ms/epoch - 8ms/step\n",
      "Epoch 90/141\n",
      "10/10 - 0s - loss: 0.0316 - val_loss: 0.0471 - 83ms/epoch - 8ms/step\n",
      "Epoch 91/141\n",
      "10/10 - 0s - loss: 0.0312 - val_loss: 0.0466 - 96ms/epoch - 10ms/step\n",
      "Epoch 92/141\n",
      "10/10 - 0s - loss: 0.0306 - val_loss: 0.0461 - 86ms/epoch - 9ms/step\n",
      "Epoch 93/141\n",
      "10/10 - 0s - loss: 0.0301 - val_loss: 0.0456 - 113ms/epoch - 11ms/step\n",
      "Epoch 94/141\n",
      "10/10 - 0s - loss: 0.0297 - val_loss: 0.0450 - 117ms/epoch - 12ms/step\n",
      "Epoch 95/141\n",
      "10/10 - 0s - loss: 0.0292 - val_loss: 0.0445 - 88ms/epoch - 9ms/step\n",
      "Epoch 96/141\n",
      "10/10 - 0s - loss: 0.0288 - val_loss: 0.0440 - 83ms/epoch - 8ms/step\n",
      "Epoch 97/141\n",
      "10/10 - 0s - loss: 0.0284 - val_loss: 0.0435 - 97ms/epoch - 10ms/step\n",
      "Epoch 98/141\n",
      "10/10 - 0s - loss: 0.0281 - val_loss: 0.0430 - 84ms/epoch - 8ms/step\n",
      "Epoch 99/141\n",
      "10/10 - 0s - loss: 0.0274 - val_loss: 0.0425 - 85ms/epoch - 8ms/step\n",
      "Epoch 100/141\n",
      "10/10 - 0s - loss: 0.0272 - val_loss: 0.0420 - 97ms/epoch - 10ms/step\n",
      "Epoch 101/141\n",
      "10/10 - 0s - loss: 0.0267 - val_loss: 0.0415 - 85ms/epoch - 9ms/step\n",
      "Epoch 102/141\n",
      "10/10 - 0s - loss: 0.0263 - val_loss: 0.0410 - 81ms/epoch - 8ms/step\n",
      "Epoch 103/141\n",
      "10/10 - 0s - loss: 0.0259 - val_loss: 0.0405 - 130ms/epoch - 13ms/step\n",
      "Epoch 104/141\n",
      "10/10 - 0s - loss: 0.0255 - val_loss: 0.0400 - 89ms/epoch - 9ms/step\n",
      "Epoch 105/141\n",
      "10/10 - 0s - loss: 0.0249 - val_loss: 0.0395 - 81ms/epoch - 8ms/step\n",
      "Epoch 106/141\n",
      "10/10 - 0s - loss: 0.0246 - val_loss: 0.0390 - 81ms/epoch - 8ms/step\n",
      "Epoch 107/141\n",
      "10/10 - 0s - loss: 0.0240 - val_loss: 0.0385 - 91ms/epoch - 9ms/step\n",
      "Epoch 108/141\n",
      "10/10 - 0s - loss: 0.0237 - val_loss: 0.0380 - 82ms/epoch - 8ms/step\n",
      "Epoch 109/141\n",
      "10/10 - 0s - loss: 0.0233 - val_loss: 0.0375 - 81ms/epoch - 8ms/step\n",
      "Epoch 110/141\n",
      "10/10 - 0s - loss: 0.0230 - val_loss: 0.0370 - 82ms/epoch - 8ms/step\n",
      "Epoch 111/141\n",
      "10/10 - 0s - loss: 0.0225 - val_loss: 0.0365 - 92ms/epoch - 9ms/step\n",
      "Epoch 112/141\n",
      "10/10 - 0s - loss: 0.0221 - val_loss: 0.0361 - 84ms/epoch - 8ms/step\n",
      "Epoch 113/141\n",
      "10/10 - 0s - loss: 0.0218 - val_loss: 0.0356 - 114ms/epoch - 11ms/step\n",
      "Epoch 114/141\n",
      "10/10 - 0s - loss: 0.0212 - val_loss: 0.0351 - 99ms/epoch - 10ms/step\n",
      "Epoch 115/141\n",
      "10/10 - 0s - loss: 0.0210 - val_loss: 0.0346 - 84ms/epoch - 8ms/step\n",
      "Epoch 116/141\n",
      "10/10 - 0s - loss: 0.0206 - val_loss: 0.0342 - 83ms/epoch - 8ms/step\n",
      "Epoch 117/141\n",
      "10/10 - 0s - loss: 0.0201 - val_loss: 0.0337 - 97ms/epoch - 10ms/step\n",
      "Epoch 118/141\n",
      "10/10 - 0s - loss: 0.0197 - val_loss: 0.0333 - 82ms/epoch - 8ms/step\n",
      "Epoch 119/141\n",
      "10/10 - 0s - loss: 0.0194 - val_loss: 0.0328 - 81ms/epoch - 8ms/step\n",
      "Epoch 120/141\n",
      "10/10 - 0s - loss: 0.0190 - val_loss: 0.0323 - 90ms/epoch - 9ms/step\n",
      "Epoch 121/141\n",
      "10/10 - 0s - loss: 0.0187 - val_loss: 0.0319 - 82ms/epoch - 8ms/step\n",
      "Epoch 122/141\n",
      "10/10 - 0s - loss: 0.0182 - val_loss: 0.0314 - 82ms/epoch - 8ms/step\n",
      "Epoch 123/141\n",
      "10/10 - 0s - loss: 0.0179 - val_loss: 0.0310 - 107ms/epoch - 11ms/step\n",
      "Epoch 124/141\n",
      "10/10 - 0s - loss: 0.0174 - val_loss: 0.0306 - 99ms/epoch - 10ms/step\n",
      "Epoch 125/141\n",
      "10/10 - 0s - loss: 0.0170 - val_loss: 0.0301 - 85ms/epoch - 8ms/step\n",
      "Epoch 126/141\n",
      "10/10 - 0s - loss: 0.0167 - val_loss: 0.0297 - 79ms/epoch - 8ms/step\n",
      "Epoch 127/141\n",
      "10/10 - 0s - loss: 0.0165 - val_loss: 0.0293 - 81ms/epoch - 8ms/step\n",
      "Epoch 128/141\n",
      "10/10 - 0s - loss: 0.0161 - val_loss: 0.0288 - 98ms/epoch - 10ms/step\n",
      "Epoch 129/141\n",
      "10/10 - 0s - loss: 0.0158 - val_loss: 0.0284 - 83ms/epoch - 8ms/step\n",
      "Epoch 130/141\n",
      "10/10 - 0s - loss: 0.0153 - val_loss: 0.0280 - 90ms/epoch - 9ms/step\n",
      "Epoch 131/141\n",
      "10/10 - 0s - loss: 0.0151 - val_loss: 0.0276 - 94ms/epoch - 9ms/step\n",
      "Epoch 132/141\n",
      "10/10 - 0s - loss: 0.0147 - val_loss: 0.0272 - 83ms/epoch - 8ms/step\n",
      "Epoch 133/141\n",
      "10/10 - 0s - loss: 0.0143 - val_loss: 0.0268 - 109ms/epoch - 11ms/step\n",
      "Epoch 134/141\n",
      "10/10 - 0s - loss: 0.0139 - val_loss: 0.0264 - 96ms/epoch - 10ms/step\n",
      "Epoch 135/141\n",
      "10/10 - 0s - loss: 0.0137 - val_loss: 0.0260 - 85ms/epoch - 8ms/step\n",
      "Epoch 136/141\n",
      "10/10 - 0s - loss: 0.0133 - val_loss: 0.0256 - 80ms/epoch - 8ms/step\n",
      "Epoch 137/141\n",
      "10/10 - 0s - loss: 0.0130 - val_loss: 0.0252 - 93ms/epoch - 9ms/step\n",
      "Epoch 138/141\n",
      "10/10 - 0s - loss: 0.0127 - val_loss: 0.0249 - 84ms/epoch - 8ms/step\n",
      "Epoch 139/141\n",
      "10/10 - 0s - loss: 0.0124 - val_loss: 0.0245 - 82ms/epoch - 8ms/step\n",
      "Epoch 140/141\n",
      "10/10 - 0s - loss: 0.0120 - val_loss: 0.0241 - 81ms/epoch - 8ms/step\n",
      "Epoch 141/141\n",
      "10/10 - 0s - loss: 0.0118 - val_loss: 0.0238 - 97ms/epoch - 10ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m-276.0   \u001b[0m | \u001b[0m142.0    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1e-05    \u001b[0m | \u001b[0m105.7    \u001b[0m |\n",
      "Model: \"sequential_158\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_579 (LSTM)             (None, 1, 101)            43228     \n",
      "                                                                 \n",
      " dropout_421 (Dropout)       (None, 1, 101)            0         \n",
      "                                                                 \n",
      " lstm_580 (LSTM)             (None, 101)               82012     \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 1)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 125,342\n",
      "Trainable params: 125,342\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/168\n",
      "10/10 - 5s - loss: 0.0181 - val_loss: 0.0220 - 5s/epoch - 513ms/step\n",
      "Epoch 2/168\n",
      "10/10 - 0s - loss: 0.0042 - val_loss: 0.0124 - 81ms/epoch - 8ms/step\n",
      "Epoch 3/168\n",
      "10/10 - 0s - loss: 0.0023 - val_loss: 0.0127 - 89ms/epoch - 9ms/step\n",
      "Epoch 4/168\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0120 - 82ms/epoch - 8ms/step\n",
      "Epoch 5/168\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0104 - 79ms/epoch - 8ms/step\n",
      "Epoch 6/168\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0095 - 81ms/epoch - 8ms/step\n",
      "Epoch 7/168\n",
      "10/10 - 0s - loss: 7.7018e-04 - val_loss: 0.0086 - 81ms/epoch - 8ms/step\n",
      "Epoch 8/168\n",
      "10/10 - 0s - loss: 5.3104e-04 - val_loss: 0.0083 - 135ms/epoch - 14ms/step\n",
      "Epoch 9/168\n",
      "10/10 - 0s - loss: 4.3937e-04 - val_loss: 0.0085 - 86ms/epoch - 9ms/step\n",
      "Epoch 10/168\n",
      "10/10 - 0s - loss: 3.6849e-04 - val_loss: 0.0085 - 79ms/epoch - 8ms/step\n",
      "Epoch 11/168\n",
      "10/10 - 0s - loss: 3.0129e-04 - val_loss: 0.0085 - 93ms/epoch - 9ms/step\n",
      "Epoch 12/168\n",
      "10/10 - 0s - loss: 3.0046e-04 - val_loss: 0.0084 - 81ms/epoch - 8ms/step\n",
      "Epoch 13/168\n",
      "10/10 - 0s - loss: 2.7569e-04 - val_loss: 0.0084 - 87ms/epoch - 9ms/step\n",
      "Epoch 14/168\n",
      "10/10 - 0s - loss: 2.9817e-04 - val_loss: 0.0084 - 103ms/epoch - 10ms/step\n",
      "Epoch 15/168\n",
      "10/10 - 0s - loss: 3.0594e-04 - val_loss: 0.0084 - 79ms/epoch - 8ms/step\n",
      "Epoch 16/168\n",
      "10/10 - 0s - loss: 2.9847e-04 - val_loss: 0.0085 - 80ms/epoch - 8ms/step\n",
      "Epoch 17/168\n",
      "10/10 - 0s - loss: 2.8172e-04 - val_loss: 0.0084 - 80ms/epoch - 8ms/step\n",
      "Epoch 18/168\n",
      "10/10 - 0s - loss: 2.7139e-04 - val_loss: 0.0084 - 93ms/epoch - 9ms/step\n",
      "Epoch 19/168\n",
      "10/10 - 0s - loss: 2.9695e-04 - val_loss: 0.0084 - 86ms/epoch - 9ms/step\n",
      "Epoch 20/168\n",
      "10/10 - 0s - loss: 3.0965e-04 - val_loss: 0.0084 - 90ms/epoch - 9ms/step\n",
      "Epoch 21/168\n",
      "10/10 - 0s - loss: 2.6023e-04 - val_loss: 0.0085 - 137ms/epoch - 14ms/step\n",
      "Epoch 22/168\n",
      "10/10 - 0s - loss: 2.6390e-04 - val_loss: 0.0085 - 88ms/epoch - 9ms/step\n",
      "Epoch 23/168\n",
      "10/10 - 0s - loss: 3.0400e-04 - val_loss: 0.0084 - 85ms/epoch - 9ms/step\n",
      "Epoch 24/168\n",
      "10/10 - 0s - loss: 2.8008e-04 - val_loss: 0.0084 - 98ms/epoch - 10ms/step\n",
      "Epoch 25/168\n",
      "10/10 - 0s - loss: 2.4145e-04 - val_loss: 0.0084 - 81ms/epoch - 8ms/step\n",
      "Epoch 26/168\n",
      "10/10 - 0s - loss: 2.3368e-04 - val_loss: 0.0085 - 81ms/epoch - 8ms/step\n",
      "Epoch 27/168\n",
      "10/10 - 0s - loss: 2.2335e-04 - val_loss: 0.0084 - 91ms/epoch - 9ms/step\n",
      "Epoch 28/168\n",
      "10/10 - 0s - loss: 2.1872e-04 - val_loss: 0.0085 - 84ms/epoch - 8ms/step\n",
      "Epoch 29/168\n",
      "10/10 - 0s - loss: 2.2494e-04 - val_loss: 0.0084 - 81ms/epoch - 8ms/step\n",
      "Epoch 30/168\n",
      "10/10 - 0s - loss: 2.1057e-04 - val_loss: 0.0084 - 94ms/epoch - 9ms/step\n",
      "Epoch 31/168\n",
      "10/10 - 0s - loss: 2.0073e-04 - val_loss: 0.0084 - 82ms/epoch - 8ms/step\n",
      "Epoch 32/168\n",
      "10/10 - 0s - loss: 2.1855e-04 - val_loss: 0.0085 - 82ms/epoch - 8ms/step\n",
      "Epoch 33/168\n",
      "10/10 - 0s - loss: 2.0739e-04 - val_loss: 0.0086 - 80ms/epoch - 8ms/step\n",
      "Epoch 34/168\n",
      "10/10 - 0s - loss: 2.1227e-04 - val_loss: 0.0085 - 135ms/epoch - 14ms/step\n",
      "Epoch 35/168\n",
      "10/10 - 0s - loss: 2.2744e-04 - val_loss: 0.0084 - 86ms/epoch - 9ms/step\n",
      "Epoch 36/168\n",
      "10/10 - 0s - loss: 1.9488e-04 - val_loss: 0.0086 - 79ms/epoch - 8ms/step\n",
      "Epoch 37/168\n",
      "10/10 - 0s - loss: 1.9570e-04 - val_loss: 0.0086 - 91ms/epoch - 9ms/step\n",
      "Epoch 38/168\n",
      "10/10 - 0s - loss: 1.9784e-04 - val_loss: 0.0086 - 79ms/epoch - 8ms/step\n",
      "Epoch 39/168\n",
      "10/10 - 0s - loss: 2.0549e-04 - val_loss: 0.0086 - 79ms/epoch - 8ms/step\n",
      "Epoch 40/168\n",
      "10/10 - 0s - loss: 2.1806e-04 - val_loss: 0.0087 - 82ms/epoch - 8ms/step\n",
      "Epoch 41/168\n",
      "10/10 - 0s - loss: 2.1896e-04 - val_loss: 0.0086 - 93ms/epoch - 9ms/step\n",
      "Epoch 42/168\n",
      "10/10 - 0s - loss: 2.1836e-04 - val_loss: 0.0086 - 82ms/epoch - 8ms/step\n",
      "Epoch 43/168\n",
      "10/10 - 0s - loss: 1.8999e-04 - val_loss: 0.0086 - 82ms/epoch - 8ms/step\n",
      "Epoch 44/168\n",
      "10/10 - 0s - loss: 1.8413e-04 - val_loss: 0.0088 - 105ms/epoch - 11ms/step\n",
      "Epoch 45/168\n",
      "10/10 - 0s - loss: 1.9684e-04 - val_loss: 0.0087 - 91ms/epoch - 9ms/step\n",
      "Epoch 46/168\n",
      "10/10 - 0s - loss: 1.8695e-04 - val_loss: 0.0087 - 80ms/epoch - 8ms/step\n",
      "Epoch 47/168\n",
      "10/10 - 0s - loss: 1.9552e-04 - val_loss: 0.0088 - 81ms/epoch - 8ms/step\n",
      "Epoch 48/168\n",
      "10/10 - 0s - loss: 2.1530e-04 - val_loss: 0.0087 - 94ms/epoch - 9ms/step\n",
      "Epoch 49/168\n",
      "10/10 - 0s - loss: 2.0672e-04 - val_loss: 0.0088 - 81ms/epoch - 8ms/step\n",
      "Epoch 50/168\n",
      "10/10 - 0s - loss: 2.3008e-04 - val_loss: 0.0087 - 80ms/epoch - 8ms/step\n",
      "Epoch 51/168\n",
      "10/10 - 0s - loss: 2.1482e-04 - val_loss: 0.0087 - 89ms/epoch - 9ms/step\n",
      "Epoch 52/168\n",
      "10/10 - 0s - loss: 1.9867e-04 - val_loss: 0.0088 - 80ms/epoch - 8ms/step\n",
      "Epoch 53/168\n",
      "10/10 - 0s - loss: 1.7926e-04 - val_loss: 0.0089 - 80ms/epoch - 8ms/step\n",
      "Epoch 54/168\n",
      "10/10 - 0s - loss: 2.2262e-04 - val_loss: 0.0088 - 134ms/epoch - 13ms/step\n",
      "Epoch 55/168\n",
      "10/10 - 0s - loss: 2.5773e-04 - val_loss: 0.0088 - 83ms/epoch - 8ms/step\n",
      "Epoch 56/168\n",
      "10/10 - 0s - loss: 2.2661e-04 - val_loss: 0.0087 - 81ms/epoch - 8ms/step\n",
      "Epoch 57/168\n",
      "10/10 - 0s - loss: 1.9529e-04 - val_loss: 0.0088 - 94ms/epoch - 9ms/step\n",
      "Epoch 58/168\n",
      "10/10 - 0s - loss: 1.9508e-04 - val_loss: 0.0087 - 80ms/epoch - 8ms/step\n",
      "Epoch 59/168\n",
      "10/10 - 0s - loss: 1.9637e-04 - val_loss: 0.0088 - 79ms/epoch - 8ms/step\n",
      "Epoch 60/168\n",
      "10/10 - 0s - loss: 2.1147e-04 - val_loss: 0.0088 - 92ms/epoch - 9ms/step\n",
      "Epoch 61/168\n",
      "10/10 - 0s - loss: 2.4114e-04 - val_loss: 0.0089 - 81ms/epoch - 8ms/step\n",
      "Epoch 62/168\n",
      "10/10 - 0s - loss: 2.4744e-04 - val_loss: 0.0088 - 81ms/epoch - 8ms/step\n",
      "Epoch 63/168\n",
      "10/10 - 0s - loss: 2.1005e-04 - val_loss: 0.0088 - 116ms/epoch - 12ms/step\n",
      "Epoch 64/168\n",
      "10/10 - 0s - loss: 2.3145e-04 - val_loss: 0.0087 - 87ms/epoch - 9ms/step\n",
      "Epoch 65/168\n",
      "10/10 - 0s - loss: 2.0128e-04 - val_loss: 0.0088 - 82ms/epoch - 8ms/step\n",
      "Epoch 66/168\n",
      "10/10 - 0s - loss: 1.8786e-04 - val_loss: 0.0089 - 90ms/epoch - 9ms/step\n",
      "Epoch 67/168\n",
      "10/10 - 0s - loss: 1.8024e-04 - val_loss: 0.0089 - 80ms/epoch - 8ms/step\n",
      "Epoch 68/168\n",
      "10/10 - 0s - loss: 2.1158e-04 - val_loss: 0.0090 - 81ms/epoch - 8ms/step\n",
      "Epoch 69/168\n",
      "10/10 - 0s - loss: 1.9673e-04 - val_loss: 0.0089 - 94ms/epoch - 9ms/step\n",
      "Epoch 70/168\n",
      "10/10 - 0s - loss: 1.6947e-04 - val_loss: 0.0089 - 79ms/epoch - 8ms/step\n",
      "Epoch 71/168\n",
      "10/10 - 0s - loss: 1.7936e-04 - val_loss: 0.0089 - 81ms/epoch - 8ms/step\n",
      "Epoch 72/168\n",
      "10/10 - 0s - loss: 2.0266e-04 - val_loss: 0.0089 - 89ms/epoch - 9ms/step\n",
      "Epoch 73/168\n",
      "10/10 - 0s - loss: 1.8320e-04 - val_loss: 0.0091 - 81ms/epoch - 8ms/step\n",
      "Epoch 74/168\n",
      "10/10 - 0s - loss: 1.8371e-04 - val_loss: 0.0090 - 79ms/epoch - 8ms/step\n",
      "Epoch 75/168\n",
      "10/10 - 0s - loss: 2.0816e-04 - val_loss: 0.0090 - 130ms/epoch - 13ms/step\n",
      "Epoch 76/168\n",
      "10/10 - 0s - loss: 2.0315e-04 - val_loss: 0.0092 - 81ms/epoch - 8ms/step\n",
      "Epoch 77/168\n",
      "10/10 - 0s - loss: 1.7644e-04 - val_loss: 0.0091 - 82ms/epoch - 8ms/step\n",
      "Epoch 78/168\n",
      "10/10 - 0s - loss: 1.7959e-04 - val_loss: 0.0091 - 80ms/epoch - 8ms/step\n",
      "Epoch 79/168\n",
      "10/10 - 0s - loss: 1.6847e-04 - val_loss: 0.0091 - 93ms/epoch - 9ms/step\n",
      "Epoch 80/168\n",
      "10/10 - 0s - loss: 1.8096e-04 - val_loss: 0.0090 - 80ms/epoch - 8ms/step\n",
      "Epoch 81/168\n",
      "10/10 - 0s - loss: 1.7776e-04 - val_loss: 0.0091 - 80ms/epoch - 8ms/step\n",
      "Epoch 82/168\n",
      "10/10 - 0s - loss: 2.0412e-04 - val_loss: 0.0090 - 95ms/epoch - 9ms/step\n",
      "Epoch 83/168\n",
      "10/10 - 0s - loss: 1.9574e-04 - val_loss: 0.0091 - 82ms/epoch - 8ms/step\n",
      "Epoch 84/168\n",
      "10/10 - 0s - loss: 1.9233e-04 - val_loss: 0.0091 - 81ms/epoch - 8ms/step\n",
      "Epoch 85/168\n",
      "10/10 - 0s - loss: 1.7291e-04 - val_loss: 0.0092 - 87ms/epoch - 9ms/step\n",
      "Epoch 86/168\n",
      "10/10 - 0s - loss: 1.7518e-04 - val_loss: 0.0093 - 140ms/epoch - 14ms/step\n",
      "Epoch 87/168\n",
      "10/10 - 0s - loss: 1.8772e-04 - val_loss: 0.0094 - 86ms/epoch - 9ms/step\n",
      "Epoch 88/168\n",
      "10/10 - 0s - loss: 1.7433e-04 - val_loss: 0.0093 - 87ms/epoch - 9ms/step\n",
      "Epoch 89/168\n",
      "10/10 - 0s - loss: 1.6924e-04 - val_loss: 0.0094 - 100ms/epoch - 10ms/step\n",
      "Epoch 90/168\n",
      "10/10 - 0s - loss: 1.9348e-04 - val_loss: 0.0094 - 83ms/epoch - 8ms/step\n",
      "Epoch 91/168\n",
      "10/10 - 0s - loss: 1.7549e-04 - val_loss: 0.0093 - 80ms/epoch - 8ms/step\n",
      "Epoch 92/168\n",
      "10/10 - 0s - loss: 1.7371e-04 - val_loss: 0.0094 - 93ms/epoch - 9ms/step\n",
      "Epoch 93/168\n",
      "10/10 - 0s - loss: 1.6803e-04 - val_loss: 0.0095 - 79ms/epoch - 8ms/step\n",
      "Epoch 94/168\n",
      "10/10 - 0s - loss: 2.0136e-04 - val_loss: 0.0093 - 79ms/epoch - 8ms/step\n",
      "Epoch 95/168\n",
      "10/10 - 0s - loss: 1.8904e-04 - val_loss: 0.0093 - 91ms/epoch - 9ms/step\n",
      "Epoch 96/168\n",
      "10/10 - 0s - loss: 1.6929e-04 - val_loss: 0.0095 - 79ms/epoch - 8ms/step\n",
      "Epoch 97/168\n",
      "10/10 - 0s - loss: 1.7773e-04 - val_loss: 0.0096 - 97ms/epoch - 10ms/step\n",
      "Epoch 98/168\n",
      "10/10 - 0s - loss: 1.8007e-04 - val_loss: 0.0093 - 104ms/epoch - 10ms/step\n",
      "Epoch 99/168\n",
      "10/10 - 0s - loss: 2.0126e-04 - val_loss: 0.0095 - 82ms/epoch - 8ms/step\n",
      "Epoch 100/168\n",
      "10/10 - 0s - loss: 2.3275e-04 - val_loss: 0.0094 - 80ms/epoch - 8ms/step\n",
      "Epoch 101/168\n",
      "10/10 - 0s - loss: 2.9483e-04 - val_loss: 0.0092 - 88ms/epoch - 9ms/step\n",
      "Epoch 102/168\n",
      "10/10 - 0s - loss: 2.0407e-04 - val_loss: 0.0093 - 80ms/epoch - 8ms/step\n",
      "Epoch 103/168\n",
      "10/10 - 0s - loss: 1.9233e-04 - val_loss: 0.0092 - 79ms/epoch - 8ms/step\n",
      "Epoch 104/168\n",
      "10/10 - 0s - loss: 1.8577e-04 - val_loss: 0.0092 - 79ms/epoch - 8ms/step\n",
      "Epoch 105/168\n",
      "10/10 - 0s - loss: 1.9435e-04 - val_loss: 0.0092 - 94ms/epoch - 9ms/step\n",
      "Epoch 106/168\n",
      "10/10 - 0s - loss: 1.7356e-04 - val_loss: 0.0094 - 80ms/epoch - 8ms/step\n",
      "Epoch 107/168\n",
      "10/10 - 0s - loss: 2.0021e-04 - val_loss: 0.0093 - 79ms/epoch - 8ms/step\n",
      "Epoch 108/168\n",
      "10/10 - 0s - loss: 1.9242e-04 - val_loss: 0.0095 - 125ms/epoch - 12ms/step\n",
      "Epoch 109/168\n",
      "10/10 - 0s - loss: 1.7765e-04 - val_loss: 0.0093 - 82ms/epoch - 8ms/step\n",
      "Epoch 110/168\n",
      "10/10 - 0s - loss: 1.8430e-04 - val_loss: 0.0095 - 80ms/epoch - 8ms/step\n",
      "Epoch 111/168\n",
      "10/10 - 0s - loss: 1.7740e-04 - val_loss: 0.0095 - 92ms/epoch - 9ms/step\n",
      "Epoch 112/168\n",
      "10/10 - 0s - loss: 1.7650e-04 - val_loss: 0.0094 - 80ms/epoch - 8ms/step\n",
      "Epoch 113/168\n",
      "10/10 - 0s - loss: 2.0286e-04 - val_loss: 0.0095 - 79ms/epoch - 8ms/step\n",
      "Epoch 114/168\n",
      "10/10 - 0s - loss: 2.0519e-04 - val_loss: 0.0094 - 94ms/epoch - 9ms/step\n",
      "Epoch 115/168\n",
      "10/10 - 0s - loss: 1.8661e-04 - val_loss: 0.0094 - 83ms/epoch - 8ms/step\n",
      "Epoch 116/168\n",
      "10/10 - 0s - loss: 1.8247e-04 - val_loss: 0.0094 - 80ms/epoch - 8ms/step\n",
      "Epoch 117/168\n",
      "10/10 - 0s - loss: 1.8320e-04 - val_loss: 0.0094 - 106ms/epoch - 11ms/step\n",
      "Epoch 118/168\n",
      "10/10 - 0s - loss: 1.8922e-04 - val_loss: 0.0094 - 89ms/epoch - 9ms/step\n",
      "Epoch 119/168\n",
      "10/10 - 0s - loss: 1.6487e-04 - val_loss: 0.0095 - 80ms/epoch - 8ms/step\n",
      "Epoch 120/168\n",
      "10/10 - 0s - loss: 1.7750e-04 - val_loss: 0.0095 - 91ms/epoch - 9ms/step\n",
      "Epoch 121/168\n",
      "10/10 - 0s - loss: 1.8619e-04 - val_loss: 0.0095 - 82ms/epoch - 8ms/step\n",
      "Epoch 122/168\n",
      "10/10 - 0s - loss: 1.7634e-04 - val_loss: 0.0097 - 80ms/epoch - 8ms/step\n",
      "Epoch 123/168\n",
      "10/10 - 0s - loss: 2.4279e-04 - val_loss: 0.0094 - 80ms/epoch - 8ms/step\n",
      "Epoch 124/168\n",
      "10/10 - 0s - loss: 2.5641e-04 - val_loss: 0.0093 - 89ms/epoch - 9ms/step\n",
      "Epoch 125/168\n",
      "10/10 - 0s - loss: 1.9898e-04 - val_loss: 0.0094 - 81ms/epoch - 8ms/step\n",
      "Epoch 126/168\n",
      "10/10 - 0s - loss: 2.3392e-04 - val_loss: 0.0093 - 80ms/epoch - 8ms/step\n",
      "Epoch 127/168\n",
      "10/10 - 0s - loss: 2.5400e-04 - val_loss: 0.0092 - 87ms/epoch - 9ms/step\n",
      "Epoch 128/168\n",
      "10/10 - 0s - loss: 2.2921e-04 - val_loss: 0.0095 - 103ms/epoch - 10ms/step\n",
      "Epoch 129/168\n",
      "10/10 - 0s - loss: 1.8022e-04 - val_loss: 0.0094 - 82ms/epoch - 8ms/step\n",
      "Epoch 130/168\n",
      "10/10 - 0s - loss: 1.7755e-04 - val_loss: 0.0094 - 90ms/epoch - 9ms/step\n",
      "Epoch 131/168\n",
      "10/10 - 0s - loss: 1.6527e-04 - val_loss: 0.0095 - 80ms/epoch - 8ms/step\n",
      "Epoch 132/168\n",
      "10/10 - 0s - loss: 1.9498e-04 - val_loss: 0.0094 - 81ms/epoch - 8ms/step\n",
      "Epoch 133/168\n",
      "10/10 - 0s - loss: 1.8908e-04 - val_loss: 0.0094 - 90ms/epoch - 9ms/step\n",
      "Epoch 134/168\n",
      "10/10 - 0s - loss: 1.7103e-04 - val_loss: 0.0095 - 81ms/epoch - 8ms/step\n",
      "Epoch 135/168\n",
      "10/10 - 0s - loss: 1.7204e-04 - val_loss: 0.0094 - 78ms/epoch - 8ms/step\n",
      "Epoch 136/168\n",
      "10/10 - 0s - loss: 1.8139e-04 - val_loss: 0.0095 - 91ms/epoch - 9ms/step\n",
      "Epoch 137/168\n",
      "10/10 - 0s - loss: 1.8432e-04 - val_loss: 0.0094 - 79ms/epoch - 8ms/step\n",
      "Epoch 138/168\n",
      "10/10 - 0s - loss: 1.8001e-04 - val_loss: 0.0096 - 100ms/epoch - 10ms/step\n",
      "Epoch 139/168\n",
      "10/10 - 0s - loss: 1.9101e-04 - val_loss: 0.0094 - 99ms/epoch - 10ms/step\n",
      "Epoch 140/168\n",
      "10/10 - 0s - loss: 1.8617e-04 - val_loss: 0.0096 - 82ms/epoch - 8ms/step\n",
      "Epoch 141/168\n",
      "10/10 - 0s - loss: 1.9229e-04 - val_loss: 0.0097 - 84ms/epoch - 8ms/step\n",
      "Epoch 142/168\n",
      "10/10 - 0s - loss: 1.7990e-04 - val_loss: 0.0096 - 93ms/epoch - 9ms/step\n",
      "Epoch 143/168\n",
      "10/10 - 0s - loss: 1.6922e-04 - val_loss: 0.0097 - 81ms/epoch - 8ms/step\n",
      "Epoch 144/168\n",
      "10/10 - 0s - loss: 1.8164e-04 - val_loss: 0.0097 - 81ms/epoch - 8ms/step\n",
      "Epoch 145/168\n",
      "10/10 - 0s - loss: 1.9019e-04 - val_loss: 0.0095 - 93ms/epoch - 9ms/step\n",
      "Epoch 146/168\n",
      "10/10 - 0s - loss: 1.9374e-04 - val_loss: 0.0097 - 78ms/epoch - 8ms/step\n",
      "Epoch 147/168\n",
      "10/10 - 0s - loss: 1.6875e-04 - val_loss: 0.0098 - 81ms/epoch - 8ms/step\n",
      "Epoch 148/168\n",
      "10/10 - 0s - loss: 2.1231e-04 - val_loss: 0.0098 - 81ms/epoch - 8ms/step\n",
      "Epoch 149/168\n",
      "10/10 - 0s - loss: 2.3611e-04 - val_loss: 0.0096 - 132ms/epoch - 13ms/step\n",
      "Epoch 150/168\n",
      "10/10 - 0s - loss: 2.2227e-04 - val_loss: 0.0099 - 80ms/epoch - 8ms/step\n",
      "Epoch 151/168\n",
      "10/10 - 0s - loss: 2.0474e-04 - val_loss: 0.0093 - 80ms/epoch - 8ms/step\n",
      "Epoch 152/168\n",
      "10/10 - 0s - loss: 1.9321e-04 - val_loss: 0.0095 - 78ms/epoch - 8ms/step\n",
      "Epoch 153/168\n",
      "10/10 - 0s - loss: 2.1387e-04 - val_loss: 0.0093 - 93ms/epoch - 9ms/step\n",
      "Epoch 154/168\n",
      "10/10 - 0s - loss: 2.0254e-04 - val_loss: 0.0095 - 80ms/epoch - 8ms/step\n",
      "Epoch 155/168\n",
      "10/10 - 0s - loss: 1.6712e-04 - val_loss: 0.0094 - 80ms/epoch - 8ms/step\n",
      "Epoch 156/168\n",
      "10/10 - 0s - loss: 1.6563e-04 - val_loss: 0.0095 - 96ms/epoch - 10ms/step\n",
      "Epoch 157/168\n",
      "10/10 - 0s - loss: 1.7705e-04 - val_loss: 0.0095 - 80ms/epoch - 8ms/step\n",
      "Epoch 158/168\n",
      "10/10 - 0s - loss: 1.6809e-04 - val_loss: 0.0096 - 102ms/epoch - 10ms/step\n",
      "Epoch 159/168\n",
      "10/10 - 0s - loss: 1.7154e-04 - val_loss: 0.0095 - 92ms/epoch - 9ms/step\n",
      "Epoch 160/168\n",
      "10/10 - 0s - loss: 2.3657e-04 - val_loss: 0.0095 - 80ms/epoch - 8ms/step\n",
      "Epoch 161/168\n",
      "10/10 - 0s - loss: 2.1617e-04 - val_loss: 0.0095 - 79ms/epoch - 8ms/step\n",
      "Epoch 162/168\n",
      "10/10 - 0s - loss: 2.2377e-04 - val_loss: 0.0094 - 79ms/epoch - 8ms/step\n",
      "Epoch 163/168\n",
      "10/10 - 0s - loss: 2.0509e-04 - val_loss: 0.0097 - 93ms/epoch - 9ms/step\n",
      "Epoch 164/168\n",
      "10/10 - 0s - loss: 1.7272e-04 - val_loss: 0.0094 - 80ms/epoch - 8ms/step\n",
      "Epoch 165/168\n",
      "10/10 - 0s - loss: 1.9856e-04 - val_loss: 0.0095 - 80ms/epoch - 8ms/step\n",
      "Epoch 166/168\n",
      "10/10 - 0s - loss: 1.7083e-04 - val_loss: 0.0098 - 81ms/epoch - 8ms/step\n",
      "Epoch 167/168\n",
      "10/10 - 0s - loss: 1.8092e-04 - val_loss: 0.0097 - 94ms/epoch - 9ms/step\n",
      "Epoch 168/168\n",
      "10/10 - 0s - loss: 1.9418e-04 - val_loss: 0.0098 - 80ms/epoch - 8ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m-177.2   \u001b[0m | \u001b[0m168.8    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m101.9    \u001b[0m |\n",
      "Model: \"sequential_159\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_581 (LSTM)             (None, 1, 23)             2668      \n",
      "                                                                 \n",
      " dropout_422 (Dropout)       (None, 1, 23)             0         \n",
      "                                                                 \n",
      " lstm_582 (LSTM)             (None, 23)                4324      \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,016\n",
      "Trainable params: 7,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/156\n",
      "10/10 - 4s - loss: 0.0246 - val_loss: 0.0189 - 4s/epoch - 384ms/step\n",
      "Epoch 2/156\n",
      "10/10 - 0s - loss: 0.0047 - val_loss: 0.0178 - 60ms/epoch - 6ms/step\n",
      "Epoch 3/156\n",
      "10/10 - 0s - loss: 0.0032 - val_loss: 0.0135 - 69ms/epoch - 7ms/step\n",
      "Epoch 4/156\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0136 - 61ms/epoch - 6ms/step\n",
      "Epoch 5/156\n",
      "10/10 - 0s - loss: 0.0021 - val_loss: 0.0135 - 61ms/epoch - 6ms/step\n",
      "Epoch 6/156\n",
      "10/10 - 0s - loss: 0.0020 - val_loss: 0.0123 - 60ms/epoch - 6ms/step\n",
      "Epoch 7/156\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0121 - 69ms/epoch - 7ms/step\n",
      "Epoch 8/156\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0109 - 61ms/epoch - 6ms/step\n",
      "Epoch 9/156\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0101 - 61ms/epoch - 6ms/step\n",
      "Epoch 10/156\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0094 - 59ms/epoch - 6ms/step\n",
      "Epoch 11/156\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0088 - 107ms/epoch - 11ms/step\n",
      "Epoch 12/156\n",
      "10/10 - 0s - loss: 8.2845e-04 - val_loss: 0.0084 - 63ms/epoch - 6ms/step\n",
      "Epoch 13/156\n",
      "10/10 - 0s - loss: 6.4460e-04 - val_loss: 0.0084 - 60ms/epoch - 6ms/step\n",
      "Epoch 14/156\n",
      "10/10 - 0s - loss: 6.1834e-04 - val_loss: 0.0085 - 68ms/epoch - 7ms/step\n",
      "Epoch 15/156\n",
      "10/10 - 0s - loss: 5.9897e-04 - val_loss: 0.0087 - 59ms/epoch - 6ms/step\n",
      "Epoch 16/156\n",
      "10/10 - 0s - loss: 5.0079e-04 - val_loss: 0.0089 - 58ms/epoch - 6ms/step\n",
      "Epoch 17/156\n",
      "10/10 - 0s - loss: 4.3791e-04 - val_loss: 0.0090 - 69ms/epoch - 7ms/step\n",
      "Epoch 18/156\n",
      "10/10 - 0s - loss: 4.1990e-04 - val_loss: 0.0090 - 64ms/epoch - 6ms/step\n",
      "Epoch 19/156\n",
      "10/10 - 0s - loss: 4.0872e-04 - val_loss: 0.0090 - 61ms/epoch - 6ms/step\n",
      "Epoch 20/156\n",
      "10/10 - 0s - loss: 3.8018e-04 - val_loss: 0.0091 - 67ms/epoch - 7ms/step\n",
      "Epoch 21/156\n",
      "10/10 - 0s - loss: 3.5669e-04 - val_loss: 0.0090 - 59ms/epoch - 6ms/step\n",
      "Epoch 22/156\n",
      "10/10 - 0s - loss: 3.1499e-04 - val_loss: 0.0093 - 59ms/epoch - 6ms/step\n",
      "Epoch 23/156\n",
      "10/10 - 0s - loss: 3.2300e-04 - val_loss: 0.0095 - 69ms/epoch - 7ms/step\n",
      "Epoch 24/156\n",
      "10/10 - 0s - loss: 3.1989e-04 - val_loss: 0.0092 - 82ms/epoch - 8ms/step\n",
      "Epoch 25/156\n",
      "10/10 - 0s - loss: 2.8644e-04 - val_loss: 0.0092 - 71ms/epoch - 7ms/step\n",
      "Epoch 26/156\n",
      "10/10 - 0s - loss: 2.7855e-04 - val_loss: 0.0092 - 70ms/epoch - 7ms/step\n",
      "Epoch 27/156\n",
      "10/10 - 0s - loss: 2.6695e-04 - val_loss: 0.0093 - 65ms/epoch - 6ms/step\n",
      "Epoch 28/156\n",
      "10/10 - 0s - loss: 2.7222e-04 - val_loss: 0.0093 - 69ms/epoch - 7ms/step\n",
      "Epoch 29/156\n",
      "10/10 - 0s - loss: 2.7221e-04 - val_loss: 0.0095 - 68ms/epoch - 7ms/step\n",
      "Epoch 30/156\n",
      "10/10 - 0s - loss: 2.6921e-04 - val_loss: 0.0094 - 60ms/epoch - 6ms/step\n",
      "Epoch 31/156\n",
      "10/10 - 0s - loss: 2.6681e-04 - val_loss: 0.0093 - 60ms/epoch - 6ms/step\n",
      "Epoch 32/156\n",
      "10/10 - 0s - loss: 2.3947e-04 - val_loss: 0.0094 - 59ms/epoch - 6ms/step\n",
      "Epoch 33/156\n",
      "10/10 - 0s - loss: 2.4967e-04 - val_loss: 0.0096 - 99ms/epoch - 10ms/step\n",
      "Epoch 34/156\n",
      "10/10 - 0s - loss: 2.6068e-04 - val_loss: 0.0094 - 63ms/epoch - 6ms/step\n",
      "Epoch 35/156\n",
      "10/10 - 0s - loss: 2.5239e-04 - val_loss: 0.0092 - 57ms/epoch - 6ms/step\n",
      "Epoch 36/156\n",
      "10/10 - 0s - loss: 2.4788e-04 - val_loss: 0.0093 - 67ms/epoch - 7ms/step\n",
      "Epoch 37/156\n",
      "10/10 - 0s - loss: 2.4733e-04 - val_loss: 0.0094 - 59ms/epoch - 6ms/step\n",
      "Epoch 38/156\n",
      "10/10 - 0s - loss: 2.6679e-04 - val_loss: 0.0093 - 59ms/epoch - 6ms/step\n",
      "Epoch 39/156\n",
      "10/10 - 0s - loss: 2.6807e-04 - val_loss: 0.0096 - 60ms/epoch - 6ms/step\n",
      "Epoch 40/156\n",
      "10/10 - 0s - loss: 2.6559e-04 - val_loss: 0.0095 - 70ms/epoch - 7ms/step\n",
      "Epoch 41/156\n",
      "10/10 - 0s - loss: 2.4542e-04 - val_loss: 0.0096 - 58ms/epoch - 6ms/step\n",
      "Epoch 42/156\n",
      "10/10 - 0s - loss: 2.3927e-04 - val_loss: 0.0095 - 88ms/epoch - 9ms/step\n",
      "Epoch 43/156\n",
      "10/10 - 0s - loss: 2.4935e-04 - val_loss: 0.0096 - 73ms/epoch - 7ms/step\n",
      "Epoch 44/156\n",
      "10/10 - 0s - loss: 2.4041e-04 - val_loss: 0.0096 - 70ms/epoch - 7ms/step\n",
      "Epoch 45/156\n",
      "10/10 - 0s - loss: 2.4721e-04 - val_loss: 0.0092 - 60ms/epoch - 6ms/step\n",
      "Epoch 46/156\n",
      "10/10 - 0s - loss: 3.2656e-04 - val_loss: 0.0096 - 61ms/epoch - 6ms/step\n",
      "Epoch 47/156\n",
      "10/10 - 0s - loss: 3.2213e-04 - val_loss: 0.0092 - 64ms/epoch - 6ms/step\n",
      "Epoch 48/156\n",
      "10/10 - 0s - loss: 2.6393e-04 - val_loss: 0.0091 - 80ms/epoch - 8ms/step\n",
      "Epoch 49/156\n",
      "10/10 - 0s - loss: 2.5612e-04 - val_loss: 0.0093 - 70ms/epoch - 7ms/step\n",
      "Epoch 50/156\n",
      "10/10 - 0s - loss: 2.2594e-04 - val_loss: 0.0094 - 62ms/epoch - 6ms/step\n",
      "Epoch 51/156\n",
      "10/10 - 0s - loss: 2.3501e-04 - val_loss: 0.0092 - 108ms/epoch - 11ms/step\n",
      "Epoch 52/156\n",
      "10/10 - 0s - loss: 2.8390e-04 - val_loss: 0.0096 - 70ms/epoch - 7ms/step\n",
      "Epoch 53/156\n",
      "10/10 - 0s - loss: 2.4559e-04 - val_loss: 0.0091 - 63ms/epoch - 6ms/step\n",
      "Epoch 54/156\n",
      "10/10 - 0s - loss: 2.3359e-04 - val_loss: 0.0092 - 68ms/epoch - 7ms/step\n",
      "Epoch 55/156\n",
      "10/10 - 0s - loss: 2.3495e-04 - val_loss: 0.0093 - 60ms/epoch - 6ms/step\n",
      "Epoch 56/156\n",
      "10/10 - 0s - loss: 2.1541e-04 - val_loss: 0.0093 - 61ms/epoch - 6ms/step\n",
      "Epoch 57/156\n",
      "10/10 - 0s - loss: 2.3937e-04 - val_loss: 0.0091 - 59ms/epoch - 6ms/step\n",
      "Epoch 58/156\n",
      "10/10 - 0s - loss: 2.4121e-04 - val_loss: 0.0092 - 79ms/epoch - 8ms/step\n",
      "Epoch 59/156\n",
      "10/10 - 0s - loss: 2.4345e-04 - val_loss: 0.0091 - 64ms/epoch - 6ms/step\n",
      "Epoch 60/156\n",
      "10/10 - 0s - loss: 2.3318e-04 - val_loss: 0.0097 - 86ms/epoch - 9ms/step\n",
      "Epoch 61/156\n",
      "10/10 - 0s - loss: 2.4370e-04 - val_loss: 0.0092 - 81ms/epoch - 8ms/step\n",
      "Epoch 62/156\n",
      "10/10 - 0s - loss: 2.5093e-04 - val_loss: 0.0093 - 64ms/epoch - 6ms/step\n",
      "Epoch 63/156\n",
      "10/10 - 0s - loss: 2.2896e-04 - val_loss: 0.0092 - 61ms/epoch - 6ms/step\n",
      "Epoch 64/156\n",
      "10/10 - 0s - loss: 2.1872e-04 - val_loss: 0.0093 - 70ms/epoch - 7ms/step\n",
      "Epoch 65/156\n",
      "10/10 - 0s - loss: 2.2594e-04 - val_loss: 0.0094 - 59ms/epoch - 6ms/step\n",
      "Epoch 66/156\n",
      "10/10 - 0s - loss: 2.3826e-04 - val_loss: 0.0091 - 60ms/epoch - 6ms/step\n",
      "Epoch 67/156\n",
      "10/10 - 0s - loss: 2.5078e-04 - val_loss: 0.0093 - 79ms/epoch - 8ms/step\n",
      "Epoch 68/156\n",
      "10/10 - 0s - loss: 2.2746e-04 - val_loss: 0.0093 - 72ms/epoch - 7ms/step\n",
      "Epoch 69/156\n",
      "10/10 - 0s - loss: 2.0787e-04 - val_loss: 0.0094 - 97ms/epoch - 10ms/step\n",
      "Epoch 70/156\n",
      "10/10 - 0s - loss: 2.0599e-04 - val_loss: 0.0092 - 72ms/epoch - 7ms/step\n",
      "Epoch 71/156\n",
      "10/10 - 0s - loss: 2.3513e-04 - val_loss: 0.0093 - 61ms/epoch - 6ms/step\n",
      "Epoch 72/156\n",
      "10/10 - 0s - loss: 2.3003e-04 - val_loss: 0.0092 - 60ms/epoch - 6ms/step\n",
      "Epoch 73/156\n",
      "10/10 - 0s - loss: 2.3270e-04 - val_loss: 0.0092 - 70ms/epoch - 7ms/step\n",
      "Epoch 74/156\n",
      "10/10 - 0s - loss: 2.5201e-04 - val_loss: 0.0093 - 60ms/epoch - 6ms/step\n",
      "Epoch 75/156\n",
      "10/10 - 0s - loss: 2.4277e-04 - val_loss: 0.0093 - 59ms/epoch - 6ms/step\n",
      "Epoch 76/156\n",
      "10/10 - 0s - loss: 2.3453e-04 - val_loss: 0.0092 - 70ms/epoch - 7ms/step\n",
      "Epoch 77/156\n",
      "10/10 - 0s - loss: 2.3891e-04 - val_loss: 0.0091 - 61ms/epoch - 6ms/step\n",
      "Epoch 78/156\n",
      "10/10 - 0s - loss: 2.3340e-04 - val_loss: 0.0094 - 58ms/epoch - 6ms/step\n",
      "Epoch 79/156\n",
      "10/10 - 0s - loss: 2.1491e-04 - val_loss: 0.0093 - 68ms/epoch - 7ms/step\n",
      "Epoch 80/156\n",
      "10/10 - 0s - loss: 2.0210e-04 - val_loss: 0.0091 - 59ms/epoch - 6ms/step\n",
      "Epoch 81/156\n",
      "10/10 - 0s - loss: 2.5114e-04 - val_loss: 0.0092 - 61ms/epoch - 6ms/step\n",
      "Epoch 82/156\n",
      "10/10 - 0s - loss: 2.1813e-04 - val_loss: 0.0093 - 108ms/epoch - 11ms/step\n",
      "Epoch 83/156\n",
      "10/10 - 0s - loss: 2.2835e-04 - val_loss: 0.0093 - 63ms/epoch - 6ms/step\n",
      "Epoch 84/156\n",
      "10/10 - 0s - loss: 2.4160e-04 - val_loss: 0.0092 - 58ms/epoch - 6ms/step\n",
      "Epoch 85/156\n",
      "10/10 - 0s - loss: 2.1677e-04 - val_loss: 0.0091 - 69ms/epoch - 7ms/step\n",
      "Epoch 86/156\n",
      "10/10 - 0s - loss: 2.1651e-04 - val_loss: 0.0093 - 60ms/epoch - 6ms/step\n",
      "Epoch 87/156\n",
      "10/10 - 0s - loss: 2.0929e-04 - val_loss: 0.0094 - 58ms/epoch - 6ms/step\n",
      "Epoch 88/156\n",
      "10/10 - 0s - loss: 2.2988e-04 - val_loss: 0.0091 - 59ms/epoch - 6ms/step\n",
      "Epoch 89/156\n",
      "10/10 - 0s - loss: 2.2578e-04 - val_loss: 0.0092 - 68ms/epoch - 7ms/step\n",
      "Epoch 90/156\n",
      "10/10 - 0s - loss: 2.2385e-04 - val_loss: 0.0092 - 69ms/epoch - 7ms/step\n",
      "Epoch 91/156\n",
      "10/10 - 0s - loss: 2.3512e-04 - val_loss: 0.0091 - 76ms/epoch - 8ms/step\n",
      "Epoch 92/156\n",
      "10/10 - 0s - loss: 2.4495e-04 - val_loss: 0.0092 - 58ms/epoch - 6ms/step\n",
      "Epoch 93/156\n",
      "10/10 - 0s - loss: 2.2812e-04 - val_loss: 0.0092 - 68ms/epoch - 7ms/step\n",
      "Epoch 94/156\n",
      "10/10 - 0s - loss: 2.3095e-04 - val_loss: 0.0091 - 59ms/epoch - 6ms/step\n",
      "Epoch 95/156\n",
      "10/10 - 0s - loss: 2.3090e-04 - val_loss: 0.0090 - 59ms/epoch - 6ms/step\n",
      "Epoch 96/156\n",
      "10/10 - 0s - loss: 2.3474e-04 - val_loss: 0.0091 - 68ms/epoch - 7ms/step\n",
      "Epoch 97/156\n",
      "10/10 - 0s - loss: 2.1104e-04 - val_loss: 0.0092 - 58ms/epoch - 6ms/step\n",
      "Epoch 98/156\n",
      "10/10 - 0s - loss: 2.1867e-04 - val_loss: 0.0093 - 58ms/epoch - 6ms/step\n",
      "Epoch 99/156\n",
      "10/10 - 0s - loss: 2.4989e-04 - val_loss: 0.0092 - 70ms/epoch - 7ms/step\n",
      "Epoch 100/156\n",
      "10/10 - 0s - loss: 2.3943e-04 - val_loss: 0.0091 - 86ms/epoch - 9ms/step\n",
      "Epoch 101/156\n",
      "10/10 - 0s - loss: 2.1524e-04 - val_loss: 0.0091 - 63ms/epoch - 6ms/step\n",
      "Epoch 102/156\n",
      "10/10 - 0s - loss: 2.3449e-04 - val_loss: 0.0090 - 69ms/epoch - 7ms/step\n",
      "Epoch 103/156\n",
      "10/10 - 0s - loss: 2.3803e-04 - val_loss: 0.0092 - 57ms/epoch - 6ms/step\n",
      "Epoch 104/156\n",
      "10/10 - 0s - loss: 2.2287e-04 - val_loss: 0.0092 - 58ms/epoch - 6ms/step\n",
      "Epoch 105/156\n",
      "10/10 - 0s - loss: 2.2526e-04 - val_loss: 0.0091 - 71ms/epoch - 7ms/step\n",
      "Epoch 106/156\n",
      "10/10 - 0s - loss: 2.0732e-04 - val_loss: 0.0091 - 59ms/epoch - 6ms/step\n",
      "Epoch 107/156\n",
      "10/10 - 0s - loss: 2.1073e-04 - val_loss: 0.0093 - 59ms/epoch - 6ms/step\n",
      "Epoch 108/156\n",
      "10/10 - 0s - loss: 2.1371e-04 - val_loss: 0.0092 - 68ms/epoch - 7ms/step\n",
      "Epoch 109/156\n",
      "10/10 - 0s - loss: 2.1909e-04 - val_loss: 0.0091 - 60ms/epoch - 6ms/step\n",
      "Epoch 110/156\n",
      "10/10 - 0s - loss: 2.2193e-04 - val_loss: 0.0091 - 59ms/epoch - 6ms/step\n",
      "Epoch 111/156\n",
      "10/10 - 0s - loss: 2.2045e-04 - val_loss: 0.0094 - 58ms/epoch - 6ms/step\n",
      "Epoch 112/156\n",
      "10/10 - 0s - loss: 2.3311e-04 - val_loss: 0.0091 - 68ms/epoch - 7ms/step\n",
      "Epoch 113/156\n",
      "10/10 - 0s - loss: 2.5384e-04 - val_loss: 0.0091 - 83ms/epoch - 8ms/step\n",
      "Epoch 114/156\n",
      "10/10 - 0s - loss: 2.1426e-04 - val_loss: 0.0091 - 63ms/epoch - 6ms/step\n",
      "Epoch 115/156\n",
      "10/10 - 0s - loss: 2.2369e-04 - val_loss: 0.0093 - 57ms/epoch - 6ms/step\n",
      "Epoch 116/156\n",
      "10/10 - 0s - loss: 2.2589e-04 - val_loss: 0.0091 - 66ms/epoch - 7ms/step\n",
      "Epoch 117/156\n",
      "10/10 - 0s - loss: 2.0821e-04 - val_loss: 0.0092 - 59ms/epoch - 6ms/step\n",
      "Epoch 118/156\n",
      "10/10 - 0s - loss: 2.2820e-04 - val_loss: 0.0093 - 57ms/epoch - 6ms/step\n",
      "Epoch 119/156\n",
      "10/10 - 0s - loss: 2.1610e-04 - val_loss: 0.0090 - 58ms/epoch - 6ms/step\n",
      "Epoch 120/156\n",
      "10/10 - 0s - loss: 2.0458e-04 - val_loss: 0.0092 - 68ms/epoch - 7ms/step\n",
      "Epoch 121/156\n",
      "10/10 - 0s - loss: 2.1356e-04 - val_loss: 0.0091 - 58ms/epoch - 6ms/step\n",
      "Epoch 122/156\n",
      "10/10 - 0s - loss: 2.1884e-04 - val_loss: 0.0090 - 60ms/epoch - 6ms/step\n",
      "Epoch 123/156\n",
      "10/10 - 0s - loss: 2.2162e-04 - val_loss: 0.0091 - 57ms/epoch - 6ms/step\n",
      "Epoch 124/156\n",
      "10/10 - 0s - loss: 2.1765e-04 - val_loss: 0.0091 - 66ms/epoch - 7ms/step\n",
      "Epoch 125/156\n",
      "10/10 - 0s - loss: 2.1190e-04 - val_loss: 0.0091 - 86ms/epoch - 9ms/step\n",
      "Epoch 126/156\n",
      "10/10 - 0s - loss: 2.9862e-04 - val_loss: 0.0089 - 60ms/epoch - 6ms/step\n",
      "Epoch 127/156\n",
      "10/10 - 0s - loss: 2.1139e-04 - val_loss: 0.0092 - 67ms/epoch - 7ms/step\n",
      "Epoch 128/156\n",
      "10/10 - 0s - loss: 2.2342e-04 - val_loss: 0.0092 - 60ms/epoch - 6ms/step\n",
      "Epoch 129/156\n",
      "10/10 - 0s - loss: 2.2928e-04 - val_loss: 0.0090 - 59ms/epoch - 6ms/step\n",
      "Epoch 130/156\n",
      "10/10 - 0s - loss: 2.2423e-04 - val_loss: 0.0090 - 67ms/epoch - 7ms/step\n",
      "Epoch 131/156\n",
      "10/10 - 0s - loss: 2.1100e-04 - val_loss: 0.0090 - 58ms/epoch - 6ms/step\n",
      "Epoch 132/156\n",
      "10/10 - 0s - loss: 2.2844e-04 - val_loss: 0.0092 - 59ms/epoch - 6ms/step\n",
      "Epoch 133/156\n",
      "10/10 - 0s - loss: 2.6692e-04 - val_loss: 0.0090 - 66ms/epoch - 7ms/step\n",
      "Epoch 134/156\n",
      "10/10 - 0s - loss: 2.3723e-04 - val_loss: 0.0091 - 58ms/epoch - 6ms/step\n",
      "Epoch 135/156\n",
      "10/10 - 0s - loss: 2.4978e-04 - val_loss: 0.0089 - 57ms/epoch - 6ms/step\n",
      "Epoch 136/156\n",
      "10/10 - 0s - loss: 2.0652e-04 - val_loss: 0.0089 - 100ms/epoch - 10ms/step\n",
      "Epoch 137/156\n",
      "10/10 - 0s - loss: 2.1405e-04 - val_loss: 0.0091 - 65ms/epoch - 6ms/step\n",
      "Epoch 138/156\n",
      "10/10 - 0s - loss: 2.0544e-04 - val_loss: 0.0089 - 59ms/epoch - 6ms/step\n",
      "Epoch 139/156\n",
      "10/10 - 0s - loss: 2.1871e-04 - val_loss: 0.0090 - 59ms/epoch - 6ms/step\n",
      "Epoch 140/156\n",
      "10/10 - 0s - loss: 2.0957e-04 - val_loss: 0.0089 - 78ms/epoch - 8ms/step\n",
      "Epoch 141/156\n",
      "10/10 - 0s - loss: 2.0945e-04 - val_loss: 0.0091 - 63ms/epoch - 6ms/step\n",
      "Epoch 142/156\n",
      "10/10 - 0s - loss: 2.4092e-04 - val_loss: 0.0090 - 60ms/epoch - 6ms/step\n",
      "Epoch 143/156\n",
      "10/10 - 0s - loss: 2.3289e-04 - val_loss: 0.0089 - 60ms/epoch - 6ms/step\n",
      "Epoch 144/156\n",
      "10/10 - 0s - loss: 2.1874e-04 - val_loss: 0.0090 - 67ms/epoch - 7ms/step\n",
      "Epoch 145/156\n",
      "10/10 - 0s - loss: 2.0935e-04 - val_loss: 0.0089 - 58ms/epoch - 6ms/step\n",
      "Epoch 146/156\n",
      "10/10 - 0s - loss: 2.1052e-04 - val_loss: 0.0090 - 59ms/epoch - 6ms/step\n",
      "Epoch 147/156\n",
      "10/10 - 0s - loss: 2.2668e-04 - val_loss: 0.0089 - 68ms/epoch - 7ms/step\n",
      "Epoch 148/156\n",
      "10/10 - 0s - loss: 2.2242e-04 - val_loss: 0.0089 - 59ms/epoch - 6ms/step\n",
      "Epoch 149/156\n",
      "10/10 - 0s - loss: 2.5971e-04 - val_loss: 0.0089 - 58ms/epoch - 6ms/step\n",
      "Epoch 150/156\n",
      "10/10 - 0s - loss: 2.4961e-04 - val_loss: 0.0089 - 91ms/epoch - 9ms/step\n",
      "Epoch 151/156\n",
      "10/10 - 0s - loss: 2.1149e-04 - val_loss: 0.0089 - 70ms/epoch - 7ms/step\n",
      "Epoch 152/156\n",
      "10/10 - 0s - loss: 2.2642e-04 - val_loss: 0.0089 - 60ms/epoch - 6ms/step\n",
      "Epoch 153/156\n",
      "10/10 - 0s - loss: 2.4276e-04 - val_loss: 0.0087 - 58ms/epoch - 6ms/step\n",
      "Epoch 154/156\n",
      "10/10 - 0s - loss: 2.4071e-04 - val_loss: 0.0087 - 67ms/epoch - 7ms/step\n",
      "Epoch 155/156\n",
      "10/10 - 0s - loss: 2.2454e-04 - val_loss: 0.0089 - 58ms/epoch - 6ms/step\n",
      "Epoch 156/156\n",
      "10/10 - 0s - loss: 2.2462e-04 - val_loss: 0.0088 - 58ms/epoch - 6ms/step\n",
      "9/9 [==============================] - 1s 1ms/step\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m-168.1   \u001b[0m | \u001b[0m156.5    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m23.59    \u001b[0m |\n",
      "Model: \"sequential_160\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_583 (LSTM)             (None, 1, 39)             7020      \n",
      "                                                                 \n",
      " dropout_423 (Dropout)       (None, 1, 39)             0         \n",
      "                                                                 \n",
      " lstm_584 (LSTM)             (None, 39)                12324     \n",
      "                                                                 \n",
      " dense_160 (Dense)           (None, 1)                 40        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,384\n",
      "Trainable params: 19,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "10/10 - 4s - loss: 0.0275 - val_loss: 0.0169 - 4s/epoch - 387ms/step\n",
      "Epoch 2/150\n",
      "10/10 - 0s - loss: 0.0055 - val_loss: 0.0157 - 62ms/epoch - 6ms/step\n",
      "Epoch 3/150\n",
      "10/10 - 0s - loss: 0.0034 - val_loss: 0.0125 - 71ms/epoch - 7ms/step\n",
      "Epoch 4/150\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0121 - 63ms/epoch - 6ms/step\n",
      "Epoch 5/150\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0126 - 61ms/epoch - 6ms/step\n",
      "Epoch 6/150\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0113 - 62ms/epoch - 6ms/step\n",
      "Epoch 7/150\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0111 - 72ms/epoch - 7ms/step\n",
      "Epoch 8/150\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0102 - 63ms/epoch - 6ms/step\n",
      "Epoch 9/150\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0095 - 63ms/epoch - 6ms/step\n",
      "Epoch 10/150\n",
      "10/10 - 0s - loss: 9.9371e-04 - val_loss: 0.0092 - 70ms/epoch - 7ms/step\n",
      "Epoch 11/150\n",
      "10/10 - 0s - loss: 7.8680e-04 - val_loss: 0.0086 - 61ms/epoch - 6ms/step\n",
      "Epoch 12/150\n",
      "10/10 - 0s - loss: 6.9361e-04 - val_loss: 0.0086 - 64ms/epoch - 6ms/step\n",
      "Epoch 13/150\n",
      "10/10 - 0s - loss: 6.0881e-04 - val_loss: 0.0087 - 73ms/epoch - 7ms/step\n",
      "Epoch 14/150\n",
      "10/10 - 0s - loss: 5.1792e-04 - val_loss: 0.0088 - 109ms/epoch - 11ms/step\n",
      "Epoch 15/150\n",
      "10/10 - 0s - loss: 4.4724e-04 - val_loss: 0.0090 - 63ms/epoch - 6ms/step\n",
      "Epoch 16/150\n",
      "10/10 - 0s - loss: 4.8615e-04 - val_loss: 0.0091 - 66ms/epoch - 7ms/step\n",
      "Epoch 17/150\n",
      "10/10 - 0s - loss: 4.1660e-04 - val_loss: 0.0091 - 63ms/epoch - 6ms/step\n",
      "Epoch 18/150\n",
      "10/10 - 0s - loss: 4.6571e-04 - val_loss: 0.0089 - 71ms/epoch - 7ms/step\n",
      "Epoch 19/150\n",
      "10/10 - 0s - loss: 3.8987e-04 - val_loss: 0.0090 - 62ms/epoch - 6ms/step\n",
      "Epoch 20/150\n",
      "10/10 - 0s - loss: 3.9578e-04 - val_loss: 0.0091 - 62ms/epoch - 6ms/step\n",
      "Epoch 21/150\n",
      "10/10 - 0s - loss: 4.2513e-04 - val_loss: 0.0090 - 61ms/epoch - 6ms/step\n",
      "Epoch 22/150\n",
      "10/10 - 0s - loss: 3.3407e-04 - val_loss: 0.0090 - 69ms/epoch - 7ms/step\n",
      "Epoch 23/150\n",
      "10/10 - 0s - loss: 3.6745e-04 - val_loss: 0.0090 - 62ms/epoch - 6ms/step\n",
      "Epoch 24/150\n",
      "10/10 - 0s - loss: 3.2727e-04 - val_loss: 0.0091 - 62ms/epoch - 6ms/step\n",
      "Epoch 25/150\n",
      "10/10 - 0s - loss: 3.3749e-04 - val_loss: 0.0090 - 59ms/epoch - 6ms/step\n",
      "Epoch 26/150\n",
      "10/10 - 0s - loss: 3.2776e-04 - val_loss: 0.0089 - 73ms/epoch - 7ms/step\n",
      "Epoch 27/150\n",
      "10/10 - 0s - loss: 3.1811e-04 - val_loss: 0.0090 - 60ms/epoch - 6ms/step\n",
      "Epoch 28/150\n",
      "10/10 - 0s - loss: 3.1818e-04 - val_loss: 0.0093 - 61ms/epoch - 6ms/step\n",
      "Epoch 29/150\n",
      "10/10 - 0s - loss: 3.3533e-04 - val_loss: 0.0093 - 62ms/epoch - 6ms/step\n",
      "Epoch 30/150\n",
      "10/10 - 0s - loss: 3.0005e-04 - val_loss: 0.0091 - 70ms/epoch - 7ms/step\n",
      "Epoch 31/150\n",
      "10/10 - 0s - loss: 2.9683e-04 - val_loss: 0.0089 - 86ms/epoch - 9ms/step\n",
      "Epoch 32/150\n",
      "10/10 - 0s - loss: 3.0301e-04 - val_loss: 0.0090 - 68ms/epoch - 7ms/step\n",
      "Epoch 33/150\n",
      "10/10 - 0s - loss: 2.7003e-04 - val_loss: 0.0091 - 60ms/epoch - 6ms/step\n",
      "Epoch 34/150\n",
      "10/10 - 0s - loss: 3.0115e-04 - val_loss: 0.0090 - 71ms/epoch - 7ms/step\n",
      "Epoch 35/150\n",
      "10/10 - 0s - loss: 2.8139e-04 - val_loss: 0.0089 - 61ms/epoch - 6ms/step\n",
      "Epoch 36/150\n",
      "10/10 - 0s - loss: 2.5535e-04 - val_loss: 0.0089 - 60ms/epoch - 6ms/step\n",
      "Epoch 37/150\n",
      "10/10 - 0s - loss: 2.5199e-04 - val_loss: 0.0090 - 64ms/epoch - 6ms/step\n",
      "Epoch 38/150\n",
      "10/10 - 0s - loss: 2.5437e-04 - val_loss: 0.0089 - 69ms/epoch - 7ms/step\n",
      "Epoch 39/150\n",
      "10/10 - 0s - loss: 2.7896e-04 - val_loss: 0.0089 - 61ms/epoch - 6ms/step\n",
      "Epoch 40/150\n",
      "10/10 - 0s - loss: 2.7409e-04 - val_loss: 0.0093 - 78ms/epoch - 8ms/step\n",
      "Epoch 41/150\n",
      "10/10 - 0s - loss: 3.0275e-04 - val_loss: 0.0089 - 78ms/epoch - 8ms/step\n",
      "Epoch 42/150\n",
      "10/10 - 0s - loss: 2.5232e-04 - val_loss: 0.0089 - 63ms/epoch - 6ms/step\n",
      "Epoch 43/150\n",
      "10/10 - 0s - loss: 2.4273e-04 - val_loss: 0.0088 - 60ms/epoch - 6ms/step\n",
      "Epoch 44/150\n",
      "10/10 - 0s - loss: 2.4668e-04 - val_loss: 0.0088 - 61ms/epoch - 6ms/step\n",
      "Epoch 45/150\n",
      "10/10 - 0s - loss: 2.3912e-04 - val_loss: 0.0088 - 69ms/epoch - 7ms/step\n",
      "Epoch 46/150\n",
      "10/10 - 0s - loss: 2.4909e-04 - val_loss: 0.0089 - 61ms/epoch - 6ms/step\n",
      "Epoch 47/150\n",
      "10/10 - 0s - loss: 2.5409e-04 - val_loss: 0.0089 - 62ms/epoch - 6ms/step\n",
      "Epoch 48/150\n",
      "10/10 - 0s - loss: 2.4259e-04 - val_loss: 0.0089 - 61ms/epoch - 6ms/step\n",
      "Epoch 49/150\n",
      "10/10 - 0s - loss: 2.5796e-04 - val_loss: 0.0088 - 93ms/epoch - 9ms/step\n",
      "Epoch 50/150\n",
      "10/10 - 0s - loss: 2.5582e-04 - val_loss: 0.0087 - 70ms/epoch - 7ms/step\n",
      "Epoch 51/150\n",
      "10/10 - 0s - loss: 2.6708e-04 - val_loss: 0.0089 - 61ms/epoch - 6ms/step\n",
      "Epoch 52/150\n",
      "10/10 - 0s - loss: 2.2368e-04 - val_loss: 0.0088 - 61ms/epoch - 6ms/step\n",
      "Epoch 53/150\n",
      "10/10 - 0s - loss: 2.5924e-04 - val_loss: 0.0088 - 71ms/epoch - 7ms/step\n",
      "Epoch 54/150\n",
      "10/10 - 0s - loss: 2.5644e-04 - val_loss: 0.0089 - 60ms/epoch - 6ms/step\n",
      "Epoch 55/150\n",
      "10/10 - 0s - loss: 2.3902e-04 - val_loss: 0.0087 - 62ms/epoch - 6ms/step\n",
      "Epoch 56/150\n",
      "10/10 - 0s - loss: 2.6154e-04 - val_loss: 0.0087 - 62ms/epoch - 6ms/step\n",
      "Epoch 57/150\n",
      "10/10 - 0s - loss: 2.3479e-04 - val_loss: 0.0090 - 88ms/epoch - 9ms/step\n",
      "Epoch 58/150\n",
      "10/10 - 0s - loss: 2.4452e-04 - val_loss: 0.0088 - 73ms/epoch - 7ms/step\n",
      "Epoch 59/150\n",
      "10/10 - 0s - loss: 2.3028e-04 - val_loss: 0.0087 - 62ms/epoch - 6ms/step\n",
      "Epoch 60/150\n",
      "10/10 - 0s - loss: 2.2452e-04 - val_loss: 0.0087 - 61ms/epoch - 6ms/step\n",
      "Epoch 61/150\n",
      "10/10 - 0s - loss: 2.2857e-04 - val_loss: 0.0087 - 74ms/epoch - 7ms/step\n",
      "Epoch 62/150\n",
      "10/10 - 0s - loss: 2.3741e-04 - val_loss: 0.0087 - 63ms/epoch - 6ms/step\n",
      "Epoch 63/150\n",
      "10/10 - 0s - loss: 2.4602e-04 - val_loss: 0.0089 - 62ms/epoch - 6ms/step\n",
      "Epoch 64/150\n",
      "10/10 - 0s - loss: 2.4686e-04 - val_loss: 0.0086 - 64ms/epoch - 6ms/step\n",
      "Epoch 65/150\n",
      "10/10 - 0s - loss: 2.3376e-04 - val_loss: 0.0087 - 73ms/epoch - 7ms/step\n",
      "Epoch 66/150\n",
      "10/10 - 0s - loss: 2.2520e-04 - val_loss: 0.0088 - 79ms/epoch - 8ms/step\n",
      "Epoch 67/150\n",
      "10/10 - 0s - loss: 2.2640e-04 - val_loss: 0.0086 - 74ms/epoch - 7ms/step\n",
      "Epoch 68/150\n",
      "10/10 - 0s - loss: 2.4183e-04 - val_loss: 0.0089 - 62ms/epoch - 6ms/step\n",
      "Epoch 69/150\n",
      "10/10 - 0s - loss: 2.1366e-04 - val_loss: 0.0088 - 75ms/epoch - 8ms/step\n",
      "Epoch 70/150\n",
      "10/10 - 0s - loss: 2.2307e-04 - val_loss: 0.0087 - 62ms/epoch - 6ms/step\n",
      "Epoch 71/150\n",
      "10/10 - 0s - loss: 2.0864e-04 - val_loss: 0.0087 - 61ms/epoch - 6ms/step\n",
      "Epoch 72/150\n",
      "10/10 - 0s - loss: 2.2236e-04 - val_loss: 0.0087 - 60ms/epoch - 6ms/step\n",
      "Epoch 73/150\n",
      "10/10 - 0s - loss: 2.2665e-04 - val_loss: 0.0089 - 70ms/epoch - 7ms/step\n",
      "Epoch 74/150\n",
      "10/10 - 0s - loss: 2.4304e-04 - val_loss: 0.0088 - 61ms/epoch - 6ms/step\n",
      "Epoch 75/150\n",
      "10/10 - 0s - loss: 2.4053e-04 - val_loss: 0.0088 - 61ms/epoch - 6ms/step\n",
      "Epoch 76/150\n",
      "10/10 - 0s - loss: 2.2606e-04 - val_loss: 0.0087 - 73ms/epoch - 7ms/step\n",
      "Epoch 77/150\n",
      "10/10 - 0s - loss: 2.0921e-04 - val_loss: 0.0087 - 60ms/epoch - 6ms/step\n",
      "Epoch 78/150\n",
      "10/10 - 0s - loss: 2.1000e-04 - val_loss: 0.0090 - 75ms/epoch - 7ms/step\n",
      "Epoch 79/150\n",
      "10/10 - 0s - loss: 2.3485e-04 - val_loss: 0.0087 - 72ms/epoch - 7ms/step\n",
      "Epoch 80/150\n",
      "10/10 - 0s - loss: 2.2107e-04 - val_loss: 0.0088 - 74ms/epoch - 7ms/step\n",
      "Epoch 81/150\n",
      "10/10 - 0s - loss: 2.1818e-04 - val_loss: 0.0090 - 63ms/epoch - 6ms/step\n",
      "Epoch 82/150\n",
      "10/10 - 0s - loss: 2.1616e-04 - val_loss: 0.0087 - 62ms/epoch - 6ms/step\n",
      "Epoch 83/150\n",
      "10/10 - 0s - loss: 2.0340e-04 - val_loss: 0.0088 - 60ms/epoch - 6ms/step\n",
      "Epoch 84/150\n",
      "10/10 - 0s - loss: 2.0841e-04 - val_loss: 0.0091 - 73ms/epoch - 7ms/step\n",
      "Epoch 85/150\n",
      "10/10 - 0s - loss: 2.2383e-04 - val_loss: 0.0087 - 61ms/epoch - 6ms/step\n",
      "Epoch 86/150\n",
      "10/10 - 0s - loss: 2.1320e-04 - val_loss: 0.0088 - 61ms/epoch - 6ms/step\n",
      "Epoch 87/150\n",
      "10/10 - 0s - loss: 2.1431e-04 - val_loss: 0.0089 - 60ms/epoch - 6ms/step\n",
      "Epoch 88/150\n",
      "10/10 - 0s - loss: 1.9915e-04 - val_loss: 0.0089 - 109ms/epoch - 11ms/step\n",
      "Epoch 89/150\n",
      "10/10 - 0s - loss: 2.0752e-04 - val_loss: 0.0087 - 66ms/epoch - 7ms/step\n",
      "Epoch 90/150\n",
      "10/10 - 0s - loss: 2.0986e-04 - val_loss: 0.0088 - 62ms/epoch - 6ms/step\n",
      "Epoch 91/150\n",
      "10/10 - 0s - loss: 2.1202e-04 - val_loss: 0.0089 - 61ms/epoch - 6ms/step\n",
      "Epoch 92/150\n",
      "10/10 - 0s - loss: 2.0645e-04 - val_loss: 0.0090 - 68ms/epoch - 7ms/step\n",
      "Epoch 93/150\n",
      "10/10 - 0s - loss: 2.0673e-04 - val_loss: 0.0088 - 63ms/epoch - 6ms/step\n",
      "Epoch 94/150\n",
      "10/10 - 0s - loss: 2.0150e-04 - val_loss: 0.0090 - 62ms/epoch - 6ms/step\n",
      "Epoch 95/150\n",
      "10/10 - 0s - loss: 2.0933e-04 - val_loss: 0.0089 - 77ms/epoch - 8ms/step\n",
      "Epoch 96/150\n",
      "10/10 - 0s - loss: 2.2314e-04 - val_loss: 0.0090 - 78ms/epoch - 8ms/step\n",
      "Epoch 97/150\n",
      "10/10 - 0s - loss: 2.2484e-04 - val_loss: 0.0088 - 90ms/epoch - 9ms/step\n",
      "Epoch 98/150\n",
      "10/10 - 0s - loss: 2.0118e-04 - val_loss: 0.0090 - 84ms/epoch - 8ms/step\n",
      "Epoch 99/150\n",
      "10/10 - 0s - loss: 2.0458e-04 - val_loss: 0.0089 - 70ms/epoch - 7ms/step\n",
      "Epoch 100/150\n",
      "10/10 - 0s - loss: 2.0385e-04 - val_loss: 0.0090 - 72ms/epoch - 7ms/step\n",
      "Epoch 101/150\n",
      "10/10 - 0s - loss: 2.1456e-04 - val_loss: 0.0089 - 81ms/epoch - 8ms/step\n",
      "Epoch 102/150\n",
      "10/10 - 0s - loss: 2.1159e-04 - val_loss: 0.0090 - 67ms/epoch - 7ms/step\n",
      "Epoch 103/150\n",
      "10/10 - 0s - loss: 2.0874e-04 - val_loss: 0.0090 - 73ms/epoch - 7ms/step\n",
      "Epoch 104/150\n",
      "10/10 - 0s - loss: 2.0552e-04 - val_loss: 0.0089 - 81ms/epoch - 8ms/step\n",
      "Epoch 105/150\n",
      "10/10 - 0s - loss: 2.0999e-04 - val_loss: 0.0089 - 68ms/epoch - 7ms/step\n",
      "Epoch 106/150\n",
      "10/10 - 0s - loss: 2.0806e-04 - val_loss: 0.0091 - 63ms/epoch - 6ms/step\n",
      "Epoch 107/150\n",
      "10/10 - 0s - loss: 1.9099e-04 - val_loss: 0.0090 - 81ms/epoch - 8ms/step\n",
      "Epoch 108/150\n",
      "10/10 - 0s - loss: 2.0782e-04 - val_loss: 0.0090 - 76ms/epoch - 8ms/step\n",
      "Epoch 109/150\n",
      "10/10 - 0s - loss: 1.8983e-04 - val_loss: 0.0089 - 83ms/epoch - 8ms/step\n",
      "Epoch 110/150\n",
      "10/10 - 0s - loss: 2.1717e-04 - val_loss: 0.0090 - 64ms/epoch - 6ms/step\n",
      "Epoch 111/150\n",
      "10/10 - 0s - loss: 2.5441e-04 - val_loss: 0.0089 - 84ms/epoch - 8ms/step\n",
      "Epoch 112/150\n",
      "10/10 - 0s - loss: 2.1994e-04 - val_loss: 0.0089 - 66ms/epoch - 7ms/step\n",
      "Epoch 113/150\n",
      "10/10 - 0s - loss: 2.1912e-04 - val_loss: 0.0091 - 66ms/epoch - 7ms/step\n",
      "Epoch 114/150\n",
      "10/10 - 0s - loss: 1.9519e-04 - val_loss: 0.0092 - 76ms/epoch - 8ms/step\n",
      "Epoch 115/150\n",
      "10/10 - 0s - loss: 1.9498e-04 - val_loss: 0.0089 - 73ms/epoch - 7ms/step\n",
      "Epoch 116/150\n",
      "10/10 - 0s - loss: 1.9511e-04 - val_loss: 0.0090 - 87ms/epoch - 9ms/step\n",
      "Epoch 117/150\n",
      "10/10 - 0s - loss: 1.9980e-04 - val_loss: 0.0091 - 76ms/epoch - 8ms/step\n",
      "Epoch 118/150\n",
      "10/10 - 0s - loss: 1.9361e-04 - val_loss: 0.0091 - 64ms/epoch - 6ms/step\n",
      "Epoch 119/150\n",
      "10/10 - 0s - loss: 1.9500e-04 - val_loss: 0.0091 - 60ms/epoch - 6ms/step\n",
      "Epoch 120/150\n",
      "10/10 - 0s - loss: 2.0421e-04 - val_loss: 0.0093 - 60ms/epoch - 6ms/step\n",
      "Epoch 121/150\n",
      "10/10 - 0s - loss: 2.3133e-04 - val_loss: 0.0090 - 72ms/epoch - 7ms/step\n",
      "Epoch 122/150\n",
      "10/10 - 0s - loss: 1.9712e-04 - val_loss: 0.0090 - 65ms/epoch - 6ms/step\n",
      "Epoch 123/150\n",
      "10/10 - 0s - loss: 2.0228e-04 - val_loss: 0.0092 - 66ms/epoch - 7ms/step\n",
      "Epoch 124/150\n",
      "10/10 - 0s - loss: 2.0329e-04 - val_loss: 0.0092 - 96ms/epoch - 10ms/step\n",
      "Epoch 125/150\n",
      "10/10 - 0s - loss: 1.9454e-04 - val_loss: 0.0092 - 78ms/epoch - 8ms/step\n",
      "Epoch 126/150\n",
      "10/10 - 0s - loss: 1.9698e-04 - val_loss: 0.0091 - 66ms/epoch - 7ms/step\n",
      "Epoch 127/150\n",
      "10/10 - 0s - loss: 1.9006e-04 - val_loss: 0.0093 - 76ms/epoch - 8ms/step\n",
      "Epoch 128/150\n",
      "10/10 - 0s - loss: 1.9725e-04 - val_loss: 0.0092 - 65ms/epoch - 6ms/step\n",
      "Epoch 129/150\n",
      "10/10 - 0s - loss: 1.9537e-04 - val_loss: 0.0092 - 66ms/epoch - 7ms/step\n",
      "Epoch 130/150\n",
      "10/10 - 0s - loss: 1.8847e-04 - val_loss: 0.0092 - 78ms/epoch - 8ms/step\n",
      "Epoch 131/150\n",
      "10/10 - 0s - loss: 2.1113e-04 - val_loss: 0.0092 - 65ms/epoch - 7ms/step\n",
      "Epoch 132/150\n",
      "10/10 - 0s - loss: 2.3106e-04 - val_loss: 0.0095 - 68ms/epoch - 7ms/step\n",
      "Epoch 133/150\n",
      "10/10 - 0s - loss: 2.3254e-04 - val_loss: 0.0091 - 82ms/epoch - 8ms/step\n",
      "Epoch 134/150\n",
      "10/10 - 0s - loss: 2.4348e-04 - val_loss: 0.0092 - 94ms/epoch - 9ms/step\n",
      "Epoch 135/150\n",
      "10/10 - 0s - loss: 2.0892e-04 - val_loss: 0.0093 - 79ms/epoch - 8ms/step\n",
      "Epoch 136/150\n",
      "10/10 - 0s - loss: 1.9278e-04 - val_loss: 0.0091 - 84ms/epoch - 8ms/step\n",
      "Epoch 137/150\n",
      "10/10 - 0s - loss: 2.0340e-04 - val_loss: 0.0092 - 66ms/epoch - 7ms/step\n",
      "Epoch 138/150\n",
      "10/10 - 0s - loss: 2.3823e-04 - val_loss: 0.0091 - 66ms/epoch - 7ms/step\n",
      "Epoch 139/150\n",
      "10/10 - 0s - loss: 2.2778e-04 - val_loss: 0.0091 - 89ms/epoch - 9ms/step\n",
      "Epoch 140/150\n",
      "10/10 - 0s - loss: 1.8021e-04 - val_loss: 0.0092 - 81ms/epoch - 8ms/step\n",
      "Epoch 141/150\n",
      "10/10 - 0s - loss: 1.8524e-04 - val_loss: 0.0093 - 67ms/epoch - 7ms/step\n",
      "Epoch 142/150\n",
      "10/10 - 0s - loss: 1.8924e-04 - val_loss: 0.0092 - 76ms/epoch - 8ms/step\n",
      "Epoch 143/150\n",
      "10/10 - 0s - loss: 1.9740e-04 - val_loss: 0.0092 - 66ms/epoch - 7ms/step\n",
      "Epoch 144/150\n",
      "10/10 - 0s - loss: 1.8985e-04 - val_loss: 0.0092 - 64ms/epoch - 6ms/step\n",
      "Epoch 145/150\n",
      "10/10 - 0s - loss: 1.9348e-04 - val_loss: 0.0093 - 77ms/epoch - 8ms/step\n",
      "Epoch 146/150\n",
      "10/10 - 0s - loss: 1.9731e-04 - val_loss: 0.0093 - 67ms/epoch - 7ms/step\n",
      "Epoch 147/150\n",
      "10/10 - 0s - loss: 1.8817e-04 - val_loss: 0.0093 - 63ms/epoch - 6ms/step\n",
      "Epoch 148/150\n",
      "10/10 - 0s - loss: 1.9589e-04 - val_loss: 0.0093 - 74ms/epoch - 7ms/step\n",
      "Epoch 149/150\n",
      "10/10 - 0s - loss: 1.9604e-04 - val_loss: 0.0092 - 63ms/epoch - 6ms/step\n",
      "Epoch 150/150\n",
      "10/10 - 0s - loss: 1.8979e-04 - val_loss: 0.0092 - 65ms/epoch - 7ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m-171.5   \u001b[0m | \u001b[0m150.1    \u001b[0m | \u001b[0m1.871    \u001b[0m | \u001b[0m0.00626  \u001b[0m | \u001b[0m39.26    \u001b[0m |\n",
      "Model: \"sequential_161\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_585 (LSTM)             (None, 1, 48)             10368     \n",
      "                                                                 \n",
      " dropout_424 (Dropout)       (None, 1, 48)             0         \n",
      "                                                                 \n",
      " lstm_586 (LSTM)             (None, 48)                18624     \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 1)                 49        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,041\n",
      "Trainable params: 29,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/136\n",
      "10/10 - 4s - loss: 0.0204 - val_loss: 0.0123 - 4s/epoch - 395ms/step\n",
      "Epoch 2/136\n",
      "10/10 - 0s - loss: 0.0038 - val_loss: 0.0126 - 65ms/epoch - 6ms/step\n",
      "Epoch 3/136\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0138 - 71ms/epoch - 7ms/step\n",
      "Epoch 4/136\n",
      "10/10 - 0s - loss: 0.0021 - val_loss: 0.0121 - 64ms/epoch - 6ms/step\n",
      "Epoch 5/136\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0119 - 65ms/epoch - 6ms/step\n",
      "Epoch 6/136\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0104 - 67ms/epoch - 7ms/step\n",
      "Epoch 7/136\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0095 - 107ms/epoch - 11ms/step\n",
      "Epoch 8/136\n",
      "10/10 - 0s - loss: 9.4024e-04 - val_loss: 0.0088 - 65ms/epoch - 7ms/step\n",
      "Epoch 9/136\n",
      "10/10 - 0s - loss: 6.7653e-04 - val_loss: 0.0084 - 63ms/epoch - 6ms/step\n",
      "Epoch 10/136\n",
      "10/10 - 0s - loss: 5.3462e-04 - val_loss: 0.0086 - 74ms/epoch - 7ms/step\n",
      "Epoch 11/136\n",
      "10/10 - 0s - loss: 4.6016e-04 - val_loss: 0.0088 - 64ms/epoch - 6ms/step\n",
      "Epoch 12/136\n",
      "10/10 - 0s - loss: 3.8055e-04 - val_loss: 0.0088 - 65ms/epoch - 6ms/step\n",
      "Epoch 13/136\n",
      "10/10 - 0s - loss: 3.7837e-04 - val_loss: 0.0088 - 76ms/epoch - 8ms/step\n",
      "Epoch 14/136\n",
      "10/10 - 0s - loss: 3.6731e-04 - val_loss: 0.0086 - 64ms/epoch - 6ms/step\n",
      "Epoch 15/136\n",
      "10/10 - 0s - loss: 3.5351e-04 - val_loss: 0.0087 - 100ms/epoch - 10ms/step\n",
      "Epoch 16/136\n",
      "10/10 - 0s - loss: 3.1462e-04 - val_loss: 0.0087 - 86ms/epoch - 9ms/step\n",
      "Epoch 17/136\n",
      "10/10 - 0s - loss: 3.0878e-04 - val_loss: 0.0087 - 64ms/epoch - 6ms/step\n",
      "Epoch 18/136\n",
      "10/10 - 0s - loss: 3.3788e-04 - val_loss: 0.0086 - 79ms/epoch - 8ms/step\n",
      "Epoch 19/136\n",
      "10/10 - 0s - loss: 3.0861e-04 - val_loss: 0.0089 - 68ms/epoch - 7ms/step\n",
      "Epoch 20/136\n",
      "10/10 - 0s - loss: 2.9475e-04 - val_loss: 0.0088 - 64ms/epoch - 6ms/step\n",
      "Epoch 21/136\n",
      "10/10 - 0s - loss: 2.5275e-04 - val_loss: 0.0088 - 73ms/epoch - 7ms/step\n",
      "Epoch 22/136\n",
      "10/10 - 0s - loss: 2.5539e-04 - val_loss: 0.0090 - 62ms/epoch - 6ms/step\n",
      "Epoch 23/136\n",
      "10/10 - 0s - loss: 2.6778e-04 - val_loss: 0.0086 - 65ms/epoch - 7ms/step\n",
      "Epoch 24/136\n",
      "10/10 - 0s - loss: 2.5079e-04 - val_loss: 0.0087 - 72ms/epoch - 7ms/step\n",
      "Epoch 25/136\n",
      "10/10 - 0s - loss: 2.3946e-04 - val_loss: 0.0089 - 66ms/epoch - 7ms/step\n",
      "Epoch 26/136\n",
      "10/10 - 0s - loss: 2.5938e-04 - val_loss: 0.0087 - 62ms/epoch - 6ms/step\n",
      "Epoch 27/136\n",
      "10/10 - 0s - loss: 2.8581e-04 - val_loss: 0.0087 - 122ms/epoch - 12ms/step\n",
      "Epoch 28/136\n",
      "10/10 - 0s - loss: 2.3671e-04 - val_loss: 0.0088 - 72ms/epoch - 7ms/step\n",
      "Epoch 29/136\n",
      "10/10 - 0s - loss: 2.1794e-04 - val_loss: 0.0088 - 60ms/epoch - 6ms/step\n",
      "Epoch 30/136\n",
      "10/10 - 0s - loss: 2.2806e-04 - val_loss: 0.0090 - 61ms/epoch - 6ms/step\n",
      "Epoch 31/136\n",
      "10/10 - 0s - loss: 2.4104e-04 - val_loss: 0.0086 - 71ms/epoch - 7ms/step\n",
      "Epoch 32/136\n",
      "10/10 - 0s - loss: 2.3939e-04 - val_loss: 0.0090 - 68ms/epoch - 7ms/step\n",
      "Epoch 33/136\n",
      "10/10 - 0s - loss: 2.4543e-04 - val_loss: 0.0088 - 70ms/epoch - 7ms/step\n",
      "Epoch 34/136\n",
      "10/10 - 0s - loss: 2.2697e-04 - val_loss: 0.0088 - 75ms/epoch - 8ms/step\n",
      "Epoch 35/136\n",
      "10/10 - 0s - loss: 2.3861e-04 - val_loss: 0.0088 - 77ms/epoch - 8ms/step\n",
      "Epoch 36/136\n",
      "10/10 - 0s - loss: 2.1269e-04 - val_loss: 0.0088 - 65ms/epoch - 7ms/step\n",
      "Epoch 37/136\n",
      "10/10 - 0s - loss: 2.0780e-04 - val_loss: 0.0090 - 89ms/epoch - 9ms/step\n",
      "Epoch 38/136\n",
      "10/10 - 0s - loss: 2.1559e-04 - val_loss: 0.0088 - 76ms/epoch - 8ms/step\n",
      "Epoch 39/136\n",
      "10/10 - 0s - loss: 2.2995e-04 - val_loss: 0.0090 - 63ms/epoch - 6ms/step\n",
      "Epoch 40/136\n",
      "10/10 - 0s - loss: 2.2399e-04 - val_loss: 0.0088 - 62ms/epoch - 6ms/step\n",
      "Epoch 41/136\n",
      "10/10 - 0s - loss: 2.1609e-04 - val_loss: 0.0090 - 70ms/epoch - 7ms/step\n",
      "Epoch 42/136\n",
      "10/10 - 0s - loss: 2.2492e-04 - val_loss: 0.0090 - 62ms/epoch - 6ms/step\n",
      "Epoch 43/136\n",
      "10/10 - 0s - loss: 2.2442e-04 - val_loss: 0.0087 - 62ms/epoch - 6ms/step\n",
      "Epoch 44/136\n",
      "10/10 - 0s - loss: 2.1474e-04 - val_loss: 0.0088 - 61ms/epoch - 6ms/step\n",
      "Epoch 45/136\n",
      "10/10 - 0s - loss: 2.3246e-04 - val_loss: 0.0089 - 71ms/epoch - 7ms/step\n",
      "Epoch 46/136\n",
      "10/10 - 0s - loss: 2.1856e-04 - val_loss: 0.0088 - 63ms/epoch - 6ms/step\n",
      "Epoch 47/136\n",
      "10/10 - 0s - loss: 2.2600e-04 - val_loss: 0.0088 - 63ms/epoch - 6ms/step\n",
      "Epoch 48/136\n",
      "10/10 - 0s - loss: 2.3270e-04 - val_loss: 0.0088 - 73ms/epoch - 7ms/step\n",
      "Epoch 49/136\n",
      "10/10 - 0s - loss: 2.0284e-04 - val_loss: 0.0090 - 84ms/epoch - 8ms/step\n",
      "Epoch 50/136\n",
      "10/10 - 0s - loss: 2.1599e-04 - val_loss: 0.0089 - 67ms/epoch - 7ms/step\n",
      "Epoch 51/136\n",
      "10/10 - 0s - loss: 2.2239e-04 - val_loss: 0.0089 - 64ms/epoch - 6ms/step\n",
      "Epoch 52/136\n",
      "10/10 - 0s - loss: 2.2634e-04 - val_loss: 0.0090 - 72ms/epoch - 7ms/step\n",
      "Epoch 53/136\n",
      "10/10 - 0s - loss: 1.9929e-04 - val_loss: 0.0090 - 63ms/epoch - 6ms/step\n",
      "Epoch 54/136\n",
      "10/10 - 0s - loss: 2.0099e-04 - val_loss: 0.0090 - 62ms/epoch - 6ms/step\n",
      "Epoch 55/136\n",
      "10/10 - 0s - loss: 2.0032e-04 - val_loss: 0.0090 - 75ms/epoch - 7ms/step\n",
      "Epoch 56/136\n",
      "10/10 - 0s - loss: 2.0850e-04 - val_loss: 0.0090 - 64ms/epoch - 6ms/step\n",
      "Epoch 57/136\n",
      "10/10 - 0s - loss: 2.0847e-04 - val_loss: 0.0090 - 64ms/epoch - 6ms/step\n",
      "Epoch 58/136\n",
      "10/10 - 0s - loss: 1.9978e-04 - val_loss: 0.0091 - 64ms/epoch - 6ms/step\n",
      "Epoch 59/136\n",
      "10/10 - 0s - loss: 2.0646e-04 - val_loss: 0.0091 - 99ms/epoch - 10ms/step\n",
      "Epoch 60/136\n",
      "10/10 - 0s - loss: 2.0518e-04 - val_loss: 0.0091 - 74ms/epoch - 7ms/step\n",
      "Epoch 61/136\n",
      "10/10 - 0s - loss: 2.0542e-04 - val_loss: 0.0089 - 61ms/epoch - 6ms/step\n",
      "Epoch 62/136\n",
      "10/10 - 0s - loss: 2.0918e-04 - val_loss: 0.0091 - 64ms/epoch - 6ms/step\n",
      "Epoch 63/136\n",
      "10/10 - 0s - loss: 2.1230e-04 - val_loss: 0.0092 - 76ms/epoch - 8ms/step\n",
      "Epoch 64/136\n",
      "10/10 - 0s - loss: 2.0061e-04 - val_loss: 0.0091 - 65ms/epoch - 7ms/step\n",
      "Epoch 65/136\n",
      "10/10 - 0s - loss: 2.1008e-04 - val_loss: 0.0091 - 75ms/epoch - 8ms/step\n",
      "Epoch 66/136\n",
      "10/10 - 0s - loss: 2.0640e-04 - val_loss: 0.0090 - 61ms/epoch - 6ms/step\n",
      "Epoch 67/136\n",
      "10/10 - 0s - loss: 2.1961e-04 - val_loss: 0.0090 - 63ms/epoch - 6ms/step\n",
      "Epoch 68/136\n",
      "10/10 - 0s - loss: 2.2261e-04 - val_loss: 0.0090 - 62ms/epoch - 6ms/step\n",
      "Epoch 69/136\n",
      "10/10 - 0s - loss: 2.1087e-04 - val_loss: 0.0091 - 86ms/epoch - 9ms/step\n",
      "Epoch 70/136\n",
      "10/10 - 0s - loss: 2.1649e-04 - val_loss: 0.0092 - 77ms/epoch - 8ms/step\n",
      "Epoch 71/136\n",
      "10/10 - 0s - loss: 2.0748e-04 - val_loss: 0.0093 - 65ms/epoch - 6ms/step\n",
      "Epoch 72/136\n",
      "10/10 - 0s - loss: 2.4766e-04 - val_loss: 0.0091 - 74ms/epoch - 7ms/step\n",
      "Epoch 73/136\n",
      "10/10 - 0s - loss: 2.4649e-04 - val_loss: 0.0090 - 61ms/epoch - 6ms/step\n",
      "Epoch 74/136\n",
      "10/10 - 0s - loss: 2.0838e-04 - val_loss: 0.0090 - 71ms/epoch - 7ms/step\n",
      "Epoch 75/136\n",
      "10/10 - 0s - loss: 1.9026e-04 - val_loss: 0.0092 - 64ms/epoch - 6ms/step\n",
      "Epoch 76/136\n",
      "10/10 - 0s - loss: 2.1696e-04 - val_loss: 0.0092 - 64ms/epoch - 6ms/step\n",
      "Epoch 77/136\n",
      "10/10 - 0s - loss: 2.3151e-04 - val_loss: 0.0091 - 70ms/epoch - 7ms/step\n",
      "Epoch 78/136\n",
      "10/10 - 0s - loss: 2.0582e-04 - val_loss: 0.0092 - 62ms/epoch - 6ms/step\n",
      "Epoch 79/136\n",
      "10/10 - 0s - loss: 2.3751e-04 - val_loss: 0.0090 - 62ms/epoch - 6ms/step\n",
      "Epoch 80/136\n",
      "10/10 - 0s - loss: 2.6428e-04 - val_loss: 0.0088 - 75ms/epoch - 7ms/step\n",
      "Epoch 81/136\n",
      "10/10 - 0s - loss: 2.0731e-04 - val_loss: 0.0092 - 87ms/epoch - 9ms/step\n",
      "Epoch 82/136\n",
      "10/10 - 0s - loss: 2.1142e-04 - val_loss: 0.0092 - 66ms/epoch - 7ms/step\n",
      "Epoch 83/136\n",
      "10/10 - 0s - loss: 2.0180e-04 - val_loss: 0.0090 - 68ms/epoch - 7ms/step\n",
      "Epoch 84/136\n",
      "10/10 - 0s - loss: 1.9210e-04 - val_loss: 0.0092 - 61ms/epoch - 6ms/step\n",
      "Epoch 85/136\n",
      "10/10 - 0s - loss: 2.0652e-04 - val_loss: 0.0091 - 60ms/epoch - 6ms/step\n",
      "Epoch 86/136\n",
      "10/10 - 0s - loss: 1.9663e-04 - val_loss: 0.0091 - 68ms/epoch - 7ms/step\n",
      "Epoch 87/136\n",
      "10/10 - 0s - loss: 1.8903e-04 - val_loss: 0.0092 - 63ms/epoch - 6ms/step\n",
      "Epoch 88/136\n",
      "10/10 - 0s - loss: 2.0119e-04 - val_loss: 0.0091 - 65ms/epoch - 6ms/step\n",
      "Epoch 89/136\n",
      "10/10 - 0s - loss: 2.6381e-04 - val_loss: 0.0090 - 71ms/epoch - 7ms/step\n",
      "Epoch 90/136\n",
      "10/10 - 0s - loss: 2.4765e-04 - val_loss: 0.0092 - 85ms/epoch - 8ms/step\n",
      "Epoch 91/136\n",
      "10/10 - 0s - loss: 2.2116e-04 - val_loss: 0.0090 - 74ms/epoch - 7ms/step\n",
      "Epoch 92/136\n",
      "10/10 - 0s - loss: 2.0291e-04 - val_loss: 0.0090 - 64ms/epoch - 6ms/step\n",
      "Epoch 93/136\n",
      "10/10 - 0s - loss: 1.7553e-04 - val_loss: 0.0091 - 71ms/epoch - 7ms/step\n",
      "Epoch 94/136\n",
      "10/10 - 0s - loss: 1.9616e-04 - val_loss: 0.0090 - 60ms/epoch - 6ms/step\n",
      "Epoch 95/136\n",
      "10/10 - 0s - loss: 1.9510e-04 - val_loss: 0.0092 - 76ms/epoch - 8ms/step\n",
      "Epoch 96/136\n",
      "10/10 - 0s - loss: 1.9662e-04 - val_loss: 0.0092 - 61ms/epoch - 6ms/step\n",
      "Epoch 97/136\n",
      "10/10 - 0s - loss: 2.1853e-04 - val_loss: 0.0091 - 69ms/epoch - 7ms/step\n",
      "Epoch 98/136\n",
      "10/10 - 0s - loss: 2.0349e-04 - val_loss: 0.0091 - 59ms/epoch - 6ms/step\n",
      "Epoch 99/136\n",
      "10/10 - 0s - loss: 1.9810e-04 - val_loss: 0.0091 - 68ms/epoch - 7ms/step\n",
      "Epoch 100/136\n",
      "10/10 - 0s - loss: 1.9169e-04 - val_loss: 0.0091 - 86ms/epoch - 9ms/step\n",
      "Epoch 101/136\n",
      "10/10 - 0s - loss: 1.8041e-04 - val_loss: 0.0092 - 78ms/epoch - 8ms/step\n",
      "Epoch 102/136\n",
      "10/10 - 0s - loss: 1.8763e-04 - val_loss: 0.0092 - 65ms/epoch - 7ms/step\n",
      "Epoch 103/136\n",
      "10/10 - 0s - loss: 1.9196e-04 - val_loss: 0.0092 - 70ms/epoch - 7ms/step\n",
      "Epoch 104/136\n",
      "10/10 - 0s - loss: 1.9253e-04 - val_loss: 0.0092 - 64ms/epoch - 6ms/step\n",
      "Epoch 105/136\n",
      "10/10 - 0s - loss: 1.8323e-04 - val_loss: 0.0092 - 69ms/epoch - 7ms/step\n",
      "Epoch 106/136\n",
      "10/10 - 0s - loss: 1.7519e-04 - val_loss: 0.0093 - 61ms/epoch - 6ms/step\n",
      "Epoch 107/136\n",
      "10/10 - 0s - loss: 2.1522e-04 - val_loss: 0.0094 - 61ms/epoch - 6ms/step\n",
      "Epoch 108/136\n",
      "10/10 - 0s - loss: 1.8761e-04 - val_loss: 0.0093 - 72ms/epoch - 7ms/step\n",
      "Epoch 109/136\n",
      "10/10 - 0s - loss: 1.8772e-04 - val_loss: 0.0095 - 63ms/epoch - 6ms/step\n",
      "Epoch 110/136\n",
      "10/10 - 0s - loss: 2.1109e-04 - val_loss: 0.0092 - 62ms/epoch - 6ms/step\n",
      "Epoch 111/136\n",
      "10/10 - 0s - loss: 1.9565e-04 - val_loss: 0.0094 - 74ms/epoch - 7ms/step\n",
      "Epoch 112/136\n",
      "10/10 - 0s - loss: 1.8936e-04 - val_loss: 0.0092 - 62ms/epoch - 6ms/step\n",
      "Epoch 113/136\n",
      "10/10 - 0s - loss: 1.8631e-04 - val_loss: 0.0092 - 111ms/epoch - 11ms/step\n",
      "Epoch 114/136\n",
      "10/10 - 0s - loss: 1.8865e-04 - val_loss: 0.0094 - 67ms/epoch - 7ms/step\n",
      "Epoch 115/136\n",
      "10/10 - 0s - loss: 1.9416e-04 - val_loss: 0.0092 - 73ms/epoch - 7ms/step\n",
      "Epoch 116/136\n",
      "10/10 - 0s - loss: 1.9003e-04 - val_loss: 0.0092 - 63ms/epoch - 6ms/step\n",
      "Epoch 117/136\n",
      "10/10 - 0s - loss: 1.9959e-04 - val_loss: 0.0093 - 61ms/epoch - 6ms/step\n",
      "Epoch 118/136\n",
      "10/10 - 0s - loss: 2.1329e-04 - val_loss: 0.0091 - 95ms/epoch - 9ms/step\n",
      "Epoch 119/136\n",
      "10/10 - 0s - loss: 2.4504e-04 - val_loss: 0.0092 - 63ms/epoch - 6ms/step\n",
      "Epoch 120/136\n",
      "10/10 - 0s - loss: 2.9492e-04 - val_loss: 0.0091 - 64ms/epoch - 6ms/step\n",
      "Epoch 121/136\n",
      "10/10 - 0s - loss: 1.9358e-04 - val_loss: 0.0094 - 72ms/epoch - 7ms/step\n",
      "Epoch 122/136\n",
      "10/10 - 0s - loss: 1.8367e-04 - val_loss: 0.0092 - 60ms/epoch - 6ms/step\n",
      "Epoch 123/136\n",
      "10/10 - 0s - loss: 1.7617e-04 - val_loss: 0.0092 - 88ms/epoch - 9ms/step\n",
      "Epoch 124/136\n",
      "10/10 - 0s - loss: 1.7764e-04 - val_loss: 0.0093 - 71ms/epoch - 7ms/step\n",
      "Epoch 125/136\n",
      "10/10 - 0s - loss: 1.7331e-04 - val_loss: 0.0097 - 62ms/epoch - 6ms/step\n",
      "Epoch 126/136\n",
      "10/10 - 0s - loss: 2.0067e-04 - val_loss: 0.0092 - 62ms/epoch - 6ms/step\n",
      "Epoch 127/136\n",
      "10/10 - 0s - loss: 1.8290e-04 - val_loss: 0.0094 - 72ms/epoch - 7ms/step\n",
      "Epoch 128/136\n",
      "10/10 - 0s - loss: 1.8301e-04 - val_loss: 0.0093 - 65ms/epoch - 7ms/step\n",
      "Epoch 129/136\n",
      "10/10 - 0s - loss: 1.9045e-04 - val_loss: 0.0095 - 75ms/epoch - 7ms/step\n",
      "Epoch 130/136\n",
      "10/10 - 0s - loss: 2.0001e-04 - val_loss: 0.0092 - 65ms/epoch - 6ms/step\n",
      "Epoch 131/136\n",
      "10/10 - 0s - loss: 1.9083e-04 - val_loss: 0.0095 - 75ms/epoch - 7ms/step\n",
      "Epoch 132/136\n",
      "10/10 - 0s - loss: 1.9886e-04 - val_loss: 0.0093 - 60ms/epoch - 6ms/step\n",
      "Epoch 133/136\n",
      "10/10 - 0s - loss: 1.8978e-04 - val_loss: 0.0094 - 76ms/epoch - 8ms/step\n",
      "Epoch 134/136\n",
      "10/10 - 0s - loss: 1.9261e-04 - val_loss: 0.0093 - 78ms/epoch - 8ms/step\n",
      "Epoch 135/136\n",
      "10/10 - 0s - loss: 1.9742e-04 - val_loss: 0.0094 - 63ms/epoch - 6ms/step\n",
      "Epoch 136/136\n",
      "10/10 - 0s - loss: 1.9969e-04 - val_loss: 0.0094 - 61ms/epoch - 6ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m-173.7   \u001b[0m | \u001b[0m136.8    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m48.13    \u001b[0m |\n",
      "Model: \"sequential_162\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_587 (LSTM)             (None, 1, 9)              540       \n",
      "                                                                 \n",
      " dropout_425 (Dropout)       (None, 1, 9)              0         \n",
      "                                                                 \n",
      " lstm_588 (LSTM)             (None, 1, 9)              684       \n",
      "                                                                 \n",
      " dropout_426 (Dropout)       (None, 1, 9)              0         \n",
      "                                                                 \n",
      " lstm_589 (LSTM)             (None, 1, 9)              684       \n",
      "                                                                 \n",
      " dropout_427 (Dropout)       (None, 1, 9)              0         \n",
      "                                                                 \n",
      " lstm_590 (LSTM)             (None, 9)                 684       \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 1)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,602\n",
      "Trainable params: 2,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/160\n",
      "10/10 - 8s - loss: 0.0617 - val_loss: 0.0709 - 8s/epoch - 849ms/step\n",
      "Epoch 2/160\n",
      "10/10 - 0s - loss: 0.0425 - val_loss: 0.0508 - 76ms/epoch - 8ms/step\n",
      "Epoch 3/160\n",
      "10/10 - 0s - loss: 0.0246 - val_loss: 0.0329 - 75ms/epoch - 7ms/step\n",
      "Epoch 4/160\n",
      "10/10 - 0s - loss: 0.0105 - val_loss: 0.0196 - 85ms/epoch - 8ms/step\n",
      "Epoch 5/160\n",
      "10/10 - 0s - loss: 0.0038 - val_loss: 0.0156 - 76ms/epoch - 8ms/step\n",
      "Epoch 6/160\n",
      "10/10 - 0s - loss: 0.0039 - val_loss: 0.0157 - 75ms/epoch - 7ms/step\n",
      "Epoch 7/160\n",
      "10/10 - 0s - loss: 0.0033 - val_loss: 0.0164 - 76ms/epoch - 8ms/step\n",
      "Epoch 8/160\n",
      "10/10 - 0s - loss: 0.0032 - val_loss: 0.0166 - 85ms/epoch - 9ms/step\n",
      "Epoch 9/160\n",
      "10/10 - 0s - loss: 0.0032 - val_loss: 0.0162 - 97ms/epoch - 10ms/step\n",
      "Epoch 10/160\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0159 - 96ms/epoch - 10ms/step\n",
      "Epoch 11/160\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0160 - 77ms/epoch - 8ms/step\n",
      "Epoch 12/160\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0158 - 84ms/epoch - 8ms/step\n",
      "Epoch 13/160\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0156 - 74ms/epoch - 7ms/step\n",
      "Epoch 14/160\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0155 - 76ms/epoch - 8ms/step\n",
      "Epoch 15/160\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0153 - 84ms/epoch - 8ms/step\n",
      "Epoch 16/160\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0150 - 74ms/epoch - 7ms/step\n",
      "Epoch 17/160\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0148 - 84ms/epoch - 8ms/step\n",
      "Epoch 18/160\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0143 - 73ms/epoch - 7ms/step\n",
      "Epoch 19/160\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0140 - 85ms/epoch - 8ms/step\n",
      "Epoch 20/160\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0132 - 75ms/epoch - 8ms/step\n",
      "Epoch 21/160\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0126 - 85ms/epoch - 8ms/step\n",
      "Epoch 22/160\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0120 - 75ms/epoch - 8ms/step\n",
      "Epoch 23/160\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0113 - 82ms/epoch - 8ms/step\n",
      "Epoch 24/160\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0102 - 77ms/epoch - 8ms/step\n",
      "Epoch 25/160\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0096 - 121ms/epoch - 12ms/step\n",
      "Epoch 26/160\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0089 - 75ms/epoch - 8ms/step\n",
      "Epoch 27/160\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0086 - 85ms/epoch - 9ms/step\n",
      "Epoch 28/160\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0086 - 72ms/epoch - 7ms/step\n",
      "Epoch 29/160\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0086 - 86ms/epoch - 9ms/step\n",
      "Epoch 30/160\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0088 - 74ms/epoch - 7ms/step\n",
      "Epoch 31/160\n",
      "10/10 - 0s - loss: 9.3842e-04 - val_loss: 0.0089 - 86ms/epoch - 9ms/step\n",
      "Epoch 32/160\n",
      "10/10 - 0s - loss: 8.5746e-04 - val_loss: 0.0090 - 77ms/epoch - 8ms/step\n",
      "Epoch 33/160\n",
      "10/10 - 0s - loss: 8.3709e-04 - val_loss: 0.0093 - 84ms/epoch - 8ms/step\n",
      "Epoch 34/160\n",
      "10/10 - 0s - loss: 8.0534e-04 - val_loss: 0.0091 - 101ms/epoch - 10ms/step\n",
      "Epoch 35/160\n",
      "10/10 - 0s - loss: 9.4051e-04 - val_loss: 0.0089 - 86ms/epoch - 9ms/step\n",
      "Epoch 36/160\n",
      "10/10 - 0s - loss: 8.3184e-04 - val_loss: 0.0087 - 77ms/epoch - 8ms/step\n",
      "Epoch 37/160\n",
      "10/10 - 0s - loss: 9.1852e-04 - val_loss: 0.0088 - 86ms/epoch - 9ms/step\n",
      "Epoch 38/160\n",
      "10/10 - 0s - loss: 8.2228e-04 - val_loss: 0.0088 - 74ms/epoch - 7ms/step\n",
      "Epoch 39/160\n",
      "10/10 - 0s - loss: 6.9127e-04 - val_loss: 0.0089 - 75ms/epoch - 7ms/step\n",
      "Epoch 40/160\n",
      "10/10 - 0s - loss: 7.5501e-04 - val_loss: 0.0087 - 84ms/epoch - 8ms/step\n",
      "Epoch 41/160\n",
      "10/10 - 0s - loss: 7.9698e-04 - val_loss: 0.0086 - 74ms/epoch - 7ms/step\n",
      "Epoch 42/160\n",
      "10/10 - 0s - loss: 6.6379e-04 - val_loss: 0.0084 - 103ms/epoch - 10ms/step\n",
      "Epoch 43/160\n",
      "10/10 - 0s - loss: 6.9176e-04 - val_loss: 0.0085 - 101ms/epoch - 10ms/step\n",
      "Epoch 44/160\n",
      "10/10 - 0s - loss: 6.3283e-04 - val_loss: 0.0084 - 87ms/epoch - 9ms/step\n",
      "Epoch 45/160\n",
      "10/10 - 0s - loss: 7.0940e-04 - val_loss: 0.0084 - 77ms/epoch - 8ms/step\n",
      "Epoch 46/160\n",
      "10/10 - 0s - loss: 7.0454e-04 - val_loss: 0.0083 - 90ms/epoch - 9ms/step\n",
      "Epoch 47/160\n",
      "10/10 - 0s - loss: 6.8808e-04 - val_loss: 0.0082 - 74ms/epoch - 7ms/step\n",
      "Epoch 48/160\n",
      "10/10 - 0s - loss: 6.2944e-04 - val_loss: 0.0082 - 83ms/epoch - 8ms/step\n",
      "Epoch 49/160\n",
      "10/10 - 0s - loss: 6.5915e-04 - val_loss: 0.0082 - 75ms/epoch - 7ms/step\n",
      "Epoch 50/160\n",
      "10/10 - 0s - loss: 6.6787e-04 - val_loss: 0.0081 - 76ms/epoch - 8ms/step\n",
      "Epoch 51/160\n",
      "10/10 - 0s - loss: 5.9431e-04 - val_loss: 0.0081 - 106ms/epoch - 11ms/step\n",
      "Epoch 52/160\n",
      "10/10 - 0s - loss: 6.7078e-04 - val_loss: 0.0080 - 83ms/epoch - 8ms/step\n",
      "Epoch 53/160\n",
      "10/10 - 0s - loss: 6.5623e-04 - val_loss: 0.0080 - 88ms/epoch - 9ms/step\n",
      "Epoch 54/160\n",
      "10/10 - 0s - loss: 6.3612e-04 - val_loss: 0.0080 - 75ms/epoch - 7ms/step\n",
      "Epoch 55/160\n",
      "10/10 - 0s - loss: 6.5508e-04 - val_loss: 0.0079 - 85ms/epoch - 8ms/step\n",
      "Epoch 56/160\n",
      "10/10 - 0s - loss: 6.2637e-04 - val_loss: 0.0079 - 74ms/epoch - 7ms/step\n",
      "Epoch 57/160\n",
      "10/10 - 0s - loss: 6.4282e-04 - val_loss: 0.0079 - 75ms/epoch - 7ms/step\n",
      "Epoch 58/160\n",
      "10/10 - 0s - loss: 5.6484e-04 - val_loss: 0.0079 - 85ms/epoch - 9ms/step\n",
      "Epoch 59/160\n",
      "10/10 - 0s - loss: 5.3383e-04 - val_loss: 0.0078 - 91ms/epoch - 9ms/step\n",
      "Epoch 60/160\n",
      "10/10 - 0s - loss: 5.6941e-04 - val_loss: 0.0078 - 89ms/epoch - 9ms/step\n",
      "Epoch 61/160\n",
      "10/10 - 0s - loss: 5.9807e-04 - val_loss: 0.0079 - 84ms/epoch - 8ms/step\n",
      "Epoch 62/160\n",
      "10/10 - 0s - loss: 5.9937e-04 - val_loss: 0.0079 - 76ms/epoch - 8ms/step\n",
      "Epoch 63/160\n",
      "10/10 - 0s - loss: 6.0887e-04 - val_loss: 0.0078 - 74ms/epoch - 7ms/step\n",
      "Epoch 64/160\n",
      "10/10 - 0s - loss: 5.6173e-04 - val_loss: 0.0078 - 83ms/epoch - 8ms/step\n",
      "Epoch 65/160\n",
      "10/10 - 0s - loss: 5.5150e-04 - val_loss: 0.0078 - 74ms/epoch - 7ms/step\n",
      "Epoch 66/160\n",
      "10/10 - 0s - loss: 5.6303e-04 - val_loss: 0.0078 - 85ms/epoch - 8ms/step\n",
      "Epoch 67/160\n",
      "10/10 - 0s - loss: 5.7075e-04 - val_loss: 0.0078 - 73ms/epoch - 7ms/step\n",
      "Epoch 68/160\n",
      "10/10 - 0s - loss: 5.8139e-04 - val_loss: 0.0078 - 106ms/epoch - 11ms/step\n",
      "Epoch 69/160\n",
      "10/10 - 0s - loss: 4.9972e-04 - val_loss: 0.0079 - 83ms/epoch - 8ms/step\n",
      "Epoch 70/160\n",
      "10/10 - 0s - loss: 4.9189e-04 - val_loss: 0.0079 - 86ms/epoch - 9ms/step\n",
      "Epoch 71/160\n",
      "10/10 - 0s - loss: 4.9969e-04 - val_loss: 0.0079 - 73ms/epoch - 7ms/step\n",
      "Epoch 72/160\n",
      "10/10 - 0s - loss: 5.5091e-04 - val_loss: 0.0079 - 84ms/epoch - 8ms/step\n",
      "Epoch 73/160\n",
      "10/10 - 0s - loss: 5.4066e-04 - val_loss: 0.0079 - 74ms/epoch - 7ms/step\n",
      "Epoch 74/160\n",
      "10/10 - 0s - loss: 5.3063e-04 - val_loss: 0.0079 - 84ms/epoch - 8ms/step\n",
      "Epoch 75/160\n",
      "10/10 - 0s - loss: 5.0296e-04 - val_loss: 0.0079 - 73ms/epoch - 7ms/step\n",
      "Epoch 76/160\n",
      "10/10 - 0s - loss: 5.2140e-04 - val_loss: 0.0079 - 84ms/epoch - 8ms/step\n",
      "Epoch 77/160\n",
      "10/10 - 0s - loss: 5.2149e-04 - val_loss: 0.0081 - 73ms/epoch - 7ms/step\n",
      "Epoch 78/160\n",
      "10/10 - 0s - loss: 5.5738e-04 - val_loss: 0.0081 - 81ms/epoch - 8ms/step\n",
      "Epoch 79/160\n",
      "10/10 - 0s - loss: 5.1027e-04 - val_loss: 0.0082 - 74ms/epoch - 7ms/step\n",
      "Epoch 80/160\n",
      "10/10 - 0s - loss: 4.8799e-04 - val_loss: 0.0082 - 121ms/epoch - 12ms/step\n",
      "Epoch 81/160\n",
      "10/10 - 0s - loss: 4.9464e-04 - val_loss: 0.0083 - 74ms/epoch - 7ms/step\n",
      "Epoch 82/160\n",
      "10/10 - 0s - loss: 5.2278e-04 - val_loss: 0.0083 - 82ms/epoch - 8ms/step\n",
      "Epoch 83/160\n",
      "10/10 - 0s - loss: 4.4670e-04 - val_loss: 0.0083 - 72ms/epoch - 7ms/step\n",
      "Epoch 84/160\n",
      "10/10 - 0s - loss: 4.7034e-04 - val_loss: 0.0084 - 73ms/epoch - 7ms/step\n",
      "Epoch 85/160\n",
      "10/10 - 0s - loss: 4.7747e-04 - val_loss: 0.0084 - 85ms/epoch - 8ms/step\n",
      "Epoch 86/160\n",
      "10/10 - 0s - loss: 5.0304e-04 - val_loss: 0.0086 - 74ms/epoch - 7ms/step\n",
      "Epoch 87/160\n",
      "10/10 - 0s - loss: 4.8791e-04 - val_loss: 0.0086 - 73ms/epoch - 7ms/step\n",
      "Epoch 88/160\n",
      "10/10 - 0s - loss: 4.5364e-04 - val_loss: 0.0087 - 83ms/epoch - 8ms/step\n",
      "Epoch 89/160\n",
      "10/10 - 0s - loss: 4.3271e-04 - val_loss: 0.0087 - 76ms/epoch - 8ms/step\n",
      "Epoch 90/160\n",
      "10/10 - 0s - loss: 4.3688e-04 - val_loss: 0.0088 - 87ms/epoch - 9ms/step\n",
      "Epoch 91/160\n",
      "10/10 - 0s - loss: 5.2021e-04 - val_loss: 0.0089 - 74ms/epoch - 7ms/step\n",
      "Epoch 92/160\n",
      "10/10 - 0s - loss: 4.9461e-04 - val_loss: 0.0088 - 80ms/epoch - 8ms/step\n",
      "Epoch 93/160\n",
      "10/10 - 0s - loss: 4.7984e-04 - val_loss: 0.0088 - 81ms/epoch - 8ms/step\n",
      "Epoch 94/160\n",
      "10/10 - 0s - loss: 5.1829e-04 - val_loss: 0.0090 - 93ms/epoch - 9ms/step\n",
      "Epoch 95/160\n",
      "10/10 - 0s - loss: 4.4062e-04 - val_loss: 0.0093 - 87ms/epoch - 9ms/step\n",
      "Epoch 96/160\n",
      "10/10 - 0s - loss: 4.6308e-04 - val_loss: 0.0094 - 74ms/epoch - 7ms/step\n",
      "Epoch 97/160\n",
      "10/10 - 0s - loss: 4.3101e-04 - val_loss: 0.0093 - 76ms/epoch - 8ms/step\n",
      "Epoch 98/160\n",
      "10/10 - 0s - loss: 4.2964e-04 - val_loss: 0.0092 - 84ms/epoch - 8ms/step\n",
      "Epoch 99/160\n",
      "10/10 - 0s - loss: 4.2142e-04 - val_loss: 0.0092 - 77ms/epoch - 8ms/step\n",
      "Epoch 100/160\n",
      "10/10 - 0s - loss: 4.7869e-04 - val_loss: 0.0096 - 74ms/epoch - 7ms/step\n",
      "Epoch 101/160\n",
      "10/10 - 0s - loss: 4.3791e-04 - val_loss: 0.0097 - 84ms/epoch - 8ms/step\n",
      "Epoch 102/160\n",
      "10/10 - 0s - loss: 4.3266e-04 - val_loss: 0.0097 - 73ms/epoch - 7ms/step\n",
      "Epoch 103/160\n",
      "10/10 - 0s - loss: 4.3053e-04 - val_loss: 0.0095 - 74ms/epoch - 7ms/step\n",
      "Epoch 104/160\n",
      "10/10 - 0s - loss: 4.3214e-04 - val_loss: 0.0097 - 85ms/epoch - 8ms/step\n",
      "Epoch 105/160\n",
      "10/10 - 0s - loss: 4.1594e-04 - val_loss: 0.0099 - 76ms/epoch - 8ms/step\n",
      "Epoch 106/160\n",
      "10/10 - 0s - loss: 4.1599e-04 - val_loss: 0.0100 - 74ms/epoch - 7ms/step\n",
      "Epoch 107/160\n",
      "10/10 - 0s - loss: 4.4265e-04 - val_loss: 0.0099 - 122ms/epoch - 12ms/step\n",
      "Epoch 108/160\n",
      "10/10 - 0s - loss: 4.1810e-04 - val_loss: 0.0100 - 76ms/epoch - 8ms/step\n",
      "Epoch 109/160\n",
      "10/10 - 0s - loss: 4.3749e-04 - val_loss: 0.0100 - 82ms/epoch - 8ms/step\n",
      "Epoch 110/160\n",
      "10/10 - 0s - loss: 3.8466e-04 - val_loss: 0.0101 - 76ms/epoch - 8ms/step\n",
      "Epoch 111/160\n",
      "10/10 - 0s - loss: 3.6976e-04 - val_loss: 0.0102 - 84ms/epoch - 8ms/step\n",
      "Epoch 112/160\n",
      "10/10 - 0s - loss: 4.1024e-04 - val_loss: 0.0105 - 76ms/epoch - 8ms/step\n",
      "Epoch 113/160\n",
      "10/10 - 0s - loss: 4.3686e-04 - val_loss: 0.0104 - 86ms/epoch - 9ms/step\n",
      "Epoch 114/160\n",
      "10/10 - 0s - loss: 4.2629e-04 - val_loss: 0.0106 - 75ms/epoch - 8ms/step\n",
      "Epoch 115/160\n",
      "10/10 - 0s - loss: 4.3940e-04 - val_loss: 0.0106 - 126ms/epoch - 13ms/step\n",
      "Epoch 116/160\n",
      "10/10 - 0s - loss: 3.9852e-04 - val_loss: 0.0108 - 79ms/epoch - 8ms/step\n",
      "Epoch 117/160\n",
      "10/10 - 0s - loss: 4.0932e-04 - val_loss: 0.0109 - 85ms/epoch - 8ms/step\n",
      "Epoch 118/160\n",
      "10/10 - 0s - loss: 4.3651e-04 - val_loss: 0.0106 - 73ms/epoch - 7ms/step\n",
      "Epoch 119/160\n",
      "10/10 - 0s - loss: 4.1607e-04 - val_loss: 0.0108 - 84ms/epoch - 8ms/step\n",
      "Epoch 120/160\n",
      "10/10 - 0s - loss: 3.7644e-04 - val_loss: 0.0109 - 75ms/epoch - 7ms/step\n",
      "Epoch 121/160\n",
      "10/10 - 0s - loss: 4.3466e-04 - val_loss: 0.0106 - 89ms/epoch - 9ms/step\n",
      "Epoch 122/160\n",
      "10/10 - 0s - loss: 4.2051e-04 - val_loss: 0.0109 - 77ms/epoch - 8ms/step\n",
      "Epoch 123/160\n",
      "10/10 - 0s - loss: 3.9536e-04 - val_loss: 0.0115 - 79ms/epoch - 8ms/step\n",
      "Epoch 124/160\n",
      "10/10 - 0s - loss: 4.2011e-04 - val_loss: 0.0111 - 83ms/epoch - 8ms/step\n",
      "Epoch 125/160\n",
      "10/10 - 0s - loss: 4.4016e-04 - val_loss: 0.0110 - 73ms/epoch - 7ms/step\n",
      "Epoch 126/160\n",
      "10/10 - 0s - loss: 4.2893e-04 - val_loss: 0.0110 - 115ms/epoch - 11ms/step\n",
      "Epoch 127/160\n",
      "10/10 - 0s - loss: 4.0304e-04 - val_loss: 0.0109 - 74ms/epoch - 7ms/step\n",
      "Epoch 128/160\n",
      "10/10 - 0s - loss: 4.1606e-04 - val_loss: 0.0113 - 84ms/epoch - 8ms/step\n",
      "Epoch 129/160\n",
      "10/10 - 0s - loss: 4.8786e-04 - val_loss: 0.0113 - 75ms/epoch - 8ms/step\n",
      "Epoch 130/160\n",
      "10/10 - 0s - loss: 4.0721e-04 - val_loss: 0.0114 - 73ms/epoch - 7ms/step\n",
      "Epoch 131/160\n",
      "10/10 - 0s - loss: 4.1642e-04 - val_loss: 0.0114 - 83ms/epoch - 8ms/step\n",
      "Epoch 132/160\n",
      "10/10 - 0s - loss: 4.2787e-04 - val_loss: 0.0115 - 73ms/epoch - 7ms/step\n",
      "Epoch 133/160\n",
      "10/10 - 0s - loss: 4.2332e-04 - val_loss: 0.0115 - 72ms/epoch - 7ms/step\n",
      "Epoch 134/160\n",
      "10/10 - 0s - loss: 4.0645e-04 - val_loss: 0.0114 - 90ms/epoch - 9ms/step\n",
      "Epoch 135/160\n",
      "10/10 - 0s - loss: 4.0107e-04 - val_loss: 0.0117 - 96ms/epoch - 10ms/step\n",
      "Epoch 136/160\n",
      "10/10 - 0s - loss: 4.2696e-04 - val_loss: 0.0117 - 75ms/epoch - 8ms/step\n",
      "Epoch 137/160\n",
      "10/10 - 0s - loss: 3.7817e-04 - val_loss: 0.0115 - 83ms/epoch - 8ms/step\n",
      "Epoch 138/160\n",
      "10/10 - 0s - loss: 3.7688e-04 - val_loss: 0.0117 - 75ms/epoch - 7ms/step\n",
      "Epoch 139/160\n",
      "10/10 - 0s - loss: 4.1104e-04 - val_loss: 0.0114 - 84ms/epoch - 8ms/step\n",
      "Epoch 140/160\n",
      "10/10 - 0s - loss: 4.1209e-04 - val_loss: 0.0114 - 77ms/epoch - 8ms/step\n",
      "Epoch 141/160\n",
      "10/10 - 0s - loss: 4.2283e-04 - val_loss: 0.0118 - 83ms/epoch - 8ms/step\n",
      "Epoch 142/160\n",
      "10/10 - 0s - loss: 3.9644e-04 - val_loss: 0.0117 - 76ms/epoch - 8ms/step\n",
      "Epoch 143/160\n",
      "10/10 - 0s - loss: 4.1776e-04 - val_loss: 0.0116 - 74ms/epoch - 7ms/step\n",
      "Epoch 144/160\n",
      "10/10 - 0s - loss: 3.8935e-04 - val_loss: 0.0118 - 92ms/epoch - 9ms/step\n",
      "Epoch 145/160\n",
      "10/10 - 0s - loss: 4.0468e-04 - val_loss: 0.0115 - 75ms/epoch - 7ms/step\n",
      "Epoch 146/160\n",
      "10/10 - 0s - loss: 3.9461e-04 - val_loss: 0.0120 - 85ms/epoch - 8ms/step\n",
      "Epoch 147/160\n",
      "10/10 - 0s - loss: 3.9081e-04 - val_loss: 0.0121 - 96ms/epoch - 10ms/step\n",
      "Epoch 148/160\n",
      "10/10 - 0s - loss: 4.0634e-04 - val_loss: 0.0122 - 91ms/epoch - 9ms/step\n",
      "Epoch 149/160\n",
      "10/10 - 0s - loss: 4.1328e-04 - val_loss: 0.0120 - 75ms/epoch - 7ms/step\n",
      "Epoch 150/160\n",
      "10/10 - 0s - loss: 3.6774e-04 - val_loss: 0.0115 - 74ms/epoch - 7ms/step\n",
      "Epoch 151/160\n",
      "10/10 - 0s - loss: 3.9738e-04 - val_loss: 0.0118 - 84ms/epoch - 8ms/step\n",
      "Epoch 152/160\n",
      "10/10 - 0s - loss: 3.9560e-04 - val_loss: 0.0119 - 80ms/epoch - 8ms/step\n",
      "Epoch 153/160\n",
      "10/10 - 0s - loss: 3.9420e-04 - val_loss: 0.0119 - 74ms/epoch - 7ms/step\n",
      "Epoch 154/160\n",
      "10/10 - 0s - loss: 4.2973e-04 - val_loss: 0.0119 - 86ms/epoch - 9ms/step\n",
      "Epoch 155/160\n",
      "10/10 - 0s - loss: 4.0451e-04 - val_loss: 0.0118 - 75ms/epoch - 7ms/step\n",
      "Epoch 156/160\n",
      "10/10 - 0s - loss: 3.9889e-04 - val_loss: 0.0116 - 76ms/epoch - 8ms/step\n",
      "Epoch 157/160\n",
      "10/10 - 0s - loss: 4.1371e-04 - val_loss: 0.0117 - 113ms/epoch - 11ms/step\n",
      "Epoch 158/160\n",
      "10/10 - 0s - loss: 4.0896e-04 - val_loss: 0.0117 - 77ms/epoch - 8ms/step\n",
      "Epoch 159/160\n",
      "10/10 - 0s - loss: 3.7452e-04 - val_loss: 0.0116 - 74ms/epoch - 7ms/step\n",
      "Epoch 160/160\n",
      "10/10 - 0s - loss: 3.9905e-04 - val_loss: 0.0119 - 83ms/epoch - 8ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m-195.7   \u001b[0m | \u001b[0m160.7    \u001b[0m | \u001b[0m3.259    \u001b[0m | \u001b[0m0.002304 \u001b[0m | \u001b[0m9.676    \u001b[0m |\n",
      "Model: \"sequential_163\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_591 (LSTM)             (None, 1, 76)             24928     \n",
      "                                                                 \n",
      " dropout_428 (Dropout)       (None, 1, 76)             0         \n",
      "                                                                 \n",
      " lstm_592 (LSTM)             (None, 76)                46512     \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 1)                 77        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71,517\n",
      "Trainable params: 71,517\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/161\n",
      "10/10 - 4s - loss: 0.0202 - val_loss: 0.0125 - 4s/epoch - 390ms/step\n",
      "Epoch 2/161\n",
      "10/10 - 0s - loss: 0.0035 - val_loss: 0.0122 - 73ms/epoch - 7ms/step\n",
      "Epoch 3/161\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0137 - 85ms/epoch - 8ms/step\n",
      "Epoch 4/161\n",
      "10/10 - 0s - loss: 0.0020 - val_loss: 0.0115 - 72ms/epoch - 7ms/step\n",
      "Epoch 5/161\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0115 - 84ms/epoch - 8ms/step\n",
      "Epoch 6/161\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0101 - 71ms/epoch - 7ms/step\n",
      "Epoch 7/161\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0091 - 78ms/epoch - 8ms/step\n",
      "Epoch 8/161\n",
      "10/10 - 0s - loss: 7.9248e-04 - val_loss: 0.0084 - 74ms/epoch - 7ms/step\n",
      "Epoch 9/161\n",
      "10/10 - 0s - loss: 5.3441e-04 - val_loss: 0.0082 - 79ms/epoch - 8ms/step\n",
      "Epoch 10/161\n",
      "10/10 - 0s - loss: 4.0464e-04 - val_loss: 0.0085 - 71ms/epoch - 7ms/step\n",
      "Epoch 11/161\n",
      "10/10 - 0s - loss: 3.9047e-04 - val_loss: 0.0086 - 80ms/epoch - 8ms/step\n",
      "Epoch 12/161\n",
      "10/10 - 0s - loss: 3.5012e-04 - val_loss: 0.0086 - 69ms/epoch - 7ms/step\n",
      "Epoch 13/161\n",
      "10/10 - 0s - loss: 3.9466e-04 - val_loss: 0.0085 - 84ms/epoch - 8ms/step\n",
      "Epoch 14/161\n",
      "10/10 - 0s - loss: 3.3834e-04 - val_loss: 0.0086 - 97ms/epoch - 10ms/step\n",
      "Epoch 15/161\n",
      "10/10 - 0s - loss: 3.2420e-04 - val_loss: 0.0084 - 84ms/epoch - 8ms/step\n",
      "Epoch 16/161\n",
      "10/10 - 0s - loss: 3.3044e-04 - val_loss: 0.0084 - 78ms/epoch - 8ms/step\n",
      "Epoch 17/161\n",
      "10/10 - 0s - loss: 2.8786e-04 - val_loss: 0.0084 - 89ms/epoch - 9ms/step\n",
      "Epoch 18/161\n",
      "10/10 - 0s - loss: 3.0230e-04 - val_loss: 0.0083 - 73ms/epoch - 7ms/step\n",
      "Epoch 19/161\n",
      "10/10 - 0s - loss: 2.7910e-04 - val_loss: 0.0084 - 87ms/epoch - 9ms/step\n",
      "Epoch 20/161\n",
      "10/10 - 0s - loss: 2.6074e-04 - val_loss: 0.0084 - 83ms/epoch - 8ms/step\n",
      "Epoch 21/161\n",
      "10/10 - 0s - loss: 2.7190e-04 - val_loss: 0.0084 - 84ms/epoch - 8ms/step\n",
      "Epoch 22/161\n",
      "10/10 - 0s - loss: 2.4704e-04 - val_loss: 0.0083 - 71ms/epoch - 7ms/step\n",
      "Epoch 23/161\n",
      "10/10 - 0s - loss: 2.5059e-04 - val_loss: 0.0083 - 118ms/epoch - 12ms/step\n",
      "Epoch 24/161\n",
      "10/10 - 0s - loss: 2.4260e-04 - val_loss: 0.0083 - 75ms/epoch - 7ms/step\n",
      "Epoch 25/161\n",
      "10/10 - 0s - loss: 2.4834e-04 - val_loss: 0.0084 - 94ms/epoch - 9ms/step\n",
      "Epoch 26/161\n",
      "10/10 - 0s - loss: 2.4159e-04 - val_loss: 0.0083 - 72ms/epoch - 7ms/step\n",
      "Epoch 27/161\n",
      "10/10 - 0s - loss: 2.2825e-04 - val_loss: 0.0084 - 85ms/epoch - 8ms/step\n",
      "Epoch 28/161\n",
      "10/10 - 0s - loss: 2.3934e-04 - val_loss: 0.0084 - 71ms/epoch - 7ms/step\n",
      "Epoch 29/161\n",
      "10/10 - 0s - loss: 2.2931e-04 - val_loss: 0.0084 - 82ms/epoch - 8ms/step\n",
      "Epoch 30/161\n",
      "10/10 - 0s - loss: 2.1883e-04 - val_loss: 0.0086 - 71ms/epoch - 7ms/step\n",
      "Epoch 31/161\n",
      "10/10 - 0s - loss: 2.4009e-04 - val_loss: 0.0083 - 87ms/epoch - 9ms/step\n",
      "Epoch 32/161\n",
      "10/10 - 0s - loss: 2.2425e-04 - val_loss: 0.0084 - 98ms/epoch - 10ms/step\n",
      "Epoch 33/161\n",
      "10/10 - 0s - loss: 2.1397e-04 - val_loss: 0.0083 - 87ms/epoch - 9ms/step\n",
      "Epoch 34/161\n",
      "10/10 - 0s - loss: 2.2614e-04 - val_loss: 0.0084 - 73ms/epoch - 7ms/step\n",
      "Epoch 35/161\n",
      "10/10 - 0s - loss: 2.4545e-04 - val_loss: 0.0085 - 80ms/epoch - 8ms/step\n",
      "Epoch 36/161\n",
      "10/10 - 0s - loss: 2.1496e-04 - val_loss: 0.0084 - 72ms/epoch - 7ms/step\n",
      "Epoch 37/161\n",
      "10/10 - 0s - loss: 2.0064e-04 - val_loss: 0.0084 - 82ms/epoch - 8ms/step\n",
      "Epoch 38/161\n",
      "10/10 - 0s - loss: 2.3112e-04 - val_loss: 0.0084 - 73ms/epoch - 7ms/step\n",
      "Epoch 39/161\n",
      "10/10 - 0s - loss: 2.5209e-04 - val_loss: 0.0085 - 78ms/epoch - 8ms/step\n",
      "Epoch 40/161\n",
      "10/10 - 0s - loss: 2.0122e-04 - val_loss: 0.0085 - 71ms/epoch - 7ms/step\n",
      "Epoch 41/161\n",
      "10/10 - 0s - loss: 1.9951e-04 - val_loss: 0.0085 - 95ms/epoch - 10ms/step\n",
      "Epoch 42/161\n",
      "10/10 - 0s - loss: 2.0050e-04 - val_loss: 0.0086 - 92ms/epoch - 9ms/step\n",
      "Epoch 43/161\n",
      "10/10 - 0s - loss: 2.1107e-04 - val_loss: 0.0086 - 72ms/epoch - 7ms/step\n",
      "Epoch 44/161\n",
      "10/10 - 0s - loss: 2.0439e-04 - val_loss: 0.0087 - 71ms/epoch - 7ms/step\n",
      "Epoch 45/161\n",
      "10/10 - 0s - loss: 2.0104e-04 - val_loss: 0.0087 - 80ms/epoch - 8ms/step\n",
      "Epoch 46/161\n",
      "10/10 - 0s - loss: 2.1186e-04 - val_loss: 0.0087 - 71ms/epoch - 7ms/step\n",
      "Epoch 47/161\n",
      "10/10 - 0s - loss: 1.9866e-04 - val_loss: 0.0086 - 72ms/epoch - 7ms/step\n",
      "Epoch 48/161\n",
      "10/10 - 0s - loss: 2.0915e-04 - val_loss: 0.0087 - 86ms/epoch - 9ms/step\n",
      "Epoch 49/161\n",
      "10/10 - 0s - loss: 2.0295e-04 - val_loss: 0.0088 - 72ms/epoch - 7ms/step\n",
      "Epoch 50/161\n",
      "10/10 - 0s - loss: 1.9809e-04 - val_loss: 0.0089 - 106ms/epoch - 11ms/step\n",
      "Epoch 51/161\n",
      "10/10 - 0s - loss: 1.9424e-04 - val_loss: 0.0087 - 87ms/epoch - 9ms/step\n",
      "Epoch 52/161\n",
      "10/10 - 0s - loss: 1.8111e-04 - val_loss: 0.0089 - 74ms/epoch - 7ms/step\n",
      "Epoch 53/161\n",
      "10/10 - 0s - loss: 2.1967e-04 - val_loss: 0.0087 - 84ms/epoch - 8ms/step\n",
      "Epoch 54/161\n",
      "10/10 - 0s - loss: 1.9121e-04 - val_loss: 0.0088 - 72ms/epoch - 7ms/step\n",
      "Epoch 55/161\n",
      "10/10 - 0s - loss: 1.9673e-04 - val_loss: 0.0088 - 81ms/epoch - 8ms/step\n",
      "Epoch 56/161\n",
      "10/10 - 0s - loss: 2.0638e-04 - val_loss: 0.0088 - 71ms/epoch - 7ms/step\n",
      "Epoch 57/161\n",
      "10/10 - 0s - loss: 1.8311e-04 - val_loss: 0.0089 - 81ms/epoch - 8ms/step\n",
      "Epoch 58/161\n",
      "10/10 - 0s - loss: 2.0594e-04 - val_loss: 0.0087 - 72ms/epoch - 7ms/step\n",
      "Epoch 59/161\n",
      "10/10 - 0s - loss: 2.0694e-04 - val_loss: 0.0089 - 121ms/epoch - 12ms/step\n",
      "Epoch 60/161\n",
      "10/10 - 0s - loss: 2.0557e-04 - val_loss: 0.0089 - 75ms/epoch - 8ms/step\n",
      "Epoch 61/161\n",
      "10/10 - 0s - loss: 2.0470e-04 - val_loss: 0.0088 - 71ms/epoch - 7ms/step\n",
      "Epoch 62/161\n",
      "10/10 - 0s - loss: 1.9406e-04 - val_loss: 0.0088 - 82ms/epoch - 8ms/step\n",
      "Epoch 63/161\n",
      "10/10 - 0s - loss: 2.0046e-04 - val_loss: 0.0089 - 71ms/epoch - 7ms/step\n",
      "Epoch 64/161\n",
      "10/10 - 0s - loss: 2.3329e-04 - val_loss: 0.0089 - 72ms/epoch - 7ms/step\n",
      "Epoch 65/161\n",
      "10/10 - 0s - loss: 2.5000e-04 - val_loss: 0.0089 - 82ms/epoch - 8ms/step\n",
      "Epoch 66/161\n",
      "10/10 - 0s - loss: 2.5101e-04 - val_loss: 0.0087 - 71ms/epoch - 7ms/step\n",
      "Epoch 67/161\n",
      "10/10 - 0s - loss: 2.2524e-04 - val_loss: 0.0091 - 71ms/epoch - 7ms/step\n",
      "Epoch 68/161\n",
      "10/10 - 0s - loss: 2.0645e-04 - val_loss: 0.0090 - 102ms/epoch - 10ms/step\n",
      "Epoch 69/161\n",
      "10/10 - 0s - loss: 1.9899e-04 - val_loss: 0.0088 - 81ms/epoch - 8ms/step\n",
      "Epoch 70/161\n",
      "10/10 - 0s - loss: 1.8710e-04 - val_loss: 0.0089 - 71ms/epoch - 7ms/step\n",
      "Epoch 71/161\n",
      "10/10 - 0s - loss: 1.8011e-04 - val_loss: 0.0091 - 79ms/epoch - 8ms/step\n",
      "Epoch 72/161\n",
      "10/10 - 0s - loss: 1.9839e-04 - val_loss: 0.0089 - 72ms/epoch - 7ms/step\n",
      "Epoch 73/161\n",
      "10/10 - 0s - loss: 1.8751e-04 - val_loss: 0.0088 - 71ms/epoch - 7ms/step\n",
      "Epoch 74/161\n",
      "10/10 - 0s - loss: 1.9244e-04 - val_loss: 0.0090 - 86ms/epoch - 9ms/step\n",
      "Epoch 75/161\n",
      "10/10 - 0s - loss: 1.8541e-04 - val_loss: 0.0091 - 80ms/epoch - 8ms/step\n",
      "Epoch 76/161\n",
      "10/10 - 0s - loss: 2.0778e-04 - val_loss: 0.0090 - 70ms/epoch - 7ms/step\n",
      "Epoch 77/161\n",
      "10/10 - 0s - loss: 2.0438e-04 - val_loss: 0.0090 - 120ms/epoch - 12ms/step\n",
      "Epoch 78/161\n",
      "10/10 - 0s - loss: 1.7928e-04 - val_loss: 0.0091 - 72ms/epoch - 7ms/step\n",
      "Epoch 79/161\n",
      "10/10 - 0s - loss: 1.8864e-04 - val_loss: 0.0090 - 86ms/epoch - 9ms/step\n",
      "Epoch 80/161\n",
      "10/10 - 0s - loss: 1.9040e-04 - val_loss: 0.0089 - 76ms/epoch - 8ms/step\n",
      "Epoch 81/161\n",
      "10/10 - 0s - loss: 1.9969e-04 - val_loss: 0.0090 - 82ms/epoch - 8ms/step\n",
      "Epoch 82/161\n",
      "10/10 - 0s - loss: 1.9464e-04 - val_loss: 0.0092 - 73ms/epoch - 7ms/step\n",
      "Epoch 83/161\n",
      "10/10 - 0s - loss: 2.0872e-04 - val_loss: 0.0091 - 81ms/epoch - 8ms/step\n",
      "Epoch 84/161\n",
      "10/10 - 0s - loss: 1.9050e-04 - val_loss: 0.0091 - 73ms/epoch - 7ms/step\n",
      "Epoch 85/161\n",
      "10/10 - 0s - loss: 1.9033e-04 - val_loss: 0.0091 - 82ms/epoch - 8ms/step\n",
      "Epoch 86/161\n",
      "10/10 - 0s - loss: 2.1546e-04 - val_loss: 0.0090 - 99ms/epoch - 10ms/step\n",
      "Epoch 87/161\n",
      "10/10 - 0s - loss: 2.0897e-04 - val_loss: 0.0090 - 90ms/epoch - 9ms/step\n",
      "Epoch 88/161\n",
      "10/10 - 0s - loss: 2.2990e-04 - val_loss: 0.0090 - 72ms/epoch - 7ms/step\n",
      "Epoch 89/161\n",
      "10/10 - 0s - loss: 2.0732e-04 - val_loss: 0.0090 - 82ms/epoch - 8ms/step\n",
      "Epoch 90/161\n",
      "10/10 - 0s - loss: 2.0315e-04 - val_loss: 0.0091 - 72ms/epoch - 7ms/step\n",
      "Epoch 91/161\n",
      "10/10 - 0s - loss: 1.8381e-04 - val_loss: 0.0091 - 85ms/epoch - 8ms/step\n",
      "Epoch 92/161\n",
      "10/10 - 0s - loss: 2.0616e-04 - val_loss: 0.0092 - 74ms/epoch - 7ms/step\n",
      "Epoch 93/161\n",
      "10/10 - 0s - loss: 2.1249e-04 - val_loss: 0.0091 - 84ms/epoch - 8ms/step\n",
      "Epoch 94/161\n",
      "10/10 - 0s - loss: 1.8988e-04 - val_loss: 0.0090 - 72ms/epoch - 7ms/step\n",
      "Epoch 95/161\n",
      "10/10 - 0s - loss: 1.7670e-04 - val_loss: 0.0092 - 80ms/epoch - 8ms/step\n",
      "Epoch 96/161\n",
      "10/10 - 0s - loss: 1.9864e-04 - val_loss: 0.0091 - 70ms/epoch - 7ms/step\n",
      "Epoch 97/161\n",
      "10/10 - 0s - loss: 1.9262e-04 - val_loss: 0.0091 - 81ms/epoch - 8ms/step\n",
      "Epoch 98/161\n",
      "10/10 - 0s - loss: 1.8198e-04 - val_loss: 0.0091 - 72ms/epoch - 7ms/step\n",
      "Epoch 99/161\n",
      "10/10 - 0s - loss: 2.0083e-04 - val_loss: 0.0092 - 78ms/epoch - 8ms/step\n",
      "Epoch 100/161\n",
      "10/10 - 0s - loss: 2.4734e-04 - val_loss: 0.0090 - 91ms/epoch - 9ms/step\n",
      "Epoch 101/161\n",
      "10/10 - 0s - loss: 2.4237e-04 - val_loss: 0.0091 - 78ms/epoch - 8ms/step\n",
      "Epoch 102/161\n",
      "10/10 - 0s - loss: 2.3025e-04 - val_loss: 0.0090 - 83ms/epoch - 8ms/step\n",
      "Epoch 103/161\n",
      "10/10 - 0s - loss: 2.7344e-04 - val_loss: 0.0092 - 70ms/epoch - 7ms/step\n",
      "Epoch 104/161\n",
      "10/10 - 0s - loss: 2.4901e-04 - val_loss: 0.0089 - 82ms/epoch - 8ms/step\n",
      "Epoch 105/161\n",
      "10/10 - 0s - loss: 2.3608e-04 - val_loss: 0.0090 - 74ms/epoch - 7ms/step\n",
      "Epoch 106/161\n",
      "10/10 - 0s - loss: 2.0214e-04 - val_loss: 0.0090 - 82ms/epoch - 8ms/step\n",
      "Epoch 107/161\n",
      "10/10 - 0s - loss: 1.9113e-04 - val_loss: 0.0091 - 72ms/epoch - 7ms/step\n",
      "Epoch 108/161\n",
      "10/10 - 0s - loss: 1.8812e-04 - val_loss: 0.0090 - 70ms/epoch - 7ms/step\n",
      "Epoch 109/161\n",
      "10/10 - 0s - loss: 2.0528e-04 - val_loss: 0.0091 - 122ms/epoch - 12ms/step\n",
      "Epoch 110/161\n",
      "10/10 - 0s - loss: 2.2049e-04 - val_loss: 0.0092 - 73ms/epoch - 7ms/step\n",
      "Epoch 111/161\n",
      "10/10 - 0s - loss: 2.1366e-04 - val_loss: 0.0092 - 72ms/epoch - 7ms/step\n",
      "Epoch 112/161\n",
      "10/10 - 0s - loss: 2.1370e-04 - val_loss: 0.0091 - 85ms/epoch - 8ms/step\n",
      "Epoch 113/161\n",
      "10/10 - 0s - loss: 1.8362e-04 - val_loss: 0.0090 - 73ms/epoch - 7ms/step\n",
      "Epoch 114/161\n",
      "10/10 - 0s - loss: 1.9543e-04 - val_loss: 0.0093 - 73ms/epoch - 7ms/step\n",
      "Epoch 115/161\n",
      "10/10 - 0s - loss: 1.8656e-04 - val_loss: 0.0090 - 83ms/epoch - 8ms/step\n",
      "Epoch 116/161\n",
      "10/10 - 0s - loss: 1.8882e-04 - val_loss: 0.0091 - 72ms/epoch - 7ms/step\n",
      "Epoch 117/161\n",
      "10/10 - 0s - loss: 1.9773e-04 - val_loss: 0.0092 - 71ms/epoch - 7ms/step\n",
      "Epoch 118/161\n",
      "10/10 - 0s - loss: 1.9217e-04 - val_loss: 0.0092 - 119ms/epoch - 12ms/step\n",
      "Epoch 119/161\n",
      "10/10 - 0s - loss: 1.8910e-04 - val_loss: 0.0092 - 74ms/epoch - 7ms/step\n",
      "Epoch 120/161\n",
      "10/10 - 0s - loss: 2.2290e-04 - val_loss: 0.0090 - 72ms/epoch - 7ms/step\n",
      "Epoch 121/161\n",
      "10/10 - 0s - loss: 1.9193e-04 - val_loss: 0.0093 - 81ms/epoch - 8ms/step\n",
      "Epoch 122/161\n",
      "10/10 - 0s - loss: 1.8918e-04 - val_loss: 0.0093 - 71ms/epoch - 7ms/step\n",
      "Epoch 123/161\n",
      "10/10 - 0s - loss: 1.7347e-04 - val_loss: 0.0093 - 72ms/epoch - 7ms/step\n",
      "Epoch 124/161\n",
      "10/10 - 0s - loss: 1.8090e-04 - val_loss: 0.0091 - 82ms/epoch - 8ms/step\n",
      "Epoch 125/161\n",
      "10/10 - 0s - loss: 1.6318e-04 - val_loss: 0.0095 - 71ms/epoch - 7ms/step\n",
      "Epoch 126/161\n",
      "10/10 - 0s - loss: 1.8350e-04 - val_loss: 0.0092 - 71ms/epoch - 7ms/step\n",
      "Epoch 127/161\n",
      "10/10 - 0s - loss: 1.7056e-04 - val_loss: 0.0094 - 78ms/epoch - 8ms/step\n",
      "Epoch 128/161\n",
      "10/10 - 0s - loss: 1.6696e-04 - val_loss: 0.0093 - 98ms/epoch - 10ms/step\n",
      "Epoch 129/161\n",
      "10/10 - 0s - loss: 1.7968e-04 - val_loss: 0.0093 - 74ms/epoch - 7ms/step\n",
      "Epoch 130/161\n",
      "10/10 - 0s - loss: 2.0277e-04 - val_loss: 0.0096 - 83ms/epoch - 8ms/step\n",
      "Epoch 131/161\n",
      "10/10 - 0s - loss: 2.5794e-04 - val_loss: 0.0094 - 72ms/epoch - 7ms/step\n",
      "Epoch 132/161\n",
      "10/10 - 0s - loss: 2.2709e-04 - val_loss: 0.0093 - 80ms/epoch - 8ms/step\n",
      "Epoch 133/161\n",
      "10/10 - 0s - loss: 1.8548e-04 - val_loss: 0.0092 - 72ms/epoch - 7ms/step\n",
      "Epoch 134/161\n",
      "10/10 - 0s - loss: 1.9005e-04 - val_loss: 0.0094 - 81ms/epoch - 8ms/step\n",
      "Epoch 135/161\n",
      "10/10 - 0s - loss: 1.9613e-04 - val_loss: 0.0094 - 75ms/epoch - 7ms/step\n",
      "Epoch 136/161\n",
      "10/10 - 0s - loss: 1.7685e-04 - val_loss: 0.0093 - 80ms/epoch - 8ms/step\n",
      "Epoch 137/161\n",
      "10/10 - 0s - loss: 2.1175e-04 - val_loss: 0.0091 - 82ms/epoch - 8ms/step\n",
      "Epoch 138/161\n",
      "10/10 - 0s - loss: 1.8541e-04 - val_loss: 0.0095 - 90ms/epoch - 9ms/step\n",
      "Epoch 139/161\n",
      "10/10 - 0s - loss: 1.9856e-04 - val_loss: 0.0093 - 73ms/epoch - 7ms/step\n",
      "Epoch 140/161\n",
      "10/10 - 0s - loss: 1.7134e-04 - val_loss: 0.0094 - 71ms/epoch - 7ms/step\n",
      "Epoch 141/161\n",
      "10/10 - 0s - loss: 1.7281e-04 - val_loss: 0.0094 - 81ms/epoch - 8ms/step\n",
      "Epoch 142/161\n",
      "10/10 - 0s - loss: 1.7021e-04 - val_loss: 0.0094 - 71ms/epoch - 7ms/step\n",
      "Epoch 143/161\n",
      "10/10 - 0s - loss: 1.7038e-04 - val_loss: 0.0094 - 84ms/epoch - 8ms/step\n",
      "Epoch 144/161\n",
      "10/10 - 0s - loss: 1.9643e-04 - val_loss: 0.0094 - 71ms/epoch - 7ms/step\n",
      "Epoch 145/161\n",
      "10/10 - 0s - loss: 2.0786e-04 - val_loss: 0.0096 - 86ms/epoch - 9ms/step\n",
      "Epoch 146/161\n",
      "10/10 - 0s - loss: 1.9214e-04 - val_loss: 0.0094 - 87ms/epoch - 9ms/step\n",
      "Epoch 147/161\n",
      "10/10 - 0s - loss: 1.8709e-04 - val_loss: 0.0094 - 80ms/epoch - 8ms/step\n",
      "Epoch 148/161\n",
      "10/10 - 0s - loss: 1.7157e-04 - val_loss: 0.0094 - 84ms/epoch - 8ms/step\n",
      "Epoch 149/161\n",
      "10/10 - 0s - loss: 1.8319e-04 - val_loss: 0.0094 - 74ms/epoch - 7ms/step\n",
      "Epoch 150/161\n",
      "10/10 - 0s - loss: 1.9278e-04 - val_loss: 0.0097 - 78ms/epoch - 8ms/step\n",
      "Epoch 151/161\n",
      "10/10 - 0s - loss: 2.0979e-04 - val_loss: 0.0093 - 73ms/epoch - 7ms/step\n",
      "Epoch 152/161\n",
      "10/10 - 0s - loss: 1.6867e-04 - val_loss: 0.0096 - 83ms/epoch - 8ms/step\n",
      "Epoch 153/161\n",
      "10/10 - 0s - loss: 1.7348e-04 - val_loss: 0.0095 - 72ms/epoch - 7ms/step\n",
      "Epoch 154/161\n",
      "10/10 - 0s - loss: 1.7292e-04 - val_loss: 0.0094 - 91ms/epoch - 9ms/step\n",
      "Epoch 155/161\n",
      "10/10 - 0s - loss: 1.6773e-04 - val_loss: 0.0096 - 88ms/epoch - 9ms/step\n",
      "Epoch 156/161\n",
      "10/10 - 0s - loss: 1.7245e-04 - val_loss: 0.0095 - 72ms/epoch - 7ms/step\n",
      "Epoch 157/161\n",
      "10/10 - 0s - loss: 1.9757e-04 - val_loss: 0.0099 - 83ms/epoch - 8ms/step\n",
      "Epoch 158/161\n",
      "10/10 - 0s - loss: 2.0982e-04 - val_loss: 0.0095 - 73ms/epoch - 7ms/step\n",
      "Epoch 159/161\n",
      "10/10 - 0s - loss: 1.7115e-04 - val_loss: 0.0095 - 71ms/epoch - 7ms/step\n",
      "Epoch 160/161\n",
      "10/10 - 0s - loss: 1.9930e-04 - val_loss: 0.0094 - 80ms/epoch - 8ms/step\n",
      "Epoch 161/161\n",
      "10/10 - 0s - loss: 1.7821e-04 - val_loss: 0.0097 - 71ms/epoch - 7ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m-176.4   \u001b[0m | \u001b[0m161.9    \u001b[0m | \u001b[0m1.882    \u001b[0m | \u001b[0m0.008309 \u001b[0m | \u001b[0m76.89    \u001b[0m |\n",
      "Model: \"sequential_164\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_593 (LSTM)             (None, 1, 55)             13420     \n",
      "                                                                 \n",
      " dropout_429 (Dropout)       (None, 1, 55)             0         \n",
      "                                                                 \n",
      " lstm_594 (LSTM)             (None, 1, 55)             24420     \n",
      "                                                                 \n",
      " dropout_430 (Dropout)       (None, 1, 55)             0         \n",
      "                                                                 \n",
      " lstm_595 (LSTM)             (None, 1, 55)             24420     \n",
      "                                                                 \n",
      " dropout_431 (Dropout)       (None, 1, 55)             0         \n",
      "                                                                 \n",
      " lstm_596 (LSTM)             (None, 55)                24420     \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 1)                 56        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,736\n",
      "Trainable params: 86,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "10/10 - 8s - loss: 0.0302 - val_loss: 0.0207 - 8s/epoch - 760ms/step\n",
      "Epoch 2/150\n",
      "10/10 - 0s - loss: 0.0051 - val_loss: 0.0189 - 96ms/epoch - 10ms/step\n",
      "Epoch 3/150\n",
      "10/10 - 0s - loss: 0.0036 - val_loss: 0.0164 - 93ms/epoch - 9ms/step\n",
      "Epoch 4/150\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0166 - 107ms/epoch - 11ms/step\n",
      "Epoch 5/150\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0168 - 95ms/epoch - 10ms/step\n",
      "Epoch 6/150\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0162 - 99ms/epoch - 10ms/step\n",
      "Epoch 7/150\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0161 - 95ms/epoch - 9ms/step\n",
      "Epoch 8/150\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0152 - 105ms/epoch - 11ms/step\n",
      "Epoch 9/150\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0138 - 120ms/epoch - 12ms/step\n",
      "Epoch 10/150\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0105 - 99ms/epoch - 10ms/step\n",
      "Epoch 11/150\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0087 - 109ms/epoch - 11ms/step\n",
      "Epoch 12/150\n",
      "10/10 - 0s - loss: 8.1981e-04 - val_loss: 0.0100 - 95ms/epoch - 10ms/step\n",
      "Epoch 13/150\n",
      "10/10 - 0s - loss: 6.5460e-04 - val_loss: 0.0088 - 109ms/epoch - 11ms/step\n",
      "Epoch 14/150\n",
      "10/10 - 0s - loss: 5.3532e-04 - val_loss: 0.0089 - 98ms/epoch - 10ms/step\n",
      "Epoch 15/150\n",
      "10/10 - 0s - loss: 5.1908e-04 - val_loss: 0.0091 - 106ms/epoch - 11ms/step\n",
      "Epoch 16/150\n",
      "10/10 - 0s - loss: 4.2846e-04 - val_loss: 0.0091 - 95ms/epoch - 9ms/step\n",
      "Epoch 17/150\n",
      "10/10 - 0s - loss: 4.3994e-04 - val_loss: 0.0087 - 107ms/epoch - 11ms/step\n",
      "Epoch 18/150\n",
      "10/10 - 0s - loss: 3.6954e-04 - val_loss: 0.0089 - 117ms/epoch - 12ms/step\n",
      "Epoch 19/150\n",
      "10/10 - 0s - loss: 3.5917e-04 - val_loss: 0.0087 - 104ms/epoch - 10ms/step\n",
      "Epoch 20/150\n",
      "10/10 - 0s - loss: 4.0199e-04 - val_loss: 0.0086 - 91ms/epoch - 9ms/step\n",
      "Epoch 21/150\n",
      "10/10 - 0s - loss: 3.5284e-04 - val_loss: 0.0087 - 102ms/epoch - 10ms/step\n",
      "Epoch 22/150\n",
      "10/10 - 0s - loss: 3.7918e-04 - val_loss: 0.0085 - 97ms/epoch - 10ms/step\n",
      "Epoch 23/150\n",
      "10/10 - 0s - loss: 3.7108e-04 - val_loss: 0.0085 - 106ms/epoch - 11ms/step\n",
      "Epoch 24/150\n",
      "10/10 - 0s - loss: 3.4411e-04 - val_loss: 0.0084 - 92ms/epoch - 9ms/step\n",
      "Epoch 25/150\n",
      "10/10 - 0s - loss: 3.3953e-04 - val_loss: 0.0084 - 105ms/epoch - 10ms/step\n",
      "Epoch 26/150\n",
      "10/10 - 0s - loss: 3.2986e-04 - val_loss: 0.0083 - 93ms/epoch - 9ms/step\n",
      "Epoch 27/150\n",
      "10/10 - 0s - loss: 3.2961e-04 - val_loss: 0.0083 - 140ms/epoch - 14ms/step\n",
      "Epoch 28/150\n",
      "10/10 - 0s - loss: 3.1546e-04 - val_loss: 0.0083 - 97ms/epoch - 10ms/step\n",
      "Epoch 29/150\n",
      "10/10 - 0s - loss: 3.7843e-04 - val_loss: 0.0082 - 104ms/epoch - 10ms/step\n",
      "Epoch 30/150\n",
      "10/10 - 0s - loss: 3.1762e-04 - val_loss: 0.0083 - 95ms/epoch - 9ms/step\n",
      "Epoch 31/150\n",
      "10/10 - 0s - loss: 3.1822e-04 - val_loss: 0.0081 - 106ms/epoch - 11ms/step\n",
      "Epoch 32/150\n",
      "10/10 - 0s - loss: 3.1690e-04 - val_loss: 0.0082 - 93ms/epoch - 9ms/step\n",
      "Epoch 33/150\n",
      "10/10 - 0s - loss: 3.1113e-04 - val_loss: 0.0081 - 107ms/epoch - 11ms/step\n",
      "Epoch 34/150\n",
      "10/10 - 0s - loss: 3.1619e-04 - val_loss: 0.0082 - 96ms/epoch - 10ms/step\n",
      "Epoch 35/150\n",
      "10/10 - 0s - loss: 2.9315e-04 - val_loss: 0.0081 - 103ms/epoch - 10ms/step\n",
      "Epoch 36/150\n",
      "10/10 - 0s - loss: 2.8005e-04 - val_loss: 0.0081 - 116ms/epoch - 12ms/step\n",
      "Epoch 37/150\n",
      "10/10 - 0s - loss: 3.0935e-04 - val_loss: 0.0081 - 104ms/epoch - 10ms/step\n",
      "Epoch 38/150\n",
      "10/10 - 0s - loss: 3.0705e-04 - val_loss: 0.0081 - 92ms/epoch - 9ms/step\n",
      "Epoch 39/150\n",
      "10/10 - 0s - loss: 2.6973e-04 - val_loss: 0.0080 - 101ms/epoch - 10ms/step\n",
      "Epoch 40/150\n",
      "10/10 - 0s - loss: 2.6422e-04 - val_loss: 0.0080 - 95ms/epoch - 10ms/step\n",
      "Epoch 41/150\n",
      "10/10 - 0s - loss: 2.6502e-04 - val_loss: 0.0081 - 110ms/epoch - 11ms/step\n",
      "Epoch 42/150\n",
      "10/10 - 0s - loss: 2.5990e-04 - val_loss: 0.0080 - 96ms/epoch - 10ms/step\n",
      "Epoch 43/150\n",
      "10/10 - 0s - loss: 2.8903e-04 - val_loss: 0.0081 - 106ms/epoch - 11ms/step\n",
      "Epoch 44/150\n",
      "10/10 - 0s - loss: 2.8067e-04 - val_loss: 0.0080 - 95ms/epoch - 10ms/step\n",
      "Epoch 45/150\n",
      "10/10 - 0s - loss: 2.8998e-04 - val_loss: 0.0081 - 146ms/epoch - 15ms/step\n",
      "Epoch 46/150\n",
      "10/10 - 0s - loss: 3.1171e-04 - val_loss: 0.0080 - 95ms/epoch - 10ms/step\n",
      "Epoch 47/150\n",
      "10/10 - 0s - loss: 2.8266e-04 - val_loss: 0.0080 - 102ms/epoch - 10ms/step\n",
      "Epoch 48/150\n",
      "10/10 - 0s - loss: 2.9034e-04 - val_loss: 0.0080 - 95ms/epoch - 10ms/step\n",
      "Epoch 49/150\n",
      "10/10 - 0s - loss: 2.4782e-04 - val_loss: 0.0080 - 106ms/epoch - 11ms/step\n",
      "Epoch 50/150\n",
      "10/10 - 0s - loss: 2.6896e-04 - val_loss: 0.0080 - 92ms/epoch - 9ms/step\n",
      "Epoch 51/150\n",
      "10/10 - 0s - loss: 2.7648e-04 - val_loss: 0.0080 - 104ms/epoch - 10ms/step\n",
      "Epoch 52/150\n",
      "10/10 - 0s - loss: 2.8501e-04 - val_loss: 0.0080 - 93ms/epoch - 9ms/step\n",
      "Epoch 53/150\n",
      "10/10 - 0s - loss: 2.6269e-04 - val_loss: 0.0080 - 107ms/epoch - 11ms/step\n",
      "Epoch 54/150\n",
      "10/10 - 0s - loss: 2.7602e-04 - val_loss: 0.0081 - 120ms/epoch - 12ms/step\n",
      "Epoch 55/150\n",
      "10/10 - 0s - loss: 2.6430e-04 - val_loss: 0.0080 - 106ms/epoch - 11ms/step\n",
      "Epoch 56/150\n",
      "10/10 - 0s - loss: 2.6005e-04 - val_loss: 0.0080 - 92ms/epoch - 9ms/step\n",
      "Epoch 57/150\n",
      "10/10 - 0s - loss: 2.8197e-04 - val_loss: 0.0081 - 105ms/epoch - 10ms/step\n",
      "Epoch 58/150\n",
      "10/10 - 0s - loss: 2.5930e-04 - val_loss: 0.0080 - 95ms/epoch - 9ms/step\n",
      "Epoch 59/150\n",
      "10/10 - 0s - loss: 2.5119e-04 - val_loss: 0.0080 - 107ms/epoch - 11ms/step\n",
      "Epoch 60/150\n",
      "10/10 - 0s - loss: 2.5734e-04 - val_loss: 0.0081 - 94ms/epoch - 9ms/step\n",
      "Epoch 61/150\n",
      "10/10 - 0s - loss: 2.7192e-04 - val_loss: 0.0080 - 103ms/epoch - 10ms/step\n",
      "Epoch 62/150\n",
      "10/10 - 0s - loss: 2.5686e-04 - val_loss: 0.0081 - 92ms/epoch - 9ms/step\n",
      "Epoch 63/150\n",
      "10/10 - 0s - loss: 2.8108e-04 - val_loss: 0.0081 - 146ms/epoch - 15ms/step\n",
      "Epoch 64/150\n",
      "10/10 - 0s - loss: 2.5688e-04 - val_loss: 0.0080 - 94ms/epoch - 9ms/step\n",
      "Epoch 65/150\n",
      "10/10 - 0s - loss: 2.5133e-04 - val_loss: 0.0082 - 103ms/epoch - 10ms/step\n",
      "Epoch 66/150\n",
      "10/10 - 0s - loss: 2.9304e-04 - val_loss: 0.0081 - 96ms/epoch - 10ms/step\n",
      "Epoch 67/150\n",
      "10/10 - 0s - loss: 2.4364e-04 - val_loss: 0.0080 - 109ms/epoch - 11ms/step\n",
      "Epoch 68/150\n",
      "10/10 - 0s - loss: 2.5574e-04 - val_loss: 0.0081 - 93ms/epoch - 9ms/step\n",
      "Epoch 69/150\n",
      "10/10 - 0s - loss: 2.7835e-04 - val_loss: 0.0081 - 108ms/epoch - 11ms/step\n",
      "Epoch 70/150\n",
      "10/10 - 0s - loss: 2.8411e-04 - val_loss: 0.0081 - 97ms/epoch - 10ms/step\n",
      "Epoch 71/150\n",
      "10/10 - 0s - loss: 2.5076e-04 - val_loss: 0.0080 - 108ms/epoch - 11ms/step\n",
      "Epoch 72/150\n",
      "10/10 - 0s - loss: 2.2995e-04 - val_loss: 0.0081 - 125ms/epoch - 12ms/step\n",
      "Epoch 73/150\n",
      "10/10 - 0s - loss: 2.4177e-04 - val_loss: 0.0080 - 108ms/epoch - 11ms/step\n",
      "Epoch 74/150\n",
      "10/10 - 0s - loss: 2.6866e-04 - val_loss: 0.0081 - 97ms/epoch - 10ms/step\n",
      "Epoch 75/150\n",
      "10/10 - 0s - loss: 2.6916e-04 - val_loss: 0.0081 - 111ms/epoch - 11ms/step\n",
      "Epoch 76/150\n",
      "10/10 - 0s - loss: 2.7909e-04 - val_loss: 0.0081 - 96ms/epoch - 10ms/step\n",
      "Epoch 77/150\n",
      "10/10 - 0s - loss: 3.0474e-04 - val_loss: 0.0083 - 103ms/epoch - 10ms/step\n",
      "Epoch 78/150\n",
      "10/10 - 0s - loss: 2.8650e-04 - val_loss: 0.0081 - 96ms/epoch - 10ms/step\n",
      "Epoch 79/150\n",
      "10/10 - 0s - loss: 2.5290e-04 - val_loss: 0.0082 - 106ms/epoch - 11ms/step\n",
      "Epoch 80/150\n",
      "10/10 - 0s - loss: 2.4471e-04 - val_loss: 0.0081 - 95ms/epoch - 9ms/step\n",
      "Epoch 81/150\n",
      "10/10 - 0s - loss: 2.5197e-04 - val_loss: 0.0083 - 136ms/epoch - 14ms/step\n",
      "Epoch 82/150\n",
      "10/10 - 0s - loss: 2.6600e-04 - val_loss: 0.0081 - 108ms/epoch - 11ms/step\n",
      "Epoch 83/150\n",
      "10/10 - 0s - loss: 2.4399e-04 - val_loss: 0.0082 - 108ms/epoch - 11ms/step\n",
      "Epoch 84/150\n",
      "10/10 - 0s - loss: 2.3053e-04 - val_loss: 0.0082 - 94ms/epoch - 9ms/step\n",
      "Epoch 85/150\n",
      "10/10 - 0s - loss: 2.5378e-04 - val_loss: 0.0083 - 108ms/epoch - 11ms/step\n",
      "Epoch 86/150\n",
      "10/10 - 0s - loss: 2.2797e-04 - val_loss: 0.0082 - 95ms/epoch - 9ms/step\n",
      "Epoch 87/150\n",
      "10/10 - 0s - loss: 2.4174e-04 - val_loss: 0.0084 - 105ms/epoch - 11ms/step\n",
      "Epoch 88/150\n",
      "10/10 - 0s - loss: 2.2855e-04 - val_loss: 0.0083 - 94ms/epoch - 9ms/step\n",
      "Epoch 89/150\n",
      "10/10 - 0s - loss: 2.3259e-04 - val_loss: 0.0083 - 105ms/epoch - 11ms/step\n",
      "Epoch 90/150\n",
      "10/10 - 0s - loss: 2.2365e-04 - val_loss: 0.0083 - 114ms/epoch - 11ms/step\n",
      "Epoch 91/150\n",
      "10/10 - 0s - loss: 2.2470e-04 - val_loss: 0.0083 - 94ms/epoch - 9ms/step\n",
      "Epoch 92/150\n",
      "10/10 - 0s - loss: 2.3121e-04 - val_loss: 0.0083 - 105ms/epoch - 10ms/step\n",
      "Epoch 93/150\n",
      "10/10 - 0s - loss: 2.3585e-04 - val_loss: 0.0084 - 93ms/epoch - 9ms/step\n",
      "Epoch 94/150\n",
      "10/10 - 0s - loss: 2.3292e-04 - val_loss: 0.0085 - 96ms/epoch - 10ms/step\n",
      "Epoch 95/150\n",
      "10/10 - 0s - loss: 2.5549e-04 - val_loss: 0.0085 - 108ms/epoch - 11ms/step\n",
      "Epoch 96/150\n",
      "10/10 - 0s - loss: 2.1002e-04 - val_loss: 0.0087 - 93ms/epoch - 9ms/step\n",
      "Epoch 97/150\n",
      "10/10 - 0s - loss: 2.3008e-04 - val_loss: 0.0087 - 103ms/epoch - 10ms/step\n",
      "Epoch 98/150\n",
      "10/10 - 0s - loss: 2.3127e-04 - val_loss: 0.0086 - 92ms/epoch - 9ms/step\n",
      "Epoch 99/150\n",
      "10/10 - 0s - loss: 2.2240e-04 - val_loss: 0.0087 - 107ms/epoch - 11ms/step\n",
      "Epoch 100/150\n",
      "10/10 - 0s - loss: 2.1526e-04 - val_loss: 0.0087 - 94ms/epoch - 9ms/step\n",
      "Epoch 101/150\n",
      "10/10 - 0s - loss: 2.2869e-04 - val_loss: 0.0087 - 117ms/epoch - 12ms/step\n",
      "Epoch 102/150\n",
      "10/10 - 0s - loss: 2.2928e-04 - val_loss: 0.0090 - 115ms/epoch - 11ms/step\n",
      "Epoch 103/150\n",
      "10/10 - 0s - loss: 2.2583e-04 - val_loss: 0.0089 - 96ms/epoch - 10ms/step\n",
      "Epoch 104/150\n",
      "10/10 - 0s - loss: 2.5389e-04 - val_loss: 0.0090 - 95ms/epoch - 9ms/step\n",
      "Epoch 105/150\n",
      "10/10 - 0s - loss: 2.5595e-04 - val_loss: 0.0093 - 119ms/epoch - 12ms/step\n",
      "Epoch 106/150\n",
      "10/10 - 0s - loss: 2.4670e-04 - val_loss: 0.0094 - 95ms/epoch - 9ms/step\n",
      "Epoch 107/150\n",
      "10/10 - 0s - loss: 2.2765e-04 - val_loss: 0.0093 - 94ms/epoch - 9ms/step\n",
      "Epoch 108/150\n",
      "10/10 - 0s - loss: 2.4807e-04 - val_loss: 0.0097 - 104ms/epoch - 10ms/step\n",
      "Epoch 109/150\n",
      "10/10 - 0s - loss: 2.3634e-04 - val_loss: 0.0099 - 95ms/epoch - 9ms/step\n",
      "Epoch 110/150\n",
      "10/10 - 0s - loss: 2.2725e-04 - val_loss: 0.0100 - 117ms/epoch - 12ms/step\n",
      "Epoch 111/150\n",
      "10/10 - 0s - loss: 2.2459e-04 - val_loss: 0.0102 - 108ms/epoch - 11ms/step\n",
      "Epoch 112/150\n",
      "10/10 - 0s - loss: 2.1198e-04 - val_loss: 0.0101 - 97ms/epoch - 10ms/step\n",
      "Epoch 113/150\n",
      "10/10 - 0s - loss: 2.5177e-04 - val_loss: 0.0103 - 106ms/epoch - 11ms/step\n",
      "Epoch 114/150\n",
      "10/10 - 0s - loss: 2.2263e-04 - val_loss: 0.0105 - 96ms/epoch - 10ms/step\n",
      "Epoch 115/150\n",
      "10/10 - 0s - loss: 2.3316e-04 - val_loss: 0.0105 - 94ms/epoch - 9ms/step\n",
      "Epoch 116/150\n",
      "10/10 - 0s - loss: 2.0472e-04 - val_loss: 0.0107 - 104ms/epoch - 10ms/step\n",
      "Epoch 117/150\n",
      "10/10 - 0s - loss: 2.2342e-04 - val_loss: 0.0112 - 94ms/epoch - 9ms/step\n",
      "Epoch 118/150\n",
      "10/10 - 0s - loss: 2.3847e-04 - val_loss: 0.0116 - 96ms/epoch - 10ms/step\n",
      "Epoch 119/150\n",
      "10/10 - 0s - loss: 2.3724e-04 - val_loss: 0.0123 - 107ms/epoch - 11ms/step\n",
      "Epoch 120/150\n",
      "10/10 - 0s - loss: 2.1645e-04 - val_loss: 0.0126 - 95ms/epoch - 10ms/step\n",
      "Epoch 121/150\n",
      "10/10 - 0s - loss: 2.4443e-04 - val_loss: 0.0127 - 138ms/epoch - 14ms/step\n",
      "Epoch 122/150\n",
      "10/10 - 0s - loss: 2.2004e-04 - val_loss: 0.0121 - 97ms/epoch - 10ms/step\n",
      "Epoch 123/150\n",
      "10/10 - 0s - loss: 2.1524e-04 - val_loss: 0.0123 - 103ms/epoch - 10ms/step\n",
      "Epoch 124/150\n",
      "10/10 - 0s - loss: 2.1208e-04 - val_loss: 0.0129 - 93ms/epoch - 9ms/step\n",
      "Epoch 125/150\n",
      "10/10 - 0s - loss: 2.0359e-04 - val_loss: 0.0132 - 103ms/epoch - 10ms/step\n",
      "Epoch 126/150\n",
      "10/10 - 0s - loss: 2.1860e-04 - val_loss: 0.0134 - 92ms/epoch - 9ms/step\n",
      "Epoch 127/150\n",
      "10/10 - 0s - loss: 2.2505e-04 - val_loss: 0.0141 - 108ms/epoch - 11ms/step\n",
      "Epoch 128/150\n",
      "10/10 - 0s - loss: 2.1257e-04 - val_loss: 0.0143 - 94ms/epoch - 9ms/step\n",
      "Epoch 129/150\n",
      "10/10 - 0s - loss: 2.1276e-04 - val_loss: 0.0150 - 106ms/epoch - 11ms/step\n",
      "Epoch 130/150\n",
      "10/10 - 0s - loss: 2.1632e-04 - val_loss: 0.0145 - 91ms/epoch - 9ms/step\n",
      "Epoch 131/150\n",
      "10/10 - 0s - loss: 2.3351e-04 - val_loss: 0.0150 - 105ms/epoch - 10ms/step\n",
      "Epoch 132/150\n",
      "10/10 - 0s - loss: 2.7217e-04 - val_loss: 0.0146 - 117ms/epoch - 12ms/step\n",
      "Epoch 133/150\n",
      "10/10 - 0s - loss: 2.3138e-04 - val_loss: 0.0155 - 111ms/epoch - 11ms/step\n",
      "Epoch 134/150\n",
      "10/10 - 0s - loss: 2.1546e-04 - val_loss: 0.0159 - 96ms/epoch - 10ms/step\n",
      "Epoch 135/150\n",
      "10/10 - 0s - loss: 1.9979e-04 - val_loss: 0.0163 - 106ms/epoch - 11ms/step\n",
      "Epoch 136/150\n",
      "10/10 - 0s - loss: 2.2717e-04 - val_loss: 0.0165 - 94ms/epoch - 9ms/step\n",
      "Epoch 137/150\n",
      "10/10 - 0s - loss: 2.1100e-04 - val_loss: 0.0162 - 96ms/epoch - 10ms/step\n",
      "Epoch 138/150\n",
      "10/10 - 0s - loss: 2.0976e-04 - val_loss: 0.0164 - 109ms/epoch - 11ms/step\n",
      "Epoch 139/150\n",
      "10/10 - 0s - loss: 1.8897e-04 - val_loss: 0.0170 - 94ms/epoch - 9ms/step\n",
      "Epoch 140/150\n",
      "10/10 - 0s - loss: 2.3911e-04 - val_loss: 0.0174 - 104ms/epoch - 10ms/step\n",
      "Epoch 141/150\n",
      "10/10 - 0s - loss: 2.2835e-04 - val_loss: 0.0178 - 115ms/epoch - 11ms/step\n",
      "Epoch 142/150\n",
      "10/10 - 0s - loss: 2.4984e-04 - val_loss: 0.0179 - 110ms/epoch - 11ms/step\n",
      "Epoch 143/150\n",
      "10/10 - 0s - loss: 2.3328e-04 - val_loss: 0.0174 - 95ms/epoch - 9ms/step\n",
      "Epoch 144/150\n",
      "10/10 - 0s - loss: 2.0574e-04 - val_loss: 0.0182 - 94ms/epoch - 9ms/step\n",
      "Epoch 145/150\n",
      "10/10 - 0s - loss: 2.0670e-04 - val_loss: 0.0179 - 102ms/epoch - 10ms/step\n",
      "Epoch 146/150\n",
      "10/10 - 0s - loss: 2.1667e-04 - val_loss: 0.0174 - 95ms/epoch - 10ms/step\n",
      "Epoch 147/150\n",
      "10/10 - 0s - loss: 2.1648e-04 - val_loss: 0.0178 - 104ms/epoch - 10ms/step\n",
      "Epoch 148/150\n",
      "10/10 - 0s - loss: 2.2370e-04 - val_loss: 0.0186 - 95ms/epoch - 9ms/step\n",
      "Epoch 149/150\n",
      "10/10 - 0s - loss: 2.0857e-04 - val_loss: 0.0180 - 139ms/epoch - 14ms/step\n",
      "Epoch 150/150\n",
      "10/10 - 0s - loss: 2.1552e-04 - val_loss: 0.0194 - 95ms/epoch - 10ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m-249.2   \u001b[0m | \u001b[0m150.6    \u001b[0m | \u001b[0m3.348    \u001b[0m | \u001b[0m0.005457 \u001b[0m | \u001b[0m55.07    \u001b[0m |\n",
      "Model: \"sequential_165\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_597 (LSTM)             (None, 1, 95)             38380     \n",
      "                                                                 \n",
      " dropout_432 (Dropout)       (None, 1, 95)             0         \n",
      "                                                                 \n",
      " lstm_598 (LSTM)             (None, 95)                72580     \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 1)                 96        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111,056\n",
      "Trainable params: 111,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/118\n",
      "10/10 - 4s - loss: 0.0230 - val_loss: 0.0123 - 4s/epoch - 392ms/step\n",
      "Epoch 2/118\n",
      "10/10 - 0s - loss: 0.0036 - val_loss: 0.0127 - 79ms/epoch - 8ms/step\n",
      "Epoch 3/118\n",
      "10/10 - 0s - loss: 0.0020 - val_loss: 0.0111 - 93ms/epoch - 9ms/step\n",
      "Epoch 4/118\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0111 - 76ms/epoch - 8ms/step\n",
      "Epoch 5/118\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0106 - 85ms/epoch - 8ms/step\n",
      "Epoch 6/118\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0096 - 75ms/epoch - 7ms/step\n",
      "Epoch 7/118\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0096 - 89ms/epoch - 9ms/step\n",
      "Epoch 8/118\n",
      "10/10 - 0s - loss: 8.6606e-04 - val_loss: 0.0086 - 77ms/epoch - 8ms/step\n",
      "Epoch 9/118\n",
      "10/10 - 0s - loss: 5.8839e-04 - val_loss: 0.0083 - 133ms/epoch - 13ms/step\n",
      "Epoch 10/118\n",
      "10/10 - 0s - loss: 4.6216e-04 - val_loss: 0.0082 - 79ms/epoch - 8ms/step\n",
      "Epoch 11/118\n",
      "10/10 - 0s - loss: 4.1657e-04 - val_loss: 0.0082 - 88ms/epoch - 9ms/step\n",
      "Epoch 12/118\n",
      "10/10 - 0s - loss: 3.8185e-04 - val_loss: 0.0083 - 78ms/epoch - 8ms/step\n",
      "Epoch 13/118\n",
      "10/10 - 0s - loss: 3.7861e-04 - val_loss: 0.0083 - 89ms/epoch - 9ms/step\n",
      "Epoch 14/118\n",
      "10/10 - 0s - loss: 3.5260e-04 - val_loss: 0.0084 - 78ms/epoch - 8ms/step\n",
      "Epoch 15/118\n",
      "10/10 - 0s - loss: 3.4757e-04 - val_loss: 0.0083 - 91ms/epoch - 9ms/step\n",
      "Epoch 16/118\n",
      "10/10 - 0s - loss: 3.2916e-04 - val_loss: 0.0083 - 89ms/epoch - 9ms/step\n",
      "Epoch 17/118\n",
      "10/10 - 0s - loss: 3.3376e-04 - val_loss: 0.0083 - 108ms/epoch - 11ms/step\n",
      "Epoch 18/118\n",
      "10/10 - 0s - loss: 3.1535e-04 - val_loss: 0.0082 - 90ms/epoch - 9ms/step\n",
      "Epoch 19/118\n",
      "10/10 - 0s - loss: 3.0431e-04 - val_loss: 0.0083 - 89ms/epoch - 9ms/step\n",
      "Epoch 20/118\n",
      "10/10 - 0s - loss: 3.0407e-04 - val_loss: 0.0082 - 77ms/epoch - 8ms/step\n",
      "Epoch 21/118\n",
      "10/10 - 0s - loss: 3.0163e-04 - val_loss: 0.0083 - 88ms/epoch - 9ms/step\n",
      "Epoch 22/118\n",
      "10/10 - 0s - loss: 2.9255e-04 - val_loss: 0.0083 - 79ms/epoch - 8ms/step\n",
      "Epoch 23/118\n",
      "10/10 - 0s - loss: 2.9596e-04 - val_loss: 0.0083 - 88ms/epoch - 9ms/step\n",
      "Epoch 24/118\n",
      "10/10 - 0s - loss: 2.6578e-04 - val_loss: 0.0082 - 79ms/epoch - 8ms/step\n",
      "Epoch 25/118\n",
      "10/10 - 0s - loss: 2.4613e-04 - val_loss: 0.0082 - 126ms/epoch - 13ms/step\n",
      "Epoch 26/118\n",
      "10/10 - 0s - loss: 2.6560e-04 - val_loss: 0.0082 - 77ms/epoch - 8ms/step\n",
      "Epoch 27/118\n",
      "10/10 - 0s - loss: 2.8092e-04 - val_loss: 0.0083 - 88ms/epoch - 9ms/step\n",
      "Epoch 28/118\n",
      "10/10 - 0s - loss: 2.5363e-04 - val_loss: 0.0083 - 77ms/epoch - 8ms/step\n",
      "Epoch 29/118\n",
      "10/10 - 0s - loss: 2.6204e-04 - val_loss: 0.0083 - 83ms/epoch - 8ms/step\n",
      "Epoch 30/118\n",
      "10/10 - 0s - loss: 2.5601e-04 - val_loss: 0.0084 - 78ms/epoch - 8ms/step\n",
      "Epoch 31/118\n",
      "10/10 - 0s - loss: 2.5765e-04 - val_loss: 0.0083 - 85ms/epoch - 8ms/step\n",
      "Epoch 32/118\n",
      "10/10 - 0s - loss: 2.3855e-04 - val_loss: 0.0082 - 79ms/epoch - 8ms/step\n",
      "Epoch 33/118\n",
      "10/10 - 0s - loss: 2.5239e-04 - val_loss: 0.0084 - 133ms/epoch - 13ms/step\n",
      "Epoch 34/118\n",
      "10/10 - 0s - loss: 2.4978e-04 - val_loss: 0.0082 - 80ms/epoch - 8ms/step\n",
      "Epoch 35/118\n",
      "10/10 - 0s - loss: 2.3342e-04 - val_loss: 0.0082 - 89ms/epoch - 9ms/step\n",
      "Epoch 36/118\n",
      "10/10 - 0s - loss: 2.1269e-04 - val_loss: 0.0083 - 78ms/epoch - 8ms/step\n",
      "Epoch 37/118\n",
      "10/10 - 0s - loss: 2.2776e-04 - val_loss: 0.0083 - 75ms/epoch - 7ms/step\n",
      "Epoch 38/118\n",
      "10/10 - 0s - loss: 2.0974e-04 - val_loss: 0.0084 - 87ms/epoch - 9ms/step\n",
      "Epoch 39/118\n",
      "10/10 - 0s - loss: 2.1895e-04 - val_loss: 0.0084 - 78ms/epoch - 8ms/step\n",
      "Epoch 40/118\n",
      "10/10 - 0s - loss: 2.1275e-04 - val_loss: 0.0084 - 84ms/epoch - 8ms/step\n",
      "Epoch 41/118\n",
      "10/10 - 0s - loss: 2.1288e-04 - val_loss: 0.0084 - 77ms/epoch - 8ms/step\n",
      "Epoch 42/118\n",
      "10/10 - 0s - loss: 2.0385e-04 - val_loss: 0.0084 - 128ms/epoch - 13ms/step\n",
      "Epoch 43/118\n",
      "10/10 - 0s - loss: 2.1189e-04 - val_loss: 0.0084 - 76ms/epoch - 8ms/step\n",
      "Epoch 44/118\n",
      "10/10 - 0s - loss: 2.1584e-04 - val_loss: 0.0084 - 79ms/epoch - 8ms/step\n",
      "Epoch 45/118\n",
      "10/10 - 0s - loss: 1.9341e-04 - val_loss: 0.0085 - 92ms/epoch - 9ms/step\n",
      "Epoch 46/118\n",
      "10/10 - 0s - loss: 2.0395e-04 - val_loss: 0.0085 - 77ms/epoch - 8ms/step\n",
      "Epoch 47/118\n",
      "10/10 - 0s - loss: 1.9525e-04 - val_loss: 0.0085 - 88ms/epoch - 9ms/step\n",
      "Epoch 48/118\n",
      "10/10 - 0s - loss: 2.0984e-04 - val_loss: 0.0085 - 75ms/epoch - 7ms/step\n",
      "Epoch 49/118\n",
      "10/10 - 0s - loss: 2.1847e-04 - val_loss: 0.0085 - 83ms/epoch - 8ms/step\n",
      "Epoch 50/118\n",
      "10/10 - 0s - loss: 2.1881e-04 - val_loss: 0.0086 - 78ms/epoch - 8ms/step\n",
      "Epoch 51/118\n",
      "10/10 - 0s - loss: 2.0053e-04 - val_loss: 0.0085 - 129ms/epoch - 13ms/step\n",
      "Epoch 52/118\n",
      "10/10 - 0s - loss: 2.0743e-04 - val_loss: 0.0087 - 86ms/epoch - 9ms/step\n",
      "Epoch 53/118\n",
      "10/10 - 0s - loss: 2.3497e-04 - val_loss: 0.0085 - 115ms/epoch - 11ms/step\n",
      "Epoch 54/118\n",
      "10/10 - 0s - loss: 2.2717e-04 - val_loss: 0.0087 - 81ms/epoch - 8ms/step\n",
      "Epoch 55/118\n",
      "10/10 - 0s - loss: 1.9318e-04 - val_loss: 0.0085 - 101ms/epoch - 10ms/step\n",
      "Epoch 56/118\n",
      "10/10 - 0s - loss: 1.8392e-04 - val_loss: 0.0086 - 84ms/epoch - 8ms/step\n",
      "Epoch 57/118\n",
      "10/10 - 0s - loss: 1.8368e-04 - val_loss: 0.0086 - 105ms/epoch - 10ms/step\n",
      "Epoch 58/118\n",
      "10/10 - 0s - loss: 2.1208e-04 - val_loss: 0.0086 - 84ms/epoch - 8ms/step\n",
      "Epoch 59/118\n",
      "10/10 - 0s - loss: 2.0248e-04 - val_loss: 0.0087 - 94ms/epoch - 9ms/step\n",
      "Epoch 60/118\n",
      "10/10 - 0s - loss: 2.0220e-04 - val_loss: 0.0087 - 121ms/epoch - 12ms/step\n",
      "Epoch 61/118\n",
      "10/10 - 0s - loss: 1.9366e-04 - val_loss: 0.0087 - 120ms/epoch - 12ms/step\n",
      "Epoch 62/118\n",
      "10/10 - 0s - loss: 1.8596e-04 - val_loss: 0.0087 - 85ms/epoch - 9ms/step\n",
      "Epoch 63/118\n",
      "10/10 - 0s - loss: 1.9767e-04 - val_loss: 0.0086 - 106ms/epoch - 11ms/step\n",
      "Epoch 64/118\n",
      "10/10 - 0s - loss: 1.9584e-04 - val_loss: 0.0088 - 81ms/epoch - 8ms/step\n",
      "Epoch 65/118\n",
      "10/10 - 0s - loss: 1.8540e-04 - val_loss: 0.0088 - 96ms/epoch - 10ms/step\n",
      "Epoch 66/118\n",
      "10/10 - 0s - loss: 2.0051e-04 - val_loss: 0.0087 - 78ms/epoch - 8ms/step\n",
      "Epoch 67/118\n",
      "10/10 - 0s - loss: 2.1687e-04 - val_loss: 0.0091 - 88ms/epoch - 9ms/step\n",
      "Epoch 68/118\n",
      "10/10 - 0s - loss: 2.4409e-04 - val_loss: 0.0087 - 103ms/epoch - 10ms/step\n",
      "Epoch 69/118\n",
      "10/10 - 0s - loss: 1.9005e-04 - val_loss: 0.0088 - 93ms/epoch - 9ms/step\n",
      "Epoch 70/118\n",
      "10/10 - 0s - loss: 1.9084e-04 - val_loss: 0.0088 - 78ms/epoch - 8ms/step\n",
      "Epoch 71/118\n",
      "10/10 - 0s - loss: 2.1041e-04 - val_loss: 0.0088 - 88ms/epoch - 9ms/step\n",
      "Epoch 72/118\n",
      "10/10 - 0s - loss: 2.1416e-04 - val_loss: 0.0088 - 78ms/epoch - 8ms/step\n",
      "Epoch 73/118\n",
      "10/10 - 0s - loss: 1.8813e-04 - val_loss: 0.0089 - 85ms/epoch - 8ms/step\n",
      "Epoch 74/118\n",
      "10/10 - 0s - loss: 1.9416e-04 - val_loss: 0.0088 - 77ms/epoch - 8ms/step\n",
      "Epoch 75/118\n",
      "10/10 - 0s - loss: 1.8241e-04 - val_loss: 0.0088 - 88ms/epoch - 9ms/step\n",
      "Epoch 76/118\n",
      "10/10 - 0s - loss: 1.8355e-04 - val_loss: 0.0089 - 106ms/epoch - 11ms/step\n",
      "Epoch 77/118\n",
      "10/10 - 0s - loss: 1.7999e-04 - val_loss: 0.0089 - 87ms/epoch - 9ms/step\n",
      "Epoch 78/118\n",
      "10/10 - 0s - loss: 1.7664e-04 - val_loss: 0.0089 - 75ms/epoch - 7ms/step\n",
      "Epoch 79/118\n",
      "10/10 - 0s - loss: 1.7276e-04 - val_loss: 0.0090 - 90ms/epoch - 9ms/step\n",
      "Epoch 80/118\n",
      "10/10 - 0s - loss: 1.8569e-04 - val_loss: 0.0089 - 82ms/epoch - 8ms/step\n",
      "Epoch 81/118\n",
      "10/10 - 0s - loss: 1.8061e-04 - val_loss: 0.0089 - 92ms/epoch - 9ms/step\n",
      "Epoch 82/118\n",
      "10/10 - 0s - loss: 1.7276e-04 - val_loss: 0.0090 - 78ms/epoch - 8ms/step\n",
      "Epoch 83/118\n",
      "10/10 - 0s - loss: 1.8537e-04 - val_loss: 0.0089 - 134ms/epoch - 13ms/step\n",
      "Epoch 84/118\n",
      "10/10 - 0s - loss: 1.8304e-04 - val_loss: 0.0090 - 84ms/epoch - 8ms/step\n",
      "Epoch 85/118\n",
      "10/10 - 0s - loss: 1.7984e-04 - val_loss: 0.0092 - 92ms/epoch - 9ms/step\n",
      "Epoch 86/118\n",
      "10/10 - 0s - loss: 2.3119e-04 - val_loss: 0.0088 - 79ms/epoch - 8ms/step\n",
      "Epoch 87/118\n",
      "10/10 - 0s - loss: 1.8882e-04 - val_loss: 0.0089 - 94ms/epoch - 9ms/step\n",
      "Epoch 88/118\n",
      "10/10 - 0s - loss: 1.7691e-04 - val_loss: 0.0091 - 82ms/epoch - 8ms/step\n",
      "Epoch 89/118\n",
      "10/10 - 0s - loss: 1.7378e-04 - val_loss: 0.0090 - 91ms/epoch - 9ms/step\n",
      "Epoch 90/118\n",
      "10/10 - 0s - loss: 1.7232e-04 - val_loss: 0.0090 - 107ms/epoch - 11ms/step\n",
      "Epoch 91/118\n",
      "10/10 - 0s - loss: 1.8319e-04 - val_loss: 0.0091 - 97ms/epoch - 10ms/step\n",
      "Epoch 92/118\n",
      "10/10 - 0s - loss: 1.8324e-04 - val_loss: 0.0090 - 80ms/epoch - 8ms/step\n",
      "Epoch 93/118\n",
      "10/10 - 0s - loss: 1.7189e-04 - val_loss: 0.0091 - 94ms/epoch - 9ms/step\n",
      "Epoch 94/118\n",
      "10/10 - 0s - loss: 1.7412e-04 - val_loss: 0.0091 - 79ms/epoch - 8ms/step\n",
      "Epoch 95/118\n",
      "10/10 - 0s - loss: 1.6959e-04 - val_loss: 0.0091 - 90ms/epoch - 9ms/step\n",
      "Epoch 96/118\n",
      "10/10 - 0s - loss: 1.7911e-04 - val_loss: 0.0091 - 80ms/epoch - 8ms/step\n",
      "Epoch 97/118\n",
      "10/10 - 0s - loss: 1.9317e-04 - val_loss: 0.0092 - 93ms/epoch - 9ms/step\n",
      "Epoch 98/118\n",
      "10/10 - 0s - loss: 1.9770e-04 - val_loss: 0.0090 - 80ms/epoch - 8ms/step\n",
      "Epoch 99/118\n",
      "10/10 - 0s - loss: 1.7698e-04 - val_loss: 0.0093 - 129ms/epoch - 13ms/step\n",
      "Epoch 100/118\n",
      "10/10 - 0s - loss: 1.7502e-04 - val_loss: 0.0092 - 83ms/epoch - 8ms/step\n",
      "Epoch 101/118\n",
      "10/10 - 0s - loss: 1.6965e-04 - val_loss: 0.0092 - 91ms/epoch - 9ms/step\n",
      "Epoch 102/118\n",
      "10/10 - 0s - loss: 1.7590e-04 - val_loss: 0.0093 - 79ms/epoch - 8ms/step\n",
      "Epoch 103/118\n",
      "10/10 - 0s - loss: 1.8736e-04 - val_loss: 0.0093 - 93ms/epoch - 9ms/step\n",
      "Epoch 104/118\n",
      "10/10 - 0s - loss: 1.8084e-04 - val_loss: 0.0092 - 80ms/epoch - 8ms/step\n",
      "Epoch 105/118\n",
      "10/10 - 0s - loss: 1.7447e-04 - val_loss: 0.0093 - 96ms/epoch - 10ms/step\n",
      "Epoch 106/118\n",
      "10/10 - 0s - loss: 2.0793e-04 - val_loss: 0.0093 - 79ms/epoch - 8ms/step\n",
      "Epoch 107/118\n",
      "10/10 - 0s - loss: 1.7704e-04 - val_loss: 0.0092 - 93ms/epoch - 9ms/step\n",
      "Epoch 108/118\n",
      "10/10 - 0s - loss: 1.7378e-04 - val_loss: 0.0093 - 114ms/epoch - 11ms/step\n",
      "Epoch 109/118\n",
      "10/10 - 0s - loss: 1.7531e-04 - val_loss: 0.0093 - 94ms/epoch - 9ms/step\n",
      "Epoch 110/118\n",
      "10/10 - 0s - loss: 2.3251e-04 - val_loss: 0.0093 - 81ms/epoch - 8ms/step\n",
      "Epoch 111/118\n",
      "10/10 - 0s - loss: 1.9041e-04 - val_loss: 0.0095 - 86ms/epoch - 9ms/step\n",
      "Epoch 112/118\n",
      "10/10 - 0s - loss: 1.8436e-04 - val_loss: 0.0092 - 76ms/epoch - 8ms/step\n",
      "Epoch 113/118\n",
      "10/10 - 0s - loss: 1.8379e-04 - val_loss: 0.0094 - 88ms/epoch - 9ms/step\n",
      "Epoch 114/118\n",
      "10/10 - 0s - loss: 2.1838e-04 - val_loss: 0.0094 - 77ms/epoch - 8ms/step\n",
      "Epoch 115/118\n",
      "10/10 - 0s - loss: 2.0501e-04 - val_loss: 0.0092 - 88ms/epoch - 9ms/step\n",
      "Epoch 116/118\n",
      "10/10 - 0s - loss: 1.8914e-04 - val_loss: 0.0092 - 78ms/epoch - 8ms/step\n",
      "Epoch 117/118\n",
      "10/10 - 0s - loss: 1.8961e-04 - val_loss: 0.0092 - 135ms/epoch - 14ms/step\n",
      "Epoch 118/118\n",
      "10/10 - 0s - loss: 1.7039e-04 - val_loss: 0.0093 - 78ms/epoch - 8ms/step\n",
      "9/9 [==============================] - 1s 1ms/step\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m-172.7   \u001b[0m | \u001b[0m118.2    \u001b[0m | \u001b[0m1.728    \u001b[0m | \u001b[0m0.005195 \u001b[0m | \u001b[0m95.7     \u001b[0m |\n",
      "Model: \"sequential_166\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_599 (LSTM)             (None, 1, 56)             13888     \n",
      "                                                                 \n",
      " dropout_433 (Dropout)       (None, 1, 56)             0         \n",
      "                                                                 \n",
      " lstm_600 (LSTM)             (None, 1, 56)             25312     \n",
      "                                                                 \n",
      " dropout_434 (Dropout)       (None, 1, 56)             0         \n",
      "                                                                 \n",
      " lstm_601 (LSTM)             (None, 1, 56)             25312     \n",
      "                                                                 \n",
      " dropout_435 (Dropout)       (None, 1, 56)             0         \n",
      "                                                                 \n",
      " lstm_602 (LSTM)             (None, 1, 56)             25312     \n",
      "                                                                 \n",
      " dropout_436 (Dropout)       (None, 1, 56)             0         \n",
      "                                                                 \n",
      " lstm_603 (LSTM)             (None, 1, 56)             25312     \n",
      "                                                                 \n",
      " dropout_437 (Dropout)       (None, 1, 56)             0         \n",
      "                                                                 \n",
      " lstm_604 (LSTM)             (None, 56)                25312     \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 1)                 57        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 140,505\n",
      "Trainable params: 140,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/123\n",
      "10/10 - 13s - loss: 0.0705 - val_loss: 0.0916 - 13s/epoch - 1s/step\n",
      "Epoch 2/123\n",
      "10/10 - 0s - loss: 0.0703 - val_loss: 0.0914 - 149ms/epoch - 15ms/step\n",
      "Epoch 3/123\n",
      "10/10 - 0s - loss: 0.0701 - val_loss: 0.0912 - 126ms/epoch - 13ms/step\n",
      "Epoch 4/123\n",
      "10/10 - 0s - loss: 0.0699 - val_loss: 0.0910 - 125ms/epoch - 12ms/step\n",
      "Epoch 5/123\n",
      "10/10 - 0s - loss: 0.0697 - val_loss: 0.0908 - 145ms/epoch - 14ms/step\n",
      "Epoch 6/123\n",
      "10/10 - 0s - loss: 0.0695 - val_loss: 0.0906 - 127ms/epoch - 13ms/step\n",
      "Epoch 7/123\n",
      "10/10 - 0s - loss: 0.0693 - val_loss: 0.0904 - 143ms/epoch - 14ms/step\n",
      "Epoch 8/123\n",
      "10/10 - 0s - loss: 0.0691 - val_loss: 0.0902 - 128ms/epoch - 13ms/step\n",
      "Epoch 9/123\n",
      "10/10 - 0s - loss: 0.0689 - val_loss: 0.0900 - 205ms/epoch - 20ms/step\n",
      "Epoch 10/123\n",
      "10/10 - 0s - loss: 0.0688 - val_loss: 0.0898 - 127ms/epoch - 13ms/step\n",
      "Epoch 11/123\n",
      "10/10 - 0s - loss: 0.0686 - val_loss: 0.0896 - 138ms/epoch - 14ms/step\n",
      "Epoch 12/123\n",
      "10/10 - 0s - loss: 0.0684 - val_loss: 0.0894 - 122ms/epoch - 12ms/step\n",
      "Epoch 13/123\n",
      "10/10 - 0s - loss: 0.0682 - val_loss: 0.0892 - 143ms/epoch - 14ms/step\n",
      "Epoch 14/123\n",
      "10/10 - 0s - loss: 0.0680 - val_loss: 0.0890 - 128ms/epoch - 13ms/step\n",
      "Epoch 15/123\n",
      "10/10 - 0s - loss: 0.0678 - val_loss: 0.0888 - 146ms/epoch - 15ms/step\n",
      "Epoch 16/123\n",
      "10/10 - 0s - loss: 0.0676 - val_loss: 0.0885 - 128ms/epoch - 13ms/step\n",
      "Epoch 17/123\n",
      "10/10 - 0s - loss: 0.0674 - val_loss: 0.0883 - 132ms/epoch - 13ms/step\n",
      "Epoch 18/123\n",
      "10/10 - 0s - loss: 0.0672 - val_loss: 0.0881 - 149ms/epoch - 15ms/step\n",
      "Epoch 19/123\n",
      "10/10 - 0s - loss: 0.0670 - val_loss: 0.0879 - 141ms/epoch - 14ms/step\n",
      "Epoch 20/123\n",
      "10/10 - 0s - loss: 0.0668 - val_loss: 0.0877 - 120ms/epoch - 12ms/step\n",
      "Epoch 21/123\n",
      "10/10 - 0s - loss: 0.0666 - val_loss: 0.0875 - 135ms/epoch - 14ms/step\n",
      "Epoch 22/123\n",
      "10/10 - 0s - loss: 0.0664 - val_loss: 0.0873 - 120ms/epoch - 12ms/step\n",
      "Epoch 23/123\n",
      "10/10 - 0s - loss: 0.0662 - val_loss: 0.0870 - 137ms/epoch - 14ms/step\n",
      "Epoch 24/123\n",
      "10/10 - 0s - loss: 0.0659 - val_loss: 0.0868 - 128ms/epoch - 13ms/step\n",
      "Epoch 25/123\n",
      "10/10 - 0s - loss: 0.0657 - val_loss: 0.0866 - 147ms/epoch - 15ms/step\n",
      "Epoch 26/123\n",
      "10/10 - 0s - loss: 0.0655 - val_loss: 0.0864 - 122ms/epoch - 12ms/step\n",
      "Epoch 27/123\n",
      "10/10 - 0s - loss: 0.0653 - val_loss: 0.0862 - 170ms/epoch - 17ms/step\n",
      "Epoch 28/123\n",
      "10/10 - 0s - loss: 0.0651 - val_loss: 0.0859 - 122ms/epoch - 12ms/step\n",
      "Epoch 29/123\n",
      "10/10 - 0s - loss: 0.0649 - val_loss: 0.0857 - 139ms/epoch - 14ms/step\n",
      "Epoch 30/123\n",
      "10/10 - 0s - loss: 0.0647 - val_loss: 0.0855 - 119ms/epoch - 12ms/step\n",
      "Epoch 31/123\n",
      "10/10 - 0s - loss: 0.0645 - val_loss: 0.0852 - 139ms/epoch - 14ms/step\n",
      "Epoch 32/123\n",
      "10/10 - 0s - loss: 0.0642 - val_loss: 0.0850 - 124ms/epoch - 12ms/step\n",
      "Epoch 33/123\n",
      "10/10 - 0s - loss: 0.0640 - val_loss: 0.0848 - 136ms/epoch - 14ms/step\n",
      "Epoch 34/123\n",
      "10/10 - 0s - loss: 0.0638 - val_loss: 0.0846 - 125ms/epoch - 13ms/step\n",
      "Epoch 35/123\n",
      "10/10 - 0s - loss: 0.0636 - val_loss: 0.0843 - 142ms/epoch - 14ms/step\n",
      "Epoch 36/123\n",
      "10/10 - 0s - loss: 0.0634 - val_loss: 0.0841 - 134ms/epoch - 13ms/step\n",
      "Epoch 37/123\n",
      "10/10 - 0s - loss: 0.0631 - val_loss: 0.0839 - 135ms/epoch - 14ms/step\n",
      "Epoch 38/123\n",
      "10/10 - 0s - loss: 0.0629 - val_loss: 0.0836 - 135ms/epoch - 13ms/step\n",
      "Epoch 39/123\n",
      "10/10 - 0s - loss: 0.0627 - val_loss: 0.0834 - 133ms/epoch - 13ms/step\n",
      "Epoch 40/123\n",
      "10/10 - 0s - loss: 0.0625 - val_loss: 0.0831 - 121ms/epoch - 12ms/step\n",
      "Epoch 41/123\n",
      "10/10 - 0s - loss: 0.0622 - val_loss: 0.0829 - 136ms/epoch - 14ms/step\n",
      "Epoch 42/123\n",
      "10/10 - 0s - loss: 0.0620 - val_loss: 0.0827 - 123ms/epoch - 12ms/step\n",
      "Epoch 43/123\n",
      "10/10 - 0s - loss: 0.0618 - val_loss: 0.0824 - 142ms/epoch - 14ms/step\n",
      "Epoch 44/123\n",
      "10/10 - 0s - loss: 0.0616 - val_loss: 0.0822 - 147ms/epoch - 15ms/step\n",
      "Epoch 45/123\n",
      "10/10 - 0s - loss: 0.0613 - val_loss: 0.0819 - 146ms/epoch - 15ms/step\n",
      "Epoch 46/123\n",
      "10/10 - 0s - loss: 0.0611 - val_loss: 0.0817 - 121ms/epoch - 12ms/step\n",
      "Epoch 47/123\n",
      "10/10 - 0s - loss: 0.0608 - val_loss: 0.0814 - 142ms/epoch - 14ms/step\n",
      "Epoch 48/123\n",
      "10/10 - 0s - loss: 0.0606 - val_loss: 0.0812 - 130ms/epoch - 13ms/step\n",
      "Epoch 49/123\n",
      "10/10 - 0s - loss: 0.0604 - val_loss: 0.0809 - 159ms/epoch - 16ms/step\n",
      "Epoch 50/123\n",
      "10/10 - 0s - loss: 0.0601 - val_loss: 0.0807 - 125ms/epoch - 12ms/step\n",
      "Epoch 51/123\n",
      "10/10 - 0s - loss: 0.0599 - val_loss: 0.0804 - 144ms/epoch - 14ms/step\n",
      "Epoch 52/123\n",
      "10/10 - 0s - loss: 0.0597 - val_loss: 0.0801 - 146ms/epoch - 15ms/step\n",
      "Epoch 53/123\n",
      "10/10 - 0s - loss: 0.0594 - val_loss: 0.0799 - 174ms/epoch - 17ms/step\n",
      "Epoch 54/123\n",
      "10/10 - 0s - loss: 0.0592 - val_loss: 0.0796 - 123ms/epoch - 12ms/step\n",
      "Epoch 55/123\n",
      "10/10 - 0s - loss: 0.0589 - val_loss: 0.0794 - 134ms/epoch - 13ms/step\n",
      "Epoch 56/123\n",
      "10/10 - 0s - loss: 0.0587 - val_loss: 0.0791 - 124ms/epoch - 12ms/step\n",
      "Epoch 57/123\n",
      "10/10 - 0s - loss: 0.0584 - val_loss: 0.0788 - 156ms/epoch - 16ms/step\n",
      "Epoch 58/123\n",
      "10/10 - 0s - loss: 0.0582 - val_loss: 0.0786 - 122ms/epoch - 12ms/step\n",
      "Epoch 59/123\n",
      "10/10 - 0s - loss: 0.0579 - val_loss: 0.0783 - 136ms/epoch - 14ms/step\n",
      "Epoch 60/123\n",
      "10/10 - 0s - loss: 0.0577 - val_loss: 0.0780 - 127ms/epoch - 13ms/step\n",
      "Epoch 61/123\n",
      "10/10 - 0s - loss: 0.0574 - val_loss: 0.0778 - 156ms/epoch - 16ms/step\n",
      "Epoch 62/123\n",
      "10/10 - 0s - loss: 0.0571 - val_loss: 0.0775 - 130ms/epoch - 13ms/step\n",
      "Epoch 63/123\n",
      "10/10 - 0s - loss: 0.0569 - val_loss: 0.0772 - 140ms/epoch - 14ms/step\n",
      "Epoch 64/123\n",
      "10/10 - 0s - loss: 0.0566 - val_loss: 0.0769 - 120ms/epoch - 12ms/step\n",
      "Epoch 65/123\n",
      "10/10 - 0s - loss: 0.0564 - val_loss: 0.0767 - 136ms/epoch - 14ms/step\n",
      "Epoch 66/123\n",
      "10/10 - 0s - loss: 0.0561 - val_loss: 0.0764 - 119ms/epoch - 12ms/step\n",
      "Epoch 67/123\n",
      "10/10 - 0s - loss: 0.0558 - val_loss: 0.0761 - 128ms/epoch - 13ms/step\n",
      "Epoch 68/123\n",
      "10/10 - 0s - loss: 0.0556 - val_loss: 0.0758 - 119ms/epoch - 12ms/step\n",
      "Epoch 69/123\n",
      "10/10 - 0s - loss: 0.0553 - val_loss: 0.0755 - 142ms/epoch - 14ms/step\n",
      "Epoch 70/123\n",
      "10/10 - 0s - loss: 0.0551 - val_loss: 0.0752 - 154ms/epoch - 15ms/step\n",
      "Epoch 71/123\n",
      "10/10 - 0s - loss: 0.0548 - val_loss: 0.0749 - 142ms/epoch - 14ms/step\n",
      "Epoch 72/123\n",
      "10/10 - 0s - loss: 0.0545 - val_loss: 0.0747 - 121ms/epoch - 12ms/step\n",
      "Epoch 73/123\n",
      "10/10 - 0s - loss: 0.0542 - val_loss: 0.0744 - 134ms/epoch - 13ms/step\n",
      "Epoch 74/123\n",
      "10/10 - 0s - loss: 0.0539 - val_loss: 0.0741 - 121ms/epoch - 12ms/step\n",
      "Epoch 75/123\n",
      "10/10 - 0s - loss: 0.0537 - val_loss: 0.0738 - 134ms/epoch - 13ms/step\n",
      "Epoch 76/123\n",
      "10/10 - 0s - loss: 0.0534 - val_loss: 0.0735 - 123ms/epoch - 12ms/step\n",
      "Epoch 77/123\n",
      "10/10 - 0s - loss: 0.0531 - val_loss: 0.0732 - 131ms/epoch - 13ms/step\n",
      "Epoch 78/123\n",
      "10/10 - 0s - loss: 0.0528 - val_loss: 0.0729 - 144ms/epoch - 14ms/step\n",
      "Epoch 79/123\n",
      "10/10 - 0s - loss: 0.0526 - val_loss: 0.0726 - 149ms/epoch - 15ms/step\n",
      "Epoch 80/123\n",
      "10/10 - 0s - loss: 0.0522 - val_loss: 0.0723 - 123ms/epoch - 12ms/step\n",
      "Epoch 81/123\n",
      "10/10 - 0s - loss: 0.0520 - val_loss: 0.0720 - 135ms/epoch - 14ms/step\n",
      "Epoch 82/123\n",
      "10/10 - 0s - loss: 0.0516 - val_loss: 0.0716 - 121ms/epoch - 12ms/step\n",
      "Epoch 83/123\n",
      "10/10 - 0s - loss: 0.0514 - val_loss: 0.0713 - 135ms/epoch - 14ms/step\n",
      "Epoch 84/123\n",
      "10/10 - 0s - loss: 0.0511 - val_loss: 0.0710 - 120ms/epoch - 12ms/step\n",
      "Epoch 85/123\n",
      "10/10 - 0s - loss: 0.0508 - val_loss: 0.0707 - 154ms/epoch - 15ms/step\n",
      "Epoch 86/123\n",
      "10/10 - 0s - loss: 0.0505 - val_loss: 0.0704 - 139ms/epoch - 14ms/step\n",
      "Epoch 87/123\n",
      "10/10 - 0s - loss: 0.0502 - val_loss: 0.0701 - 141ms/epoch - 14ms/step\n",
      "Epoch 88/123\n",
      "10/10 - 0s - loss: 0.0499 - val_loss: 0.0697 - 124ms/epoch - 12ms/step\n",
      "Epoch 89/123\n",
      "10/10 - 0s - loss: 0.0496 - val_loss: 0.0694 - 138ms/epoch - 14ms/step\n",
      "Epoch 90/123\n",
      "10/10 - 0s - loss: 0.0493 - val_loss: 0.0691 - 122ms/epoch - 12ms/step\n",
      "Epoch 91/123\n",
      "10/10 - 0s - loss: 0.0490 - val_loss: 0.0688 - 137ms/epoch - 14ms/step\n",
      "Epoch 92/123\n",
      "10/10 - 0s - loss: 0.0487 - val_loss: 0.0684 - 166ms/epoch - 17ms/step\n",
      "Epoch 93/123\n",
      "10/10 - 0s - loss: 0.0483 - val_loss: 0.0681 - 141ms/epoch - 14ms/step\n",
      "Epoch 94/123\n",
      "10/10 - 0s - loss: 0.0480 - val_loss: 0.0678 - 122ms/epoch - 12ms/step\n",
      "Epoch 95/123\n",
      "10/10 - 0s - loss: 0.0477 - val_loss: 0.0674 - 141ms/epoch - 14ms/step\n",
      "Epoch 96/123\n",
      "10/10 - 0s - loss: 0.0474 - val_loss: 0.0671 - 123ms/epoch - 12ms/step\n",
      "Epoch 97/123\n",
      "10/10 - 0s - loss: 0.0471 - val_loss: 0.0667 - 136ms/epoch - 14ms/step\n",
      "Epoch 98/123\n",
      "10/10 - 0s - loss: 0.0468 - val_loss: 0.0664 - 123ms/epoch - 12ms/step\n",
      "Epoch 99/123\n",
      "10/10 - 0s - loss: 0.0464 - val_loss: 0.0660 - 159ms/epoch - 16ms/step\n",
      "Epoch 100/123\n",
      "10/10 - 0s - loss: 0.0462 - val_loss: 0.0657 - 123ms/epoch - 12ms/step\n",
      "Epoch 101/123\n",
      "10/10 - 0s - loss: 0.0458 - val_loss: 0.0653 - 137ms/epoch - 14ms/step\n",
      "Epoch 102/123\n",
      "10/10 - 0s - loss: 0.0455 - val_loss: 0.0650 - 121ms/epoch - 12ms/step\n",
      "Epoch 103/123\n",
      "10/10 - 0s - loss: 0.0452 - val_loss: 0.0646 - 129ms/epoch - 13ms/step\n",
      "Epoch 104/123\n",
      "10/10 - 0s - loss: 0.0448 - val_loss: 0.0643 - 118ms/epoch - 12ms/step\n",
      "Epoch 105/123\n",
      "10/10 - 0s - loss: 0.0445 - val_loss: 0.0639 - 137ms/epoch - 14ms/step\n",
      "Epoch 106/123\n",
      "10/10 - 0s - loss: 0.0441 - val_loss: 0.0636 - 125ms/epoch - 12ms/step\n",
      "Epoch 107/123\n",
      "10/10 - 0s - loss: 0.0439 - val_loss: 0.0632 - 146ms/epoch - 15ms/step\n",
      "Epoch 108/123\n",
      "10/10 - 0s - loss: 0.0435 - val_loss: 0.0628 - 163ms/epoch - 16ms/step\n",
      "Epoch 109/123\n",
      "10/10 - 0s - loss: 0.0431 - val_loss: 0.0625 - 146ms/epoch - 15ms/step\n",
      "Epoch 110/123\n",
      "10/10 - 0s - loss: 0.0428 - val_loss: 0.0621 - 143ms/epoch - 14ms/step\n",
      "Epoch 111/123\n",
      "10/10 - 0s - loss: 0.0424 - val_loss: 0.0617 - 152ms/epoch - 15ms/step\n",
      "Epoch 112/123\n",
      "10/10 - 0s - loss: 0.0421 - val_loss: 0.0613 - 123ms/epoch - 12ms/step\n",
      "Epoch 113/123\n",
      "10/10 - 0s - loss: 0.0417 - val_loss: 0.0609 - 140ms/epoch - 14ms/step\n",
      "Epoch 114/123\n",
      "10/10 - 0s - loss: 0.0414 - val_loss: 0.0606 - 120ms/epoch - 12ms/step\n",
      "Epoch 115/123\n",
      "10/10 - 0s - loss: 0.0410 - val_loss: 0.0602 - 138ms/epoch - 14ms/step\n",
      "Epoch 116/123\n",
      "10/10 - 0s - loss: 0.0406 - val_loss: 0.0598 - 144ms/epoch - 14ms/step\n",
      "Epoch 117/123\n",
      "10/10 - 0s - loss: 0.0403 - val_loss: 0.0594 - 188ms/epoch - 19ms/step\n",
      "Epoch 118/123\n",
      "10/10 - 0s - loss: 0.0400 - val_loss: 0.0590 - 122ms/epoch - 12ms/step\n",
      "Epoch 119/123\n",
      "10/10 - 0s - loss: 0.0397 - val_loss: 0.0586 - 144ms/epoch - 14ms/step\n",
      "Epoch 120/123\n",
      "10/10 - 0s - loss: 0.0393 - val_loss: 0.0582 - 131ms/epoch - 13ms/step\n",
      "Epoch 121/123\n",
      "10/10 - 0s - loss: 0.0389 - val_loss: 0.0578 - 145ms/epoch - 14ms/step\n",
      "Epoch 122/123\n",
      "10/10 - 0s - loss: 0.0385 - val_loss: 0.0574 - 124ms/epoch - 12ms/step\n",
      "Epoch 123/123\n",
      "10/10 - 0s - loss: 0.0381 - val_loss: 0.0570 - 158ms/epoch - 16ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m-427.6   \u001b[0m | \u001b[0m123.2    \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m1e-05    \u001b[0m | \u001b[0m56.13    \u001b[0m |\n",
      "Model: \"sequential_167\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_605 (LSTM)             (None, 1, 111)            51948     \n",
      "                                                                 \n",
      " dropout_438 (Dropout)       (None, 1, 111)            0         \n",
      "                                                                 \n",
      " lstm_606 (LSTM)             (None, 111)               99012     \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 1)                 112       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151,072\n",
      "Trainable params: 151,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/101\n",
      "10/10 - 4s - loss: 0.0704 - val_loss: 0.0913 - 4s/epoch - 385ms/step\n",
      "Epoch 2/101\n",
      "10/10 - 0s - loss: 0.0700 - val_loss: 0.0908 - 85ms/epoch - 9ms/step\n",
      "Epoch 3/101\n",
      "10/10 - 0s - loss: 0.0695 - val_loss: 0.0904 - 98ms/epoch - 10ms/step\n",
      "Epoch 4/101\n",
      "10/10 - 0s - loss: 0.0691 - val_loss: 0.0899 - 86ms/epoch - 9ms/step\n",
      "Epoch 5/101\n",
      "10/10 - 0s - loss: 0.0687 - val_loss: 0.0894 - 84ms/epoch - 8ms/step\n",
      "Epoch 6/101\n",
      "10/10 - 0s - loss: 0.0682 - val_loss: 0.0890 - 94ms/epoch - 9ms/step\n",
      "Epoch 7/101\n",
      "10/10 - 0s - loss: 0.0678 - val_loss: 0.0885 - 83ms/epoch - 8ms/step\n",
      "Epoch 8/101\n",
      "10/10 - 0s - loss: 0.0674 - val_loss: 0.0880 - 83ms/epoch - 8ms/step\n",
      "Epoch 9/101\n",
      "10/10 - 0s - loss: 0.0670 - val_loss: 0.0876 - 92ms/epoch - 9ms/step\n",
      "Epoch 10/101\n",
      "10/10 - 0s - loss: 0.0666 - val_loss: 0.0871 - 83ms/epoch - 8ms/step\n",
      "Epoch 11/101\n",
      "10/10 - 0s - loss: 0.0662 - val_loss: 0.0866 - 95ms/epoch - 10ms/step\n",
      "Epoch 12/101\n",
      "10/10 - 0s - loss: 0.0657 - val_loss: 0.0862 - 111ms/epoch - 11ms/step\n",
      "Epoch 13/101\n",
      "10/10 - 0s - loss: 0.0654 - val_loss: 0.0857 - 87ms/epoch - 9ms/step\n",
      "Epoch 14/101\n",
      "10/10 - 0s - loss: 0.0649 - val_loss: 0.0852 - 95ms/epoch - 9ms/step\n",
      "Epoch 15/101\n",
      "10/10 - 0s - loss: 0.0645 - val_loss: 0.0848 - 83ms/epoch - 8ms/step\n",
      "Epoch 16/101\n",
      "10/10 - 0s - loss: 0.0641 - val_loss: 0.0843 - 91ms/epoch - 9ms/step\n",
      "Epoch 17/101\n",
      "10/10 - 0s - loss: 0.0637 - val_loss: 0.0838 - 83ms/epoch - 8ms/step\n",
      "Epoch 18/101\n",
      "10/10 - 0s - loss: 0.0633 - val_loss: 0.0834 - 92ms/epoch - 9ms/step\n",
      "Epoch 19/101\n",
      "10/10 - 0s - loss: 0.0629 - val_loss: 0.0829 - 86ms/epoch - 9ms/step\n",
      "Epoch 20/101\n",
      "10/10 - 0s - loss: 0.0624 - val_loss: 0.0824 - 135ms/epoch - 13ms/step\n",
      "Epoch 21/101\n",
      "10/10 - 0s - loss: 0.0620 - val_loss: 0.0819 - 85ms/epoch - 9ms/step\n",
      "Epoch 22/101\n",
      "10/10 - 0s - loss: 0.0616 - val_loss: 0.0815 - 84ms/epoch - 8ms/step\n",
      "Epoch 23/101\n",
      "10/10 - 0s - loss: 0.0611 - val_loss: 0.0810 - 96ms/epoch - 10ms/step\n",
      "Epoch 24/101\n",
      "10/10 - 0s - loss: 0.0608 - val_loss: 0.0805 - 85ms/epoch - 8ms/step\n",
      "Epoch 25/101\n",
      "10/10 - 0s - loss: 0.0603 - val_loss: 0.0800 - 82ms/epoch - 8ms/step\n",
      "Epoch 26/101\n",
      "10/10 - 0s - loss: 0.0599 - val_loss: 0.0796 - 95ms/epoch - 9ms/step\n",
      "Epoch 27/101\n",
      "10/10 - 0s - loss: 0.0595 - val_loss: 0.0791 - 84ms/epoch - 8ms/step\n",
      "Epoch 28/101\n",
      "10/10 - 0s - loss: 0.0590 - val_loss: 0.0786 - 98ms/epoch - 10ms/step\n",
      "Epoch 29/101\n",
      "10/10 - 0s - loss: 0.0587 - val_loss: 0.0781 - 110ms/epoch - 11ms/step\n",
      "Epoch 30/101\n",
      "10/10 - 0s - loss: 0.0582 - val_loss: 0.0776 - 98ms/epoch - 10ms/step\n",
      "Epoch 31/101\n",
      "10/10 - 0s - loss: 0.0578 - val_loss: 0.0772 - 84ms/epoch - 8ms/step\n",
      "Epoch 32/101\n",
      "10/10 - 0s - loss: 0.0573 - val_loss: 0.0767 - 95ms/epoch - 10ms/step\n",
      "Epoch 33/101\n",
      "10/10 - 0s - loss: 0.0569 - val_loss: 0.0762 - 81ms/epoch - 8ms/step\n",
      "Epoch 34/101\n",
      "10/10 - 0s - loss: 0.0565 - val_loss: 0.0757 - 97ms/epoch - 10ms/step\n",
      "Epoch 35/101\n",
      "10/10 - 0s - loss: 0.0560 - val_loss: 0.0752 - 83ms/epoch - 8ms/step\n",
      "Epoch 36/101\n",
      "10/10 - 0s - loss: 0.0556 - val_loss: 0.0747 - 84ms/epoch - 8ms/step\n",
      "Epoch 37/101\n",
      "10/10 - 0s - loss: 0.0552 - val_loss: 0.0742 - 139ms/epoch - 14ms/step\n",
      "Epoch 38/101\n",
      "10/10 - 0s - loss: 0.0547 - val_loss: 0.0737 - 87ms/epoch - 9ms/step\n",
      "Epoch 39/101\n",
      "10/10 - 0s - loss: 0.0543 - val_loss: 0.0732 - 83ms/epoch - 8ms/step\n",
      "Epoch 40/101\n",
      "10/10 - 0s - loss: 0.0538 - val_loss: 0.0727 - 97ms/epoch - 10ms/step\n",
      "Epoch 41/101\n",
      "10/10 - 0s - loss: 0.0535 - val_loss: 0.0722 - 84ms/epoch - 8ms/step\n",
      "Epoch 42/101\n",
      "10/10 - 0s - loss: 0.0529 - val_loss: 0.0717 - 94ms/epoch - 9ms/step\n",
      "Epoch 43/101\n",
      "10/10 - 0s - loss: 0.0525 - val_loss: 0.0712 - 89ms/epoch - 9ms/step\n",
      "Epoch 44/101\n",
      "10/10 - 0s - loss: 0.0520 - val_loss: 0.0707 - 99ms/epoch - 10ms/step\n",
      "Epoch 45/101\n",
      "10/10 - 0s - loss: 0.0516 - val_loss: 0.0702 - 116ms/epoch - 12ms/step\n",
      "Epoch 46/101\n",
      "10/10 - 0s - loss: 0.0512 - val_loss: 0.0696 - 89ms/epoch - 9ms/step\n",
      "Epoch 47/101\n",
      "10/10 - 0s - loss: 0.0507 - val_loss: 0.0691 - 98ms/epoch - 10ms/step\n",
      "Epoch 48/101\n",
      "10/10 - 0s - loss: 0.0503 - val_loss: 0.0686 - 84ms/epoch - 8ms/step\n",
      "Epoch 49/101\n",
      "10/10 - 0s - loss: 0.0498 - val_loss: 0.0681 - 95ms/epoch - 9ms/step\n",
      "Epoch 50/101\n",
      "10/10 - 0s - loss: 0.0494 - val_loss: 0.0676 - 84ms/epoch - 8ms/step\n",
      "Epoch 51/101\n",
      "10/10 - 0s - loss: 0.0489 - val_loss: 0.0670 - 99ms/epoch - 10ms/step\n",
      "Epoch 52/101\n",
      "10/10 - 0s - loss: 0.0485 - val_loss: 0.0665 - 84ms/epoch - 8ms/step\n",
      "Epoch 53/101\n",
      "10/10 - 0s - loss: 0.0480 - val_loss: 0.0660 - 126ms/epoch - 13ms/step\n",
      "Epoch 54/101\n",
      "10/10 - 0s - loss: 0.0475 - val_loss: 0.0655 - 87ms/epoch - 9ms/step\n",
      "Epoch 55/101\n",
      "10/10 - 0s - loss: 0.0471 - val_loss: 0.0649 - 84ms/epoch - 8ms/step\n",
      "Epoch 56/101\n",
      "10/10 - 0s - loss: 0.0466 - val_loss: 0.0644 - 94ms/epoch - 9ms/step\n",
      "Epoch 57/101\n",
      "10/10 - 0s - loss: 0.0462 - val_loss: 0.0639 - 82ms/epoch - 8ms/step\n",
      "Epoch 58/101\n",
      "10/10 - 0s - loss: 0.0457 - val_loss: 0.0633 - 97ms/epoch - 10ms/step\n",
      "Epoch 59/101\n",
      "10/10 - 0s - loss: 0.0452 - val_loss: 0.0628 - 84ms/epoch - 8ms/step\n",
      "Epoch 60/101\n",
      "10/10 - 0s - loss: 0.0447 - val_loss: 0.0623 - 116ms/epoch - 12ms/step\n",
      "Epoch 61/101\n",
      "10/10 - 0s - loss: 0.0443 - val_loss: 0.0617 - 83ms/epoch - 8ms/step\n",
      "Epoch 62/101\n",
      "10/10 - 0s - loss: 0.0437 - val_loss: 0.0612 - 129ms/epoch - 13ms/step\n",
      "Epoch 63/101\n",
      "10/10 - 0s - loss: 0.0433 - val_loss: 0.0607 - 84ms/epoch - 8ms/step\n",
      "Epoch 64/101\n",
      "10/10 - 0s - loss: 0.0428 - val_loss: 0.0601 - 95ms/epoch - 10ms/step\n",
      "Epoch 65/101\n",
      "10/10 - 0s - loss: 0.0424 - val_loss: 0.0596 - 86ms/epoch - 9ms/step\n",
      "Epoch 66/101\n",
      "10/10 - 0s - loss: 0.0419 - val_loss: 0.0590 - 92ms/epoch - 9ms/step\n",
      "Epoch 67/101\n",
      "10/10 - 0s - loss: 0.0414 - val_loss: 0.0585 - 96ms/epoch - 10ms/step\n",
      "Epoch 68/101\n",
      "10/10 - 0s - loss: 0.0410 - val_loss: 0.0579 - 82ms/epoch - 8ms/step\n",
      "Epoch 69/101\n",
      "10/10 - 0s - loss: 0.0405 - val_loss: 0.0574 - 129ms/epoch - 13ms/step\n",
      "Epoch 70/101\n",
      "10/10 - 0s - loss: 0.0400 - val_loss: 0.0568 - 88ms/epoch - 9ms/step\n",
      "Epoch 71/101\n",
      "10/10 - 0s - loss: 0.0395 - val_loss: 0.0563 - 83ms/epoch - 8ms/step\n",
      "Epoch 72/101\n",
      "10/10 - 0s - loss: 0.0389 - val_loss: 0.0557 - 96ms/epoch - 10ms/step\n",
      "Epoch 73/101\n",
      "10/10 - 0s - loss: 0.0386 - val_loss: 0.0552 - 83ms/epoch - 8ms/step\n",
      "Epoch 74/101\n",
      "10/10 - 0s - loss: 0.0381 - val_loss: 0.0546 - 93ms/epoch - 9ms/step\n",
      "Epoch 75/101\n",
      "10/10 - 0s - loss: 0.0376 - val_loss: 0.0541 - 88ms/epoch - 9ms/step\n",
      "Epoch 76/101\n",
      "10/10 - 0s - loss: 0.0371 - val_loss: 0.0535 - 91ms/epoch - 9ms/step\n",
      "Epoch 77/101\n",
      "10/10 - 0s - loss: 0.0368 - val_loss: 0.0530 - 114ms/epoch - 11ms/step\n",
      "Epoch 78/101\n",
      "10/10 - 0s - loss: 0.0363 - val_loss: 0.0524 - 83ms/epoch - 8ms/step\n",
      "Epoch 79/101\n",
      "10/10 - 0s - loss: 0.0357 - val_loss: 0.0519 - 96ms/epoch - 10ms/step\n",
      "Epoch 80/101\n",
      "10/10 - 0s - loss: 0.0352 - val_loss: 0.0513 - 83ms/epoch - 8ms/step\n",
      "Epoch 81/101\n",
      "10/10 - 0s - loss: 0.0347 - val_loss: 0.0508 - 82ms/epoch - 8ms/step\n",
      "Epoch 82/101\n",
      "10/10 - 0s - loss: 0.0343 - val_loss: 0.0502 - 95ms/epoch - 10ms/step\n",
      "Epoch 83/101\n",
      "10/10 - 0s - loss: 0.0338 - val_loss: 0.0497 - 84ms/epoch - 8ms/step\n",
      "Epoch 84/101\n",
      "10/10 - 0s - loss: 0.0332 - val_loss: 0.0491 - 95ms/epoch - 9ms/step\n",
      "Epoch 85/101\n",
      "10/10 - 0s - loss: 0.0327 - val_loss: 0.0486 - 87ms/epoch - 9ms/step\n",
      "Epoch 86/101\n",
      "10/10 - 0s - loss: 0.0324 - val_loss: 0.0480 - 118ms/epoch - 12ms/step\n",
      "Epoch 87/101\n",
      "10/10 - 0s - loss: 0.0318 - val_loss: 0.0475 - 98ms/epoch - 10ms/step\n",
      "Epoch 88/101\n",
      "10/10 - 0s - loss: 0.0314 - val_loss: 0.0469 - 84ms/epoch - 8ms/step\n",
      "Epoch 89/101\n",
      "10/10 - 0s - loss: 0.0309 - val_loss: 0.0463 - 81ms/epoch - 8ms/step\n",
      "Epoch 90/101\n",
      "10/10 - 0s - loss: 0.0305 - val_loss: 0.0458 - 97ms/epoch - 10ms/step\n",
      "Epoch 91/101\n",
      "10/10 - 0s - loss: 0.0302 - val_loss: 0.0453 - 86ms/epoch - 9ms/step\n",
      "Epoch 92/101\n",
      "10/10 - 0s - loss: 0.0295 - val_loss: 0.0447 - 94ms/epoch - 9ms/step\n",
      "Epoch 93/101\n",
      "10/10 - 0s - loss: 0.0292 - val_loss: 0.0442 - 83ms/epoch - 8ms/step\n",
      "Epoch 94/101\n",
      "10/10 - 0s - loss: 0.0287 - val_loss: 0.0436 - 84ms/epoch - 8ms/step\n",
      "Epoch 95/101\n",
      "10/10 - 0s - loss: 0.0281 - val_loss: 0.0431 - 137ms/epoch - 14ms/step\n",
      "Epoch 96/101\n",
      "10/10 - 0s - loss: 0.0277 - val_loss: 0.0426 - 88ms/epoch - 9ms/step\n",
      "Epoch 97/101\n",
      "10/10 - 0s - loss: 0.0272 - val_loss: 0.0420 - 96ms/epoch - 10ms/step\n",
      "Epoch 98/101\n",
      "10/10 - 0s - loss: 0.0268 - val_loss: 0.0415 - 85ms/epoch - 8ms/step\n",
      "Epoch 99/101\n",
      "10/10 - 0s - loss: 0.0263 - val_loss: 0.0410 - 94ms/epoch - 9ms/step\n",
      "Epoch 100/101\n",
      "10/10 - 0s - loss: 0.0260 - val_loss: 0.0404 - 84ms/epoch - 8ms/step\n",
      "Epoch 101/101\n",
      "10/10 - 0s - loss: 0.0255 - val_loss: 0.0399 - 92ms/epoch - 9ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m-357.7   \u001b[0m | \u001b[0m101.7    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1e-05    \u001b[0m | \u001b[0m111.5    \u001b[0m |\n",
      "Model: \"sequential_168\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_607 (LSTM)             (None, 1, 89)             33820     \n",
      "                                                                 \n",
      " dropout_439 (Dropout)       (None, 1, 89)             0         \n",
      "                                                                 \n",
      " lstm_608 (LSTM)             (None, 1, 89)             63724     \n",
      "                                                                 \n",
      " dropout_440 (Dropout)       (None, 1, 89)             0         \n",
      "                                                                 \n",
      " lstm_609 (LSTM)             (None, 1, 89)             63724     \n",
      "                                                                 \n",
      " dropout_441 (Dropout)       (None, 1, 89)             0         \n",
      "                                                                 \n",
      " lstm_610 (LSTM)             (None, 1, 89)             63724     \n",
      "                                                                 \n",
      " dropout_442 (Dropout)       (None, 1, 89)             0         \n",
      "                                                                 \n",
      " lstm_611 (LSTM)             (None, 89)                63724     \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 1)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 288,806\n",
      "Trainable params: 288,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/156\n",
      "10/10 - 9s - loss: 0.0283 - val_loss: 0.0176 - 9s/epoch - 936ms/step\n",
      "Epoch 2/156\n",
      "10/10 - 0s - loss: 0.0038 - val_loss: 0.0182 - 136ms/epoch - 14ms/step\n",
      "Epoch 3/156\n",
      "10/10 - 0s - loss: 0.0033 - val_loss: 0.0168 - 155ms/epoch - 16ms/step\n",
      "Epoch 4/156\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0172 - 133ms/epoch - 13ms/step\n",
      "Epoch 5/156\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0169 - 145ms/epoch - 15ms/step\n",
      "Epoch 6/156\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0170 - 130ms/epoch - 13ms/step\n",
      "Epoch 7/156\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0169 - 142ms/epoch - 14ms/step\n",
      "Epoch 8/156\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0165 - 132ms/epoch - 13ms/step\n",
      "Epoch 9/156\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0148 - 166ms/epoch - 17ms/step\n",
      "Epoch 10/156\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0102 - 131ms/epoch - 13ms/step\n",
      "Epoch 11/156\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0085 - 145ms/epoch - 14ms/step\n",
      "Epoch 12/156\n",
      "10/10 - 0s - loss: 5.4858e-04 - val_loss: 0.0084 - 131ms/epoch - 13ms/step\n",
      "Epoch 13/156\n",
      "10/10 - 0s - loss: 5.3987e-04 - val_loss: 0.0080 - 141ms/epoch - 14ms/step\n",
      "Epoch 14/156\n",
      "10/10 - 0s - loss: 4.4121e-04 - val_loss: 0.0080 - 129ms/epoch - 13ms/step\n",
      "Epoch 15/156\n",
      "10/10 - 0s - loss: 4.0910e-04 - val_loss: 0.0079 - 144ms/epoch - 14ms/step\n",
      "Epoch 16/156\n",
      "10/10 - 0s - loss: 4.3078e-04 - val_loss: 0.0082 - 129ms/epoch - 13ms/step\n",
      "Epoch 17/156\n",
      "10/10 - 0s - loss: 3.6438e-04 - val_loss: 0.0080 - 142ms/epoch - 14ms/step\n",
      "Epoch 18/156\n",
      "10/10 - 0s - loss: 3.0470e-04 - val_loss: 0.0079 - 155ms/epoch - 16ms/step\n",
      "Epoch 19/156\n",
      "10/10 - 0s - loss: 3.5392e-04 - val_loss: 0.0081 - 140ms/epoch - 14ms/step\n",
      "Epoch 20/156\n",
      "10/10 - 0s - loss: 3.1622e-04 - val_loss: 0.0079 - 129ms/epoch - 13ms/step\n",
      "Epoch 21/156\n",
      "10/10 - 0s - loss: 3.5196e-04 - val_loss: 0.0079 - 142ms/epoch - 14ms/step\n",
      "Epoch 22/156\n",
      "10/10 - 0s - loss: 2.8837e-04 - val_loss: 0.0079 - 131ms/epoch - 13ms/step\n",
      "Epoch 23/156\n",
      "10/10 - 0s - loss: 3.0922e-04 - val_loss: 0.0082 - 144ms/epoch - 14ms/step\n",
      "Epoch 24/156\n",
      "10/10 - 0s - loss: 3.3730e-04 - val_loss: 0.0079 - 129ms/epoch - 13ms/step\n",
      "Epoch 25/156\n",
      "10/10 - 0s - loss: 3.5838e-04 - val_loss: 0.0079 - 142ms/epoch - 14ms/step\n",
      "Epoch 26/156\n",
      "10/10 - 0s - loss: 2.7803e-04 - val_loss: 0.0079 - 127ms/epoch - 13ms/step\n",
      "Epoch 27/156\n",
      "10/10 - 0s - loss: 2.8600e-04 - val_loss: 0.0079 - 183ms/epoch - 18ms/step\n",
      "Epoch 28/156\n",
      "10/10 - 0s - loss: 3.0222e-04 - val_loss: 0.0079 - 128ms/epoch - 13ms/step\n",
      "Epoch 29/156\n",
      "10/10 - 0s - loss: 2.7123e-04 - val_loss: 0.0079 - 162ms/epoch - 16ms/step\n",
      "Epoch 30/156\n",
      "10/10 - 0s - loss: 2.9937e-04 - val_loss: 0.0081 - 129ms/epoch - 13ms/step\n",
      "Epoch 31/156\n",
      "10/10 - 0s - loss: 2.8966e-04 - val_loss: 0.0079 - 151ms/epoch - 15ms/step\n",
      "Epoch 32/156\n",
      "10/10 - 0s - loss: 2.9676e-04 - val_loss: 0.0078 - 131ms/epoch - 13ms/step\n",
      "Epoch 33/156\n",
      "10/10 - 0s - loss: 2.8026e-04 - val_loss: 0.0079 - 146ms/epoch - 15ms/step\n",
      "Epoch 34/156\n",
      "10/10 - 0s - loss: 2.8219e-04 - val_loss: 0.0082 - 176ms/epoch - 18ms/step\n",
      "Epoch 35/156\n",
      "10/10 - 0s - loss: 2.9093e-04 - val_loss: 0.0082 - 152ms/epoch - 15ms/step\n",
      "Epoch 36/156\n",
      "10/10 - 0s - loss: 2.8373e-04 - val_loss: 0.0083 - 134ms/epoch - 13ms/step\n",
      "Epoch 37/156\n",
      "10/10 - 0s - loss: 2.7729e-04 - val_loss: 0.0080 - 151ms/epoch - 15ms/step\n",
      "Epoch 38/156\n",
      "10/10 - 0s - loss: 2.8736e-04 - val_loss: 0.0082 - 133ms/epoch - 13ms/step\n",
      "Epoch 39/156\n",
      "10/10 - 0s - loss: 3.1903e-04 - val_loss: 0.0086 - 144ms/epoch - 14ms/step\n",
      "Epoch 40/156\n",
      "10/10 - 0s - loss: 2.7938e-04 - val_loss: 0.0086 - 130ms/epoch - 13ms/step\n",
      "Epoch 41/156\n",
      "10/10 - 0s - loss: 2.5854e-04 - val_loss: 0.0087 - 167ms/epoch - 17ms/step\n",
      "Epoch 42/156\n",
      "10/10 - 0s - loss: 3.0078e-04 - val_loss: 0.0092 - 132ms/epoch - 13ms/step\n",
      "Epoch 43/156\n",
      "10/10 - 0s - loss: 2.8639e-04 - val_loss: 0.0092 - 142ms/epoch - 14ms/step\n",
      "Epoch 44/156\n",
      "10/10 - 0s - loss: 2.7112e-04 - val_loss: 0.0094 - 130ms/epoch - 13ms/step\n",
      "Epoch 45/156\n",
      "10/10 - 0s - loss: 2.6478e-04 - val_loss: 0.0095 - 143ms/epoch - 14ms/step\n",
      "Epoch 46/156\n",
      "10/10 - 0s - loss: 2.6777e-04 - val_loss: 0.0099 - 131ms/epoch - 13ms/step\n",
      "Epoch 47/156\n",
      "10/10 - 0s - loss: 2.7826e-04 - val_loss: 0.0100 - 145ms/epoch - 14ms/step\n",
      "Epoch 48/156\n",
      "10/10 - 0s - loss: 2.6949e-04 - val_loss: 0.0106 - 131ms/epoch - 13ms/step\n",
      "Epoch 49/156\n",
      "10/10 - 0s - loss: 2.6446e-04 - val_loss: 0.0111 - 177ms/epoch - 18ms/step\n",
      "Epoch 50/156\n",
      "10/10 - 0s - loss: 2.7761e-04 - val_loss: 0.0117 - 130ms/epoch - 13ms/step\n",
      "Epoch 51/156\n",
      "10/10 - 0s - loss: 2.4796e-04 - val_loss: 0.0124 - 146ms/epoch - 15ms/step\n",
      "Epoch 52/156\n",
      "10/10 - 0s - loss: 2.3878e-04 - val_loss: 0.0137 - 139ms/epoch - 14ms/step\n",
      "Epoch 53/156\n",
      "10/10 - 0s - loss: 2.4262e-04 - val_loss: 0.0134 - 142ms/epoch - 14ms/step\n",
      "Epoch 54/156\n",
      "10/10 - 0s - loss: 2.4348e-04 - val_loss: 0.0138 - 142ms/epoch - 14ms/step\n",
      "Epoch 55/156\n",
      "10/10 - 0s - loss: 2.8423e-04 - val_loss: 0.0140 - 163ms/epoch - 16ms/step\n",
      "Epoch 56/156\n",
      "10/10 - 0s - loss: 2.6489e-04 - val_loss: 0.0147 - 144ms/epoch - 14ms/step\n",
      "Epoch 57/156\n",
      "10/10 - 0s - loss: 2.3846e-04 - val_loss: 0.0150 - 170ms/epoch - 17ms/step\n",
      "Epoch 58/156\n",
      "10/10 - 0s - loss: 2.2807e-04 - val_loss: 0.0163 - 147ms/epoch - 15ms/step\n",
      "Epoch 59/156\n",
      "10/10 - 0s - loss: 2.6318e-04 - val_loss: 0.0162 - 148ms/epoch - 15ms/step\n",
      "Epoch 60/156\n",
      "10/10 - 0s - loss: 2.5465e-04 - val_loss: 0.0161 - 132ms/epoch - 13ms/step\n",
      "Epoch 61/156\n",
      "10/10 - 0s - loss: 2.2887e-04 - val_loss: 0.0164 - 149ms/epoch - 15ms/step\n",
      "Epoch 62/156\n",
      "10/10 - 0s - loss: 2.5646e-04 - val_loss: 0.0175 - 130ms/epoch - 13ms/step\n",
      "Epoch 63/156\n",
      "10/10 - 0s - loss: 3.1981e-04 - val_loss: 0.0175 - 147ms/epoch - 15ms/step\n",
      "Epoch 64/156\n",
      "10/10 - 0s - loss: 2.8592e-04 - val_loss: 0.0182 - 131ms/epoch - 13ms/step\n",
      "Epoch 65/156\n",
      "10/10 - 0s - loss: 2.1730e-04 - val_loss: 0.0187 - 195ms/epoch - 20ms/step\n",
      "Epoch 66/156\n",
      "10/10 - 0s - loss: 2.3926e-04 - val_loss: 0.0187 - 145ms/epoch - 14ms/step\n",
      "Epoch 67/156\n",
      "10/10 - 0s - loss: 2.4938e-04 - val_loss: 0.0185 - 152ms/epoch - 15ms/step\n",
      "Epoch 68/156\n",
      "10/10 - 0s - loss: 2.3032e-04 - val_loss: 0.0185 - 156ms/epoch - 16ms/step\n",
      "Epoch 69/156\n",
      "10/10 - 0s - loss: 2.3404e-04 - val_loss: 0.0184 - 152ms/epoch - 15ms/step\n",
      "Epoch 70/156\n",
      "10/10 - 0s - loss: 2.2923e-04 - val_loss: 0.0180 - 130ms/epoch - 13ms/step\n",
      "Epoch 71/156\n",
      "10/10 - 0s - loss: 2.2425e-04 - val_loss: 0.0179 - 153ms/epoch - 15ms/step\n",
      "Epoch 72/156\n",
      "10/10 - 0s - loss: 2.2394e-04 - val_loss: 0.0190 - 168ms/epoch - 17ms/step\n",
      "Epoch 73/156\n",
      "10/10 - 0s - loss: 2.1662e-04 - val_loss: 0.0196 - 159ms/epoch - 16ms/step\n",
      "Epoch 74/156\n",
      "10/10 - 0s - loss: 2.2882e-04 - val_loss: 0.0181 - 137ms/epoch - 14ms/step\n",
      "Epoch 75/156\n",
      "10/10 - 0s - loss: 2.4073e-04 - val_loss: 0.0187 - 158ms/epoch - 16ms/step\n",
      "Epoch 76/156\n",
      "10/10 - 0s - loss: 2.5575e-04 - val_loss: 0.0199 - 136ms/epoch - 14ms/step\n",
      "Epoch 77/156\n",
      "10/10 - 0s - loss: 3.0123e-04 - val_loss: 0.0189 - 159ms/epoch - 16ms/step\n",
      "Epoch 78/156\n",
      "10/10 - 0s - loss: 2.9450e-04 - val_loss: 0.0197 - 152ms/epoch - 15ms/step\n",
      "Epoch 79/156\n",
      "10/10 - 0s - loss: 2.3340e-04 - val_loss: 0.0199 - 192ms/epoch - 19ms/step\n",
      "Epoch 80/156\n",
      "10/10 - 0s - loss: 2.3907e-04 - val_loss: 0.0197 - 151ms/epoch - 15ms/step\n",
      "Epoch 81/156\n",
      "10/10 - 0s - loss: 2.2117e-04 - val_loss: 0.0199 - 154ms/epoch - 15ms/step\n",
      "Epoch 82/156\n",
      "10/10 - 0s - loss: 2.3375e-04 - val_loss: 0.0207 - 130ms/epoch - 13ms/step\n",
      "Epoch 83/156\n",
      "10/10 - 0s - loss: 2.2673e-04 - val_loss: 0.0201 - 145ms/epoch - 14ms/step\n",
      "Epoch 84/156\n",
      "10/10 - 0s - loss: 2.2357e-04 - val_loss: 0.0207 - 132ms/epoch - 13ms/step\n",
      "Epoch 85/156\n",
      "10/10 - 0s - loss: 1.9829e-04 - val_loss: 0.0197 - 144ms/epoch - 14ms/step\n",
      "Epoch 86/156\n",
      "10/10 - 0s - loss: 2.1666e-04 - val_loss: 0.0213 - 128ms/epoch - 13ms/step\n",
      "Epoch 87/156\n",
      "10/10 - 0s - loss: 2.1092e-04 - val_loss: 0.0186 - 179ms/epoch - 18ms/step\n",
      "Epoch 88/156\n",
      "10/10 - 0s - loss: 2.3860e-04 - val_loss: 0.0199 - 137ms/epoch - 14ms/step\n",
      "Epoch 89/156\n",
      "10/10 - 0s - loss: 2.3228e-04 - val_loss: 0.0205 - 145ms/epoch - 14ms/step\n",
      "Epoch 90/156\n",
      "10/10 - 0s - loss: 2.3085e-04 - val_loss: 0.0188 - 129ms/epoch - 13ms/step\n",
      "Epoch 91/156\n",
      "10/10 - 0s - loss: 2.2891e-04 - val_loss: 0.0204 - 148ms/epoch - 15ms/step\n",
      "Epoch 92/156\n",
      "10/10 - 0s - loss: 2.2149e-04 - val_loss: 0.0203 - 129ms/epoch - 13ms/step\n",
      "Epoch 93/156\n",
      "10/10 - 0s - loss: 2.0985e-04 - val_loss: 0.0196 - 193ms/epoch - 19ms/step\n",
      "Epoch 94/156\n",
      "10/10 - 0s - loss: 1.9825e-04 - val_loss: 0.0197 - 132ms/epoch - 13ms/step\n",
      "Epoch 95/156\n",
      "10/10 - 0s - loss: 2.1314e-04 - val_loss: 0.0209 - 150ms/epoch - 15ms/step\n",
      "Epoch 96/156\n",
      "10/10 - 0s - loss: 2.2322e-04 - val_loss: 0.0194 - 130ms/epoch - 13ms/step\n",
      "Epoch 97/156\n",
      "10/10 - 0s - loss: 2.0523e-04 - val_loss: 0.0204 - 144ms/epoch - 14ms/step\n",
      "Epoch 98/156\n",
      "10/10 - 0s - loss: 2.1729e-04 - val_loss: 0.0205 - 129ms/epoch - 13ms/step\n",
      "Epoch 99/156\n",
      "10/10 - 0s - loss: 2.2682e-04 - val_loss: 0.0199 - 145ms/epoch - 14ms/step\n",
      "Epoch 100/156\n",
      "10/10 - 0s - loss: 2.1655e-04 - val_loss: 0.0200 - 131ms/epoch - 13ms/step\n",
      "Epoch 101/156\n",
      "10/10 - 0s - loss: 2.1194e-04 - val_loss: 0.0194 - 157ms/epoch - 16ms/step\n",
      "Epoch 102/156\n",
      "10/10 - 0s - loss: 2.2337e-04 - val_loss: 0.0200 - 131ms/epoch - 13ms/step\n",
      "Epoch 103/156\n",
      "10/10 - 0s - loss: 2.1974e-04 - val_loss: 0.0199 - 139ms/epoch - 14ms/step\n",
      "Epoch 104/156\n",
      "10/10 - 0s - loss: 1.9550e-04 - val_loss: 0.0206 - 160ms/epoch - 16ms/step\n",
      "Epoch 105/156\n",
      "10/10 - 0s - loss: 1.9933e-04 - val_loss: 0.0195 - 151ms/epoch - 15ms/step\n",
      "Epoch 106/156\n",
      "10/10 - 0s - loss: 2.1381e-04 - val_loss: 0.0210 - 133ms/epoch - 13ms/step\n",
      "Epoch 107/156\n",
      "10/10 - 0s - loss: 2.2904e-04 - val_loss: 0.0196 - 151ms/epoch - 15ms/step\n",
      "Epoch 108/156\n",
      "10/10 - 0s - loss: 2.1319e-04 - val_loss: 0.0213 - 132ms/epoch - 13ms/step\n",
      "Epoch 109/156\n",
      "10/10 - 0s - loss: 2.1269e-04 - val_loss: 0.0207 - 141ms/epoch - 14ms/step\n",
      "Epoch 110/156\n",
      "10/10 - 0s - loss: 2.3410e-04 - val_loss: 0.0205 - 133ms/epoch - 13ms/step\n",
      "Epoch 111/156\n",
      "10/10 - 0s - loss: 2.0496e-04 - val_loss: 0.0210 - 144ms/epoch - 14ms/step\n",
      "Epoch 112/156\n",
      "10/10 - 0s - loss: 2.0468e-04 - val_loss: 0.0209 - 134ms/epoch - 13ms/step\n",
      "Epoch 113/156\n",
      "10/10 - 0s - loss: 2.1786e-04 - val_loss: 0.0206 - 175ms/epoch - 17ms/step\n",
      "Epoch 114/156\n",
      "10/10 - 0s - loss: 2.8040e-04 - val_loss: 0.0210 - 135ms/epoch - 13ms/step\n",
      "Epoch 115/156\n",
      "10/10 - 0s - loss: 2.8534e-04 - val_loss: 0.0214 - 148ms/epoch - 15ms/step\n",
      "Epoch 116/156\n",
      "10/10 - 0s - loss: 2.2432e-04 - val_loss: 0.0209 - 131ms/epoch - 13ms/step\n",
      "Epoch 117/156\n",
      "10/10 - 0s - loss: 2.9157e-04 - val_loss: 0.0215 - 147ms/epoch - 15ms/step\n",
      "Epoch 118/156\n",
      "10/10 - 0s - loss: 2.0876e-04 - val_loss: 0.0215 - 134ms/epoch - 13ms/step\n",
      "Epoch 119/156\n",
      "10/10 - 0s - loss: 2.0166e-04 - val_loss: 0.0213 - 144ms/epoch - 14ms/step\n",
      "Epoch 120/156\n",
      "10/10 - 0s - loss: 2.0705e-04 - val_loss: 0.0215 - 155ms/epoch - 15ms/step\n",
      "Epoch 121/156\n",
      "10/10 - 0s - loss: 2.1439e-04 - val_loss: 0.0206 - 140ms/epoch - 14ms/step\n",
      "Epoch 122/156\n",
      "10/10 - 0s - loss: 2.1343e-04 - val_loss: 0.0219 - 128ms/epoch - 13ms/step\n",
      "Epoch 123/156\n",
      "10/10 - 0s - loss: 2.0740e-04 - val_loss: 0.0211 - 137ms/epoch - 14ms/step\n",
      "Epoch 124/156\n",
      "10/10 - 0s - loss: 2.1233e-04 - val_loss: 0.0204 - 128ms/epoch - 13ms/step\n",
      "Epoch 125/156\n",
      "10/10 - 0s - loss: 2.2529e-04 - val_loss: 0.0220 - 142ms/epoch - 14ms/step\n",
      "Epoch 126/156\n",
      "10/10 - 0s - loss: 2.3357e-04 - val_loss: 0.0202 - 148ms/epoch - 15ms/step\n",
      "Epoch 127/156\n",
      "10/10 - 0s - loss: 2.2719e-04 - val_loss: 0.0225 - 161ms/epoch - 16ms/step\n",
      "Epoch 128/156\n",
      "10/10 - 0s - loss: 1.9624e-04 - val_loss: 0.0207 - 144ms/epoch - 14ms/step\n",
      "Epoch 129/156\n",
      "10/10 - 0s - loss: 2.0529e-04 - val_loss: 0.0222 - 169ms/epoch - 17ms/step\n",
      "Epoch 130/156\n",
      "10/10 - 0s - loss: 1.9251e-04 - val_loss: 0.0204 - 143ms/epoch - 14ms/step\n",
      "Epoch 131/156\n",
      "10/10 - 0s - loss: 2.0944e-04 - val_loss: 0.0217 - 160ms/epoch - 16ms/step\n",
      "Epoch 132/156\n",
      "10/10 - 0s - loss: 2.1074e-04 - val_loss: 0.0221 - 155ms/epoch - 16ms/step\n",
      "Epoch 133/156\n",
      "10/10 - 0s - loss: 2.1268e-04 - val_loss: 0.0209 - 164ms/epoch - 16ms/step\n",
      "Epoch 134/156\n",
      "10/10 - 0s - loss: 2.0036e-04 - val_loss: 0.0212 - 163ms/epoch - 16ms/step\n",
      "Epoch 135/156\n",
      "10/10 - 0s - loss: 1.8483e-04 - val_loss: 0.0219 - 145ms/epoch - 14ms/step\n",
      "Epoch 136/156\n",
      "10/10 - 0s - loss: 2.1183e-04 - val_loss: 0.0212 - 144ms/epoch - 14ms/step\n",
      "Epoch 137/156\n",
      "10/10 - 0s - loss: 2.2191e-04 - val_loss: 0.0208 - 167ms/epoch - 17ms/step\n",
      "Epoch 138/156\n",
      "10/10 - 0s - loss: 1.9989e-04 - val_loss: 0.0209 - 139ms/epoch - 14ms/step\n",
      "Epoch 139/156\n",
      "10/10 - 0s - loss: 2.0460e-04 - val_loss: 0.0215 - 135ms/epoch - 13ms/step\n",
      "Epoch 140/156\n",
      "10/10 - 0s - loss: 2.5691e-04 - val_loss: 0.0222 - 161ms/epoch - 16ms/step\n",
      "Epoch 141/156\n",
      "10/10 - 0s - loss: 2.5003e-04 - val_loss: 0.0222 - 152ms/epoch - 15ms/step\n",
      "Epoch 142/156\n",
      "10/10 - 0s - loss: 2.1116e-04 - val_loss: 0.0220 - 134ms/epoch - 13ms/step\n",
      "Epoch 143/156\n",
      "10/10 - 0s - loss: 2.0658e-04 - val_loss: 0.0223 - 140ms/epoch - 14ms/step\n",
      "Epoch 144/156\n",
      "10/10 - 0s - loss: 2.3811e-04 - val_loss: 0.0213 - 137ms/epoch - 14ms/step\n",
      "Epoch 145/156\n",
      "10/10 - 0s - loss: 2.5006e-04 - val_loss: 0.0224 - 137ms/epoch - 14ms/step\n",
      "Epoch 146/156\n",
      "10/10 - 0s - loss: 2.3766e-04 - val_loss: 0.0213 - 131ms/epoch - 13ms/step\n",
      "Epoch 147/156\n",
      "10/10 - 0s - loss: 2.2380e-04 - val_loss: 0.0223 - 133ms/epoch - 13ms/step\n",
      "Epoch 148/156\n",
      "10/10 - 0s - loss: 2.0833e-04 - val_loss: 0.0208 - 133ms/epoch - 13ms/step\n",
      "Epoch 149/156\n",
      "10/10 - 0s - loss: 2.0922e-04 - val_loss: 0.0218 - 131ms/epoch - 13ms/step\n",
      "Epoch 150/156\n",
      "10/10 - 0s - loss: 2.2890e-04 - val_loss: 0.0211 - 136ms/epoch - 14ms/step\n",
      "Epoch 151/156\n",
      "10/10 - 0s - loss: 2.0048e-04 - val_loss: 0.0212 - 137ms/epoch - 14ms/step\n",
      "Epoch 152/156\n",
      "10/10 - 0s - loss: 2.0825e-04 - val_loss: 0.0210 - 137ms/epoch - 14ms/step\n",
      "Epoch 153/156\n",
      "10/10 - 0s - loss: 2.5423e-04 - val_loss: 0.0215 - 146ms/epoch - 15ms/step\n",
      "Epoch 154/156\n",
      "10/10 - 0s - loss: 1.9681e-04 - val_loss: 0.0213 - 127ms/epoch - 13ms/step\n",
      "Epoch 155/156\n",
      "10/10 - 0s - loss: 2.0666e-04 - val_loss: 0.0209 - 126ms/epoch - 13ms/step\n",
      "Epoch 156/156\n",
      "10/10 - 0s - loss: 1.9891e-04 - val_loss: 0.0215 - 127ms/epoch - 13ms/step\n",
      "9/9 [==============================] - 2s 2ms/step\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m-262.7   \u001b[0m | \u001b[0m156.0    \u001b[0m | \u001b[0m4.446    \u001b[0m | \u001b[0m0.005386 \u001b[0m | \u001b[0m89.43    \u001b[0m |\n",
      "Model: \"sequential_169\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_612 (LSTM)             (None, 1, 39)             7020      \n",
      "                                                                 \n",
      " dropout_443 (Dropout)       (None, 1, 39)             0         \n",
      "                                                                 \n",
      " lstm_613 (LSTM)             (None, 39)                12324     \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 1)                 40        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,384\n",
      "Trainable params: 19,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/140\n",
      "10/10 - 4s - loss: 0.0416 - val_loss: 0.0214 - 4s/epoch - 385ms/step\n",
      "Epoch 2/140\n",
      "10/10 - 0s - loss: 0.0053 - val_loss: 0.0138 - 61ms/epoch - 6ms/step\n",
      "Epoch 3/140\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0140 - 76ms/epoch - 8ms/step\n",
      "Epoch 4/140\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0122 - 63ms/epoch - 6ms/step\n",
      "Epoch 5/140\n",
      "10/10 - 0s - loss: 0.0019 - val_loss: 0.0113 - 62ms/epoch - 6ms/step\n",
      "Epoch 6/140\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0117 - 76ms/epoch - 8ms/step\n",
      "Epoch 7/140\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0110 - 63ms/epoch - 6ms/step\n",
      "Epoch 8/140\n",
      "10/10 - 0s - loss: 0.0015 - val_loss: 0.0106 - 63ms/epoch - 6ms/step\n",
      "Epoch 9/140\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0102 - 75ms/epoch - 8ms/step\n",
      "Epoch 10/140\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0097 - 62ms/epoch - 6ms/step\n",
      "Epoch 11/140\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0093 - 63ms/epoch - 6ms/step\n",
      "Epoch 12/140\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0089 - 91ms/epoch - 9ms/step\n",
      "Epoch 13/140\n",
      "10/10 - 0s - loss: 8.9615e-04 - val_loss: 0.0086 - 72ms/epoch - 7ms/step\n",
      "Epoch 14/140\n",
      "10/10 - 0s - loss: 7.7318e-04 - val_loss: 0.0083 - 63ms/epoch - 6ms/step\n",
      "Epoch 15/140\n",
      "10/10 - 0s - loss: 6.9912e-04 - val_loss: 0.0082 - 86ms/epoch - 9ms/step\n",
      "Epoch 16/140\n",
      "10/10 - 0s - loss: 5.7886e-04 - val_loss: 0.0082 - 78ms/epoch - 8ms/step\n",
      "Epoch 17/140\n",
      "10/10 - 0s - loss: 6.2146e-04 - val_loss: 0.0083 - 76ms/epoch - 8ms/step\n",
      "Epoch 18/140\n",
      "10/10 - 0s - loss: 4.8283e-04 - val_loss: 0.0084 - 97ms/epoch - 10ms/step\n",
      "Epoch 19/140\n",
      "10/10 - 0s - loss: 4.5644e-04 - val_loss: 0.0085 - 72ms/epoch - 7ms/step\n",
      "Epoch 20/140\n",
      "10/10 - 0s - loss: 5.0343e-04 - val_loss: 0.0087 - 77ms/epoch - 8ms/step\n",
      "Epoch 21/140\n",
      "10/10 - 0s - loss: 4.3797e-04 - val_loss: 0.0086 - 69ms/epoch - 7ms/step\n",
      "Epoch 22/140\n",
      "10/10 - 0s - loss: 4.6024e-04 - val_loss: 0.0087 - 65ms/epoch - 7ms/step\n",
      "Epoch 23/140\n",
      "10/10 - 0s - loss: 4.3288e-04 - val_loss: 0.0087 - 76ms/epoch - 8ms/step\n",
      "Epoch 24/140\n",
      "10/10 - 0s - loss: 4.2721e-04 - val_loss: 0.0086 - 75ms/epoch - 8ms/step\n",
      "Epoch 25/140\n",
      "10/10 - 0s - loss: 3.8067e-04 - val_loss: 0.0086 - 65ms/epoch - 6ms/step\n",
      "Epoch 26/140\n",
      "10/10 - 0s - loss: 3.5870e-04 - val_loss: 0.0087 - 86ms/epoch - 9ms/step\n",
      "Epoch 27/140\n",
      "10/10 - 0s - loss: 3.4081e-04 - val_loss: 0.0086 - 66ms/epoch - 7ms/step\n",
      "Epoch 28/140\n",
      "10/10 - 0s - loss: 4.2668e-04 - val_loss: 0.0086 - 62ms/epoch - 6ms/step\n",
      "Epoch 29/140\n",
      "10/10 - 0s - loss: 3.5059e-04 - val_loss: 0.0087 - 86ms/epoch - 9ms/step\n",
      "Epoch 30/140\n",
      "10/10 - 0s - loss: 3.5778e-04 - val_loss: 0.0087 - 84ms/epoch - 8ms/step\n",
      "Epoch 31/140\n",
      "10/10 - 0s - loss: 3.0608e-04 - val_loss: 0.0087 - 77ms/epoch - 8ms/step\n",
      "Epoch 32/140\n",
      "10/10 - 0s - loss: 3.5487e-04 - val_loss: 0.0087 - 78ms/epoch - 8ms/step\n",
      "Epoch 33/140\n",
      "10/10 - 0s - loss: 3.3035e-04 - val_loss: 0.0087 - 76ms/epoch - 8ms/step\n",
      "Epoch 34/140\n",
      "10/10 - 0s - loss: 3.4130e-04 - val_loss: 0.0086 - 65ms/epoch - 6ms/step\n",
      "Epoch 35/140\n",
      "10/10 - 0s - loss: 3.4299e-04 - val_loss: 0.0087 - 62ms/epoch - 6ms/step\n",
      "Epoch 36/140\n",
      "10/10 - 0s - loss: 3.1464e-04 - val_loss: 0.0087 - 67ms/epoch - 7ms/step\n",
      "Epoch 37/140\n",
      "10/10 - 0s - loss: 3.1956e-04 - val_loss: 0.0087 - 63ms/epoch - 6ms/step\n",
      "Epoch 38/140\n",
      "10/10 - 0s - loss: 2.8822e-04 - val_loss: 0.0089 - 66ms/epoch - 7ms/step\n",
      "Epoch 39/140\n",
      "10/10 - 0s - loss: 2.6541e-04 - val_loss: 0.0090 - 94ms/epoch - 9ms/step\n",
      "Epoch 40/140\n",
      "10/10 - 0s - loss: 2.8843e-04 - val_loss: 0.0087 - 72ms/epoch - 7ms/step\n",
      "Epoch 41/140\n",
      "10/10 - 0s - loss: 2.7194e-04 - val_loss: 0.0087 - 68ms/epoch - 7ms/step\n",
      "Epoch 42/140\n",
      "10/10 - 0s - loss: 2.9524e-04 - val_loss: 0.0086 - 69ms/epoch - 7ms/step\n",
      "Epoch 43/140\n",
      "10/10 - 0s - loss: 2.7673e-04 - val_loss: 0.0087 - 88ms/epoch - 9ms/step\n",
      "Epoch 44/140\n",
      "10/10 - 0s - loss: 2.5660e-04 - val_loss: 0.0087 - 70ms/epoch - 7ms/step\n",
      "Epoch 45/140\n",
      "10/10 - 0s - loss: 2.5793e-04 - val_loss: 0.0087 - 61ms/epoch - 6ms/step\n",
      "Epoch 46/140\n",
      "10/10 - 0s - loss: 2.8036e-04 - val_loss: 0.0088 - 62ms/epoch - 6ms/step\n",
      "Epoch 47/140\n",
      "10/10 - 0s - loss: 2.5296e-04 - val_loss: 0.0090 - 63ms/epoch - 6ms/step\n",
      "Epoch 48/140\n",
      "10/10 - 0s - loss: 2.6892e-04 - val_loss: 0.0090 - 62ms/epoch - 6ms/step\n",
      "Epoch 49/140\n",
      "10/10 - 0s - loss: 2.6033e-04 - val_loss: 0.0087 - 61ms/epoch - 6ms/step\n",
      "Epoch 50/140\n",
      "10/10 - 0s - loss: 2.5127e-04 - val_loss: 0.0087 - 61ms/epoch - 6ms/step\n",
      "Epoch 51/140\n",
      "10/10 - 0s - loss: 2.4894e-04 - val_loss: 0.0087 - 63ms/epoch - 6ms/step\n",
      "Epoch 52/140\n",
      "10/10 - 0s - loss: 2.3951e-04 - val_loss: 0.0087 - 63ms/epoch - 6ms/step\n",
      "Epoch 53/140\n",
      "10/10 - 0s - loss: 2.5231e-04 - val_loss: 0.0087 - 61ms/epoch - 6ms/step\n",
      "Epoch 54/140\n",
      "10/10 - 0s - loss: 2.4948e-04 - val_loss: 0.0087 - 61ms/epoch - 6ms/step\n",
      "Epoch 55/140\n",
      "10/10 - 0s - loss: 2.4902e-04 - val_loss: 0.0087 - 61ms/epoch - 6ms/step\n",
      "Epoch 56/140\n",
      "10/10 - 0s - loss: 2.3439e-04 - val_loss: 0.0087 - 71ms/epoch - 7ms/step\n",
      "Epoch 57/140\n",
      "10/10 - 0s - loss: 2.3536e-04 - val_loss: 0.0087 - 61ms/epoch - 6ms/step\n",
      "Epoch 58/140\n",
      "10/10 - 0s - loss: 2.4472e-04 - val_loss: 0.0088 - 60ms/epoch - 6ms/step\n",
      "Epoch 59/140\n",
      "10/10 - 0s - loss: 2.3764e-04 - val_loss: 0.0089 - 61ms/epoch - 6ms/step\n",
      "Epoch 60/140\n",
      "10/10 - 0s - loss: 2.2729e-04 - val_loss: 0.0088 - 70ms/epoch - 7ms/step\n",
      "Epoch 61/140\n",
      "10/10 - 0s - loss: 2.3826e-04 - val_loss: 0.0088 - 64ms/epoch - 6ms/step\n",
      "Epoch 62/140\n",
      "10/10 - 0s - loss: 2.3431e-04 - val_loss: 0.0088 - 68ms/epoch - 7ms/step\n",
      "Epoch 63/140\n",
      "10/10 - 0s - loss: 2.2307e-04 - val_loss: 0.0090 - 71ms/epoch - 7ms/step\n",
      "Epoch 64/140\n",
      "10/10 - 0s - loss: 2.3159e-04 - val_loss: 0.0090 - 71ms/epoch - 7ms/step\n",
      "Epoch 65/140\n",
      "10/10 - 0s - loss: 2.2655e-04 - val_loss: 0.0089 - 89ms/epoch - 9ms/step\n",
      "Epoch 66/140\n",
      "10/10 - 0s - loss: 2.1397e-04 - val_loss: 0.0089 - 69ms/epoch - 7ms/step\n",
      "Epoch 67/140\n",
      "10/10 - 0s - loss: 2.1387e-04 - val_loss: 0.0089 - 113ms/epoch - 11ms/step\n",
      "Epoch 68/140\n",
      "10/10 - 0s - loss: 2.1255e-04 - val_loss: 0.0089 - 82ms/epoch - 8ms/step\n",
      "Epoch 69/140\n",
      "10/10 - 0s - loss: 2.1912e-04 - val_loss: 0.0089 - 79ms/epoch - 8ms/step\n",
      "Epoch 70/140\n",
      "10/10 - 0s - loss: 2.3635e-04 - val_loss: 0.0090 - 66ms/epoch - 7ms/step\n",
      "Epoch 71/140\n",
      "10/10 - 0s - loss: 2.0534e-04 - val_loss: 0.0091 - 60ms/epoch - 6ms/step\n",
      "Epoch 72/140\n",
      "10/10 - 0s - loss: 2.2053e-04 - val_loss: 0.0091 - 74ms/epoch - 7ms/step\n",
      "Epoch 73/140\n",
      "10/10 - 0s - loss: 2.2421e-04 - val_loss: 0.0089 - 62ms/epoch - 6ms/step\n",
      "Epoch 74/140\n",
      "10/10 - 0s - loss: 2.1044e-04 - val_loss: 0.0089 - 60ms/epoch - 6ms/step\n",
      "Epoch 75/140\n",
      "10/10 - 0s - loss: 2.2151e-04 - val_loss: 0.0088 - 70ms/epoch - 7ms/step\n",
      "Epoch 76/140\n",
      "10/10 - 0s - loss: 2.0998e-04 - val_loss: 0.0090 - 62ms/epoch - 6ms/step\n",
      "Epoch 77/140\n",
      "10/10 - 0s - loss: 2.1271e-04 - val_loss: 0.0090 - 60ms/epoch - 6ms/step\n",
      "Epoch 78/140\n",
      "10/10 - 0s - loss: 2.0125e-04 - val_loss: 0.0090 - 73ms/epoch - 7ms/step\n",
      "Epoch 79/140\n",
      "10/10 - 0s - loss: 2.0982e-04 - val_loss: 0.0089 - 61ms/epoch - 6ms/step\n",
      "Epoch 80/140\n",
      "10/10 - 0s - loss: 2.1383e-04 - val_loss: 0.0089 - 60ms/epoch - 6ms/step\n",
      "Epoch 81/140\n",
      "10/10 - 0s - loss: 2.2609e-04 - val_loss: 0.0091 - 72ms/epoch - 7ms/step\n",
      "Epoch 82/140\n",
      "10/10 - 0s - loss: 2.5274e-04 - val_loss: 0.0090 - 62ms/epoch - 6ms/step\n",
      "Epoch 83/140\n",
      "10/10 - 0s - loss: 2.0749e-04 - val_loss: 0.0089 - 60ms/epoch - 6ms/step\n",
      "Epoch 84/140\n",
      "10/10 - 0s - loss: 1.9593e-04 - val_loss: 0.0090 - 70ms/epoch - 7ms/step\n",
      "Epoch 85/140\n",
      "10/10 - 0s - loss: 2.0387e-04 - val_loss: 0.0091 - 60ms/epoch - 6ms/step\n",
      "Epoch 86/140\n",
      "10/10 - 0s - loss: 2.2085e-04 - val_loss: 0.0091 - 103ms/epoch - 10ms/step\n",
      "Epoch 87/140\n",
      "10/10 - 0s - loss: 2.0845e-04 - val_loss: 0.0091 - 70ms/epoch - 7ms/step\n",
      "Epoch 88/140\n",
      "10/10 - 0s - loss: 2.1129e-04 - val_loss: 0.0090 - 63ms/epoch - 6ms/step\n",
      "Epoch 89/140\n",
      "10/10 - 0s - loss: 2.1928e-04 - val_loss: 0.0090 - 72ms/epoch - 7ms/step\n",
      "Epoch 90/140\n",
      "10/10 - 0s - loss: 1.9886e-04 - val_loss: 0.0090 - 59ms/epoch - 6ms/step\n",
      "Epoch 91/140\n",
      "10/10 - 0s - loss: 2.1171e-04 - val_loss: 0.0091 - 61ms/epoch - 6ms/step\n",
      "Epoch 92/140\n",
      "10/10 - 0s - loss: 2.0467e-04 - val_loss: 0.0091 - 75ms/epoch - 7ms/step\n",
      "Epoch 93/140\n",
      "10/10 - 0s - loss: 2.1740e-04 - val_loss: 0.0090 - 61ms/epoch - 6ms/step\n",
      "Epoch 94/140\n",
      "10/10 - 0s - loss: 2.1317e-04 - val_loss: 0.0092 - 61ms/epoch - 6ms/step\n",
      "Epoch 95/140\n",
      "10/10 - 0s - loss: 1.9922e-04 - val_loss: 0.0092 - 70ms/epoch - 7ms/step\n",
      "Epoch 96/140\n",
      "10/10 - 0s - loss: 2.0834e-04 - val_loss: 0.0090 - 60ms/epoch - 6ms/step\n",
      "Epoch 97/140\n",
      "10/10 - 0s - loss: 2.2452e-04 - val_loss: 0.0093 - 69ms/epoch - 7ms/step\n",
      "Epoch 98/140\n",
      "10/10 - 0s - loss: 2.3237e-04 - val_loss: 0.0091 - 94ms/epoch - 9ms/step\n",
      "Epoch 99/140\n",
      "10/10 - 0s - loss: 2.2801e-04 - val_loss: 0.0090 - 62ms/epoch - 6ms/step\n",
      "Epoch 100/140\n",
      "10/10 - 0s - loss: 2.4159e-04 - val_loss: 0.0091 - 71ms/epoch - 7ms/step\n",
      "Epoch 101/140\n",
      "10/10 - 0s - loss: 2.1222e-04 - val_loss: 0.0092 - 60ms/epoch - 6ms/step\n",
      "Epoch 102/140\n",
      "10/10 - 0s - loss: 2.0456e-04 - val_loss: 0.0091 - 60ms/epoch - 6ms/step\n",
      "Epoch 103/140\n",
      "10/10 - 0s - loss: 2.1263e-04 - val_loss: 0.0091 - 71ms/epoch - 7ms/step\n",
      "Epoch 104/140\n",
      "10/10 - 0s - loss: 2.0539e-04 - val_loss: 0.0091 - 61ms/epoch - 6ms/step\n",
      "Epoch 105/140\n",
      "10/10 - 0s - loss: 1.9319e-04 - val_loss: 0.0092 - 72ms/epoch - 7ms/step\n",
      "Epoch 106/140\n",
      "10/10 - 0s - loss: 1.9570e-04 - val_loss: 0.0091 - 62ms/epoch - 6ms/step\n",
      "Epoch 107/140\n",
      "10/10 - 0s - loss: 2.0454e-04 - val_loss: 0.0091 - 59ms/epoch - 6ms/step\n",
      "Epoch 108/140\n",
      "10/10 - 0s - loss: 2.0332e-04 - val_loss: 0.0091 - 73ms/epoch - 7ms/step\n",
      "Epoch 109/140\n",
      "10/10 - 0s - loss: 2.0760e-04 - val_loss: 0.0092 - 85ms/epoch - 8ms/step\n",
      "Epoch 110/140\n",
      "10/10 - 0s - loss: 2.0953e-04 - val_loss: 0.0092 - 62ms/epoch - 6ms/step\n",
      "Epoch 111/140\n",
      "10/10 - 0s - loss: 1.9614e-04 - val_loss: 0.0091 - 75ms/epoch - 8ms/step\n",
      "Epoch 112/140\n",
      "10/10 - 0s - loss: 2.1407e-04 - val_loss: 0.0091 - 61ms/epoch - 6ms/step\n",
      "Epoch 113/140\n",
      "10/10 - 0s - loss: 2.1186e-04 - val_loss: 0.0093 - 59ms/epoch - 6ms/step\n",
      "Epoch 114/140\n",
      "10/10 - 0s - loss: 2.2087e-04 - val_loss: 0.0091 - 70ms/epoch - 7ms/step\n",
      "Epoch 115/140\n",
      "10/10 - 0s - loss: 1.9977e-04 - val_loss: 0.0091 - 60ms/epoch - 6ms/step\n",
      "Epoch 116/140\n",
      "10/10 - 0s - loss: 2.0063e-04 - val_loss: 0.0092 - 63ms/epoch - 6ms/step\n",
      "Epoch 117/140\n",
      "10/10 - 0s - loss: 1.9694e-04 - val_loss: 0.0092 - 112ms/epoch - 11ms/step\n",
      "Epoch 118/140\n",
      "10/10 - 0s - loss: 1.8682e-04 - val_loss: 0.0091 - 65ms/epoch - 7ms/step\n",
      "Epoch 119/140\n",
      "10/10 - 0s - loss: 2.0282e-04 - val_loss: 0.0091 - 60ms/epoch - 6ms/step\n",
      "Epoch 120/140\n",
      "10/10 - 0s - loss: 1.9602e-04 - val_loss: 0.0093 - 73ms/epoch - 7ms/step\n",
      "Epoch 121/140\n",
      "10/10 - 0s - loss: 1.9053e-04 - val_loss: 0.0093 - 60ms/epoch - 6ms/step\n",
      "Epoch 122/140\n",
      "10/10 - 0s - loss: 1.9927e-04 - val_loss: 0.0093 - 71ms/epoch - 7ms/step\n",
      "Epoch 123/140\n",
      "10/10 - 0s - loss: 2.0048e-04 - val_loss: 0.0092 - 62ms/epoch - 6ms/step\n",
      "Epoch 124/140\n",
      "10/10 - 0s - loss: 1.9405e-04 - val_loss: 0.0091 - 72ms/epoch - 7ms/step\n",
      "Epoch 125/140\n",
      "10/10 - 0s - loss: 2.0250e-04 - val_loss: 0.0092 - 67ms/epoch - 7ms/step\n",
      "Epoch 126/140\n",
      "10/10 - 0s - loss: 1.8814e-04 - val_loss: 0.0092 - 87ms/epoch - 9ms/step\n",
      "Epoch 127/140\n",
      "10/10 - 0s - loss: 1.9154e-04 - val_loss: 0.0094 - 61ms/epoch - 6ms/step\n",
      "Epoch 128/140\n",
      "10/10 - 0s - loss: 1.9685e-04 - val_loss: 0.0094 - 73ms/epoch - 7ms/step\n",
      "Epoch 129/140\n",
      "10/10 - 0s - loss: 1.9136e-04 - val_loss: 0.0092 - 61ms/epoch - 6ms/step\n",
      "Epoch 130/140\n",
      "10/10 - 0s - loss: 1.8292e-04 - val_loss: 0.0092 - 60ms/epoch - 6ms/step\n",
      "Epoch 131/140\n",
      "10/10 - 0s - loss: 1.9083e-04 - val_loss: 0.0093 - 71ms/epoch - 7ms/step\n",
      "Epoch 132/140\n",
      "10/10 - 0s - loss: 2.0466e-04 - val_loss: 0.0092 - 61ms/epoch - 6ms/step\n",
      "Epoch 133/140\n",
      "10/10 - 0s - loss: 2.1031e-04 - val_loss: 0.0092 - 60ms/epoch - 6ms/step\n",
      "Epoch 134/140\n",
      "10/10 - 0s - loss: 2.1946e-04 - val_loss: 0.0092 - 73ms/epoch - 7ms/step\n",
      "Epoch 135/140\n",
      "10/10 - 0s - loss: 1.9565e-04 - val_loss: 0.0093 - 59ms/epoch - 6ms/step\n",
      "Epoch 136/140\n",
      "10/10 - 0s - loss: 2.0716e-04 - val_loss: 0.0091 - 60ms/epoch - 6ms/step\n",
      "Epoch 137/140\n",
      "10/10 - 0s - loss: 1.8325e-04 - val_loss: 0.0093 - 76ms/epoch - 8ms/step\n",
      "Epoch 138/140\n",
      "10/10 - 0s - loss: 2.0648e-04 - val_loss: 0.0093 - 86ms/epoch - 9ms/step\n",
      "Epoch 139/140\n",
      "10/10 - 0s - loss: 1.9579e-04 - val_loss: 0.0092 - 63ms/epoch - 6ms/step\n",
      "Epoch 140/140\n",
      "10/10 - 0s - loss: 1.9421e-04 - val_loss: 0.0092 - 70ms/epoch - 7ms/step\n",
      "9/9 [==============================] - 1s 1ms/step\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m-171.6   \u001b[0m | \u001b[0m140.9    \u001b[0m | \u001b[0m1.562    \u001b[0m | \u001b[0m0.003596 \u001b[0m | \u001b[0m39.09    \u001b[0m |\n",
      "Model: \"sequential_170\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_614 (LSTM)             (None, 1, 102)            44064     \n",
      "                                                                 \n",
      " dropout_444 (Dropout)       (None, 1, 102)            0         \n",
      "                                                                 \n",
      " lstm_615 (LSTM)             (None, 1, 102)            83640     \n",
      "                                                                 \n",
      " dropout_445 (Dropout)       (None, 1, 102)            0         \n",
      "                                                                 \n",
      " lstm_616 (LSTM)             (None, 1, 102)            83640     \n",
      "                                                                 \n",
      " dropout_446 (Dropout)       (None, 1, 102)            0         \n",
      "                                                                 \n",
      " lstm_617 (LSTM)             (None, 1, 102)            83640     \n",
      "                                                                 \n",
      " dropout_447 (Dropout)       (None, 1, 102)            0         \n",
      "                                                                 \n",
      " lstm_618 (LSTM)             (None, 1, 102)            83640     \n",
      "                                                                 \n",
      " dropout_448 (Dropout)       (None, 1, 102)            0         \n",
      "                                                                 \n",
      " lstm_619 (LSTM)             (None, 102)               83640     \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 1)                 103       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 462,367\n",
      "Trainable params: 462,367\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/83\n",
      "10/10 - 12s - loss: 0.0199 - val_loss: 0.0190 - 12s/epoch - 1s/step\n",
      "Epoch 2/83\n",
      "10/10 - 0s - loss: 0.0037 - val_loss: 0.0169 - 170ms/epoch - 17ms/step\n",
      "Epoch 3/83\n",
      "10/10 - 0s - loss: 0.0032 - val_loss: 0.0167 - 183ms/epoch - 18ms/step\n",
      "Epoch 4/83\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0117 - 169ms/epoch - 17ms/step\n",
      "Epoch 5/83\n",
      "10/10 - 0s - loss: 0.0012 - val_loss: 0.0081 - 168ms/epoch - 17ms/step\n",
      "Epoch 6/83\n",
      "10/10 - 0s - loss: 6.8349e-04 - val_loss: 0.0079 - 185ms/epoch - 19ms/step\n",
      "Epoch 7/83\n",
      "10/10 - 0s - loss: 4.8896e-04 - val_loss: 0.0084 - 168ms/epoch - 17ms/step\n",
      "Epoch 8/83\n",
      "10/10 - 0s - loss: 4.8919e-04 - val_loss: 0.0081 - 193ms/epoch - 19ms/step\n",
      "Epoch 9/83\n",
      "10/10 - 0s - loss: 3.8020e-04 - val_loss: 0.0079 - 212ms/epoch - 21ms/step\n",
      "Epoch 10/83\n",
      "10/10 - 0s - loss: 3.2418e-04 - val_loss: 0.0079 - 240ms/epoch - 24ms/step\n",
      "Epoch 11/83\n",
      "10/10 - 0s - loss: 3.1848e-04 - val_loss: 0.0079 - 174ms/epoch - 17ms/step\n",
      "Epoch 12/83\n",
      "10/10 - 0s - loss: 3.0161e-04 - val_loss: 0.0078 - 189ms/epoch - 19ms/step\n",
      "Epoch 13/83\n",
      "10/10 - 0s - loss: 2.8900e-04 - val_loss: 0.0078 - 171ms/epoch - 17ms/step\n",
      "Epoch 14/83\n",
      "10/10 - 0s - loss: 3.1609e-04 - val_loss: 0.0080 - 185ms/epoch - 19ms/step\n",
      "Epoch 15/83\n",
      "10/10 - 0s - loss: 2.9937e-04 - val_loss: 0.0079 - 170ms/epoch - 17ms/step\n",
      "Epoch 16/83\n",
      "10/10 - 0s - loss: 3.0140e-04 - val_loss: 0.0079 - 185ms/epoch - 19ms/step\n",
      "Epoch 17/83\n",
      "10/10 - 0s - loss: 3.5516e-04 - val_loss: 0.0080 - 167ms/epoch - 17ms/step\n",
      "Epoch 18/83\n",
      "10/10 - 0s - loss: 3.6783e-04 - val_loss: 0.0082 - 183ms/epoch - 18ms/step\n",
      "Epoch 19/83\n",
      "10/10 - 0s - loss: 3.1459e-04 - val_loss: 0.0079 - 196ms/epoch - 20ms/step\n",
      "Epoch 20/83\n",
      "10/10 - 0s - loss: 2.9667e-04 - val_loss: 0.0084 - 206ms/epoch - 21ms/step\n",
      "Epoch 21/83\n",
      "10/10 - 0s - loss: 2.6092e-04 - val_loss: 0.0083 - 187ms/epoch - 19ms/step\n",
      "Epoch 22/83\n",
      "10/10 - 0s - loss: 2.7780e-04 - val_loss: 0.0085 - 191ms/epoch - 19ms/step\n",
      "Epoch 23/83\n",
      "10/10 - 0s - loss: 2.6747e-04 - val_loss: 0.0085 - 177ms/epoch - 18ms/step\n",
      "Epoch 24/83\n",
      "10/10 - 0s - loss: 2.6392e-04 - val_loss: 0.0091 - 191ms/epoch - 19ms/step\n",
      "Epoch 25/83\n",
      "10/10 - 0s - loss: 2.7796e-04 - val_loss: 0.0085 - 171ms/epoch - 17ms/step\n",
      "Epoch 26/83\n",
      "10/10 - 0s - loss: 2.8363e-04 - val_loss: 0.0095 - 186ms/epoch - 19ms/step\n",
      "Epoch 27/83\n",
      "10/10 - 0s - loss: 3.2570e-04 - val_loss: 0.0096 - 186ms/epoch - 19ms/step\n",
      "Epoch 28/83\n",
      "10/10 - 0s - loss: 3.2077e-04 - val_loss: 0.0098 - 185ms/epoch - 18ms/step\n",
      "Epoch 29/83\n",
      "10/10 - 0s - loss: 3.2518e-04 - val_loss: 0.0098 - 162ms/epoch - 16ms/step\n",
      "Epoch 30/83\n",
      "10/10 - 0s - loss: 2.8471e-04 - val_loss: 0.0103 - 180ms/epoch - 18ms/step\n",
      "Epoch 31/83\n",
      "10/10 - 0s - loss: 2.5650e-04 - val_loss: 0.0099 - 169ms/epoch - 17ms/step\n",
      "Epoch 32/83\n",
      "10/10 - 0s - loss: 2.4171e-04 - val_loss: 0.0103 - 217ms/epoch - 22ms/step\n",
      "Epoch 33/83\n",
      "10/10 - 0s - loss: 2.5683e-04 - val_loss: 0.0105 - 190ms/epoch - 19ms/step\n",
      "Epoch 34/83\n",
      "10/10 - 0s - loss: 2.5083e-04 - val_loss: 0.0109 - 229ms/epoch - 23ms/step\n",
      "Epoch 35/83\n",
      "10/10 - 0s - loss: 2.4733e-04 - val_loss: 0.0107 - 185ms/epoch - 19ms/step\n",
      "Epoch 36/83\n",
      "10/10 - 0s - loss: 2.6631e-04 - val_loss: 0.0117 - 199ms/epoch - 20ms/step\n",
      "Epoch 37/83\n",
      "10/10 - 0s - loss: 2.1766e-04 - val_loss: 0.0113 - 195ms/epoch - 19ms/step\n",
      "Epoch 38/83\n",
      "10/10 - 0s - loss: 2.8047e-04 - val_loss: 0.0113 - 223ms/epoch - 22ms/step\n",
      "Epoch 39/83\n",
      "10/10 - 0s - loss: 2.4248e-04 - val_loss: 0.0116 - 170ms/epoch - 17ms/step\n",
      "Epoch 40/83\n",
      "10/10 - 0s - loss: 2.6519e-04 - val_loss: 0.0121 - 192ms/epoch - 19ms/step\n",
      "Epoch 41/83\n",
      "10/10 - 0s - loss: 2.3733e-04 - val_loss: 0.0116 - 185ms/epoch - 18ms/step\n",
      "Epoch 42/83\n",
      "10/10 - 0s - loss: 2.6666e-04 - val_loss: 0.0125 - 206ms/epoch - 21ms/step\n",
      "Epoch 43/83\n",
      "10/10 - 0s - loss: 2.6800e-04 - val_loss: 0.0118 - 182ms/epoch - 18ms/step\n",
      "Epoch 44/83\n",
      "10/10 - 0s - loss: 2.6521e-04 - val_loss: 0.0127 - 196ms/epoch - 20ms/step\n",
      "Epoch 45/83\n",
      "10/10 - 0s - loss: 2.6070e-04 - val_loss: 0.0119 - 205ms/epoch - 21ms/step\n",
      "Epoch 46/83\n",
      "10/10 - 0s - loss: 2.3952e-04 - val_loss: 0.0123 - 188ms/epoch - 19ms/step\n",
      "Epoch 47/83\n",
      "10/10 - 0s - loss: 2.5763e-04 - val_loss: 0.0121 - 173ms/epoch - 17ms/step\n",
      "Epoch 48/83\n",
      "10/10 - 0s - loss: 2.1094e-04 - val_loss: 0.0119 - 184ms/epoch - 18ms/step\n",
      "Epoch 49/83\n",
      "10/10 - 0s - loss: 2.4353e-04 - val_loss: 0.0123 - 167ms/epoch - 17ms/step\n",
      "Epoch 50/83\n",
      "10/10 - 0s - loss: 2.2900e-04 - val_loss: 0.0124 - 188ms/epoch - 19ms/step\n",
      "Epoch 51/83\n",
      "10/10 - 0s - loss: 2.3772e-04 - val_loss: 0.0122 - 185ms/epoch - 19ms/step\n",
      "Epoch 52/83\n",
      "10/10 - 0s - loss: 2.4780e-04 - val_loss: 0.0123 - 193ms/epoch - 19ms/step\n",
      "Epoch 53/83\n",
      "10/10 - 0s - loss: 2.5577e-04 - val_loss: 0.0124 - 174ms/epoch - 17ms/step\n",
      "Epoch 54/83\n",
      "10/10 - 0s - loss: 2.4549e-04 - val_loss: 0.0127 - 227ms/epoch - 23ms/step\n",
      "Epoch 55/83\n",
      "10/10 - 0s - loss: 2.2942e-04 - val_loss: 0.0126 - 166ms/epoch - 17ms/step\n",
      "Epoch 56/83\n",
      "10/10 - 0s - loss: 2.4992e-04 - val_loss: 0.0125 - 179ms/epoch - 18ms/step\n",
      "Epoch 57/83\n",
      "10/10 - 0s - loss: 2.7765e-04 - val_loss: 0.0123 - 167ms/epoch - 17ms/step\n",
      "Epoch 58/83\n",
      "10/10 - 0s - loss: 2.4521e-04 - val_loss: 0.0124 - 180ms/epoch - 18ms/step\n",
      "Epoch 59/83\n",
      "10/10 - 0s - loss: 2.4826e-04 - val_loss: 0.0121 - 164ms/epoch - 16ms/step\n",
      "Epoch 60/83\n",
      "10/10 - 0s - loss: 2.2999e-04 - val_loss: 0.0126 - 186ms/epoch - 19ms/step\n",
      "Epoch 61/83\n",
      "10/10 - 0s - loss: 2.2922e-04 - val_loss: 0.0124 - 164ms/epoch - 16ms/step\n",
      "Epoch 62/83\n",
      "10/10 - 0s - loss: 2.7729e-04 - val_loss: 0.0127 - 181ms/epoch - 18ms/step\n",
      "Epoch 63/83\n",
      "10/10 - 0s - loss: 2.8455e-04 - val_loss: 0.0125 - 196ms/epoch - 20ms/step\n",
      "Epoch 64/83\n",
      "10/10 - 0s - loss: 2.3988e-04 - val_loss: 0.0130 - 181ms/epoch - 18ms/step\n",
      "Epoch 65/83\n",
      "10/10 - 0s - loss: 2.2153e-04 - val_loss: 0.0130 - 167ms/epoch - 17ms/step\n",
      "Epoch 66/83\n",
      "10/10 - 0s - loss: 2.5388e-04 - val_loss: 0.0128 - 183ms/epoch - 18ms/step\n",
      "Epoch 67/83\n",
      "10/10 - 0s - loss: 3.0173e-04 - val_loss: 0.0132 - 171ms/epoch - 17ms/step\n",
      "Epoch 68/83\n",
      "10/10 - 0s - loss: 2.8453e-04 - val_loss: 0.0135 - 206ms/epoch - 21ms/step\n",
      "Epoch 69/83\n",
      "10/10 - 0s - loss: 3.3010e-04 - val_loss: 0.0132 - 167ms/epoch - 17ms/step\n",
      "Epoch 70/83\n",
      "10/10 - 0s - loss: 2.4751e-04 - val_loss: 0.0130 - 186ms/epoch - 19ms/step\n",
      "Epoch 71/83\n",
      "10/10 - 0s - loss: 2.3732e-04 - val_loss: 0.0131 - 168ms/epoch - 17ms/step\n",
      "Epoch 72/83\n",
      "10/10 - 0s - loss: 2.5843e-04 - val_loss: 0.0127 - 219ms/epoch - 22ms/step\n",
      "Epoch 73/83\n",
      "10/10 - 0s - loss: 2.5419e-04 - val_loss: 0.0130 - 163ms/epoch - 16ms/step\n",
      "Epoch 74/83\n",
      "10/10 - 0s - loss: 3.7961e-04 - val_loss: 0.0134 - 181ms/epoch - 18ms/step\n",
      "Epoch 75/83\n",
      "10/10 - 0s - loss: 3.1446e-04 - val_loss: 0.0127 - 174ms/epoch - 17ms/step\n",
      "Epoch 76/83\n",
      "10/10 - 0s - loss: 2.4219e-04 - val_loss: 0.0128 - 186ms/epoch - 19ms/step\n",
      "Epoch 77/83\n",
      "10/10 - 0s - loss: 2.0980e-04 - val_loss: 0.0125 - 162ms/epoch - 16ms/step\n",
      "Epoch 78/83\n",
      "10/10 - 0s - loss: 2.3306e-04 - val_loss: 0.0127 - 181ms/epoch - 18ms/step\n",
      "Epoch 79/83\n",
      "10/10 - 0s - loss: 2.4398e-04 - val_loss: 0.0125 - 162ms/epoch - 16ms/step\n",
      "Epoch 80/83\n",
      "10/10 - 0s - loss: 2.2382e-04 - val_loss: 0.0125 - 224ms/epoch - 22ms/step\n",
      "Epoch 81/83\n",
      "10/10 - 0s - loss: 2.7729e-04 - val_loss: 0.0127 - 169ms/epoch - 17ms/step\n",
      "Epoch 82/83\n",
      "10/10 - 0s - loss: 2.6516e-04 - val_loss: 0.0125 - 182ms/epoch - 18ms/step\n",
      "Epoch 83/83\n",
      "10/10 - 0s - loss: 2.4537e-04 - val_loss: 0.0133 - 166ms/epoch - 17ms/step\n",
      "9/9 [==============================] - 1s 3ms/step\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m-206.3   \u001b[0m | \u001b[0m83.15    \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m102.1    \u001b[0m |\n",
      "Model: \"sequential_171\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_620 (LSTM)             (None, 1, 79)             26860     \n",
      "                                                                 \n",
      " dropout_449 (Dropout)       (None, 1, 79)             0         \n",
      "                                                                 \n",
      " lstm_621 (LSTM)             (None, 1, 79)             50244     \n",
      "                                                                 \n",
      " dropout_450 (Dropout)       (None, 1, 79)             0         \n",
      "                                                                 \n",
      " lstm_622 (LSTM)             (None, 1, 79)             50244     \n",
      "                                                                 \n",
      " dropout_451 (Dropout)       (None, 1, 79)             0         \n",
      "                                                                 \n",
      " lstm_623 (LSTM)             (None, 1, 79)             50244     \n",
      "                                                                 \n",
      " dropout_452 (Dropout)       (None, 1, 79)             0         \n",
      "                                                                 \n",
      " lstm_624 (LSTM)             (None, 79)                50244     \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 1)                 80        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 227,916\n",
      "Trainable params: 227,916\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/189\n",
      "10/10 - 11s - loss: 0.0562 - val_loss: 0.0553 - 11s/epoch - 1s/step\n",
      "Epoch 2/189\n",
      "10/10 - 0s - loss: 0.0191 - val_loss: 0.0161 - 131ms/epoch - 13ms/step\n",
      "Epoch 3/189\n",
      "10/10 - 0s - loss: 0.0056 - val_loss: 0.0159 - 132ms/epoch - 13ms/step\n",
      "Epoch 4/189\n",
      "10/10 - 0s - loss: 0.0033 - val_loss: 0.0182 - 146ms/epoch - 15ms/step\n",
      "Epoch 5/189\n",
      "10/10 - 0s - loss: 0.0034 - val_loss: 0.0165 - 158ms/epoch - 16ms/step\n",
      "Epoch 6/189\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0163 - 152ms/epoch - 15ms/step\n",
      "Epoch 7/189\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0165 - 129ms/epoch - 13ms/step\n",
      "Epoch 8/189\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0164 - 150ms/epoch - 15ms/step\n",
      "Epoch 9/189\n",
      "10/10 - 0s - loss: 0.0029 - val_loss: 0.0161 - 127ms/epoch - 13ms/step\n",
      "Epoch 10/189\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0159 - 143ms/epoch - 14ms/step\n",
      "Epoch 11/189\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0156 - 128ms/epoch - 13ms/step\n",
      "Epoch 12/189\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0150 - 141ms/epoch - 14ms/step\n",
      "Epoch 13/189\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0144 - 126ms/epoch - 13ms/step\n",
      "Epoch 14/189\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0133 - 178ms/epoch - 18ms/step\n",
      "Epoch 15/189\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0125 - 128ms/epoch - 13ms/step\n",
      "Epoch 16/189\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0105 - 147ms/epoch - 15ms/step\n",
      "Epoch 17/189\n",
      "10/10 - 0s - loss: 0.0014 - val_loss: 0.0092 - 128ms/epoch - 13ms/step\n",
      "Epoch 18/189\n",
      "10/10 - 0s - loss: 9.5822e-04 - val_loss: 0.0084 - 147ms/epoch - 15ms/step\n",
      "Epoch 19/189\n",
      "10/10 - 0s - loss: 7.2688e-04 - val_loss: 0.0091 - 128ms/epoch - 13ms/step\n",
      "Epoch 20/189\n",
      "10/10 - 0s - loss: 6.3795e-04 - val_loss: 0.0093 - 146ms/epoch - 15ms/step\n",
      "Epoch 21/189\n",
      "10/10 - 0s - loss: 6.2834e-04 - val_loss: 0.0088 - 126ms/epoch - 13ms/step\n",
      "Epoch 22/189\n",
      "10/10 - 0s - loss: 5.8471e-04 - val_loss: 0.0087 - 147ms/epoch - 15ms/step\n",
      "Epoch 23/189\n",
      "10/10 - 0s - loss: 5.3674e-04 - val_loss: 0.0088 - 161ms/epoch - 16ms/step\n",
      "Epoch 24/189\n",
      "10/10 - 0s - loss: 5.1963e-04 - val_loss: 0.0090 - 146ms/epoch - 15ms/step\n",
      "Epoch 25/189\n",
      "10/10 - 0s - loss: 4.5195e-04 - val_loss: 0.0092 - 128ms/epoch - 13ms/step\n",
      "Epoch 26/189\n",
      "10/10 - 0s - loss: 4.4765e-04 - val_loss: 0.0090 - 146ms/epoch - 15ms/step\n",
      "Epoch 27/189\n",
      "10/10 - 0s - loss: 4.8941e-04 - val_loss: 0.0089 - 131ms/epoch - 13ms/step\n",
      "Epoch 28/189\n",
      "10/10 - 0s - loss: 4.0934e-04 - val_loss: 0.0087 - 144ms/epoch - 14ms/step\n",
      "Epoch 29/189\n",
      "10/10 - 0s - loss: 4.4634e-04 - val_loss: 0.0088 - 129ms/epoch - 13ms/step\n",
      "Epoch 30/189\n",
      "10/10 - 0s - loss: 3.7106e-04 - val_loss: 0.0088 - 152ms/epoch - 15ms/step\n",
      "Epoch 31/189\n",
      "10/10 - 0s - loss: 4.2546e-04 - val_loss: 0.0087 - 156ms/epoch - 16ms/step\n",
      "Epoch 32/189\n",
      "10/10 - 0s - loss: 3.7697e-04 - val_loss: 0.0087 - 146ms/epoch - 15ms/step\n",
      "Epoch 33/189\n",
      "10/10 - 0s - loss: 4.1118e-04 - val_loss: 0.0086 - 133ms/epoch - 13ms/step\n",
      "Epoch 34/189\n",
      "10/10 - 0s - loss: 4.0974e-04 - val_loss: 0.0086 - 147ms/epoch - 15ms/step\n",
      "Epoch 35/189\n",
      "10/10 - 0s - loss: 3.6836e-04 - val_loss: 0.0088 - 126ms/epoch - 13ms/step\n",
      "Epoch 36/189\n",
      "10/10 - 0s - loss: 3.7570e-04 - val_loss: 0.0087 - 145ms/epoch - 14ms/step\n",
      "Epoch 37/189\n",
      "10/10 - 0s - loss: 4.0721e-04 - val_loss: 0.0085 - 128ms/epoch - 13ms/step\n",
      "Epoch 38/189\n",
      "10/10 - 0s - loss: 3.5702e-04 - val_loss: 0.0085 - 144ms/epoch - 14ms/step\n",
      "Epoch 39/189\n",
      "10/10 - 0s - loss: 3.8277e-04 - val_loss: 0.0087 - 125ms/epoch - 12ms/step\n",
      "Epoch 40/189\n",
      "10/10 - 0s - loss: 3.4245e-04 - val_loss: 0.0087 - 180ms/epoch - 18ms/step\n",
      "Epoch 41/189\n",
      "10/10 - 0s - loss: 3.3691e-04 - val_loss: 0.0087 - 127ms/epoch - 13ms/step\n",
      "Epoch 42/189\n",
      "10/10 - 0s - loss: 3.3174e-04 - val_loss: 0.0086 - 146ms/epoch - 15ms/step\n",
      "Epoch 43/189\n",
      "10/10 - 0s - loss: 3.4406e-04 - val_loss: 0.0086 - 127ms/epoch - 13ms/step\n",
      "Epoch 44/189\n",
      "10/10 - 0s - loss: 3.2877e-04 - val_loss: 0.0086 - 144ms/epoch - 14ms/step\n",
      "Epoch 45/189\n",
      "10/10 - 0s - loss: 3.2528e-04 - val_loss: 0.0085 - 128ms/epoch - 13ms/step\n",
      "Epoch 46/189\n",
      "10/10 - 0s - loss: 3.0190e-04 - val_loss: 0.0084 - 154ms/epoch - 15ms/step\n",
      "Epoch 47/189\n",
      "10/10 - 0s - loss: 3.1698e-04 - val_loss: 0.0086 - 130ms/epoch - 13ms/step\n",
      "Epoch 48/189\n",
      "10/10 - 0s - loss: 3.4778e-04 - val_loss: 0.0085 - 148ms/epoch - 15ms/step\n",
      "Epoch 49/189\n",
      "10/10 - 0s - loss: 3.4303e-04 - val_loss: 0.0085 - 161ms/epoch - 16ms/step\n",
      "Epoch 50/189\n",
      "10/10 - 0s - loss: 2.9177e-04 - val_loss: 0.0087 - 161ms/epoch - 16ms/step\n",
      "Epoch 51/189\n",
      "10/10 - 0s - loss: 3.1716e-04 - val_loss: 0.0085 - 129ms/epoch - 13ms/step\n",
      "Epoch 52/189\n",
      "10/10 - 0s - loss: 3.3755e-04 - val_loss: 0.0085 - 146ms/epoch - 15ms/step\n",
      "Epoch 53/189\n",
      "10/10 - 0s - loss: 3.1969e-04 - val_loss: 0.0085 - 127ms/epoch - 13ms/step\n",
      "Epoch 54/189\n",
      "10/10 - 0s - loss: 2.8659e-04 - val_loss: 0.0085 - 150ms/epoch - 15ms/step\n",
      "Epoch 55/189\n",
      "10/10 - 0s - loss: 2.8367e-04 - val_loss: 0.0083 - 128ms/epoch - 13ms/step\n",
      "Epoch 56/189\n",
      "10/10 - 0s - loss: 3.2008e-04 - val_loss: 0.0084 - 192ms/epoch - 19ms/step\n",
      "Epoch 57/189\n",
      "10/10 - 0s - loss: 3.8997e-04 - val_loss: 0.0084 - 132ms/epoch - 13ms/step\n",
      "Epoch 58/189\n",
      "10/10 - 0s - loss: 2.9962e-04 - val_loss: 0.0085 - 146ms/epoch - 15ms/step\n",
      "Epoch 59/189\n",
      "10/10 - 0s - loss: 2.8221e-04 - val_loss: 0.0083 - 125ms/epoch - 13ms/step\n",
      "Epoch 60/189\n",
      "10/10 - 0s - loss: 3.0400e-04 - val_loss: 0.0084 - 142ms/epoch - 14ms/step\n",
      "Epoch 61/189\n",
      "10/10 - 0s - loss: 3.0104e-04 - val_loss: 0.0084 - 127ms/epoch - 13ms/step\n",
      "Epoch 62/189\n",
      "10/10 - 0s - loss: 2.8554e-04 - val_loss: 0.0084 - 144ms/epoch - 14ms/step\n",
      "Epoch 63/189\n",
      "10/10 - 0s - loss: 2.8413e-04 - val_loss: 0.0084 - 126ms/epoch - 13ms/step\n",
      "Epoch 64/189\n",
      "10/10 - 0s - loss: 2.9813e-04 - val_loss: 0.0084 - 144ms/epoch - 14ms/step\n",
      "Epoch 65/189\n",
      "10/10 - 0s - loss: 2.9476e-04 - val_loss: 0.0083 - 155ms/epoch - 16ms/step\n",
      "Epoch 66/189\n",
      "10/10 - 0s - loss: 2.9500e-04 - val_loss: 0.0084 - 147ms/epoch - 15ms/step\n",
      "Epoch 67/189\n",
      "10/10 - 0s - loss: 2.7377e-04 - val_loss: 0.0083 - 127ms/epoch - 13ms/step\n",
      "Epoch 68/189\n",
      "10/10 - 0s - loss: 2.9603e-04 - val_loss: 0.0082 - 146ms/epoch - 15ms/step\n",
      "Epoch 69/189\n",
      "10/10 - 0s - loss: 2.7328e-04 - val_loss: 0.0085 - 132ms/epoch - 13ms/step\n",
      "Epoch 70/189\n",
      "10/10 - 0s - loss: 2.4710e-04 - val_loss: 0.0084 - 145ms/epoch - 15ms/step\n",
      "Epoch 71/189\n",
      "10/10 - 0s - loss: 2.7652e-04 - val_loss: 0.0083 - 128ms/epoch - 13ms/step\n",
      "Epoch 72/189\n",
      "10/10 - 0s - loss: 2.5891e-04 - val_loss: 0.0085 - 151ms/epoch - 15ms/step\n",
      "Epoch 73/189\n",
      "10/10 - 0s - loss: 2.9144e-04 - val_loss: 0.0083 - 149ms/epoch - 15ms/step\n",
      "Epoch 74/189\n",
      "10/10 - 0s - loss: 2.8548e-04 - val_loss: 0.0083 - 148ms/epoch - 15ms/step\n",
      "Epoch 75/189\n",
      "10/10 - 0s - loss: 2.8664e-04 - val_loss: 0.0084 - 129ms/epoch - 13ms/step\n",
      "Epoch 76/189\n",
      "10/10 - 0s - loss: 2.6298e-04 - val_loss: 0.0083 - 139ms/epoch - 14ms/step\n",
      "Epoch 77/189\n",
      "10/10 - 0s - loss: 2.6509e-04 - val_loss: 0.0084 - 127ms/epoch - 13ms/step\n",
      "Epoch 78/189\n",
      "10/10 - 0s - loss: 2.6397e-04 - val_loss: 0.0083 - 149ms/epoch - 15ms/step\n",
      "Epoch 79/189\n",
      "10/10 - 0s - loss: 2.7341e-04 - val_loss: 0.0083 - 128ms/epoch - 13ms/step\n",
      "Epoch 80/189\n",
      "10/10 - 0s - loss: 2.6969e-04 - val_loss: 0.0083 - 182ms/epoch - 18ms/step\n",
      "Epoch 81/189\n",
      "10/10 - 0s - loss: 2.7171e-04 - val_loss: 0.0083 - 130ms/epoch - 13ms/step\n",
      "Epoch 82/189\n",
      "10/10 - 0s - loss: 2.8167e-04 - val_loss: 0.0082 - 141ms/epoch - 14ms/step\n",
      "Epoch 83/189\n",
      "10/10 - 0s - loss: 2.6474e-04 - val_loss: 0.0083 - 129ms/epoch - 13ms/step\n",
      "Epoch 84/189\n",
      "10/10 - 0s - loss: 2.5960e-04 - val_loss: 0.0082 - 147ms/epoch - 15ms/step\n",
      "Epoch 85/189\n",
      "10/10 - 0s - loss: 2.6370e-04 - val_loss: 0.0083 - 127ms/epoch - 13ms/step\n",
      "Epoch 86/189\n",
      "10/10 - 0s - loss: 2.5581e-04 - val_loss: 0.0083 - 143ms/epoch - 14ms/step\n",
      "Epoch 87/189\n",
      "10/10 - 0s - loss: 2.6335e-04 - val_loss: 0.0081 - 129ms/epoch - 13ms/step\n",
      "Epoch 88/189\n",
      "10/10 - 0s - loss: 2.4918e-04 - val_loss: 0.0082 - 145ms/epoch - 14ms/step\n",
      "Epoch 89/189\n",
      "10/10 - 0s - loss: 2.7859e-04 - val_loss: 0.0082 - 153ms/epoch - 15ms/step\n",
      "Epoch 90/189\n",
      "10/10 - 0s - loss: 2.7414e-04 - val_loss: 0.0082 - 145ms/epoch - 15ms/step\n",
      "Epoch 91/189\n",
      "10/10 - 0s - loss: 2.4578e-04 - val_loss: 0.0082 - 132ms/epoch - 13ms/step\n",
      "Epoch 92/189\n",
      "10/10 - 0s - loss: 2.7864e-04 - val_loss: 0.0082 - 148ms/epoch - 15ms/step\n",
      "Epoch 93/189\n",
      "10/10 - 0s - loss: 2.5303e-04 - val_loss: 0.0082 - 129ms/epoch - 13ms/step\n",
      "Epoch 94/189\n",
      "10/10 - 0s - loss: 2.3944e-04 - val_loss: 0.0082 - 147ms/epoch - 15ms/step\n",
      "Epoch 95/189\n",
      "10/10 - 0s - loss: 2.5911e-04 - val_loss: 0.0081 - 130ms/epoch - 13ms/step\n",
      "Epoch 96/189\n",
      "10/10 - 0s - loss: 2.5072e-04 - val_loss: 0.0082 - 150ms/epoch - 15ms/step\n",
      "Epoch 97/189\n",
      "10/10 - 0s - loss: 2.5675e-04 - val_loss: 0.0081 - 132ms/epoch - 13ms/step\n",
      "Epoch 98/189\n",
      "10/10 - 0s - loss: 2.6129e-04 - val_loss: 0.0081 - 197ms/epoch - 20ms/step\n",
      "Epoch 99/189\n",
      "10/10 - 0s - loss: 2.5170e-04 - val_loss: 0.0083 - 132ms/epoch - 13ms/step\n",
      "Epoch 100/189\n",
      "10/10 - 0s - loss: 2.6466e-04 - val_loss: 0.0081 - 146ms/epoch - 15ms/step\n",
      "Epoch 101/189\n",
      "10/10 - 0s - loss: 2.6549e-04 - val_loss: 0.0082 - 128ms/epoch - 13ms/step\n",
      "Epoch 102/189\n",
      "10/10 - 0s - loss: 2.3730e-04 - val_loss: 0.0081 - 143ms/epoch - 14ms/step\n",
      "Epoch 103/189\n",
      "10/10 - 0s - loss: 2.4580e-04 - val_loss: 0.0081 - 125ms/epoch - 12ms/step\n",
      "Epoch 104/189\n",
      "10/10 - 0s - loss: 2.3301e-04 - val_loss: 0.0082 - 143ms/epoch - 14ms/step\n",
      "Epoch 105/189\n",
      "10/10 - 0s - loss: 2.4514e-04 - val_loss: 0.0081 - 127ms/epoch - 13ms/step\n",
      "Epoch 106/189\n",
      "10/10 - 0s - loss: 2.4984e-04 - val_loss: 0.0081 - 186ms/epoch - 19ms/step\n",
      "Epoch 107/189\n",
      "10/10 - 0s - loss: 2.5551e-04 - val_loss: 0.0082 - 127ms/epoch - 13ms/step\n",
      "Epoch 108/189\n",
      "10/10 - 0s - loss: 2.7074e-04 - val_loss: 0.0081 - 149ms/epoch - 15ms/step\n",
      "Epoch 109/189\n",
      "10/10 - 0s - loss: 2.5716e-04 - val_loss: 0.0081 - 125ms/epoch - 13ms/step\n",
      "Epoch 110/189\n",
      "10/10 - 0s - loss: 2.4588e-04 - val_loss: 0.0082 - 142ms/epoch - 14ms/step\n",
      "Epoch 111/189\n",
      "10/10 - 0s - loss: 2.5309e-04 - val_loss: 0.0081 - 129ms/epoch - 13ms/step\n",
      "Epoch 112/189\n",
      "10/10 - 0s - loss: 2.5809e-04 - val_loss: 0.0081 - 131ms/epoch - 13ms/step\n",
      "Epoch 113/189\n",
      "10/10 - 0s - loss: 2.4935e-04 - val_loss: 0.0081 - 142ms/epoch - 14ms/step\n",
      "Epoch 114/189\n",
      "10/10 - 0s - loss: 2.3932e-04 - val_loss: 0.0081 - 153ms/epoch - 15ms/step\n",
      "Epoch 115/189\n",
      "10/10 - 0s - loss: 2.6817e-04 - val_loss: 0.0081 - 143ms/epoch - 14ms/step\n",
      "Epoch 116/189\n",
      "10/10 - 0s - loss: 2.4640e-04 - val_loss: 0.0081 - 127ms/epoch - 13ms/step\n",
      "Epoch 117/189\n",
      "10/10 - 0s - loss: 2.4439e-04 - val_loss: 0.0081 - 129ms/epoch - 13ms/step\n",
      "Epoch 118/189\n",
      "10/10 - 0s - loss: 2.5130e-04 - val_loss: 0.0081 - 152ms/epoch - 15ms/step\n",
      "Epoch 119/189\n",
      "10/10 - 0s - loss: 2.4154e-04 - val_loss: 0.0081 - 128ms/epoch - 13ms/step\n",
      "Epoch 120/189\n",
      "10/10 - 0s - loss: 2.5772e-04 - val_loss: 0.0080 - 138ms/epoch - 14ms/step\n",
      "Epoch 121/189\n",
      "10/10 - 0s - loss: 2.4949e-04 - val_loss: 0.0081 - 153ms/epoch - 15ms/step\n",
      "Epoch 122/189\n",
      "10/10 - 0s - loss: 2.4132e-04 - val_loss: 0.0081 - 127ms/epoch - 13ms/step\n",
      "Epoch 123/189\n",
      "10/10 - 0s - loss: 2.2774e-04 - val_loss: 0.0081 - 142ms/epoch - 14ms/step\n",
      "Epoch 124/189\n",
      "10/10 - 0s - loss: 2.2328e-04 - val_loss: 0.0081 - 127ms/epoch - 13ms/step\n",
      "Epoch 125/189\n",
      "10/10 - 0s - loss: 2.2212e-04 - val_loss: 0.0081 - 127ms/epoch - 13ms/step\n",
      "Epoch 126/189\n",
      "10/10 - 0s - loss: 2.3995e-04 - val_loss: 0.0081 - 145ms/epoch - 14ms/step\n",
      "Epoch 127/189\n",
      "10/10 - 0s - loss: 2.3488e-04 - val_loss: 0.0081 - 127ms/epoch - 13ms/step\n",
      "Epoch 128/189\n",
      "10/10 - 0s - loss: 2.4341e-04 - val_loss: 0.0081 - 125ms/epoch - 12ms/step\n",
      "Epoch 129/189\n",
      "10/10 - 0s - loss: 2.2820e-04 - val_loss: 0.0081 - 186ms/epoch - 19ms/step\n",
      "Epoch 130/189\n",
      "10/10 - 0s - loss: 2.5110e-04 - val_loss: 0.0081 - 125ms/epoch - 12ms/step\n",
      "Epoch 131/189\n",
      "10/10 - 0s - loss: 2.3534e-04 - val_loss: 0.0081 - 126ms/epoch - 13ms/step\n",
      "Epoch 132/189\n",
      "10/10 - 0s - loss: 2.5059e-04 - val_loss: 0.0080 - 149ms/epoch - 15ms/step\n",
      "Epoch 133/189\n",
      "10/10 - 0s - loss: 2.3123e-04 - val_loss: 0.0081 - 126ms/epoch - 13ms/step\n",
      "Epoch 134/189\n",
      "10/10 - 0s - loss: 2.6034e-04 - val_loss: 0.0081 - 126ms/epoch - 13ms/step\n",
      "Epoch 135/189\n",
      "10/10 - 0s - loss: 2.5862e-04 - val_loss: 0.0081 - 141ms/epoch - 14ms/step\n",
      "Epoch 136/189\n",
      "10/10 - 0s - loss: 2.3933e-04 - val_loss: 0.0081 - 125ms/epoch - 13ms/step\n",
      "Epoch 137/189\n",
      "10/10 - 0s - loss: 2.3406e-04 - val_loss: 0.0080 - 125ms/epoch - 13ms/step\n",
      "Epoch 138/189\n",
      "10/10 - 0s - loss: 2.3539e-04 - val_loss: 0.0081 - 186ms/epoch - 19ms/step\n",
      "Epoch 139/189\n",
      "10/10 - 0s - loss: 2.3042e-04 - val_loss: 0.0081 - 127ms/epoch - 13ms/step\n",
      "Epoch 140/189\n",
      "10/10 - 0s - loss: 2.5263e-04 - val_loss: 0.0081 - 145ms/epoch - 14ms/step\n",
      "Epoch 141/189\n",
      "10/10 - 0s - loss: 2.2540e-04 - val_loss: 0.0081 - 129ms/epoch - 13ms/step\n",
      "Epoch 142/189\n",
      "10/10 - 0s - loss: 2.2866e-04 - val_loss: 0.0081 - 126ms/epoch - 13ms/step\n",
      "Epoch 143/189\n",
      "10/10 - 0s - loss: 2.3589e-04 - val_loss: 0.0081 - 144ms/epoch - 14ms/step\n",
      "Epoch 144/189\n",
      "10/10 - 0s - loss: 2.3303e-04 - val_loss: 0.0081 - 126ms/epoch - 13ms/step\n",
      "Epoch 145/189\n",
      "10/10 - 0s - loss: 2.3669e-04 - val_loss: 0.0081 - 145ms/epoch - 15ms/step\n",
      "Epoch 146/189\n",
      "10/10 - 0s - loss: 2.5684e-04 - val_loss: 0.0081 - 150ms/epoch - 15ms/step\n",
      "Epoch 147/189\n",
      "10/10 - 0s - loss: 2.4886e-04 - val_loss: 0.0081 - 128ms/epoch - 13ms/step\n",
      "Epoch 148/189\n",
      "10/10 - 0s - loss: 2.3350e-04 - val_loss: 0.0081 - 145ms/epoch - 15ms/step\n",
      "Epoch 149/189\n",
      "10/10 - 0s - loss: 2.3938e-04 - val_loss: 0.0081 - 126ms/epoch - 13ms/step\n",
      "Epoch 150/189\n",
      "10/10 - 0s - loss: 2.2257e-04 - val_loss: 0.0081 - 127ms/epoch - 13ms/step\n",
      "Epoch 151/189\n",
      "10/10 - 0s - loss: 2.0439e-04 - val_loss: 0.0081 - 144ms/epoch - 14ms/step\n",
      "Epoch 152/189\n",
      "10/10 - 0s - loss: 2.3904e-04 - val_loss: 0.0081 - 125ms/epoch - 12ms/step\n",
      "Epoch 153/189\n",
      "10/10 - 0s - loss: 2.2594e-04 - val_loss: 0.0081 - 128ms/epoch - 13ms/step\n",
      "Epoch 154/189\n",
      "10/10 - 0s - loss: 2.3002e-04 - val_loss: 0.0081 - 139ms/epoch - 14ms/step\n",
      "Epoch 155/189\n",
      "10/10 - 0s - loss: 2.2394e-04 - val_loss: 0.0081 - 151ms/epoch - 15ms/step\n",
      "Epoch 156/189\n",
      "10/10 - 0s - loss: 2.2288e-04 - val_loss: 0.0081 - 146ms/epoch - 15ms/step\n",
      "Epoch 157/189\n",
      "10/10 - 0s - loss: 2.1936e-04 - val_loss: 0.0081 - 127ms/epoch - 13ms/step\n",
      "Epoch 158/189\n",
      "10/10 - 0s - loss: 2.1820e-04 - val_loss: 0.0082 - 125ms/epoch - 12ms/step\n",
      "Epoch 159/189\n",
      "10/10 - 0s - loss: 2.2944e-04 - val_loss: 0.0081 - 146ms/epoch - 15ms/step\n",
      "Epoch 160/189\n",
      "10/10 - 0s - loss: 2.0745e-04 - val_loss: 0.0082 - 128ms/epoch - 13ms/step\n",
      "Epoch 161/189\n",
      "10/10 - 0s - loss: 2.4137e-04 - val_loss: 0.0081 - 143ms/epoch - 14ms/step\n",
      "Epoch 162/189\n",
      "10/10 - 0s - loss: 2.2842e-04 - val_loss: 0.0081 - 125ms/epoch - 12ms/step\n",
      "Epoch 163/189\n",
      "10/10 - 0s - loss: 2.3289e-04 - val_loss: 0.0081 - 127ms/epoch - 13ms/step\n",
      "Epoch 164/189\n",
      "10/10 - 0s - loss: 2.2605e-04 - val_loss: 0.0081 - 177ms/epoch - 18ms/step\n",
      "Epoch 165/189\n",
      "10/10 - 0s - loss: 2.1498e-04 - val_loss: 0.0082 - 127ms/epoch - 13ms/step\n",
      "Epoch 166/189\n",
      "10/10 - 0s - loss: 2.0729e-04 - val_loss: 0.0081 - 134ms/epoch - 13ms/step\n",
      "Epoch 167/189\n",
      "10/10 - 0s - loss: 2.2587e-04 - val_loss: 0.0082 - 143ms/epoch - 14ms/step\n",
      "Epoch 168/189\n",
      "10/10 - 0s - loss: 2.3100e-04 - val_loss: 0.0081 - 127ms/epoch - 13ms/step\n",
      "Epoch 169/189\n",
      "10/10 - 0s - loss: 2.2803e-04 - val_loss: 0.0081 - 129ms/epoch - 13ms/step\n",
      "Epoch 170/189\n",
      "10/10 - 0s - loss: 2.4074e-04 - val_loss: 0.0082 - 149ms/epoch - 15ms/step\n",
      "Epoch 171/189\n",
      "10/10 - 0s - loss: 2.1261e-04 - val_loss: 0.0081 - 126ms/epoch - 13ms/step\n",
      "Epoch 172/189\n",
      "10/10 - 0s - loss: 2.2896e-04 - val_loss: 0.0081 - 126ms/epoch - 13ms/step\n",
      "Epoch 173/189\n",
      "10/10 - 0s - loss: 2.1015e-04 - val_loss: 0.0081 - 182ms/epoch - 18ms/step\n",
      "Epoch 174/189\n",
      "10/10 - 0s - loss: 2.3139e-04 - val_loss: 0.0081 - 126ms/epoch - 13ms/step\n",
      "Epoch 175/189\n",
      "10/10 - 0s - loss: 2.2509e-04 - val_loss: 0.0081 - 125ms/epoch - 13ms/step\n",
      "Epoch 176/189\n",
      "10/10 - 0s - loss: 2.2414e-04 - val_loss: 0.0081 - 146ms/epoch - 15ms/step\n",
      "Epoch 177/189\n",
      "10/10 - 0s - loss: 2.1801e-04 - val_loss: 0.0082 - 129ms/epoch - 13ms/step\n",
      "Epoch 178/189\n",
      "10/10 - 0s - loss: 2.4122e-04 - val_loss: 0.0081 - 127ms/epoch - 13ms/step\n",
      "Epoch 179/189\n",
      "10/10 - 0s - loss: 2.2695e-04 - val_loss: 0.0081 - 142ms/epoch - 14ms/step\n",
      "Epoch 180/189\n",
      "10/10 - 0s - loss: 2.3729e-04 - val_loss: 0.0082 - 126ms/epoch - 13ms/step\n",
      "Epoch 181/189\n",
      "10/10 - 0s - loss: 2.1983e-04 - val_loss: 0.0082 - 144ms/epoch - 14ms/step\n",
      "Epoch 182/189\n",
      "10/10 - 0s - loss: 2.4338e-04 - val_loss: 0.0082 - 155ms/epoch - 15ms/step\n",
      "Epoch 183/189\n",
      "10/10 - 0s - loss: 2.2795e-04 - val_loss: 0.0081 - 127ms/epoch - 13ms/step\n",
      "Epoch 184/189\n",
      "10/10 - 0s - loss: 2.2852e-04 - val_loss: 0.0082 - 151ms/epoch - 15ms/step\n",
      "Epoch 185/189\n",
      "10/10 - 0s - loss: 2.1083e-04 - val_loss: 0.0081 - 128ms/epoch - 13ms/step\n",
      "Epoch 186/189\n",
      "10/10 - 0s - loss: 2.2604e-04 - val_loss: 0.0082 - 126ms/epoch - 13ms/step\n",
      "Epoch 187/189\n",
      "10/10 - 0s - loss: 2.2140e-04 - val_loss: 0.0082 - 144ms/epoch - 14ms/step\n",
      "Epoch 188/189\n",
      "10/10 - 0s - loss: 2.3696e-04 - val_loss: 0.0082 - 126ms/epoch - 13ms/step\n",
      "Epoch 189/189\n",
      "10/10 - 0s - loss: 2.1878e-04 - val_loss: 0.0082 - 166ms/epoch - 17ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m-162.2   \u001b[0m | \u001b[0m189.1    \u001b[0m | \u001b[0m4.579    \u001b[0m | \u001b[0m0.001462 \u001b[0m | \u001b[0m79.4     \u001b[0m |\n",
      "Model: \"sequential_172\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_625 (LSTM)             (None, 1, 125)            65500     \n",
      "                                                                 \n",
      " dropout_453 (Dropout)       (None, 1, 125)            0         \n",
      "                                                                 \n",
      " lstm_626 (LSTM)             (None, 125)               125500    \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 1)                 126       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 191,126\n",
      "Trainable params: 191,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/118\n",
      "10/10 - 4s - loss: 0.0710 - val_loss: 0.0921 - 4s/epoch - 388ms/step\n",
      "Epoch 2/118\n",
      "10/10 - 0s - loss: 0.0705 - val_loss: 0.0915 - 88ms/epoch - 9ms/step\n",
      "Epoch 3/118\n",
      "10/10 - 0s - loss: 0.0700 - val_loss: 0.0910 - 88ms/epoch - 9ms/step\n",
      "Epoch 4/118\n",
      "10/10 - 0s - loss: 0.0696 - val_loss: 0.0905 - 105ms/epoch - 10ms/step\n",
      "Epoch 5/118\n",
      "10/10 - 0s - loss: 0.0691 - val_loss: 0.0900 - 91ms/epoch - 9ms/step\n",
      "Epoch 6/118\n",
      "10/10 - 0s - loss: 0.0687 - val_loss: 0.0895 - 88ms/epoch - 9ms/step\n",
      "Epoch 7/118\n",
      "10/10 - 0s - loss: 0.0682 - val_loss: 0.0890 - 101ms/epoch - 10ms/step\n",
      "Epoch 8/118\n",
      "10/10 - 0s - loss: 0.0678 - val_loss: 0.0885 - 104ms/epoch - 10ms/step\n",
      "Epoch 9/118\n",
      "10/10 - 0s - loss: 0.0674 - val_loss: 0.0879 - 98ms/epoch - 10ms/step\n",
      "Epoch 10/118\n",
      "10/10 - 0s - loss: 0.0669 - val_loss: 0.0874 - 103ms/epoch - 10ms/step\n",
      "Epoch 11/118\n",
      "10/10 - 0s - loss: 0.0664 - val_loss: 0.0869 - 89ms/epoch - 9ms/step\n",
      "Epoch 12/118\n",
      "10/10 - 0s - loss: 0.0660 - val_loss: 0.0864 - 87ms/epoch - 9ms/step\n",
      "Epoch 13/118\n",
      "10/10 - 0s - loss: 0.0655 - val_loss: 0.0859 - 106ms/epoch - 11ms/step\n",
      "Epoch 14/118\n",
      "10/10 - 0s - loss: 0.0651 - val_loss: 0.0854 - 91ms/epoch - 9ms/step\n",
      "Epoch 15/118\n",
      "10/10 - 0s - loss: 0.0646 - val_loss: 0.0849 - 102ms/epoch - 10ms/step\n",
      "Epoch 16/118\n",
      "10/10 - 0s - loss: 0.0642 - val_loss: 0.0844 - 87ms/epoch - 9ms/step\n",
      "Epoch 17/118\n",
      "10/10 - 0s - loss: 0.0637 - val_loss: 0.0839 - 114ms/epoch - 11ms/step\n",
      "Epoch 18/118\n",
      "10/10 - 0s - loss: 0.0632 - val_loss: 0.0834 - 104ms/epoch - 10ms/step\n",
      "Epoch 19/118\n",
      "10/10 - 0s - loss: 0.0628 - val_loss: 0.0828 - 96ms/epoch - 10ms/step\n",
      "Epoch 20/118\n",
      "10/10 - 0s - loss: 0.0623 - val_loss: 0.0823 - 89ms/epoch - 9ms/step\n",
      "Epoch 21/118\n",
      "10/10 - 0s - loss: 0.0619 - val_loss: 0.0818 - 104ms/epoch - 10ms/step\n",
      "Epoch 22/118\n",
      "10/10 - 0s - loss: 0.0614 - val_loss: 0.0813 - 88ms/epoch - 9ms/step\n",
      "Epoch 23/118\n",
      "10/10 - 0s - loss: 0.0610 - val_loss: 0.0808 - 86ms/epoch - 9ms/step\n",
      "Epoch 24/118\n",
      "10/10 - 0s - loss: 0.0605 - val_loss: 0.0803 - 105ms/epoch - 10ms/step\n",
      "Epoch 25/118\n",
      "10/10 - 0s - loss: 0.0600 - val_loss: 0.0797 - 115ms/epoch - 11ms/step\n",
      "Epoch 26/118\n",
      "10/10 - 0s - loss: 0.0596 - val_loss: 0.0792 - 96ms/epoch - 10ms/step\n",
      "Epoch 27/118\n",
      "10/10 - 0s - loss: 0.0591 - val_loss: 0.0787 - 107ms/epoch - 11ms/step\n",
      "Epoch 28/118\n",
      "10/10 - 0s - loss: 0.0586 - val_loss: 0.0782 - 93ms/epoch - 9ms/step\n",
      "Epoch 29/118\n",
      "10/10 - 0s - loss: 0.0582 - val_loss: 0.0776 - 93ms/epoch - 9ms/step\n",
      "Epoch 30/118\n",
      "10/10 - 0s - loss: 0.0578 - val_loss: 0.0771 - 107ms/epoch - 11ms/step\n",
      "Epoch 31/118\n",
      "10/10 - 0s - loss: 0.0573 - val_loss: 0.0766 - 89ms/epoch - 9ms/step\n",
      "Epoch 32/118\n",
      "10/10 - 0s - loss: 0.0568 - val_loss: 0.0761 - 138ms/epoch - 14ms/step\n",
      "Epoch 33/118\n",
      "10/10 - 0s - loss: 0.0564 - val_loss: 0.0755 - 94ms/epoch - 9ms/step\n",
      "Epoch 34/118\n",
      "10/10 - 0s - loss: 0.0558 - val_loss: 0.0750 - 88ms/epoch - 9ms/step\n",
      "Epoch 35/118\n",
      "10/10 - 0s - loss: 0.0554 - val_loss: 0.0744 - 107ms/epoch - 11ms/step\n",
      "Epoch 36/118\n",
      "10/10 - 0s - loss: 0.0548 - val_loss: 0.0739 - 92ms/epoch - 9ms/step\n",
      "Epoch 37/118\n",
      "10/10 - 0s - loss: 0.0544 - val_loss: 0.0734 - 87ms/epoch - 9ms/step\n",
      "Epoch 38/118\n",
      "10/10 - 0s - loss: 0.0540 - val_loss: 0.0728 - 111ms/epoch - 11ms/step\n",
      "Epoch 39/118\n",
      "10/10 - 0s - loss: 0.0534 - val_loss: 0.0723 - 116ms/epoch - 12ms/step\n",
      "Epoch 40/118\n",
      "10/10 - 0s - loss: 0.0530 - val_loss: 0.0717 - 93ms/epoch - 9ms/step\n",
      "Epoch 41/118\n",
      "10/10 - 0s - loss: 0.0525 - val_loss: 0.0712 - 103ms/epoch - 10ms/step\n",
      "Epoch 42/118\n",
      "10/10 - 0s - loss: 0.0520 - val_loss: 0.0706 - 90ms/epoch - 9ms/step\n",
      "Epoch 43/118\n",
      "10/10 - 0s - loss: 0.0515 - val_loss: 0.0701 - 105ms/epoch - 11ms/step\n",
      "Epoch 44/118\n",
      "10/10 - 0s - loss: 0.0510 - val_loss: 0.0695 - 86ms/epoch - 9ms/step\n",
      "Epoch 45/118\n",
      "10/10 - 0s - loss: 0.0505 - val_loss: 0.0690 - 91ms/epoch - 9ms/step\n",
      "Epoch 46/118\n",
      "10/10 - 0s - loss: 0.0501 - val_loss: 0.0684 - 103ms/epoch - 10ms/step\n",
      "Epoch 47/118\n",
      "10/10 - 0s - loss: 0.0495 - val_loss: 0.0678 - 110ms/epoch - 11ms/step\n",
      "Epoch 48/118\n",
      "10/10 - 0s - loss: 0.0490 - val_loss: 0.0673 - 93ms/epoch - 9ms/step\n",
      "Epoch 49/118\n",
      "10/10 - 0s - loss: 0.0486 - val_loss: 0.0667 - 106ms/epoch - 11ms/step\n",
      "Epoch 50/118\n",
      "10/10 - 0s - loss: 0.0481 - val_loss: 0.0662 - 87ms/epoch - 9ms/step\n",
      "Epoch 51/118\n",
      "10/10 - 0s - loss: 0.0477 - val_loss: 0.0656 - 89ms/epoch - 9ms/step\n",
      "Epoch 52/118\n",
      "10/10 - 0s - loss: 0.0471 - val_loss: 0.0650 - 108ms/epoch - 11ms/step\n",
      "Epoch 53/118\n",
      "10/10 - 0s - loss: 0.0466 - val_loss: 0.0644 - 88ms/epoch - 9ms/step\n",
      "Epoch 54/118\n",
      "10/10 - 0s - loss: 0.0461 - val_loss: 0.0639 - 139ms/epoch - 14ms/step\n",
      "Epoch 55/118\n",
      "10/10 - 0s - loss: 0.0456 - val_loss: 0.0633 - 95ms/epoch - 10ms/step\n",
      "Epoch 56/118\n",
      "10/10 - 0s - loss: 0.0451 - val_loss: 0.0627 - 87ms/epoch - 9ms/step\n",
      "Epoch 57/118\n",
      "10/10 - 0s - loss: 0.0446 - val_loss: 0.0621 - 104ms/epoch - 10ms/step\n",
      "Epoch 58/118\n",
      "10/10 - 0s - loss: 0.0442 - val_loss: 0.0616 - 87ms/epoch - 9ms/step\n",
      "Epoch 59/118\n",
      "10/10 - 0s - loss: 0.0436 - val_loss: 0.0610 - 88ms/epoch - 9ms/step\n",
      "Epoch 60/118\n",
      "10/10 - 0s - loss: 0.0430 - val_loss: 0.0604 - 104ms/epoch - 10ms/step\n",
      "Epoch 61/118\n",
      "10/10 - 0s - loss: 0.0425 - val_loss: 0.0598 - 88ms/epoch - 9ms/step\n",
      "Epoch 62/118\n",
      "10/10 - 0s - loss: 0.0421 - val_loss: 0.0592 - 151ms/epoch - 15ms/step\n",
      "Epoch 63/118\n",
      "10/10 - 0s - loss: 0.0415 - val_loss: 0.0587 - 91ms/epoch - 9ms/step\n",
      "Epoch 64/118\n",
      "10/10 - 0s - loss: 0.0409 - val_loss: 0.0581 - 87ms/epoch - 9ms/step\n",
      "Epoch 65/118\n",
      "10/10 - 0s - loss: 0.0406 - val_loss: 0.0575 - 104ms/epoch - 10ms/step\n",
      "Epoch 66/118\n",
      "10/10 - 0s - loss: 0.0400 - val_loss: 0.0569 - 89ms/epoch - 9ms/step\n",
      "Epoch 67/118\n",
      "10/10 - 0s - loss: 0.0395 - val_loss: 0.0563 - 101ms/epoch - 10ms/step\n",
      "Epoch 68/118\n",
      "10/10 - 0s - loss: 0.0390 - val_loss: 0.0557 - 88ms/epoch - 9ms/step\n",
      "Epoch 69/118\n",
      "10/10 - 0s - loss: 0.0386 - val_loss: 0.0551 - 99ms/epoch - 10ms/step\n",
      "Epoch 70/118\n",
      "10/10 - 0s - loss: 0.0380 - val_loss: 0.0546 - 114ms/epoch - 11ms/step\n",
      "Epoch 71/118\n",
      "10/10 - 0s - loss: 0.0374 - val_loss: 0.0540 - 108ms/epoch - 11ms/step\n",
      "Epoch 72/118\n",
      "10/10 - 0s - loss: 0.0370 - val_loss: 0.0534 - 94ms/epoch - 9ms/step\n",
      "Epoch 73/118\n",
      "10/10 - 0s - loss: 0.0365 - val_loss: 0.0528 - 88ms/epoch - 9ms/step\n",
      "Epoch 74/118\n",
      "10/10 - 0s - loss: 0.0360 - val_loss: 0.0522 - 98ms/epoch - 10ms/step\n",
      "Epoch 75/118\n",
      "10/10 - 0s - loss: 0.0354 - val_loss: 0.0516 - 87ms/epoch - 9ms/step\n",
      "Epoch 76/118\n",
      "10/10 - 0s - loss: 0.0350 - val_loss: 0.0510 - 87ms/epoch - 9ms/step\n",
      "Epoch 77/118\n",
      "10/10 - 0s - loss: 0.0344 - val_loss: 0.0504 - 132ms/epoch - 13ms/step\n",
      "Epoch 78/118\n",
      "10/10 - 0s - loss: 0.0339 - val_loss: 0.0499 - 93ms/epoch - 9ms/step\n",
      "Epoch 79/118\n",
      "10/10 - 0s - loss: 0.0334 - val_loss: 0.0493 - 86ms/epoch - 9ms/step\n",
      "Epoch 80/118\n",
      "10/10 - 0s - loss: 0.0330 - val_loss: 0.0487 - 105ms/epoch - 11ms/step\n",
      "Epoch 81/118\n",
      "10/10 - 0s - loss: 0.0324 - val_loss: 0.0481 - 91ms/epoch - 9ms/step\n",
      "Epoch 82/118\n",
      "10/10 - 0s - loss: 0.0319 - val_loss: 0.0475 - 87ms/epoch - 9ms/step\n",
      "Epoch 83/118\n",
      "10/10 - 0s - loss: 0.0315 - val_loss: 0.0469 - 104ms/epoch - 10ms/step\n",
      "Epoch 84/118\n",
      "10/10 - 0s - loss: 0.0309 - val_loss: 0.0464 - 111ms/epoch - 11ms/step\n",
      "Epoch 85/118\n",
      "10/10 - 0s - loss: 0.0304 - val_loss: 0.0458 - 115ms/epoch - 11ms/step\n",
      "Epoch 86/118\n",
      "10/10 - 0s - loss: 0.0300 - val_loss: 0.0452 - 123ms/epoch - 12ms/step\n",
      "Epoch 87/118\n",
      "10/10 - 0s - loss: 0.0293 - val_loss: 0.0446 - 104ms/epoch - 10ms/step\n",
      "Epoch 88/118\n",
      "10/10 - 0s - loss: 0.0289 - val_loss: 0.0441 - 108ms/epoch - 11ms/step\n",
      "Epoch 89/118\n",
      "10/10 - 0s - loss: 0.0284 - val_loss: 0.0435 - 96ms/epoch - 10ms/step\n",
      "Epoch 90/118\n",
      "10/10 - 0s - loss: 0.0280 - val_loss: 0.0429 - 107ms/epoch - 11ms/step\n",
      "Epoch 91/118\n",
      "10/10 - 0s - loss: 0.0274 - val_loss: 0.0423 - 96ms/epoch - 10ms/step\n",
      "Epoch 92/118\n",
      "10/10 - 0s - loss: 0.0270 - val_loss: 0.0418 - 105ms/epoch - 10ms/step\n",
      "Epoch 93/118\n",
      "10/10 - 0s - loss: 0.0264 - val_loss: 0.0412 - 121ms/epoch - 12ms/step\n",
      "Epoch 94/118\n",
      "10/10 - 0s - loss: 0.0260 - val_loss: 0.0406 - 108ms/epoch - 11ms/step\n",
      "Epoch 95/118\n",
      "10/10 - 0s - loss: 0.0255 - val_loss: 0.0401 - 90ms/epoch - 9ms/step\n",
      "Epoch 96/118\n",
      "10/10 - 0s - loss: 0.0251 - val_loss: 0.0395 - 112ms/epoch - 11ms/step\n",
      "Epoch 97/118\n",
      "10/10 - 0s - loss: 0.0246 - val_loss: 0.0390 - 92ms/epoch - 9ms/step\n",
      "Epoch 98/118\n",
      "10/10 - 0s - loss: 0.0241 - val_loss: 0.0384 - 87ms/epoch - 9ms/step\n",
      "Epoch 99/118\n",
      "10/10 - 0s - loss: 0.0236 - val_loss: 0.0379 - 108ms/epoch - 11ms/step\n",
      "Epoch 100/118\n",
      "10/10 - 0s - loss: 0.0232 - val_loss: 0.0373 - 124ms/epoch - 12ms/step\n",
      "Epoch 101/118\n",
      "10/10 - 0s - loss: 0.0227 - val_loss: 0.0368 - 99ms/epoch - 10ms/step\n",
      "Epoch 102/118\n",
      "10/10 - 0s - loss: 0.0222 - val_loss: 0.0363 - 127ms/epoch - 13ms/step\n",
      "Epoch 103/118\n",
      "10/10 - 0s - loss: 0.0218 - val_loss: 0.0357 - 101ms/epoch - 10ms/step\n",
      "Epoch 104/118\n",
      "10/10 - 0s - loss: 0.0214 - val_loss: 0.0352 - 101ms/epoch - 10ms/step\n",
      "Epoch 105/118\n",
      "10/10 - 0s - loss: 0.0210 - val_loss: 0.0347 - 122ms/epoch - 12ms/step\n",
      "Epoch 106/118\n",
      "10/10 - 0s - loss: 0.0205 - val_loss: 0.0341 - 102ms/epoch - 10ms/step\n",
      "Epoch 107/118\n",
      "10/10 - 0s - loss: 0.0201 - val_loss: 0.0336 - 128ms/epoch - 13ms/step\n",
      "Epoch 108/118\n",
      "10/10 - 0s - loss: 0.0196 - val_loss: 0.0331 - 144ms/epoch - 14ms/step\n",
      "Epoch 109/118\n",
      "10/10 - 0s - loss: 0.0192 - val_loss: 0.0326 - 103ms/epoch - 10ms/step\n",
      "Epoch 110/118\n",
      "10/10 - 0s - loss: 0.0187 - val_loss: 0.0321 - 120ms/epoch - 12ms/step\n",
      "Epoch 111/118\n",
      "10/10 - 0s - loss: 0.0182 - val_loss: 0.0316 - 103ms/epoch - 10ms/step\n",
      "Epoch 112/118\n",
      "10/10 - 0s - loss: 0.0180 - val_loss: 0.0311 - 96ms/epoch - 10ms/step\n",
      "Epoch 113/118\n",
      "10/10 - 0s - loss: 0.0174 - val_loss: 0.0306 - 140ms/epoch - 14ms/step\n",
      "Epoch 114/118\n",
      "10/10 - 0s - loss: 0.0172 - val_loss: 0.0301 - 103ms/epoch - 10ms/step\n",
      "Epoch 115/118\n",
      "10/10 - 0s - loss: 0.0167 - val_loss: 0.0296 - 120ms/epoch - 12ms/step\n",
      "Epoch 116/118\n",
      "10/10 - 0s - loss: 0.0163 - val_loss: 0.0292 - 115ms/epoch - 11ms/step\n",
      "Epoch 117/118\n",
      "10/10 - 0s - loss: 0.0160 - val_loss: 0.0287 - 90ms/epoch - 9ms/step\n",
      "Epoch 118/118\n",
      "10/10 - 0s - loss: 0.0154 - val_loss: 0.0282 - 89ms/epoch - 9ms/step\n",
      "9/9 [==============================] - 1s 2ms/step\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m-300.9   \u001b[0m | \u001b[0m118.1    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1e-05    \u001b[0m | \u001b[0m125.5    \u001b[0m |\n",
      "=========================================================================\n",
      "Best parameters: {'epoch': 141.5797811524138, 'layers': 3.9894581355077947, 'learning_rate': 0.0014795981043578003, 'units': 26.18702922140391}\n",
      "Training for 141 epochs...\n",
      "Model: \"sequential_173\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_627 (LSTM)             (None, 1, 26)             3328      \n",
      "                                                                 \n",
      " dropout_454 (Dropout)       (None, 1, 26)             0         \n",
      "                                                                 \n",
      " lstm_628 (LSTM)             (None, 1, 26)             5512      \n",
      "                                                                 \n",
      " dropout_455 (Dropout)       (None, 1, 26)             0         \n",
      "                                                                 \n",
      " lstm_629 (LSTM)             (None, 1, 26)             5512      \n",
      "                                                                 \n",
      " dropout_456 (Dropout)       (None, 1, 26)             0         \n",
      "                                                                 \n",
      " lstm_630 (LSTM)             (None, 26)                5512      \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 1)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,891\n",
      "Trainable params: 19,891\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/141\n",
      "10/10 - 8s - loss: 0.0604 - val_loss: 0.0674 - 8s/epoch - 808ms/step\n",
      "Epoch 2/141\n",
      "10/10 - 0s - loss: 0.0375 - val_loss: 0.0427 - 90ms/epoch - 9ms/step\n",
      "Epoch 3/141\n",
      "10/10 - 0s - loss: 0.0160 - val_loss: 0.0208 - 100ms/epoch - 10ms/step\n",
      "Epoch 4/141\n",
      "10/10 - 0s - loss: 0.0038 - val_loss: 0.0150 - 85ms/epoch - 9ms/step\n",
      "Epoch 5/141\n",
      "10/10 - 0s - loss: 0.0041 - val_loss: 0.0149 - 80ms/epoch - 8ms/step\n",
      "Epoch 6/141\n",
      "10/10 - 0s - loss: 0.0030 - val_loss: 0.0162 - 99ms/epoch - 10ms/step\n",
      "Epoch 7/141\n",
      "10/10 - 0s - loss: 0.0031 - val_loss: 0.0155 - 86ms/epoch - 9ms/step\n",
      "Epoch 8/141\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0150 - 91ms/epoch - 9ms/step\n",
      "Epoch 9/141\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0148 - 82ms/epoch - 8ms/step\n",
      "Epoch 10/141\n",
      "10/10 - 0s - loss: 0.0028 - val_loss: 0.0149 - 119ms/epoch - 12ms/step\n",
      "Epoch 11/141\n",
      "10/10 - 0s - loss: 0.0027 - val_loss: 0.0146 - 90ms/epoch - 9ms/step\n",
      "Epoch 12/141\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0143 - 95ms/epoch - 10ms/step\n",
      "Epoch 13/141\n",
      "10/10 - 0s - loss: 0.0026 - val_loss: 0.0140 - 85ms/epoch - 9ms/step\n",
      "Epoch 14/141\n",
      "10/10 - 0s - loss: 0.0025 - val_loss: 0.0136 - 111ms/epoch - 11ms/step\n",
      "Epoch 15/141\n",
      "10/10 - 0s - loss: 0.0024 - val_loss: 0.0130 - 81ms/epoch - 8ms/step\n",
      "Epoch 16/141\n",
      "10/10 - 0s - loss: 0.0023 - val_loss: 0.0126 - 108ms/epoch - 11ms/step\n",
      "Epoch 17/141\n",
      "10/10 - 0s - loss: 0.0022 - val_loss: 0.0123 - 88ms/epoch - 9ms/step\n",
      "Epoch 18/141\n",
      "10/10 - 0s - loss: 0.0020 - val_loss: 0.0113 - 98ms/epoch - 10ms/step\n",
      "Epoch 19/141\n",
      "10/10 - 0s - loss: 0.0018 - val_loss: 0.0106 - 110ms/epoch - 11ms/step\n",
      "Epoch 20/141\n",
      "10/10 - 0s - loss: 0.0016 - val_loss: 0.0100 - 95ms/epoch - 9ms/step\n",
      "Epoch 21/141\n",
      "10/10 - 0s - loss: 0.0017 - val_loss: 0.0095 - 81ms/epoch - 8ms/step\n",
      "Epoch 22/141\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0091 - 93ms/epoch - 9ms/step\n",
      "Epoch 23/141\n",
      "10/10 - 0s - loss: 0.0013 - val_loss: 0.0091 - 81ms/epoch - 8ms/step\n",
      "Epoch 24/141\n",
      "10/10 - 0s - loss: 0.0011 - val_loss: 0.0093 - 117ms/epoch - 12ms/step\n",
      "Epoch 25/141\n",
      "10/10 - 0s - loss: 0.0010 - val_loss: 0.0098 - 80ms/epoch - 8ms/step\n",
      "Epoch 26/141\n",
      "10/10 - 0s - loss: 9.3653e-04 - val_loss: 0.0098 - 96ms/epoch - 10ms/step\n",
      "Epoch 27/141\n",
      "10/10 - 0s - loss: 8.5493e-04 - val_loss: 0.0101 - 79ms/epoch - 8ms/step\n",
      "Epoch 28/141\n",
      "10/10 - 0s - loss: 7.3840e-04 - val_loss: 0.0102 - 115ms/epoch - 12ms/step\n",
      "Epoch 29/141\n",
      "10/10 - 0s - loss: 7.4900e-04 - val_loss: 0.0101 - 104ms/epoch - 10ms/step\n",
      "Epoch 30/141\n",
      "10/10 - 0s - loss: 7.1289e-04 - val_loss: 0.0105 - 85ms/epoch - 8ms/step\n",
      "Epoch 31/141\n",
      "10/10 - 0s - loss: 6.8664e-04 - val_loss: 0.0104 - 96ms/epoch - 10ms/step\n",
      "Epoch 32/141\n",
      "10/10 - 0s - loss: 7.7026e-04 - val_loss: 0.0108 - 95ms/epoch - 10ms/step\n",
      "Epoch 33/141\n",
      "10/10 - 0s - loss: 7.4361e-04 - val_loss: 0.0103 - 80ms/epoch - 8ms/step\n",
      "Epoch 34/141\n",
      "10/10 - 0s - loss: 6.4286e-04 - val_loss: 0.0103 - 81ms/epoch - 8ms/step\n",
      "Epoch 35/141\n",
      "10/10 - 0s - loss: 5.8402e-04 - val_loss: 0.0105 - 98ms/epoch - 10ms/step\n",
      "Epoch 36/141\n",
      "10/10 - 0s - loss: 6.1261e-04 - val_loss: 0.0104 - 80ms/epoch - 8ms/step\n",
      "Epoch 37/141\n",
      "10/10 - 0s - loss: 6.0249e-04 - val_loss: 0.0107 - 109ms/epoch - 11ms/step\n",
      "Epoch 38/141\n",
      "10/10 - 0s - loss: 5.6529e-04 - val_loss: 0.0105 - 111ms/epoch - 11ms/step\n",
      "Epoch 39/141\n",
      "10/10 - 0s - loss: 4.9917e-04 - val_loss: 0.0111 - 80ms/epoch - 8ms/step\n",
      "Epoch 40/141\n",
      "10/10 - 0s - loss: 5.5553e-04 - val_loss: 0.0103 - 94ms/epoch - 9ms/step\n",
      "Epoch 41/141\n",
      "10/10 - 0s - loss: 5.4922e-04 - val_loss: 0.0106 - 81ms/epoch - 8ms/step\n",
      "Epoch 42/141\n",
      "10/10 - 0s - loss: 5.7682e-04 - val_loss: 0.0108 - 84ms/epoch - 8ms/step\n",
      "Epoch 43/141\n",
      "10/10 - 0s - loss: 5.1593e-04 - val_loss: 0.0105 - 102ms/epoch - 10ms/step\n",
      "Epoch 44/141\n",
      "10/10 - 0s - loss: 5.0445e-04 - val_loss: 0.0107 - 83ms/epoch - 8ms/step\n",
      "Epoch 45/141\n",
      "10/10 - 0s - loss: 4.7469e-04 - val_loss: 0.0107 - 77ms/epoch - 8ms/step\n",
      "Epoch 46/141\n",
      "10/10 - 0s - loss: 4.6191e-04 - val_loss: 0.0104 - 151ms/epoch - 15ms/step\n",
      "Epoch 47/141\n",
      "10/10 - 0s - loss: 5.0949e-04 - val_loss: 0.0103 - 88ms/epoch - 9ms/step\n",
      "Epoch 48/141\n",
      "10/10 - 0s - loss: 4.5300e-04 - val_loss: 0.0104 - 79ms/epoch - 8ms/step\n",
      "Epoch 49/141\n",
      "10/10 - 0s - loss: 4.4126e-04 - val_loss: 0.0103 - 92ms/epoch - 9ms/step\n",
      "Epoch 50/141\n",
      "10/10 - 0s - loss: 4.3936e-04 - val_loss: 0.0103 - 80ms/epoch - 8ms/step\n",
      "Epoch 51/141\n",
      "10/10 - 0s - loss: 4.4847e-04 - val_loss: 0.0102 - 98ms/epoch - 10ms/step\n",
      "Epoch 52/141\n",
      "10/10 - 0s - loss: 4.1162e-04 - val_loss: 0.0103 - 80ms/epoch - 8ms/step\n",
      "Epoch 53/141\n",
      "10/10 - 0s - loss: 4.1807e-04 - val_loss: 0.0104 - 94ms/epoch - 9ms/step\n",
      "Epoch 54/141\n",
      "10/10 - 0s - loss: 4.2106e-04 - val_loss: 0.0104 - 112ms/epoch - 11ms/step\n",
      "Epoch 55/141\n",
      "10/10 - 0s - loss: 4.0672e-04 - val_loss: 0.0104 - 82ms/epoch - 8ms/step\n",
      "Epoch 56/141\n",
      "10/10 - 0s - loss: 3.9819e-04 - val_loss: 0.0103 - 96ms/epoch - 10ms/step\n",
      "Epoch 57/141\n",
      "10/10 - 0s - loss: 3.7408e-04 - val_loss: 0.0103 - 82ms/epoch - 8ms/step\n",
      "Epoch 58/141\n",
      "10/10 - 0s - loss: 4.1071e-04 - val_loss: 0.0102 - 97ms/epoch - 10ms/step\n",
      "Epoch 59/141\n",
      "10/10 - 0s - loss: 4.2396e-04 - val_loss: 0.0100 - 100ms/epoch - 10ms/step\n",
      "Epoch 60/141\n",
      "10/10 - 0s - loss: 4.4592e-04 - val_loss: 0.0098 - 83ms/epoch - 8ms/step\n",
      "Epoch 61/141\n",
      "10/10 - 0s - loss: 4.1321e-04 - val_loss: 0.0100 - 78ms/epoch - 8ms/step\n",
      "Epoch 62/141\n",
      "10/10 - 0s - loss: 4.0513e-04 - val_loss: 0.0102 - 97ms/epoch - 10ms/step\n",
      "Epoch 63/141\n",
      "10/10 - 0s - loss: 3.8937e-04 - val_loss: 0.0099 - 112ms/epoch - 11ms/step\n",
      "Epoch 64/141\n",
      "10/10 - 0s - loss: 3.8489e-04 - val_loss: 0.0097 - 80ms/epoch - 8ms/step\n",
      "Epoch 65/141\n",
      "10/10 - 0s - loss: 3.7432e-04 - val_loss: 0.0100 - 96ms/epoch - 10ms/step\n",
      "Epoch 66/141\n",
      "10/10 - 0s - loss: 3.7685e-04 - val_loss: 0.0098 - 81ms/epoch - 8ms/step\n",
      "Epoch 67/141\n",
      "10/10 - 0s - loss: 3.9032e-04 - val_loss: 0.0098 - 80ms/epoch - 8ms/step\n",
      "Epoch 68/141\n",
      "10/10 - 0s - loss: 3.8902e-04 - val_loss: 0.0098 - 94ms/epoch - 9ms/step\n",
      "Epoch 69/141\n",
      "10/10 - 0s - loss: 3.9540e-04 - val_loss: 0.0097 - 78ms/epoch - 8ms/step\n",
      "Epoch 70/141\n",
      "10/10 - 0s - loss: 3.5792e-04 - val_loss: 0.0097 - 137ms/epoch - 14ms/step\n",
      "Epoch 71/141\n",
      "10/10 - 0s - loss: 3.6855e-04 - val_loss: 0.0098 - 78ms/epoch - 8ms/step\n",
      "Epoch 72/141\n",
      "10/10 - 0s - loss: 3.7312e-04 - val_loss: 0.0097 - 79ms/epoch - 8ms/step\n",
      "Epoch 73/141\n",
      "10/10 - 0s - loss: 3.6205e-04 - val_loss: 0.0095 - 89ms/epoch - 9ms/step\n",
      "Epoch 74/141\n",
      "10/10 - 0s - loss: 3.8145e-04 - val_loss: 0.0095 - 78ms/epoch - 8ms/step\n",
      "Epoch 75/141\n",
      "10/10 - 0s - loss: 4.0119e-04 - val_loss: 0.0095 - 117ms/epoch - 12ms/step\n",
      "Epoch 76/141\n",
      "10/10 - 0s - loss: 3.4565e-04 - val_loss: 0.0094 - 80ms/epoch - 8ms/step\n",
      "Epoch 77/141\n",
      "10/10 - 0s - loss: 3.8144e-04 - val_loss: 0.0095 - 111ms/epoch - 11ms/step\n",
      "Epoch 78/141\n",
      "10/10 - 0s - loss: 3.7913e-04 - val_loss: 0.0093 - 109ms/epoch - 11ms/step\n",
      "Epoch 79/141\n",
      "10/10 - 0s - loss: 3.6370e-04 - val_loss: 0.0094 - 83ms/epoch - 8ms/step\n",
      "Epoch 80/141\n",
      "10/10 - 0s - loss: 3.9032e-04 - val_loss: 0.0093 - 94ms/epoch - 9ms/step\n",
      "Epoch 81/141\n",
      "10/10 - 0s - loss: 3.6520e-04 - val_loss: 0.0093 - 83ms/epoch - 8ms/step\n",
      "Epoch 82/141\n",
      "10/10 - 0s - loss: 3.6148e-04 - val_loss: 0.0093 - 97ms/epoch - 10ms/step\n",
      "Epoch 83/141\n",
      "10/10 - 0s - loss: 3.5692e-04 - val_loss: 0.0094 - 92ms/epoch - 9ms/step\n",
      "Epoch 84/141\n",
      "10/10 - 0s - loss: 3.7537e-04 - val_loss: 0.0092 - 134ms/epoch - 13ms/step\n",
      "Epoch 85/141\n",
      "10/10 - 0s - loss: 3.6528e-04 - val_loss: 0.0092 - 87ms/epoch - 9ms/step\n",
      "Epoch 86/141\n",
      "10/10 - 0s - loss: 3.3449e-04 - val_loss: 0.0092 - 84ms/epoch - 8ms/step\n",
      "Epoch 87/141\n",
      "10/10 - 0s - loss: 4.0855e-04 - val_loss: 0.0091 - 93ms/epoch - 9ms/step\n",
      "Epoch 88/141\n",
      "10/10 - 0s - loss: 3.5192e-04 - val_loss: 0.0091 - 82ms/epoch - 8ms/step\n",
      "Epoch 89/141\n",
      "10/10 - 0s - loss: 3.3937e-04 - val_loss: 0.0092 - 90ms/epoch - 9ms/step\n",
      "Epoch 90/141\n",
      "10/10 - 0s - loss: 3.7035e-04 - val_loss: 0.0091 - 81ms/epoch - 8ms/step\n",
      "Epoch 91/141\n",
      "10/10 - 0s - loss: 3.3384e-04 - val_loss: 0.0090 - 151ms/epoch - 15ms/step\n",
      "Epoch 92/141\n",
      "10/10 - 0s - loss: 3.4464e-04 - val_loss: 0.0091 - 90ms/epoch - 9ms/step\n",
      "Epoch 93/141\n",
      "10/10 - 0s - loss: 3.3992e-04 - val_loss: 0.0091 - 76ms/epoch - 8ms/step\n",
      "Epoch 94/141\n",
      "10/10 - 0s - loss: 3.4584e-04 - val_loss: 0.0090 - 94ms/epoch - 9ms/step\n",
      "Epoch 95/141\n",
      "10/10 - 0s - loss: 3.5002e-04 - val_loss: 0.0089 - 81ms/epoch - 8ms/step\n",
      "Epoch 96/141\n",
      "10/10 - 0s - loss: 3.4876e-04 - val_loss: 0.0090 - 78ms/epoch - 8ms/step\n",
      "Epoch 97/141\n",
      "10/10 - 0s - loss: 3.7170e-04 - val_loss: 0.0089 - 99ms/epoch - 10ms/step\n",
      "Epoch 98/141\n",
      "10/10 - 0s - loss: 3.5746e-04 - val_loss: 0.0089 - 78ms/epoch - 8ms/step\n",
      "Epoch 99/141\n",
      "10/10 - 0s - loss: 3.4572e-04 - val_loss: 0.0089 - 90ms/epoch - 9ms/step\n",
      "Epoch 100/141\n",
      "10/10 - 0s - loss: 3.2657e-04 - val_loss: 0.0090 - 112ms/epoch - 11ms/step\n",
      "Epoch 101/141\n",
      "10/10 - 0s - loss: 3.6360e-04 - val_loss: 0.0089 - 99ms/epoch - 10ms/step\n",
      "Epoch 102/141\n",
      "10/10 - 0s - loss: 3.6235e-04 - val_loss: 0.0088 - 82ms/epoch - 8ms/step\n",
      "Epoch 103/141\n",
      "10/10 - 0s - loss: 3.3626e-04 - val_loss: 0.0088 - 81ms/epoch - 8ms/step\n",
      "Epoch 104/141\n",
      "10/10 - 0s - loss: 3.3425e-04 - val_loss: 0.0087 - 92ms/epoch - 9ms/step\n",
      "Epoch 105/141\n",
      "10/10 - 0s - loss: 3.1482e-04 - val_loss: 0.0088 - 78ms/epoch - 8ms/step\n",
      "Epoch 106/141\n",
      "10/10 - 0s - loss: 3.3578e-04 - val_loss: 0.0087 - 82ms/epoch - 8ms/step\n",
      "Epoch 107/141\n",
      "10/10 - 0s - loss: 3.5628e-04 - val_loss: 0.0086 - 108ms/epoch - 11ms/step\n",
      "Epoch 108/141\n",
      "10/10 - 0s - loss: 3.4257e-04 - val_loss: 0.0087 - 109ms/epoch - 11ms/step\n",
      "Epoch 109/141\n",
      "10/10 - 0s - loss: 3.2488e-04 - val_loss: 0.0086 - 85ms/epoch - 8ms/step\n",
      "Epoch 110/141\n",
      "10/10 - 0s - loss: 3.4806e-04 - val_loss: 0.0086 - 93ms/epoch - 9ms/step\n",
      "Epoch 111/141\n",
      "10/10 - 0s - loss: 3.4623e-04 - val_loss: 0.0086 - 77ms/epoch - 8ms/step\n",
      "Epoch 112/141\n",
      "10/10 - 0s - loss: 3.1377e-04 - val_loss: 0.0086 - 77ms/epoch - 8ms/step\n",
      "Epoch 113/141\n",
      "10/10 - 0s - loss: 3.4306e-04 - val_loss: 0.0086 - 104ms/epoch - 10ms/step\n",
      "Epoch 114/141\n",
      "10/10 - 0s - loss: 3.2770e-04 - val_loss: 0.0086 - 89ms/epoch - 9ms/step\n",
      "Epoch 115/141\n",
      "10/10 - 0s - loss: 3.2225e-04 - val_loss: 0.0085 - 79ms/epoch - 8ms/step\n",
      "Epoch 116/141\n",
      "10/10 - 0s - loss: 3.2603e-04 - val_loss: 0.0085 - 111ms/epoch - 11ms/step\n",
      "Epoch 117/141\n",
      "10/10 - 0s - loss: 3.4271e-04 - val_loss: 0.0086 - 90ms/epoch - 9ms/step\n",
      "Epoch 118/141\n",
      "10/10 - 0s - loss: 2.9609e-04 - val_loss: 0.0085 - 80ms/epoch - 8ms/step\n",
      "Epoch 119/141\n",
      "10/10 - 0s - loss: 3.3970e-04 - val_loss: 0.0084 - 91ms/epoch - 9ms/step\n",
      "Epoch 120/141\n",
      "10/10 - 0s - loss: 3.0052e-04 - val_loss: 0.0084 - 80ms/epoch - 8ms/step\n",
      "Epoch 121/141\n",
      "10/10 - 0s - loss: 3.1910e-04 - val_loss: 0.0084 - 79ms/epoch - 8ms/step\n",
      "Epoch 122/141\n",
      "10/10 - 0s - loss: 3.3016e-04 - val_loss: 0.0085 - 96ms/epoch - 10ms/step\n",
      "Epoch 123/141\n",
      "10/10 - 0s - loss: 3.2655e-04 - val_loss: 0.0084 - 77ms/epoch - 8ms/step\n",
      "Epoch 124/141\n",
      "10/10 - 0s - loss: 3.2980e-04 - val_loss: 0.0084 - 129ms/epoch - 13ms/step\n",
      "Epoch 125/141\n",
      "10/10 - 0s - loss: 3.0245e-04 - val_loss: 0.0084 - 78ms/epoch - 8ms/step\n",
      "Epoch 126/141\n",
      "10/10 - 0s - loss: 3.2457e-04 - val_loss: 0.0084 - 94ms/epoch - 9ms/step\n",
      "Epoch 127/141\n",
      "10/10 - 0s - loss: 3.2449e-04 - val_loss: 0.0084 - 81ms/epoch - 8ms/step\n",
      "Epoch 128/141\n",
      "10/10 - 0s - loss: 3.4901e-04 - val_loss: 0.0083 - 93ms/epoch - 9ms/step\n",
      "Epoch 129/141\n",
      "10/10 - 0s - loss: 3.1115e-04 - val_loss: 0.0083 - 77ms/epoch - 8ms/step\n",
      "Epoch 130/141\n",
      "10/10 - 0s - loss: 3.3006e-04 - val_loss: 0.0084 - 91ms/epoch - 9ms/step\n",
      "Epoch 131/141\n",
      "10/10 - 0s - loss: 3.1661e-04 - val_loss: 0.0083 - 102ms/epoch - 10ms/step\n",
      "Epoch 132/141\n",
      "10/10 - 0s - loss: 3.3093e-04 - val_loss: 0.0083 - 99ms/epoch - 10ms/step\n",
      "Epoch 133/141\n",
      "10/10 - 0s - loss: 3.2235e-04 - val_loss: 0.0083 - 77ms/epoch - 8ms/step\n",
      "Epoch 134/141\n",
      "10/10 - 0s - loss: 3.1709e-04 - val_loss: 0.0083 - 77ms/epoch - 8ms/step\n",
      "Epoch 135/141\n",
      "10/10 - 0s - loss: 3.1993e-04 - val_loss: 0.0083 - 88ms/epoch - 9ms/step\n",
      "Epoch 136/141\n",
      "10/10 - 0s - loss: 3.2440e-04 - val_loss: 0.0083 - 80ms/epoch - 8ms/step\n",
      "Epoch 137/141\n",
      "10/10 - 0s - loss: 3.1262e-04 - val_loss: 0.0083 - 93ms/epoch - 9ms/step\n",
      "Epoch 138/141\n",
      "10/10 - 0s - loss: 3.3686e-04 - val_loss: 0.0083 - 121ms/epoch - 12ms/step\n",
      "Epoch 139/141\n",
      "10/10 - 0s - loss: 3.1443e-04 - val_loss: 0.0082 - 117ms/epoch - 12ms/step\n",
      "Epoch 140/141\n",
      "10/10 - 0s - loss: 2.7461e-04 - val_loss: 0.0082 - 81ms/epoch - 8ms/step\n",
      "Epoch 141/141\n",
      "10/10 - 0s - loss: 3.0847e-04 - val_loss: 0.0082 - 98ms/epoch - 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24542b702b0>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24542b709d0>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Model loss progress during training and validation')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Training and Validation Loss')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2453e7a13d0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Train Score: 23.70 RMSE for 141 epochs\n",
      "Test Score: 162.34 RMSE for 141 epochs\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Normalize dataset for LSTM\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(agg_df['Rate'].values.reshape(-1,1))\n",
    "\n",
    "# Split into train and test sets\n",
    "train_size = int(len(dataset) * 0.7)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "# Reshape into X=t and Y=t+1, timestep  look_back\n",
    "look_back = 5\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "# Reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "# Define the bounds of the parameters to optimize\n",
    "param_bounds = {'layers': (1, 5),  # layers\n",
    "                'units': (8, 128),  # units\n",
    "                'learning_rate': (1e-5, 1e-2),  # learning_rate\n",
    "                'epoch': (50, 200)}  # epoch\n",
    "\n",
    "# Initialize BayesianOptimization object\n",
    "optimizer = BayesianOptimization(f=objective, pbounds=param_bounds, random_state=0)\n",
    "\n",
    "# Run optimization\n",
    "optimizer.maximize(init_points=10, n_iter=40)  # 10 initial points, 40 iterations after\n",
    "\n",
    "print(\"Best parameters: {}\".format(optimizer.max['params']))\n",
    "\n",
    "# Training and evaluation with best parameters\n",
    "best_params = optimizer.max['params']\n",
    "\n",
    "# Get the best number of epochs\n",
    "best_epochs = int(best_params['epoch'])\n",
    "\n",
    "print(f'Training for {best_epochs} epochs...')\n",
    "model, history = create_LSTM_model(best_params, trainX, trainY, testX, testY, best_epochs)\n",
    "\n",
    "# Add the loss for this model to the plot\n",
    "plt.plot(history.history['loss'], label=f'Train Loss - {best_epochs} epochs')\n",
    "plt.plot(history.history['val_loss'], label=f'Validation Loss - {best_epochs} epochs')\n",
    "\n",
    "# Configure and show the plot\n",
    "plt.title('Model loss progress during training and validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show();\n",
    "\n",
    "# Evaluate LSTM Model\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "# Invert predictions back to prescaled values\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY_orig = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY_orig = scaler.inverse_transform([testY])\n",
    "\n",
    "# Calculate mean squared error\n",
    "trainScore = calculate_RMSE(trainY_orig[0], trainPredict[:,0])\n",
    "print(f'Train Score: {trainScore:.2f} RMSE for {best_epochs} epochs')\n",
    "testScore = calculate_RMSE(testY_orig[0], testPredict[:,0])\n",
    "print(f'Test Score: {testScore:.2f} RMSE for {best_epochs} epochs')\n",
    "\n",
    "# Convert the dictionary to a DataFrame for easy display\n",
    "rmse_df = pd.DataFrame(rmse_results).T\n",
    "print(rmse_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Forecast the results</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_next_weeks(model, look_back, scaler, last_values, n_weeks):\n",
    "    forecast = []\n",
    "    input_values = np.array(last_values)\n",
    "    for _ in range(n_weeks):\n",
    "        # Scale the input_values to be between 0 and 1\n",
    "        input_values_scaled = scaler.transform(input_values[-look_back:].reshape(-1, 1))\n",
    "        \n",
    "        # Reshape to [samples, time steps, features]\n",
    "        input_values_scaled = input_values_scaled.reshape((1, 1, look_back))\n",
    "\n",
    "        # Predict the next value\n",
    "        prediction = model.predict(input_values_scaled)\n",
    "        \n",
    "        # Inverse scale the predicted value\n",
    "        prediction = scaler.inverse_transform(prediction)\n",
    "        \n",
    "        # Append the predicted value to the forecast list\n",
    "        forecast.append(prediction[0, 0])\n",
    "        \n",
    "        # Append the predicted value to the input_values list to be used as input for the next prediction\n",
    "        input_values = np.append(input_values, prediction)\n",
    "\n",
    "    return forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POD</th>\n",
       "      <th>RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-12</td>\n",
       "      <td>299.040009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-19</td>\n",
       "      <td>296.329987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-26</td>\n",
       "      <td>292.609985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>289.170013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>285.529999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         POD        RATE\n",
       "0 2023-03-12  299.040009\n",
       "1 2023-03-19  296.329987\n",
       "2 2023-03-26  292.609985\n",
       "3 2023-04-02  289.170013\n",
       "4 2023-04-09  285.529999"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POD</th>\n",
       "      <th>RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>276.010010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>272.850006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-05-14</td>\n",
       "      <td>269.739990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-05-21</td>\n",
       "      <td>266.700012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-05-28</td>\n",
       "      <td>263.709991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          POD        RATE\n",
       "7  2023-04-30  276.010010\n",
       "8  2023-05-07  272.850006\n",
       "9  2023-05-14  269.739990\n",
       "10 2023-05-21  266.700012\n",
       "11 2023-05-28  263.709991"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12 entries, 0 to 11\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   POD     12 non-null     datetime64[ns]\n",
      " 1   RATE    12 non-null     float32       \n",
      "dtypes: datetime64[ns](1), float32(1)\n",
      "memory usage: 272.0 bytes\n"
     ]
    }
   ],
   "source": [
    "# How many weeks you want to forecast\n",
    "weeks = 12  # approximately equal to 240 days\n",
    "\n",
    "# Get the last \"look_back\" values\n",
    "last_values = list(df_interpolated['RATE'].values[-look_back:])\n",
    "\n",
    "# Forecast the next weeks\n",
    "forecasted_values = forecast_next_weeks(model, look_back, scaler, last_values, weeks)\n",
    "\n",
    "# Get the last date from 'POD'\n",
    "last_date = df_interpolated['POD'].iloc[-1]\n",
    "\n",
    "# Create new dates\n",
    "new_dates = pd.date_range(last_date + pd.DateOffset(weeks=1), periods=weeks, freq='W')\n",
    "\n",
    "# Create a new DataFrame for the forecasted values\n",
    "df_forecasted = pd.DataFrame(data={'POD': new_dates, 'RATE': forecasted_values})\n",
    "\n",
    "# Rounding of the rate nearest 2 decimal point\n",
    "df_forecasted[\"RATE\"] = df_forecasted[\"RATE\"].round(2)\n",
    "\n",
    "df_forecasted.head(5)\n",
    "df_forecasted.tail(5)\n",
    "df_forecasted.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Comparing with actual updated against forecasted</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n",
      "C:\\Users\\Aloysius Wong\\AppData\\Local\\Temp\\ipykernel_36656\\2601120271.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  comparison_df = comparison_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeekStart</th>\n",
       "      <th>WeekEnd</th>\n",
       "      <th>POD_actual</th>\n",
       "      <th>RATE_forecasted</th>\n",
       "      <th>RATE_actual</th>\n",
       "      <th>error</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-12</td>\n",
       "      <td>2023-03-19</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>299.040009</td>\n",
       "      <td>260.0</td>\n",
       "      <td>39.040009</td>\n",
       "      <td>84.984612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-19</td>\n",
       "      <td>2023-03-26</td>\n",
       "      <td>2023-03-19</td>\n",
       "      <td>296.329987</td>\n",
       "      <td>300.0</td>\n",
       "      <td>3.670013</td>\n",
       "      <td>98.776662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-26</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>2023-03-26</td>\n",
       "      <td>292.609985</td>\n",
       "      <td>260.0</td>\n",
       "      <td>32.609985</td>\n",
       "      <td>87.457698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-26</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>292.609985</td>\n",
       "      <td>260.0</td>\n",
       "      <td>32.609985</td>\n",
       "      <td>87.457698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>289.170013</td>\n",
       "      <td>260.0</td>\n",
       "      <td>29.170013</td>\n",
       "      <td>88.780764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>2023-04-16</td>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>285.529999</td>\n",
       "      <td>300.0</td>\n",
       "      <td>14.470001</td>\n",
       "      <td>95.176666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>2023-04-16</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>285.529999</td>\n",
       "      <td>260.0</td>\n",
       "      <td>25.529999</td>\n",
       "      <td>90.180770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-04-16</td>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>2023-04-20</td>\n",
       "      <td>282.429993</td>\n",
       "      <td>260.0</td>\n",
       "      <td>22.429993</td>\n",
       "      <td>91.373080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>279.260010</td>\n",
       "      <td>300.0</td>\n",
       "      <td>20.739990</td>\n",
       "      <td>93.086670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>276.010010</td>\n",
       "      <td>260.0</td>\n",
       "      <td>16.010010</td>\n",
       "      <td>93.842304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>2023-05-14</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>272.850006</td>\n",
       "      <td>300.0</td>\n",
       "      <td>27.149994</td>\n",
       "      <td>90.950002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-05-14</td>\n",
       "      <td>2023-05-21</td>\n",
       "      <td>2023-05-17</td>\n",
       "      <td>269.739990</td>\n",
       "      <td>260.0</td>\n",
       "      <td>9.739990</td>\n",
       "      <td>96.253850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    WeekStart    WeekEnd POD_actual  RATE_forecasted  RATE_actual      error  \\\n",
       "0  2023-03-12 2023-03-19 2023-03-15       299.040009        260.0  39.040009   \n",
       "1  2023-03-19 2023-03-26 2023-03-19       296.329987        300.0   3.670013   \n",
       "2  2023-03-26 2023-04-02 2023-03-26       292.609985        260.0  32.609985   \n",
       "3  2023-03-26 2023-04-02 2023-04-01       292.609985        260.0  32.609985   \n",
       "4  2023-04-02 2023-04-09 2023-04-08       289.170013        260.0  29.170013   \n",
       "5  2023-04-09 2023-04-16 2023-04-12       285.529999        300.0  14.470001   \n",
       "6  2023-04-09 2023-04-16 2023-04-15       285.529999        260.0  25.529999   \n",
       "7  2023-04-16 2023-04-23 2023-04-20       282.429993        260.0  22.429993   \n",
       "8  2023-04-23 2023-04-30 2023-04-26       279.260010        300.0  20.739990   \n",
       "9  2023-04-30 2023-05-07 2023-05-03       276.010010        260.0  16.010010   \n",
       "10 2023-05-07 2023-05-14 2023-05-10       272.850006        300.0  27.149994   \n",
       "11 2023-05-14 2023-05-21 2023-05-17       269.739990        260.0   9.739990   \n",
       "\n",
       "     accuracy  \n",
       "0   84.984612  \n",
       "1   98.776662  \n",
       "2   87.457698  \n",
       "3   87.457698  \n",
       "4   88.780764  \n",
       "5   95.176666  \n",
       "6   90.180770  \n",
       "7   91.373080  \n",
       "8   93.086670  \n",
       "9   93.842304  \n",
       "10  90.950002  \n",
       "11  96.253850  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12 entries, 0 to 11\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   WeekStart        12 non-null     datetime64[ns]\n",
      " 1   WeekEnd          12 non-null     datetime64[ns]\n",
      " 2   POD_actual       12 non-null     datetime64[ns]\n",
      " 3   RATE_forecasted  12 non-null     float64       \n",
      " 4   RATE_actual      12 non-null     float64       \n",
      " 5   error            12 non-null     float64       \n",
      " 6   accuracy         12 non-null     float64       \n",
      "dtypes: datetime64[ns](3), float64(4)\n",
      "memory usage: 800.0 bytes\n",
      "The mean accuracy is 91.53%\n"
     ]
    }
   ],
   "source": [
    "# Create an empty DataFrame to store comparison data\n",
    "comparison_df = pd.DataFrame(columns=['WeekStart', 'WeekEnd', 'POD_actual', 'RATE_forecasted', 'RATE_actual', 'error', 'accuracy'])\n",
    "df_forecasted['WeekEnd'] = df_forecasted['POD'] + pd.to_timedelta(7, unit='d')  \n",
    "\n",
    "# Loop over df_forecasted\n",
    "for _, row in df_forecasted.iterrows():\n",
    "    # Find the actual dates within the week of the forecasted date\n",
    "    # Add a 'WeekEnd' column to df_forecasted\n",
    "    mask = (new_dates_df['POD'] >= row['POD']) & (new_dates_df['POD'] < row['WeekEnd'])\n",
    "    actual_dates_within_week = new_dates_df[mask]\n",
    "\n",
    "    # Calculate the error and accuracy for each actual date within the week\n",
    "    for _, actual_row in actual_dates_within_week.iterrows():\n",
    "        error = abs(actual_row['RATE'] - row['RATE'])\n",
    "        error_proportion = error / actual_row['RATE']\n",
    "        accuracy = (1 - error_proportion) * 100\n",
    "\n",
    "        # Append the data to comparison_df\n",
    "        comparison_df = comparison_df.append({\n",
    "            'WeekStart': row['POD'],\n",
    "            'WeekEnd': row['WeekEnd'],\n",
    "            'POD_actual': actual_row['POD'],\n",
    "            'RATE_forecasted': row['RATE'],\n",
    "            'RATE_actual': actual_row['RATE'],\n",
    "            'error': error,\n",
    "            'accuracy': accuracy\n",
    "        }, ignore_index=True)\n",
    "\n",
    "# Remove duplicates based on 'POD_actual', 'RATE_forecasted', and 'RATE_actual'\n",
    "comparison_df = comparison_df.drop_duplicates(subset=['POD_actual', 'RATE_forecasted', 'RATE_actual']).reset_index(drop=True)\n",
    "\n",
    "# Display the comparison dataframe\n",
    "comparison_df\n",
    "comparison_df.info()\n",
    "\n",
    "total_mean_accuracy = comparison_df['accuracy'].mean()\n",
    "print(f'The mean accuracy is {total_mean_accuracy:.2f}%')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Visualise all, Conclusion</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(sel_df['POD'], sel_df['RATE'], color='blue', label=\"Actual Data\")\n",
    "plt.plot(new_dates_df['POD'], new_dates_df['RATE'], color='blue', label=\"Actual Data (Updated)\")\n",
    "\n",
    "plt.plot(df_interpolated['POD'], df_interpolated['RATE'], color='green', label=\"Aggregated Data\")\n",
    "plt.plot(df_forecasted['POD'], df_forecasted['RATE'], color='red', label=\"Forecasted Data\")\n",
    "\n",
    "plt.xlabel('Date(Year Month)')\n",
    "plt.ylabel('Cost Rate(USD)')\n",
    "plt.title('Port_BUSAN_Size_40_Type_HC_PartyID_010004286')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
