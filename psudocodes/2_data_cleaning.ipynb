{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```plaintext\n",
    "Procedure createDF:\n",
    "    Input: datasets (Path to the dataset)\n",
    "    \n",
    "    1. df = Read CSV from `datasets`, with specific type conversions\n",
    "    2. Format 'POD' field to datetime\n",
    "    3. Replace missing values in 'ENCODED_TYPE' with -1, and convert to integer\n",
    "    4. Drop rows with missing 'ENCODED_TYPE'\n",
    "    5. Replace missing values in 'RATE' with -1, and convert to float\n",
    "    6. Drop rows with missing 'RATE'\n",
    "    7. Convert 'ENCODED_TYPE' to integer\n",
    "    8. Drop rows with missing values in df and reset index\n",
    "    9. Select and rearrange columns\n",
    "    10. Exclude rows where 'POD' year is 2002\n",
    "    11. Sort rows by 'POD'\n",
    "    \n",
    "    Output: df_filtered\n",
    "\n",
    "Procedure main:\n",
    "    1. Define paths for old_data and new_data\n",
    "    2. df1 = createDF(old_data)\n",
    "    3. Display first few rows of df1\n",
    "    4. df2 = createDF(new_data)\n",
    "    5. Display first few rows of df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```plaintext\n",
    "\n",
    "Procedure getKeyPorts:\n",
    "    INPUT: keybunch\n",
    "    SET keybunch_pouch as empty list\n",
    "\n",
    "    FOR each key in keybunch:\n",
    "        IF the length of the dataframe for this key > 1000:\n",
    "            SET key_row_counts[key] to length of the dataframe\n",
    "    END FOR\n",
    "\n",
    "    SET sorted_keys to keys in key_row_counts sorted in descending order of value\n",
    "\n",
    "    FOR each key in sorted_keys:\n",
    "        SET row_count to key_row_counts[key]\n",
    "        PRINT \"Number of rows in key: row_count\"\n",
    "        APPEND key to keybunch_pouch\n",
    "    END FOR\n",
    "\n",
    "    RETURN keybunch_pouch\n",
    "END Procedure\n",
    "\n",
    "PRINT \"Old Dataset Keybunch:\"\n",
    "SET old_df to getKeyPorts(filtered_dataframe1)\n",
    "PRINT \"\\n\"\n",
    "\n",
    "PRINT \"New Dataset Keybunch:\"\n",
    "SET new_df to getKeyPorts(filtered_dataframe2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```plaintext\n",
    "\n",
    "    Perform Anderson-Darling test on 'RATE':\n",
    "        PRINT Statistic\n",
    "        IF Statistic < Critical Value at 5% significance level:\n",
    "            PRINT \"Data looks normal\"\n",
    "            SET Q1 to 25th percentile of 'RATE'\n",
    "            SET Q3 to 75th percentile of 'RATE'\n",
    "            SET IQR to Q3 - Q1\n",
    "            SET lower_bound to Q1 - 1.5*IQR\n",
    "            SET upper_bound to Q3 + 1.5*IQR\n",
    "            REMOVE from dataframe rows where 'RATE' < lower_bound or 'RATE' > upper_bound\n",
    "        ELSE:\n",
    "            PRINT \"Data does not look normal\"\n",
    "            CALCULATE z-scores for 'RATE'\n",
    "            SET threshold to 3\n",
    "            REMOVE from dataframe rows where absolute z-score > threshold\n",
    "    \n",
    "    RESET index of dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```plaintext\n",
    "\n",
    "SET robust_df to drop duplicates from robust_df based on 'POD' and 'RATE'\n",
    "RESET index of robust_df\n",
    "\n",
    "INITIALIZE new_df as an empty DataFrame\n",
    "SET new_df['POD'] to a range of dates from min 'POD' in robust_df to max 'POD' in robust_df\n",
    "\n",
    "SET df_interpolated as the result of merging new_df and robust_df on 'POD' using a 'left' merge\n",
    "PERFORM polynomial interpolation on df_interpolated['RATE'] with order 1\n",
    "ROUND df_interpolated['RATE'] to 3 decimal places\n",
    "\n",
    "SET df_interpolated['YearMonthWeek'] to 'POD' - dayofweek of 'POD' in df_interpolated\n",
    "\n",
    "SET all_weeks to a range of dates from min 'POD' in df_interpolated to max 'POD' in df_interpolated with a frequency of 1 week\n",
    "SET all_weeks_df as a DataFrame with all_weeks as 'POD'\n",
    "SET all_weeks_df['YearMonthWeek'] to 'POD' - dayofweek of 'POD' in all_weeks_df\n",
    "\n",
    "SET merged_df as the result of merging all_weeks_df and df_interpolated on 'YearMonthWeek' using a 'left' merge\n",
    "GROUP merged_df by 'YearMonthWeek' and SET grouped\n",
    "\n",
    "INITIALIZE agg_df as an empty DataFrame with columns 'YearMonthWeek' and 'Rate'\n",
    "\n",
    "FOR each group in grouped:\n",
    "    SET year_month_week to group_name\n",
    "    SET rate_sum to the sum of 'RATE' in group_df\n",
    "    SET rate_skew to the skew of 'RATE' in group_df\n",
    "\n",
    "    IF absolute rate_skew > 0.5:\n",
    "        SET rate_metric to median of 'RATE' in group_df\n",
    "    ELSE:\n",
    "        SET rate_metric to mean of 'RATE' in group_df\n",
    "\n",
    "    SET new_row to a dictionary with 'YearMonthWeek' as year_month_week and 'Rate' as rate_metric\n",
    "    APPEND new_row to agg_df\n",
    "\n",
    "SORT agg_df by 'YearMonthWeek'\n",
    "RESET index of agg_df\n",
    "ROUND 'Rate' in agg_df to 2 decimal places\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
