{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dropout, LSTM, Dense, Bidirectional\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# LSTM\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, LSTM, Dense, Bidirectional\n",
    "\n",
    "# ARIMA\n",
    "import pmdarima as pm\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Importing Datasets</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset and clean, ready as a dataframe for creating keys\n",
    "def createDF(datasets):\n",
    "    df = pd.read_csv(datasets, converters={'PARTY_ID': str, 'COM_ID': str, 'CNTR_SIZE': str})\n",
    "\n",
    "    # Formating to type and remove NaN values\n",
    "    df['POD'] = pd.to_datetime(df['POD'])\n",
    "    df['ENCODED_TYPE'] = df['ENCODED_TYPE'].fillna(-1).astype(int)\n",
    "    df = df.dropna(subset=['ENCODED_TYPE'])\n",
    "    df['RATE'] = df['RATE'].fillna(-1).astype(float)\n",
    "    df = df.dropna(subset=['RATE'])\n",
    "    df['ENCODED_TYPE'] = df['ENCODED_TYPE'].astype(int)\n",
    "    df_clean= df.dropna().reset_index(drop=True)\n",
    "\n",
    "    # Selecting and rearranging columns\n",
    "    sel_col = ['CSL_ID', 'CNTR_ID','POD_ID','ETD_POL_D','PARTY_ID',\n",
    "            'PARTY_NAME','POD','CNTR_SIZE','CNTR_TYPE','RATE']\n",
    "    df_fc = df_clean[sel_col]\n",
    "\n",
    "    # Removing years we do not want to process in our models\n",
    "    df_filtered = df_fc[df_fc['POD'].dt.year != 2002]\n",
    "\n",
    "    # Sorting the dates\n",
    "    df_filtered = df_filtered.sort_values(by='POD').reset_index(drop=True)\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframes for old and new\n",
    "old_data = '.\\Datasets\\CR_COST_FC.csv'\n",
    "df1 = createDF(old_data)\n",
    "df1.head()\n",
    "\n",
    "new_data = '.\\Datasets\\CR_COST_FC_new.csv'\n",
    "df2 = createDF(new_data)\n",
    "df2.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Creating Dictionary Keys</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe(df):\n",
    "    filtered_dataframes = {}\n",
    "\n",
    "    for (port, size, ctype, party_id), group in df.groupby(['POD_ID', 'CNTR_SIZE', 'CNTR_TYPE', 'PARTY_ID']):\n",
    "        group = group.reset_index(drop=True).sort_values(by='POD')\n",
    "        df_id = f\"Port_{port}_Size_{size}_Type_{ctype}_PartyID_{party_id}\"\n",
    "        filtered_dataframes[df_id] = group\n",
    "\n",
    "    return filtered_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating keys from data\n",
    "print(\"Old Data keys:\")\n",
    "filtered_dataframe1 = filter_dataframe(df1)\n",
    "df_ids1 = list(filtered_dataframe1.keys())\n",
    "print(list(df_ids1))\n",
    "print(len(list(df_ids1)))\n",
    "\n",
    "print(\"\\nNew Data keys:\")\n",
    "filtered_dataframe2 = filter_dataframe(df2)\n",
    "df_ids2 = list(filtered_dataframe2.keys())\n",
    "print(list(df_ids2))\n",
    "print(len(list(df_ids2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Getting Top 5 ports keys</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTop5Ports(keybunch):\n",
    "    keybunch_pouch = []\n",
    "    \n",
    "    # Get a dictionary with key and number of rows for each dataframe in filtered_dataframes\n",
    "    key_row_counts = {key: len(keybunch[key]) for key in keybunch}\n",
    "\n",
    "    # Sort the key_row_counts dictionary by value (number of rows) in descending order\n",
    "    sorted_key_row_counts = sorted(key_row_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    # Get the top 5 keys with the most rows\n",
    "    top_5_keys_tuple = sorted_key_row_counts[:5]\n",
    "\n",
    "    # Create a dictionary with the top 5 keys and their corresponding dataframes (with up to 5 rows per dataframe)\n",
    "    keybunch_subset = {}\n",
    "\n",
    "    for key, row_count in top_5_keys_tuple:\n",
    "        keybunch_subset[key] = keybunch[key][:5]\n",
    "        print(f\"Number of rows in {key}: {row_count}\")\n",
    "        keybunch_pouch.append(key)\n",
    "    \n",
    "    # Return array of keys\n",
    "    return keybunch_pouch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Old Dataset Keybunch:')\n",
    "old_df = getTop5Ports(filtered_dataframe1)\n",
    "print('\\n')\n",
    "\n",
    "print('New Dataset Keybunch:')\n",
    "new_df = getTop5Ports(filtered_dataframe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the highest count in the each keypouch, new and old.\n",
    "sel_country = old_df[1]\n",
    "print(sel_country)\n",
    "\n",
    "sel_df = filtered_dataframe1[sel_country]\n",
    "sel_df.head(5)\n",
    "sel_df.tail(5)\n",
    "sel_df.info()\n",
    "print(\"\\n\")\n",
    "\n",
    "latest_sel_df = filtered_dataframe2[sel_country]\n",
    "latest_sel_df.head(5)\n",
    "latest_sel_df.tail(5)\n",
    "latest_sel_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Select features\n",
    "sel_feat = ['POD','RATE']\n",
    "robust_df = sel_df[sel_feat].copy()  # make a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "# Robust Scaling\n",
    "scaler = RobustScaler()\n",
    "robust_df.loc[:, 'RATE'] = scaler.fit_transform(robust_df[['RATE']])\n",
    "robust_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the DataFrame has any NaN values\n",
    "if robust_df.isna().any().any():\n",
    "    print(\"The DataFrame contains NaN values.\")\n",
    "else:\n",
    "    print(\"The DataFrame does not contain NaN values.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Interpolate missing values in between dates</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated dates and cost rows\n",
    "robust_df = robust_df.drop_duplicates(subset=['POD', 'RATE']).reset_index(drop=True)\n",
    "\n",
    "# Create a new dataframe with a date range from min to max date in your dataframe\n",
    "new_df = pd.DataFrame()\n",
    "new_df['POD'] = pd.date_range(start=robust_df['POD'].min(), end=robust_df['POD'].max())\n",
    "\n",
    "# Merge the original dataframe with the new one. Missing dates in the original dataframe will be filled with NaN\n",
    "df_interpolated = pd.merge(new_df, robust_df, on='POD', how='left')  \n",
    "\n",
    "# Perform spline interpolation\n",
    "df_interpolated['RATE'] = df_interpolated['RATE'].interpolate(method='polynomial', order=1)\n",
    "\n",
    "df_interpolated['RATE'] = df_interpolated['RATE'].round(3)\n",
    "\n",
    "# Now we need to inverse the scaling\n",
    "df_interpolated['RATE'] = scaler.inverse_transform(df_interpolated[['RATE']])\n",
    "\n",
    "df_interpolated.head(5)\n",
    "df_interpolated.tail(5)\n",
    "df_interpolated.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Grouping it to week</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Create YearMonthWeek directly from the 'POD'\n",
    "df_interpolated['YearMonthWeek'] = df_interpolated['POD'] - pd.to_timedelta(df_interpolated['POD'].dt.dayofweek, unit='D')\n",
    "\n",
    "# Create a new dataframe with every week in the range\n",
    "all_weeks = pd.date_range(start=df_interpolated['POD'].min(), end=df_interpolated['POD'].max(), freq='W')\n",
    "all_weeks_df = pd.DataFrame(all_weeks, columns=['POD'])\n",
    "\n",
    "# Create YearMonthWeek in all_weeks_df\n",
    "all_weeks_df['YearMonthWeek'] = all_weeks_df['POD'] - pd.to_timedelta(all_weeks_df['POD'].dt.dayofweek, unit='D')\n",
    "\n",
    "# Merge this with your original dataframe\n",
    "merged_df = pd.merge(all_weeks_df, df_interpolated, on=['YearMonthWeek'], how='left')\n",
    "\n",
    "# Now you can group by YearMonthWeek and compute your rate\n",
    "grouped = merged_df.groupby(['YearMonthWeek'])\n",
    "\n",
    "agg_df = pd.DataFrame(columns=['YearMonthWeek', 'Rate'])\n",
    "\n",
    "for group_name, group_df in grouped:\n",
    "    year_month_week = group_name\n",
    "\n",
    "    # Skip if no data for this week\n",
    "    if group_df['RATE'].isnull().all():\n",
    "        continue\n",
    "\n",
    "    # Calculate sum and skewness of RATE values\n",
    "    rate_sum = group_df['RATE'].sum()\n",
    "    rate_skew = group_df['RATE'].skew()\n",
    "\n",
    "    # Calculate trimmed mean of RATE values\n",
    "    rate_metric = stats.trim_mean(group_df['RATE'].dropna().values, 0.1) # trimming 10% from each end\n",
    "\n",
    "    new_row = {\n",
    "        'YearMonthWeek': year_month_week,\n",
    "        'Rate': rate_metric\n",
    "    }\n",
    "\n",
    "    # Append row to aggregated dataframe\n",
    "    agg_df = agg_df.append(new_row, ignore_index=True)\n",
    "\n",
    "agg_df = agg_df.sort_values(by='YearMonthWeek').reset_index(drop=True)\n",
    "agg_df['Rate'] = agg_df['Rate'].round(2)\n",
    "\n",
    "agg_df.head(15)\n",
    "agg_df.tail(15)\n",
    "agg_df.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Latest datapoints from Latest dataframe for comparing after forecasting (Measure accuracy)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date_in_old = sel_df['POD'].max()\n",
    "\n",
    "# Create a new dataframe that only includes rows from the latest dataframe where the date is greater than the maximum date in the old dataframe\n",
    "new_dates_df = latest_sel_df[latest_sel_df['POD'] > max_date_in_old].reset_index(drop=True)\n",
    "\n",
    "# Print the new dataframe\n",
    "new_dates_df.head(3)\n",
    "new_dates_df.tail(3)\n",
    "new_dates_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(sel_df['POD'], sel_df['RATE'], color='blue', label=\"Actual Data\")\n",
    "plt.plot(agg_df['YearMonthWeek'], agg_df['Rate'], color='red', label=\"Aggregated Data(weeks)\")\n",
    "\n",
    "plt.xlabel('Date(Year Month Week)')\n",
    "plt.ylabel('Cost Rate(USD)')\n",
    "plt.title('Port_BUSAN_Size_40_Type_HC_PartyID_010004286')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Iterative Nested Forecasting</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Time series pipeline for best forecasting model to each dataframe</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Functions\n",
    "\n",
    "# Mean Square Error Function:\n",
    "def calculate_RMSE(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "def plot_train_val_loss(history):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model loss progress during training and validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>LSTM</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update create_dataset to handle multi-feature dataset\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "def create_LSTM_model(trainX, trainY, testX, testY, epochs, lstm_layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    # input layer\n",
    "    model.add(Bidirectional(LSTM(lstm_layers[0], return_sequences=True),\n",
    "                            input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # hidden layers\n",
    "    for i in range(1, len(lstm_layers)):\n",
    "        model.add(Bidirectional(\n",
    "            LSTM(lstm_layers[i], return_sequences=(i != (len(lstm_layers)-1)))))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    history = model.fit(trainX, trainY, epochs=epochs, validation_data=(testX, testY),\n",
    "                        callbacks=[EarlyStopping(\n",
    "                            monitor='val_loss', patience=10)],\n",
    "                        verbose=2, shuffle=False)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "\n",
    "def LSTM_Execute(trainX, testY):\n",
    "    # Reshape into X=t and Y=t+1, timestep  look_back\n",
    "    global look_back\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "    # Reshape input to be [samples, time steps, features]\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], look_back, 1))\n",
    "    testX = np.reshape(testX, (testX.shape[0], look_back, 1))\n",
    "\n",
    "\n",
    "    epochs_list = [100]\n",
    "\n",
    "    lstm_layers_list = [\n",
    "        [64, 64, 32, 32, 16, 16, 8, 8, 4, 4, 2, 2],\n",
    "        [32, 32, 16, 16, 8, 8, 4, 4, 2, 2],\n",
    "        [16, 16, 8, 8, 4, 4, 2, 2],\n",
    "        [8, 8, 4, 4, 2, 2],\n",
    "        [4, 4, 2, 2],\n",
    "        [2, 2]\n",
    "    ]\n",
    "\n",
    "    rmse_results = {}\n",
    "\n",
    "    for epochs in epochs_list:\n",
    "        print(f'Training for {epochs} epochs...')\n",
    "\n",
    "        for lstm_layers in lstm_layers_list:\n",
    "            print(f'Training with LSTM layers: {lstm_layers}')\n",
    "            model, history = create_LSTM_model(\n",
    "                trainX, trainY, testX, testY, epochs, lstm_layers)\n",
    "\n",
    "            # Add the loss for this model to the plot\n",
    "            plt.plot(\n",
    "                history.history['loss'], label=f'Train Loss - {epochs} epochs, layers: {lstm_layers}')\n",
    "            plt.plot(\n",
    "                history.history['val_loss'], label=f'Validation Loss - {epochs} epochs, layers: {lstm_layers}')\n",
    "\n",
    "            # Evalute LSTM Model\n",
    "            trainPredict = model.predict(trainX)\n",
    "            testPredict = model.predict(testX)\n",
    "\n",
    "            # inverse_transform\n",
    "            trainPredict = scaler.inverse_transform(trainPredict)\n",
    "            trainY_orig = scaler.inverse_transform([trainY])\n",
    "            testPredict = scaler.inverse_transform(testPredict)\n",
    "            testY_orig = scaler.inverse_transform([testY])\n",
    "\n",
    "            # Calculate mean squared error\n",
    "            trainScore = calculate_RMSE(trainY_orig[0], trainPredict[:, 0])\n",
    "            print(f'Train Score: {trainScore:.2f} RMSE for {epochs} epochs')\n",
    "            testScore = calculate_RMSE(testY_orig[0], testPredict[:, 0])\n",
    "            print(f'Test Score: {testScore:.2f} RMSE for {epochs} epochs')\n",
    "\n",
    "            rmse_results[f'{epochs} epochs, {lstm_layers} layers'] = {\n",
    "                'Train RMSE': trainScore, 'Test RMSE': testScore}\n",
    "\n",
    "    # Configure and show the plot\n",
    "    plt.title('Model loss progress during training and validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n\\n\\n')  # print some blank lines for separation\n",
    "\n",
    "    # Convert the dictionary to a DataFrame for easy display\n",
    "    rmse_df = pd.DataFrame(rmse_results).T\n",
    "    print(rmse_df)\n",
    "    return model, trainScore, testScore\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Arima</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute Auto ARIMA model\n",
    "def ARIMA_Execute(train, test):\n",
    "    # Fit an auto_arima model\n",
    "    arima_model = pm.auto_arima(train, start_p=1, start_q=1,\n",
    "                                max_p=5, max_q=5, m=12,\n",
    "                                start_P=0, seasonal=False,\n",
    "                                d=0, D=0, trace=True,\n",
    "                                error_action='ignore',\n",
    "                                suppress_warnings=True,\n",
    "                                stepwise=True)  # set to stepwise\n",
    "\n",
    "    # Print the summary of the model\n",
    "    print(arima_model.summary())\n",
    "\n",
    "    # Forecast\n",
    "    train_forecast = arima_model.predict_in_sample()\n",
    "    test_forecast = arima_model.predict(n_periods=len(test))\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    RMSE_ARIMA_train = np.sqrt(mean_squared_error(train, train_forecast))\n",
    "    print(\"Train RMSE: %.3f\" % RMSE_ARIMA_train)\n",
    "    RMSE_ARIMA_test = np.sqrt(mean_squared_error(test, test_forecast))\n",
    "    print(\"Test RMSE: %.3f\" % RMSE_ARIMA_test)\n",
    "\n",
    "    return arima_model, RMSE_ARIMA_train, RMSE_ARIMA_test\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Prophet</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Prophet_model(train):\n",
    "    # Prophet requires the variable names in the time series to be\n",
    "    # ds (Timestamp) and y (Value to forecast)\n",
    "    train = train.rename(columns = {'Date': 'ds', 'Rate': 'y'})\n",
    "  \n",
    "    model = Prophet(daily_seasonality = True) \n",
    "    model.fit(train)\n",
    "    return model\n",
    "\n",
    "def forecast_Prophet_model(model, periods):\n",
    "    # Prepare a future dataframe for prediction\n",
    "    future = model.make_future_dataframe(periods = periods, freq='W')  \n",
    "    forecast = model.predict(future)\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize dataset for LSTM\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Fit and transform the train dataset\n",
    "train_size = int(len(agg_df) * 0.7)\n",
    "train_data = agg_df['Rate'].values[:train_size].reshape(-1, 1)\n",
    "test_data = agg_df['Rate'].values[train_size:].reshape(-1, 1)\n",
    "train = scaler.fit_transform(train_data)\n",
    "\n",
    "# Only transform the test dataset\n",
    "test = scaler.transform(test_data)\n",
    "\n",
    "# Initialize a dictionary for the current key\n",
    "results_dict = {}\n",
    "\n",
    "print(f\"Key: {sel_country}\")\n",
    "\n",
    "# Run LSTM model\n",
    "look_back = 5\n",
    "model, LSTM_train_rmse, LSTM_test_rmse = LSTM_Execute(train, test)\n",
    "results_dict[sel_country] = {'LSTM': {'model': model, 'Train RMSE': LSTM_train_rmse, 'Test RMSE': LSTM_test_rmse}}\n",
    "\n",
    "# Run ARIMA model\n",
    "model, ARIMA_train_rmse, ARIMA_test_rmse = ARIMA_Execute(train_data, test_data)\n",
    "results_dict[sel_country]['ARIMA'] = {'model': model, 'Train RMSE': ARIMA_train_rmse, 'Test RMSE': ARIMA_test_rmse}\n",
    "\n",
    "# Now you can directly fetch your results using sel_country as the key\n",
    "results = results_dict[sel_country]\n",
    "best_model_name, best_model_results = min(results.items(), key=lambda x: x[1]['Test RMSE'])\n",
    "print(f\"Key: {sel_country}, Best Model: {best_model_name}, Train RMSE: {best_model_results['Train RMSE']}, Test RMSE: {best_model_results['Test RMSE']}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Forecasting with best model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add check for 'RATE_actual' values to avoid division by zero\n",
    "# Accuracy\n",
    "def compute_accuracy(row):\n",
    "    if row['RATE_actual'] == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        error = abs(row['RATE_actual'] - row['RATE_forecasted'])\n",
    "        error_proportion = error / row['RATE_actual']\n",
    "        return (1 - error_proportion) * 100\n",
    "\n",
    "# LSTM\n",
    "def forecast_next_weeks(model, look_back, scaler, last_values, n_weeks):\n",
    "    forecast = []\n",
    "    for _ in range(n_weeks):\n",
    "        # Reshape last_values to 2D array with one feature\n",
    "        last_values_2d = np.array(last_values[-look_back:]).reshape(-1, 1)\n",
    "\n",
    "        # Scale the last_values_2d to be between 0 and 1\n",
    "        input_values_scaled = scaler.transform(last_values_2d)\n",
    "\n",
    "        # Reshape input to be [samples, time steps, features]\n",
    "        input_values_scaled = input_values_scaled.reshape((1, look_back, 1))\n",
    "\n",
    "        # Predict the next value\n",
    "        prediction = model.predict(input_values_scaled)\n",
    "\n",
    "        # Rescale the prediction back to the original scale\n",
    "        prediction_rescaled = scaler.inverse_transform(prediction)\n",
    "\n",
    "        # Append the predicted value to the forecast list\n",
    "        forecast.append(prediction_rescaled[0][0])\n",
    "\n",
    "        # Append the predicted value to the last_values list to be used as input for the next prediction\n",
    "        last_values.append(prediction_rescaled[0][0])\n",
    "        # Drop the first value in the last_values list\n",
    "        last_values.pop(0)\n",
    "\n",
    "    return forecast\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks = 12\n",
    "\n",
    "# Check if the best model is LSTM, ARIMA or Prophet and perform the forecasting\n",
    "if best_model_name == 'LSTM':\n",
    "    # The best model for this key is the LSTM\n",
    "    # Fetch the model\n",
    "    best_model = results['LSTM']['model']\n",
    "\n",
    "    # Use the model to make forecasts\n",
    "    last_values = list(agg_df['Rate'].values[-look_back:])\n",
    "    forecasted_values = forecast_next_weeks(\n",
    "        best_model, look_back, scaler, last_values, weeks)\n",
    "\n",
    "elif best_model_name == 'ARIMA':\n",
    "    # The best model for this key is the ARIMA\n",
    "    # Fetch the model\n",
    "    best_model = results['ARIMA']['model']\n",
    "\n",
    "    # Use the model to make forecasts\n",
    "    forecasted_values = best_model.predict(n_periods=weeks)\n",
    "\n",
    "else:\n",
    "    # Unknown model\n",
    "    print(f\"Unknown model: {best_model_name}\")\n",
    "\n",
    "# Ensure that 'YearMonthWeek' is a datetime object\n",
    "agg_df['YearMonthWeek'] = pd.to_datetime(agg_df['YearMonthWeek'])\n",
    "last_date = agg_df['YearMonthWeek'].iloc[-1]\n",
    "\n",
    "forecasted_dates = pd.date_range(\n",
    "    start=last_date, periods=weeks+1, freq='W')[1:]\n",
    "\n",
    "df_forecasted = pd.DataFrame({\n",
    "    'POD': forecasted_dates,\n",
    "    'RATE': forecasted_values\n",
    "})\n",
    "\n",
    "df_forecasted[\"RATE\"] = df_forecasted[\"RATE\"].round(2)\n",
    "df_forecasted.head(5)\n",
    "df_forecasted.tail(5)\n",
    "df_forecasted.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Comparing with actual updated against forecasted</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame(columns=['WeekStart', 'WeekEnd', 'POD_actual', 'RATE_forecasted', 'RATE_actual'])\n",
    "df_forecasted['WeekEnd'] = df_forecasted['POD'] + pd.to_timedelta(7, unit='d')  \n",
    "\n",
    "for _, row in df_forecasted.iterrows():\n",
    "    mask = (new_dates_df['POD'] >= row['POD']) & (new_dates_df['POD'] < row['WeekEnd'])\n",
    "    actual_dates_within_week = new_dates_df[mask]\n",
    "\n",
    "    for _, actual_row in actual_dates_within_week.iterrows():\n",
    "        comparison_df = comparison_df.append({\n",
    "            'WeekStart': row['POD'],\n",
    "            'WeekEnd': row['WeekEnd'],\n",
    "            'POD_actual': actual_row['POD'],\n",
    "            'RATE_forecasted': row['RATE'],\n",
    "            'RATE_actual': actual_row['RATE']\n",
    "        }, ignore_index=True)\n",
    "\n",
    "# Remove duplicates\n",
    "comparison_df = comparison_df.drop_duplicates(subset=['POD_actual', 'RATE_forecasted', 'RATE_actual']).reset_index(drop=True)\n",
    "\n",
    "# Compute accuracy\n",
    "comparison_df['accuracy'] = comparison_df.apply(compute_accuracy, axis=1)\n",
    "comparison_df = comparison_df.dropna(subset=['accuracy'])\n",
    "\n",
    "total_mean_accuracy = comparison_df['accuracy'].mean()\n",
    "comparison_df\n",
    "print(f'The mean accuracy is {total_mean_accuracy:.2f}%\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Visualise all, Conclusion</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(sel_df['POD'], sel_df['RATE'], color='blue', label=\"Actual Data\")\n",
    "plt.plot(new_dates_df['POD'], new_dates_df['RATE'], color='blue', label=\"Actual Data (Updated)\")\n",
    "\n",
    "plt.plot(df_interpolated['POD'], df_interpolated['RATE'], color='green', label=\"Aggregated Data\")\n",
    "plt.plot(df_forecasted['POD'], df_forecasted['RATE'], color='red', label=\"Forecasted Data\")\n",
    "\n",
    "plt.xlabel('Date(Year Month)')\n",
    "plt.ylabel('Cost Rate(USD)')\n",
    "plt.title('Port_BUSAN_Size_40_Type_HC_PartyID_010004286')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
